{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb7f4fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ca8ad31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url_content(url):\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    else:\n",
    "        return f'Error: Received status code {response.status_code}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb9ff92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_raw_url(keyword):\n",
    "    # Specify the search parameters\n",
    "    #keyword = 'promote_types'  # replace with the class name or function you are looking for\n",
    "    repo = 'pytorch/pytorch'\n",
    "    token = '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'\n",
    "    # Create the search query\n",
    "    query = f'{keyword}+in:file+repo:{repo}'\n",
    "\n",
    "    # Create the request URL\n",
    "    url = f'https://api.github.com/search/code?q={query}'\n",
    "    # Create the headers for the request\n",
    "    headers = {\n",
    "    'Authorization': f'token {token}',\n",
    "    'Accept': 'application/vnd.github.v3+json',\n",
    "    }\n",
    "\n",
    "    # Send a GET request to the GitHub API\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    # Convert the response to JSON\n",
    "    response_json = response.json()\n",
    "    print(response_json)\n",
    "    # Get the URL of the first file that matches the search query\n",
    "    first_item_url = response_json['items'][0]['html_url']\n",
    "    \n",
    "    return first_item_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb53398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_code_from_github(url):\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        return f'Error: Received status code {response.status_code}'\n",
    "        \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Github stores code in <table> element with class 'highlight tab-size js-file-line-container'\n",
    "    code_blocks = soup.find_all('table', {'class': 'highlight tab-size js-file-line-container'})\n",
    "\n",
    "    code = []\n",
    "    for block in code_blocks:\n",
    "        # Code lines are stored in <td> elements with class 'blob-code blob-code-inner js-file-line'\n",
    "        lines = block.find_all('td', {'class': 'blob-code blob-code-inner js-file-line'})\n",
    "        for line in lines:\n",
    "            # Append each line of code to the code list\n",
    "            code.append(line.text)\n",
    "            \n",
    "    # Join all lines of code into a single string\n",
    "    code = '\\n'.join(code)\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19d5a2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_github_file_content(url):\n",
    "    # Replace github.com with raw.githubusercontent.com in the URL\n",
    "    # This gives the raw content of the file\n",
    "    raw_url = url.replace('github.com', 'raw.githubusercontent.com').replace('/blob', '')\n",
    "    \n",
    "    response = requests.get(raw_url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        return f'Error: Received status code {response.status_code}'\n",
    "    \n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03c3e721",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = find_raw_code('promote_types')\n",
    "#content=get_url_content(url)\n",
    "#content=extract_code_from_github(url)\n",
    "content=get_github_file_content(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0d7cf1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#define TORCH_ASSERT_ONLY_METHOD_OPERATORS\n",
      "#include <ATen/core/Tensor.h>\n",
      "#include <ATen/native/TypeProperties.h>\n",
      "\n",
      "#ifndef AT_PER_OPERATOR_HEADERS\n",
      "#include <ATen/Functions.h>\n",
      "#include <ATen/NativeFunctions.h>\n",
      "#else\n",
      "#include <ATen/ops/_has_compatible_shallow_copy_type_native.h>\n",
      "#include <ATen/ops/_is_zerotensor_native.h>\n",
      "#include <ATen/ops/can_cast_native.h>\n",
      "#include <ATen/ops/is_complex_native.h>\n",
      "#include <ATen/ops/is_conj_native.h>\n",
      "#include <ATen/ops/is_distributed_native.h>\n",
      "#include <ATen/ops/is_floating_point_native.h>\n",
      "#include <ATen/ops/is_inference_native.h>\n",
      "#include <ATen/ops/is_neg_native.h>\n",
      "#include <ATen/ops/is_signed_native.h>\n",
      "#include <ATen/ops/promote_types_native.h>\n",
      "#include <ATen/ops/result_type.h>\n",
      "#include <ATen/ops/result_type_native.h>\n",
      "#include <ATen/ops/type_as_native.h>\n",
      "#endif\n",
      "\n",
      "namespace at { namespace native {\n",
      "\n",
      "static bool is_cuda(const Tensor& self) {\n",
      "  return self.is_cuda();\n",
      "}\n",
      "\n",
      "bool is_distributed(const Tensor& self) {\n",
      "  return false;\n",
      "}\n",
      "\n",
      "bool is_complex(const Tensor& self) {\n",
      "  return self.is_complex();\n",
      "}\n",
      "\n",
      "bool is_floating_point(const Tensor& self) {\n",
      "  return self.is_floating_point();\n",
      "}\n",
      "\n",
      "bool is_inference(const Tensor& self) {\n",
      "  return self.is_inference();\n",
      "}\n",
      "\n",
      "bool is_signed(const Tensor &self) {\n",
      "  return self.is_signed();\n",
      "}\n",
      "\n",
      "bool _is_zerotensor(const Tensor& self) {\n",
      "  return self._is_zerotensor();\n",
      "}\n",
      "\n",
      "bool is_conj(const Tensor& self) {\n",
      "  return self.is_conj();\n",
      "}\n",
      "\n",
      "bool is_neg(const Tensor& self) {\n",
      "  return self.is_neg();\n",
      "}\n",
      "\n",
      "static bool is_sparse(const Tensor& self) {\n",
      "  return self.is_sparse();\n",
      "}\n",
      "\n",
      "static bool is_sparse_csr(const Tensor& self) {\n",
      "  return self.is_sparse_csr();\n",
      "}\n",
      "\n",
      "static bool is_quantized(const Tensor& self) {\n",
      "  return self.is_quantized();\n",
      "}\n",
      "\n",
      "// True if `self` and `from` have compatible tensor type so that `from`'s\n",
      "// TensorImpl can be copied to `self`.\n",
      "bool _has_compatible_shallow_copy_type(const Tensor& self, const Tensor& from) {\n",
      "  return self.unsafeGetTensorImpl()->has_compatible_shallow_copy_type(\n",
      "      from.key_set());\n",
      "}\n",
      "\n",
      "Tensor type_as(const Tensor& self, const Tensor& other) {\n",
      "  return self.to(other.options());\n",
      "}\n",
      "\n",
      "static inline ScalarType promote_skip_undefined(ScalarType a, ScalarType b) {\n",
      "  if (a == ScalarType::Undefined) {\n",
      "    return b;\n",
      "  }\n",
      "  if (b == ScalarType::Undefined) {\n",
      "    return a;\n",
      "  }\n",
      "  return promoteTypes(a, b);\n",
      "}\n",
      "\n",
      "\n",
      "static inline ScalarType combine_categories(ScalarType higher, ScalarType lower) {\n",
      "  // NOLINTNEXTLINE(bugprone-branch-clone)\n",
      "  if(isComplexType(higher)) {\n",
      "    return higher;\n",
      "  } else if (isComplexType(lower)) {\n",
      "    // preserve value type of higher if it is floating type.\n",
      "    if (isFloatingType(higher)) {\n",
      "      return toComplexType(higher);\n",
      "    }\n",
      "    // in case of integral input\n",
      "    // lower complex takes precedence.\n",
      "    return lower;\n",
      "  } else if (isFloatingType(higher)) {\n",
      "    return higher;\n",
      "  }\n",
      "  if (higher == ScalarType::Bool || isFloatingType(lower)) {\n",
      "    return promote_skip_undefined(higher, lower);\n",
      "  }\n",
      "  if (higher != ScalarType::Undefined) {\n",
      "    return higher;\n",
      "  }\n",
      "  return lower;\n",
      "}\n",
      "\n",
      "ResultTypeState update_result_type_state(const Tensor& tensor, const ResultTypeState& in_state) {\n",
      "  if (!tensor.defined()) {\n",
      "    return in_state;\n",
      "  }\n",
      "  ResultTypeState new_state = in_state;\n",
      "  ScalarType current = tensor.scalar_type();\n",
      "  if (tensor.unsafeGetTensorImpl()->is_wrapped_number()) {\n",
      "    if(isComplexType(current)) {\n",
      "      current = typeMetaToScalarType(at::get_default_complex_dtype());\n",
      "    }\n",
      "    else if(isFloatingType(current)) {\n",
      "      current = typeMetaToScalarType(at::get_default_dtype());\n",
      "    }\n",
      "  }\n",
      "  if ( tensor.dim() > 0 ) {\n",
      "    new_state.dimResult = promote_skip_undefined(in_state.dimResult, current);\n",
      "  } else if (tensor.unsafeGetTensorImpl()->is_wrapped_number()) {\n",
      "    new_state.wrappedResult = promote_skip_undefined(in_state.wrappedResult, current);\n",
      "  } else {\n",
      "    new_state.zeroResult = promote_skip_undefined(in_state.zeroResult, current);\n",
      "  }\n",
      "  return new_state;\n",
      "}\n",
      "\n",
      "ResultTypeState update_result_type_state(const Scalar& scalar, const ResultTypeState& in_state) {\n",
      "  ResultTypeState new_state = in_state;\n",
      "  ScalarType current = scalar.type();\n",
      "  if (isComplexType(current)) {\n",
      "    current = typeMetaToScalarType(at::get_default_complex_dtype());\n",
      "  } else if (isFloatingType(current)) {\n",
      "    current = typeMetaToScalarType(at::get_default_dtype());\n",
      "  }\n",
      "  new_state.wrappedResult = promote_skip_undefined(in_state.wrappedResult, current);\n",
      "  return new_state;\n",
      "}\n",
      "\n",
      "ScalarType result_type(const ResultTypeState& in_state) {\n",
      "  return combine_categories(in_state.dimResult, combine_categories(in_state.zeroResult, in_state.wrappedResult));\n",
      "}\n",
      "\n",
      "ScalarType result_type(ITensorListRef tensors) {\n",
      "  ResultTypeState state = {};\n",
      "  for (const Tensor& tensor : tensors) {\n",
      "    state = update_result_type_state(tensor, state);\n",
      "  }\n",
      "  return result_type(state);\n",
      "}\n",
      "\n",
      "ScalarType result_type(const Tensor &tensor, const Tensor &other) {\n",
      "  ResultTypeState state = {};\n",
      "  state = update_result_type_state(tensor, state);\n",
      "  state = update_result_type_state(other, state);\n",
      "  return result_type(state);\n",
      "}\n",
      "\n",
      "ScalarType result_type(const Tensor &tensor, const Scalar& other) {\n",
      "  ResultTypeState state = {};\n",
      "  state = update_result_type_state(tensor, state);\n",
      "  state = update_result_type_state(other, state);\n",
      "  return result_type(state);\n",
      "}\n",
      "\n",
      "ScalarType result_type(const Scalar& scalar, const Tensor &tensor) {\n",
      "  return at::result_type(tensor, scalar);\n",
      "}\n",
      "\n",
      "ScalarType result_type(const Scalar& scalar1, const Scalar& scalar2) {\n",
      "  ResultTypeState state = {};\n",
      "  state = update_result_type_state(scalar1, state);\n",
      "  state = update_result_type_state(scalar2, state);\n",
      "  return result_type(state);\n",
      "}\n",
      "\n",
      "bool can_cast(const at::ScalarType from, const at::ScalarType to) {\n",
      "  return at::canCast(from, to);\n",
      "}\n",
      "\n",
      "ScalarType promote_types(ScalarType type1, ScalarType type2) {\n",
      "  ScalarType ret = promoteTypes(type1, type2);\n",
      "  TORCH_CHECK(ret != ScalarType::Undefined, \"Promotion from \", type1, \" and \", type2, \" is unsupported.\");\n",
      "  return ret;\n",
      "}\n",
      "\n",
      "}} // namespace at::native\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9af904ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_api_class(api_full_name):\n",
    "    \"\"\"\n",
    "    Extracts the class or function name from a full API name.\n",
    "    Example: torch.nn.MaxUnpool1d -> MaxUnpool1d\n",
    "    \"\"\"\n",
    "    return api_full_name.split('.')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d207cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d24c21a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('torch-v1.8.0.csv')\n",
    "\n",
    "# Extract unique API names\n",
    "unique_api_names = df['API Name'].unique()\n",
    "\n",
    "# Convert the unique API names to a DataFrame\n",
    "unique_api_names_df = pd.DataFrame(unique_api_names, columns=['API Name'])\n",
    "\n",
    "# Save to a new CSV file\n",
    "#unique_api_names_df.to_csv('unique_api_names.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "611c39d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on:var\n",
      "working on:MaxUnpool1d\n",
      "working on:addcdiv\n",
      "working on:std\n",
      "working on:logcumsumexp\n",
      "working on:isclose\n",
      "working on:cross\n",
      "working on:pow\n",
      "working on:empty\n",
      "working on:imag\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworking on:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mapi_name)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Use the Search_source_code function to get the source code\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m source_code_url \u001b[38;5;241m=\u001b[39m \u001b[43mfind_raw_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m source_code\u001b[38;5;241m=\u001b[39mget_github_file_content(source_code_url)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Add the source code to the DataFrame\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[17], line 24\u001b[0m, in \u001b[0;36mfind_raw_url\u001b[0;34m(keyword)\u001b[0m\n\u001b[1;32m     21\u001b[0m response_json \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Get the URL of the first file that matches the search query\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m first_item_url \u001b[38;5;241m=\u001b[39m \u001b[43mresponse_json\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mitems\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml_url\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m first_item_url\n",
      "\u001b[0;31mKeyError\u001b[0m: 'items'"
     ]
    }
   ],
   "source": [
    "# Iterate over each unique API name\n",
    "for index, row in unique_api_names_df.iterrows():\n",
    "    # Extract the class or function name from the API name\n",
    "    api_name = extract_api_class(row['API Name'])\n",
    "    print(\"working on:\"+api_name)\n",
    "    # Use the Search_source_code function to get the source code\n",
    "    source_code_url = find_raw_url(api_name)\n",
    "    source_code=get_github_file_content(source_code_url)\n",
    "\n",
    "    # Add the source code to the DataFrame\n",
    "    unique_api_names_df.loc[index, 'Source Code'] = source_code\n",
    "\n",
    "# Save to a new CSV file\n",
    "unique_api_names_df.to_csv('unique_api_names_with_source_code.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85032141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'API rate limit exceeded for user ID 46710581.', 'documentation_url': 'https://docs.github.com/rest/overview/resources-in-the-rest-api#rate-limiting'}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m source_code_url \u001b[38;5;241m=\u001b[39m \u001b[43mfind_raw_url\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 24\u001b[0m, in \u001b[0;36mfind_raw_url\u001b[0;34m(keyword)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(response_json)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Get the URL of the first file that matches the search query\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m first_item_url \u001b[38;5;241m=\u001b[39m \u001b[43mresponse_json\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mitems\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml_url\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m first_item_url\n",
      "\u001b[0;31mKeyError\u001b[0m: 'items'"
     ]
    }
   ],
   "source": [
    "source_code_url = find_raw_url(\"imag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0916804",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
