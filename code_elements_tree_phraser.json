[
    {
        "file_path": "../pytorch/setup.py",
        "functions": [
            "build_deps",
            "check_pydep",
            "configure_extension_build",
            "print_box"
        ],
        "classes": [
            "build_ext",
            "concat_license_files",
            "install",
            "clean"
        ]
    },
    {
        "file_path": "../pytorch/.github/scripts/generate_binary_build_matrix.py",
        "functions": [
            "is_pull_request",
            "generate_matrix",
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/.github/scripts/generate_pytorch_version.py",
        "functions": [
            "get_pytorch_root",
            "get_tag",
            "get_base_version",
            "main"
        ],
        "classes": [
            "NoGitTagException",
            "PytorchVersion"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/contrib/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/contrib/aten/aten_test.py",
        "functions": [],
        "classes": [
            "TestATen"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/contrib/aten/gen_op.py",
        "functions": [
            "write",
            "read",
            "value_has_tensors",
            "value_is_tensor_type",
            "expand",
            "supports",
            "get_output",
            "attribute_names",
            "required_attribute_names",
            "self_as_first_argument",
            "get_num_inputs",
            "find_factory_methods",
            "emit_assignments"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/contrib/aten/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/contrib/aten/docs/sample.py",
        "functions": [],
        "classes": [
            "MyFunction",
            "MyModule"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/contrib/aten/docs/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/contrib/fakelowp/test/test_batchmatmul_nnpi_fp16.py",
        "functions": [],
        "classes": [
            "TestBatchMatMul"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/contrib/fakelowp/test/test_batchnorm_nnpi_fp16.py",
        "functions": [
            "reference_spatialbn_test16"
        ],
        "classes": [
            "BatchnormTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/contrib/fakelowp/test/test_chunking.py",
        "functions": [],
        "classes": [
            "Fusions"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/contrib/fakelowp/test/test_deq_swish_quant_nnpi.py",
        "functions": [],
        "classes": [
            "DeqSwishQuantTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/contrib/fakelowp/test/test_fc_nnpi_fp16.py",
        "functions": [],
        "classes": [
            "FCTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/contrib/fakelowp/test/test_fusions.py",
        "functions": [],
        "classes": [
            "Fusions"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/contrib/fakelowp/test/test_int8_ops_nnpi.py",
        "functions": [],
        "classes": [
            "Int8OpsTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/contrib/fakelowp/test/test_int8_quant.py",
        "functions": [],
        "classes": [
            "QuantTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/contrib/fakelowp/test/test_layernorm_nnpi_fp16.py",
        "functions": [],
        "classes": [
            "LayerNorm"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/contrib/fakelowp/test/test_op_nnpi_fp16.py",
        "functions": [],
        "classes": [
            "ArithmeticOpsTest",
            "UnaryOpTest",
            "ReluTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/contrib/fakelowp/test/test_sls_4bit_nnpi_fp16.py",
        "functions": [],
        "classes": [
            "SparseLengthsSum4BitFakeNNPIFp16Test"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/contrib/fakelowp/test/test_sls_8bit_nnpi_fp16.py",
        "functions": [],
        "classes": [
            "SparseLengthsSum8BitFakeNNPIFp16Test"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/contrib/fakelowp/test/test_sls_8bit_nnpi_fp32.py",
        "functions": [],
        "classes": [
            "SparseLengthsSum8BitFakeNNPIFp32Test"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/contrib/gloo/gloo_test.py",
        "functions": [],
        "classes": [
            "TemporaryDirectory",
            "TestCase"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/contrib/gloo/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/contrib/nccl/nccl_ops_test.py",
        "functions": [
            "gpu_device",
            "benchmark"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/contrib/nccl/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/contrib/nnpack/nnpack_ops_test.py",
        "functions": [
            "benchmark",
            "has_avx2"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/contrib/nnpack/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/contrib/playground/AnyExp.py",
        "functions": [
            "initOpts",
            "initDefaultModuleMap",
            "registerModuleMap",
            "aquireDatasets",
            "createTrainerClass",
            "overrideAdditionalMethods",
            "initialize_params_from_file"
        ],
        "classes": [
            "AnyExpTrainer"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/contrib/playground/AnyExpOnTerm.py",
        "functions": [
            "runShardedTrainLoop",
            "trainFun"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/contrib/playground/checkpoint.py",
        "functions": [
            "initialize_params_from_file",
            "initialize_master_xpu_model_params",
            "broadcast_parameters",
            "save_model_params",
            "save_model_params_blob",
            "unscope_name",
            "scoped_name"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/contrib/playground/compute_loss.py",
        "functions": [],
        "classes": [
            "ComputeLoss"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/contrib/playground/compute_topk_accuracy.py",
        "functions": [],
        "classes": [
            "ComputeTopKAccuracy"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/contrib/playground/meter.py",
        "functions": [],
        "classes": [
            "Meter"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/contrib/playground/ModuleRegister.py",
        "functions": [
            "registerModuleMap",
            "constructTrainerClass",
            "overrideAdditionalMethods",
            "getModule",
            "getClassFromModule"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/contrib/playground/module_map.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/contrib/playground/output_generator.py",
        "functions": [
            "fun_conclude_operator",
            "assembleAllOutputs"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/contrib/playground/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/contrib/playground/resnetdemo/caffe2_resnet50_default_forward.py",
        "functions": [
            "gen_forward_pass_builder_fun"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/contrib/playground/resnetdemo/caffe2_resnet50_default_param_update.py",
        "functions": [
            "gen_param_update_builder_fun"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/contrib/playground/resnetdemo/explicit_resnet_forward.py",
        "functions": [
            "gen_forward_pass_builder_fun",
            "resnet_imagenet_create_model"
        ],
        "classes": [
            "ResNetModelHelper"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/contrib/playground/resnetdemo/explicit_resnet_param_update.py",
        "functions": [
            "gen_param_update_builder_fun"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/contrib/playground/resnetdemo/gfs_IN1k.py",
        "functions": [
            "gen_input_builder_fun",
            "get_input_dataset",
            "get_model_input_fun"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/contrib/playground/resnetdemo/IN1k_resnet.py",
        "functions": [
            "init_model",
            "fun_per_epoch_b4RunNet",
            "fun_per_iter_b4RunNet",
            "run_training_net"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/contrib/playground/resnetdemo/IN1k_resnet_no_test_model.py",
        "functions": [
            "init_model",
            "fun_per_epoch_b4RunNet",
            "fun_per_iter_b4RunNet",
            "run_training_net"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/contrib/playground/resnetdemo/override_no_test_model_no_checkpoint.py",
        "functions": [
            "checkpoint",
            "prep_data_parallel_models",
            "run_testing_net"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/contrib/playground/resnetdemo/rendezvous_filestore.py",
        "functions": [
            "gen_rendezvous_ctx"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/contrib/playground/resnetdemo/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/contrib/prof/cuda_profile_ops_test.py",
        "functions": [],
        "classes": [
            "CudaProfileOpsTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/contrib/prof/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/contrib/script/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/contrib/script/examples/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/contrib/tensorboard/tensorboard.py",
        "functions": [
            "_show_graph",
            "visualize_cnn",
            "visualize_net",
            "visualize_ops",
            "write_events",
            "graph_def_to_event"
        ],
        "classes": [
            "Config"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/contrib/tensorboard/tensorboard_exporter.py",
        "functions": [
            "_make_unique_name",
            "_convert_to_ssa",
            "_get_blob_names",
            "_remap_keys",
            "_rename_all",
            "_add_gradient_scope",
            "_replace_colons",
            "_fill_missing_operator_names",
            "_tf_device",
            "_add_tf_shape",
            "_set_tf_attr",
            "_operator_to_node",
            "_blob_to_node",
            "_operators_to_graph_def",
            "_propagate_device_option",
            "_try_get_shapes",
            "nets_to_graph_def",
            "cnn_to_graph_def",
            "ops_to_graph_def"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/contrib/tensorboard/tensorboard_exporter_test.py",
        "functions": [],
        "classes": [
            "TensorboardExporterTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/contrib/tensorboard/tensorboard_test.py",
        "functions": [
            "load_events"
        ],
        "classes": [
            "TensorboardTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/contrib/tensorboard/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/contrib/warpctc/ctc_op.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/contrib/warpctc/ctc_ops_test.py",
        "functions": [
            "softmax"
        ],
        "classes": [
            "CTCOpsTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/contrib/warpctc/ctc_op_gpu.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/contrib/warpctc/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/core/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/core/nomnigraph/op_gen.py",
        "functions": [
            "parse_lines",
            "gen_class",
            "gen_classes",
            "gen_enum",
            "gen_names"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/core/nomnigraph/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/distributed/file_store_handler_op_test.py",
        "functions": [],
        "classes": [
            "TestFileStoreHandlerOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/distributed/redis_store_handler_op_test.py",
        "functions": [],
        "classes": [
            "TestRedisStoreHandlerOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/distributed/store_ops_test_util.py",
        "functions": [],
        "classes": [
            "StoreOpsTests"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/distributed/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/experiments/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/experiments/python/convnet_benchmarks.py",
        "functions": [
            "MLP",
            "AlexNet",
            "OverFeat",
            "VGGA",
            "net_DAG_Builder",
            "_InceptionModule",
            "Inception",
            "AddInput",
            "AddParameterUpdate",
            "Benchmark",
            "GetArgumentParser"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/experiments/python/device_reduce_sum_bench.py",
        "functions": [
            "parse_args",
            "main"
        ],
        "classes": [
            "BenchmarkMeta",
            "SumElements",
            "SumSqrElements",
            "SoftMaxWithLoss"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/experiments/python/funhash_op_test.py",
        "functions": [],
        "classes": [
            "TestFunHash"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/experiments/python/net_construct_bench.py",
        "functions": [
            "AddMomentumParameterUpdate",
            "Create",
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/experiments/python/SparseTransformer.py",
        "functions": [
            "maskNallocate",
            "transFCRelu",
            "Prune2Sparse",
            "net2list",
            "netbuilder"
        ],
        "classes": [
            "NetDefNode"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/experiments/python/sparse_funhash_op_test.py",
        "functions": [],
        "classes": [
            "TestFunHash"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/experiments/python/sparse_reshape_op_test.py",
        "functions": [
            "test_reshape"
        ],
        "classes": [
            "TestSparseMatrixReshapeOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/experiments/python/tt_contraction_op_test.py",
        "functions": [],
        "classes": [
            "TestTTContraction"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/experiments/python/tt_pad_op_test.py",
        "functions": [],
        "classes": [
            "TestTTPad"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/experiments/python/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/mobile/contrib/libopencl-stub/src/libopencl.c",
        "functions": [
            "int",
            "open_libopencl_so()",
            "get_libopencl_path(char** cl_path)",
            "stubOpenclReset()",
            "clGetPlatformIDs(cl_uint          num_entries,\n                 cl_platform_id * platforms,\n                 cl_uint *        num_platforms)",
            "clGetPlatformInfo(cl_platform_id   platform,\n                  cl_platform_info param_name,\n                  size_t           param_value_size,\n                  void *           param_value,\n                  size_t *         param_value_size_ret)",
            "clGetDeviceIDs(cl_platform_id   platform,\n               cl_device_type   device_type,\n               cl_uint          num_entries,\n               cl_device_id *   devices,\n               cl_uint *        num_devices)",
            "clGetDeviceInfo(cl_device_id    device,\n                cl_device_info  param_name,\n                size_t          param_value_size,\n                void *          param_value,\n                size_t *        param_value_size_ret)",
            "clCreateSubDevices(cl_device_id                         in_device,\n                   const cl_device_partition_property * properties,\n                   cl_uint                              num_devices,\n                   cl_device_id *                       out_devices,\n                   cl_uint *                            num_devices_ret)",
            "clRetainDevice(cl_device_id device)",
            "clReleaseDevice(cl_device_id device)",
            "clCreateContext(const cl_context_properties * properties,\n                cl_uint                 num_devices,\n                const cl_device_id *    devices,\n                void (*pfn_notify)(const char *, const void *, size_t, void *),\n                void *                  user_data,\n                cl_int *                errcode_ret)",
            "clCreateContextFromType(const cl_context_properties * properties,\n                        cl_device_type          device_type,\n                        void (*pfn_notify )(const char *, const void *, size_t, void *),\n                        void *                  user_data,\n                        cl_int *                errcode_ret)",
            "clRetainContext(cl_context context)",
            "clReleaseContext(cl_context context)",
            "clGetContextInfo(cl_context         context,\n                 cl_context_info    param_name,\n                 size_t             param_value_size,\n                 void *             param_value,\n                 size_t *           param_value_size_ret)",
            "clCreateCommandQueue(cl_context                     context,\n                     cl_device_id                   device,\n                     cl_command_queue_properties    properties,\n                     cl_int *                       errcode_ret)",
            "clRetainCommandQueue(cl_command_queue command_queue)",
            "clReleaseCommandQueue(cl_command_queue command_queue)",
            "clGetCommandQueueInfo(cl_command_queue      command_queue,\n                      cl_command_queue_info param_name,\n                      size_t                param_value_size,\n                      void *                param_value,\n                      size_t *              param_value_size_ret)",
            "clCreateBuffer(cl_context   context,\n               cl_mem_flags flags,\n               size_t       size,\n               void *       host_ptr,\n               cl_int *     errcode_ret)",
            "clCreateSubBuffer(cl_mem                   buffer,\n                  cl_mem_flags             flags,\n                  cl_buffer_create_type    buffer_create_type,\n                  const void *             buffer_create_info,\n                  cl_int *                 errcode_ret)",
            "clCreateImage(cl_context              context,\n              cl_mem_flags            flags,\n              const cl_image_format * image_format,\n              const cl_image_desc *   image_desc,\n              void *                  host_ptr,\n              cl_int *                errcode_ret)",
            "clRetainMemObject(cl_mem memobj)",
            "clReleaseMemObject(cl_mem memobj)",
            "clGetSupportedImageFormats(cl_context           context,\n                           cl_mem_flags         flags,\n                           cl_mem_object_type   image_type,\n                           cl_uint              num_entries,\n                           cl_image_format *    image_formats,\n                           cl_uint *            num_image_formats)",
            "clGetMemObjectInfo(cl_mem           memobj,\n                   cl_mem_info      param_name,\n                   size_t           param_value_size,\n                   void *           param_value,\n                   size_t *         param_value_size_ret)",
            "clGetImageInfo(cl_mem           image,\n               cl_image_info    param_name,\n               size_t           param_value_size,\n               void *           param_value,\n               size_t *         param_value_size_ret)",
            "clSetMemObjectDestructorCallback(  cl_mem memobj,\n                                   void (*pfn_notify)( cl_mem memobj, void* user_data),\n                                   void * user_data )",
            "clCreateSampler(cl_context          context,\n                cl_bool             normalized_coords,\n                cl_addressing_mode  addressing_mode,\n                cl_filter_mode      filter_mode,\n                cl_int *            errcode_ret)",
            "clRetainSampler(cl_sampler sampler)",
            "clReleaseSampler(cl_sampler sampler)",
            "clGetSamplerInfo(cl_sampler         sampler,\n                 cl_sampler_info    param_name,\n                 size_t             param_value_size,\n                 void *             param_value,\n                 size_t *           param_value_size_ret)",
            "clCreateProgramWithSource(cl_context        context,\n                          cl_uint           count,\n                          const char **     strings,\n                          const size_t *    lengths,\n                          cl_int *          errcode_ret)",
            "clCreateProgramWithBinary(cl_context                     context,\n                          cl_uint                        num_devices,\n                          const cl_device_id *           device_list,\n                          const size_t *                 lengths,\n                          const unsigned char **         binaries,\n                          cl_int *                       binary_status,\n                          cl_int *                       errcode_ret)",
            "clCreateProgramWithBuiltInKernels(cl_context            context,\n                                  cl_uint               num_devices,\n                                  const cl_device_id *  device_list,\n                                  const char *          kernel_names,\n                                  cl_int *              errcode_ret)",
            "clRetainProgram(cl_program program)",
            "clReleaseProgram(cl_program program)",
            "clBuildProgram(cl_program           program,\n               cl_uint              num_devices,\n               const cl_device_id * device_list,\n               const char *         options,\n               void (*pfn_notify)(cl_program program, void * user_data),\n               void *               user_data)",
            "clCompileProgram(cl_program           program,\n                 cl_uint              num_devices,\n                 const cl_device_id * device_list,\n                 const char *         options,\n                 cl_uint              num_input_headers,\n                 const cl_program *   input_headers,\n                 const char **        header_include_names,\n                 void (*pfn_notify)(cl_program program, void * user_data),\n                 void *               user_data)",
            "clLinkProgram(cl_context           context,\n              cl_uint              num_devices,\n              const cl_device_id * device_list,\n              const char *         options,\n              cl_uint              num_input_programs,\n              const cl_program *   input_programs,\n              void (*pfn_notify)(cl_program program, void * user_data),\n              void *               user_data,\n              cl_int *             errcode_ret)",
            "clUnloadPlatformCompiler(cl_platform_id platform)",
            "clGetProgramInfo(cl_program         program,\n                 cl_program_info    param_name,\n                 size_t             param_value_size,\n                 void *             param_value,\n                 size_t *           param_value_size_ret)",
            "clGetProgramBuildInfo(cl_program            program,\n                      cl_device_id          device,\n                      cl_program_build_info param_name,\n                      size_t                param_value_size,\n                      void *                param_value,\n                      size_t *              param_value_size_ret)",
            "clCreateKernel(cl_program      program,\n               const char *    kernel_name,\n               cl_int *        errcode_ret)",
            "clCreateKernelsInProgram(cl_program     program,\n                         cl_uint        num_kernels,\n                         cl_kernel *    kernels,\n                         cl_uint *      num_kernels_ret)",
            "clRetainKernel(cl_kernel    kernel)",
            "clReleaseKernel(cl_kernel   kernel)",
            "clSetKernelArg(cl_kernel    kernel,\n               cl_uint      arg_index,\n               size_t       arg_size,\n               const void * arg_value)",
            "clGetKernelInfo(cl_kernel       kernel,\n                cl_kernel_info  param_name,\n                size_t          param_value_size,\n                void *          param_value,\n                size_t *        param_value_size_ret)",
            "clGetKernelArgInfo(cl_kernel       kernel,\n                   cl_uint         arg_indx,\n                   cl_kernel_arg_info  param_name,\n                   size_t          param_value_size,\n                   void *          param_value,\n                   size_t *        param_value_size_ret)",
            "clGetKernelWorkGroupInfo(cl_kernel                  kernel,\n                         cl_device_id               device,\n                         cl_kernel_work_group_info  param_name,\n                         size_t                     param_value_size,\n                         void *                     param_value,\n                         size_t *                   param_value_size_ret)",
            "clWaitForEvents(cl_uint             num_events,\n                const cl_event *    event_list)",
            "clGetEventInfo(cl_event         event,\n               cl_event_info    param_name,\n               size_t           param_value_size,\n               void *           param_value,\n               size_t *         param_value_size_ret)",
            "clCreateUserEvent(cl_context    context,\n                  cl_int *      errcode_ret)",
            "clRetainEvent(cl_event event)",
            "clReleaseEvent(cl_event event)",
            "clSetUserEventStatus(cl_event   event,\n                     cl_int     execution_status)",
            "clSetEventCallback( cl_event    event,\n                    cl_int      command_exec_callback_type,\n                    void (*pfn_notify)(cl_event, cl_int, void *),\n                    void *      user_data)",
            "clGetEventProfilingInfo(cl_event            event,\n                        cl_profiling_info   param_name,\n                        size_t              param_value_size,\n                        void *              param_value,\n                        size_t *            param_value_size_ret)",
            "clFlush(cl_command_queue command_queue)",
            "clFinish(cl_command_queue command_queue)",
            "clEnqueueReadBuffer(cl_command_queue    command_queue,\n                    cl_mem              buffer,\n                    cl_bool             blocking_read,\n                    size_t              offset,\n                    size_t              size,\n                    void *              ptr,\n                    cl_uint             num_events_in_wait_list,\n                    const cl_event *    event_wait_list,\n                    cl_event *          event)",
            "clEnqueueReadBufferRect(cl_command_queue    command_queue,\n                        cl_mem              buffer,\n                        cl_bool             blocking_read,\n                        const size_t *      buffer_offset,\n                        const size_t *      host_offset,\n                        const size_t *      region,\n                        size_t              buffer_row_pitch,\n                        size_t              buffer_slice_pitch,\n                        size_t              host_row_pitch,\n                        size_t              host_slice_pitch,\n                        void *              ptr,\n                        cl_uint             num_events_in_wait_list,\n                        const cl_event *    event_wait_list,\n                        cl_event *          event)",
            "clEnqueueWriteBuffer(cl_command_queue   command_queue,\n                     cl_mem             buffer,\n                     cl_bool            blocking_write,\n                     size_t             offset,\n                     size_t             size,\n                     const void *       ptr,\n                     cl_uint            num_events_in_wait_list,\n                     const cl_event *   event_wait_list,\n                     cl_event *         event)",
            "clEnqueueWriteBufferRect(cl_command_queue    command_queue,\n                         cl_mem              buffer,\n                         cl_bool             blocking_write,\n                         const size_t *      buffer_offset,\n                         const size_t *      host_offset,\n                         const size_t *      region,\n                         size_t              buffer_row_pitch,\n                         size_t              buffer_slice_pitch,\n                         size_t              host_row_pitch,\n                         size_t              host_slice_pitch,\n                         const void *        ptr,\n                         cl_uint             num_events_in_wait_list,\n                         const cl_event *    event_wait_list,\n                         cl_event *          event)",
            "clEnqueueFillBuffer(cl_command_queue   command_queue,\n                    cl_mem             buffer,\n                    const void *       pattern,\n                    size_t             pattern_size,\n                    size_t             offset,\n                    size_t             size,\n                    cl_uint            num_events_in_wait_list,\n                    const cl_event *   event_wait_list,\n                    cl_event *         event)",
            "clEnqueueCopyBuffer(cl_command_queue    command_queue,\n                    cl_mem              src_buffer,\n                    cl_mem              dst_buffer,\n                    size_t              src_offset,\n                    size_t              dst_offset,\n                    size_t              size,\n                    cl_uint             num_events_in_wait_list,\n                    const cl_event *    event_wait_list,\n                    cl_event *          event)",
            "clEnqueueCopyBufferRect(cl_command_queue    command_queue,\n                        cl_mem              src_buffer,\n                        cl_mem              dst_buffer,\n                        const size_t *      src_origin,\n                        const size_t *      dst_origin,\n                        const size_t *      region,\n                        size_t              src_row_pitch,\n                        size_t              src_slice_pitch,\n                        size_t              dst_row_pitch,\n                        size_t              dst_slice_pitch,\n                        cl_uint             num_events_in_wait_list,\n                        const cl_event *    event_wait_list,\n                        cl_event *          event)",
            "clEnqueueReadImage(cl_command_queue     command_queue,\n                   cl_mem               image,\n                   cl_bool              blocking_read,\n                   const size_t *       origin,\n                   const size_t *       region,\n                   size_t               row_pitch,\n                   size_t               slice_pitch,\n                   void *               ptr,\n                   cl_uint              num_events_in_wait_list,\n                   const cl_event *     event_wait_list,\n                   cl_event *           event)",
            "clEnqueueWriteImage(cl_command_queue    command_queue,\n                    cl_mem              image,\n                    cl_bool             blocking_write,\n                    const size_t *      origin,\n                    const size_t *      region,\n                    size_t              input_row_pitch,\n                    size_t              input_slice_pitch,\n                    const void *        ptr,\n                    cl_uint             num_events_in_wait_list,\n                    const cl_event *    event_wait_list,\n                    cl_event *          event)",
            "clEnqueueFillImage(cl_command_queue   command_queue,\n                   cl_mem             image,\n                   const void *       fill_color,\n                   const size_t *     origin,\n                   const size_t *     region,\n                   cl_uint            num_events_in_wait_list,\n                   const cl_event *   event_wait_list,\n                   cl_event *         event)",
            "clEnqueueCopyImage(cl_command_queue     command_queue,\n                   cl_mem               src_image,\n                   cl_mem               dst_image,\n                   const size_t *       src_origin,\n                   const size_t *       dst_origin,\n                   const size_t *       region,\n                   cl_uint              num_events_in_wait_list,\n                   const cl_event *     event_wait_list,\n                   cl_event *           event)",
            "clEnqueueCopyImageToBuffer(cl_command_queue command_queue,\n                           cl_mem           src_image,\n                           cl_mem           dst_buffer,\n                           const size_t *   src_origin,\n                           const size_t *   region,\n                           size_t           dst_offset,\n                           cl_uint          num_events_in_wait_list,\n                           const cl_event * event_wait_list,\n                           cl_event *       event)",
            "clEnqueueCopyBufferToImage(cl_command_queue command_queue,\n                           cl_mem           src_buffer,\n                           cl_mem           dst_image,\n                           size_t           src_offset,\n                           const size_t *   dst_origin,\n                           const size_t *   region,\n                           cl_uint          num_events_in_wait_list,\n                           const cl_event * event_wait_list,\n                           cl_event *       event)",
            "*\nclEnqueueMapBuffer(cl_command_queue command_queue,\n                   cl_mem           buffer,\n                   cl_bool          blocking_map,\n                   cl_map_flags     map_flags,\n                   size_t           offset,\n                   size_t           size,\n                   cl_uint          num_events_in_wait_list,\n                   const cl_event * event_wait_list,\n                   cl_event *       event,\n                   cl_int *         errcode_ret)",
            "*\nclEnqueueMapImage(cl_command_queue  command_queue,\n                  cl_mem            image,\n                  cl_bool           blocking_map,\n                  cl_map_flags      map_flags,\n                  const size_t *    origin,\n                  const size_t *    region,\n                  size_t *          image_row_pitch,\n                  size_t *          image_slice_pitch,\n                  cl_uint           num_events_in_wait_list,\n                  const cl_event *  event_wait_list,\n                  cl_event *        event,\n                  cl_int *          errcode_ret)",
            "clEnqueueUnmapMemObject(cl_command_queue command_queue,\n                        cl_mem           memobj,\n                        void *           mapped_ptr,\n                        cl_uint          num_events_in_wait_list,\n                        const cl_event *  event_wait_list,\n                        cl_event *        event)",
            "clEnqueueMigrateMemObjects(cl_command_queue       command_queue,\n                           cl_uint                num_mem_objects,\n                           const cl_mem *         mem_objects,\n                           cl_mem_migration_flags flags,\n                           cl_uint                num_events_in_wait_list,\n                           const cl_event *       event_wait_list,\n                           cl_event *             event)",
            "clEnqueueNDRangeKernel(cl_command_queue command_queue,\n                       cl_kernel        kernel,\n                       cl_uint          work_dim,\n                       const size_t *   global_work_offset,\n                       const size_t *   global_work_size,\n                       const size_t *   local_work_size,\n                       cl_uint          num_events_in_wait_list,\n                       const cl_event * event_wait_list,\n                       cl_event *       event)",
            "clEnqueueTask(cl_command_queue  command_queue,\n              cl_kernel         kernel,\n              cl_uint           num_events_in_wait_list,\n              const cl_event *  event_wait_list,\n              cl_event *        event)",
            "clEnqueueNativeKernel(cl_command_queue  command_queue,\n                      void (*user_func)(void *),\n                      void *            args,\n                      size_t            cb_args,\n                      cl_uint           num_mem_objects,\n                      const cl_mem *    mem_list,\n                      const void **     args_mem_loc,\n                      cl_uint           num_events_in_wait_list,\n                      const cl_event *  event_wait_list,\n                      cl_event *        event)",
            "clEnqueueMarkerWithWaitList(cl_command_queue command_queue,\n                            cl_uint           num_events_in_wait_list,\n                            const cl_event *  event_wait_list,\n                            cl_event *        event)",
            "clEnqueueBarrierWithWaitList(cl_command_queue command_queue,\n                             cl_uint           num_events_in_wait_list,\n                             const cl_event *  event_wait_list,\n                             cl_event *        event)",
            "*\nclGetExtensionFunctionAddressForPlatform(cl_platform_id platform,\n                                         const char *   func_name)",
            "clCreateImage2D(cl_context              context,\n                cl_mem_flags            flags,\n                const cl_image_format * image_format,\n                size_t                  image_width,\n                size_t                  image_height,\n                size_t                  image_row_pitch,\n                void *                  host_ptr,\n                cl_int *                errcode_ret)",
            "clCreateImage3D(cl_context              context,\n                cl_mem_flags            flags,\n                const cl_image_format * image_format,\n                size_t                  image_width,\n                size_t                  image_height,\n                size_t                  image_depth,\n                size_t                  image_row_pitch,\n                size_t                  image_slice_pitch,\n                void *                  host_ptr,\n                cl_int *                errcode_ret)",
            "clEnqueueMarker(cl_command_queue    command_queue,\n                cl_event *          event)",
            "clEnqueueWaitForEvents(cl_command_queue command_queue,\n                       cl_uint          num_events,\n                       const cl_event * event_list)",
            "clEnqueueBarrier(cl_command_queue command_queue)",
            "clUnloadCompiler(void)",
            "*\nclGetExtensionFunctionAddress(const char * func_name)",
            "clCreateFromGLBuffer(cl_context     context,\n                     cl_mem_flags   flags,\n                     cl_GLuint      bufobj,\n                     int *          errcode_ret)",
            "clCreateFromGLTexture(cl_context      context,\n                      cl_mem_flags    flags,\n                      cl_GLenum       target,\n                      cl_GLint        miplevel,\n                      cl_GLuint       texture,\n                      cl_int *        errcode_ret)",
            "clCreateFromGLRenderbuffer(cl_context   context,\n                           cl_mem_flags flags,\n                           cl_GLuint    renderbuffer,\n                           cl_int *     errcode_ret)",
            "clGetGLObjectInfo(cl_mem                memobj,\n                  cl_gl_object_type *   gl_object_type,\n                  cl_GLuint *           gl_object_name)",
            "clGetGLTextureInfo(cl_mem               memobj,\n                   cl_gl_texture_info   param_name,\n                   size_t               param_value_size,\n                   void *               param_value,\n                   size_t *             param_value_size_ret)",
            "clEnqueueAcquireGLObjects(cl_command_queue      command_queue,\n                          cl_uint               num_objects,\n                          const cl_mem *        mem_objects,\n                          cl_uint               num_events_in_wait_list,\n                          const cl_event *      event_wait_list,\n                          cl_event *            event)",
            "clEnqueueReleaseGLObjects(cl_command_queue      command_queue,\n                          cl_uint               num_objects,\n                          const cl_mem *        mem_objects,\n                          cl_uint               num_events_in_wait_list,\n                          const cl_event *      event_wait_list,\n                          cl_event *            event)",
            "clCreateFromGLTexture2D(cl_context      context,\n                        cl_mem_flags    flags,\n                        cl_GLenum       target,\n                        cl_GLint        miplevel,\n                        cl_GLuint       texture,\n                        cl_int *        errcode_ret)",
            "clCreateFromGLTexture3D(cl_context      context,\n                        cl_mem_flags    flags,\n                        cl_GLenum       target,\n                        cl_GLint        miplevel,\n                        cl_GLuint       texture,\n                        cl_int *        errcode_ret)",
            "clGetGLContextInfoKHR(const cl_context_properties * properties,\n                      cl_gl_context_info            param_name,\n                      size_t                        param_value_size,\n                      void *                        param_value,\n                      size_t *                      param_value_size_ret)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/mobile/contrib/libvulkan-stub/src/libvulkan-stub.c",
        "functions": [
            "vulkanSymbolWrapperInitLoader(void)",
            "vulkanSymbolWrapperInit(PFN_vkGetInstanceProcAddr getInstanceProcAddr)",
            "vulkanSymbolWrapperInstanceProcAddr(void)",
            "vulkanSymbolWrapperReset(void)",
            "vulkanSymbolWrapperLoadInstanceSymbol(VkInstance instance, const char *name, PFN_vkVoidFunction *ppSymbol)",
            "vulkanSymbolWrapperLoadDeviceSymbol(VkDevice device, const char *name, PFN_vkVoidFunction *ppSymbol)",
            "vulkanSymbolWrapperLoadGlobalSymbols(void)",
            "vulkanSymbolWrapperLoadCoreSymbols(VkInstance instance)",
            "vulkanSymbolWrapperLoadCoreInstanceSymbols(VkInstance instance)",
            "vulkanSymbolWrapperLoadGetPhysicalDeviceProperties2ExtensionSymbols(VkInstance instance)",
            "vulkanSymbolWrapperLoadCoreDeviceSymbols(VkDevice device)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/mobile/contrib/nnapi/dlnnapi.c",
        "functions": [
            "dlnnapi_load(struct dlnnapi* nnapi, uint32_t flags)",
            "dlnnapi_free(struct dlnnapi* nnapi)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/perfkernels/hp_emblookup_codegen.py",
        "functions": [
            "unroll",
            "generic"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/perfkernels/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/proto/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/allcompare_test.py",
        "functions": [
            "allcompare_process"
        ],
        "classes": [
            "TemporaryDirectory",
            "TestAllCompare"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/attention.py",
        "functions": [
            "s",
            "_calc_weighted_context",
            "_calc_attention_weights",
            "_calc_attention_logits_from_sum_match",
            "_apply_fc_weight_for_sum_match",
            "apply_recurrent_attention",
            "apply_regular_attention",
            "apply_dot_attention",
            "apply_soft_coverage_attention"
        ],
        "classes": [
            "AttentionType"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/benchmark_generator.py",
        "functions": [
            "parse_kwarg",
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/binarysize.py",
        "functions": [
            "GetSymbolTrie",
            "MaybeAddColor",
            "ReadableSize",
            "PrintTrie",
            "main"
        ],
        "classes": [
            "Trie"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/brew.py",
        "functions": [],
        "classes": [
            "HelperWrapper"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/brew_test.py",
        "functions": [],
        "classes": [
            "BrewTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/build.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/cached_reader.py",
        "functions": [],
        "classes": [
            "CachedReader"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/caffe_translator.py",
        "functions": [
            "_StateMeetsRule",
            "_ShouldInclude",
            "_GetLegacyDims",
            "_GetLegacyPadArgs",
            "_AdjustDims",
            "_RemoveLegacyPad",
            "_GetBlobDimMap",
            "_GetInputDims",
            "TranslateModel",
            "ConvertTensorProtosToInitNet",
            "BaseTranslate",
            "AddArgument",
            "_TranslateStridePadKernelHelper"
        ],
        "classes": [
            "TranslatorRegistry"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/caffe_translator_test.py",
        "functions": [
            "setUpModule"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/checkpoint.py",
        "functions": [
            "get_ckpt_filename",
            "db_name",
            "epoch_limiter"
        ],
        "classes": [
            "Job",
            "CheckpointManager",
            "MultiNodeCheckpointManager",
            "UploadTaskGroupBuilder",
            "JobRunner"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/checkpoint_test.py",
        "functions": [
            "build_pipeline",
            "local_copy_op"
        ],
        "classes": [
            "UploadToLocalFile",
            "TestCheckpoint"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/cnn.py",
        "functions": [],
        "classes": [
            "CNNModelHelper"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/context.py",
        "functions": [
            "_context_registry",
            "_get_managed_classes"
        ],
        "classes": [
            "_ContextInfo",
            "_ContextRegistry",
            "Managed",
            "DefaultManaged"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/context_test.py",
        "functions": [],
        "classes": [
            "MyContext",
            "DefaultMyContext",
            "ChildMyContext",
            "TestContext"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/control.py",
        "functions": [
            "_get_next_step_name",
            "_MakeList",
            "_IsNets",
            "_PrependNets",
            "_AppendNets",
            "GetConditionBlobFromNet",
            "BoolNet",
            "NotNet",
            "_CopyConditionBlobNet",
            "MergeConditionNets",
            "CombineConditions",
            "Do",
            "DoParallel",
            "_RunOnceIf",
            "_RunOnceIfNot",
            "For",
            "While",
            "Until",
            "DoWhile",
            "DoUntil",
            "Switch",
            "SwitchNot",
            "If",
            "IfNot"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/control_ops_grad.py",
        "functions": [
            "gen_do_gradient",
            "dedupe_g_output",
            "gen_while_gradient",
            "_prepare_gradient_while_ops",
            "_get_do_arguments",
            "gen_if_gradient",
            "_gen_subnet_gradient",
            "_get_net_argument",
            "getNetArgument",
            "_gen_subgradient_pass",
            "_do_op_sanity_check_and_process",
            "_prepare_blob_copy_op",
            "_prepare_gradient_do_op",
            "_gen_grad_zero_init_ops",
            "_prepare_gradient_if_op",
            "disambiguate_grad_if_op_output"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/control_ops_grad_test.py",
        "functions": [],
        "classes": [
            "TestControl"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/control_ops_util.py",
        "functions": [
            "get_external_blob_names",
            "add_if_op",
            "add_while_op"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/control_test.py",
        "functions": [],
        "classes": [
            "TestControl"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/convert.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/convert_test.py",
        "functions": [],
        "classes": [
            "TestOperator"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/convnet_benchmarks.py",
        "functions": [
            "MLP",
            "AlexNet",
            "OverFeat",
            "VGGA",
            "_InceptionModule",
            "Inception",
            "AddParameterUpdate",
            "Benchmark",
            "GetArgumentParser"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/convnet_benchmarks_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/core.py",
        "functions": [
            "_InitDataType",
            "_GetRegisteredOperators",
            "RefreshRegisteredOperators",
            "GlobalInit",
            "GetGlobalInitArgs",
            "IsOperator",
            "IsOperatorWithEngine",
            "IsGPUDeviceType",
            "DeviceOption",
            "device_option_equal",
            "InferBlobDevices",
            "InferOpBlobDevicesAsDict",
            "InferOpBlobDevices",
            "InferOpDeviceAsBlobDevices",
            "ScopedName",
            "ScopedBlobReference",
            "_RectifyInputOutput",
            "CreateOperator",
            "_RegisterPythonImpl",
            "CreatePythonOperator",
            "GetIndexFromGradientList",
            "get_ssa",
            "get_undefined_blobs",
            "get_output_producers",
            "get_op_ids_in_path",
            "recurrent_network_op_remap",
            "control_op_remap",
            "remap_proto",
            "clone_and_bind_net",
            "_get_blob_ref",
            "_recover_record_by_prefix",
            "remap_input",
            "copy_func_between_devices",
            "device_equal",
            "update_placeholder_op_output",
            "InjectCrossDeviceCopies",
            "InjectDeviceCopiesAmongNets",
            "InjectDeviceCopiesAmongNetsWithoutB2D",
            "get_net_name",
            "output_to_list",
            "_add_net_to_dict",
            "add_nets_in_order",
            "to_execution_step",
            "execution_step",
            "scoped_execution_step",
            "_extract_stacktrace"
        ],
        "classes": [
            "DataType",
            "BlobReference",
            "IR",
            "GradientRegistry",
            "Net",
            "RemapEntry",
            "ExecutionStep",
            "Plan"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/core_gradients_test.py",
        "functions": [
            "NeedAll",
            "GIS",
            "CopyDeviceOption"
        ],
        "classes": [
            "TestGradientCalculation",
            "TestGradientsAccumulationWithNoGradientOps",
            "TestGradientsAccumulationWithPassThroughGradients"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/core_test.py",
        "functions": [],
        "classes": [
            "TestScopes",
            "TestCloneNet",
            "TestExternalInputs",
            "TestCreateOperator",
            "TestAutoNaming",
            "TestAppendNet",
            "TestExtractPredictorNet",
            "TestOperatorTraceback",
            "TestCreatePlan",
            "TestOpRegistryKey",
            "TestDeviceOption",
            "TestInferDeviceCpuOnly",
            "TestRerouteTensor",
            "TestRunAllOnGPU"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/crf.py",
        "functions": [],
        "classes": [
            "CRFWithLoss"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/crf_predict.py",
        "functions": [
            "crf_update_predictions",
            "apply_crf"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/crf_viterbi_test.py",
        "functions": [],
        "classes": [
            "TestCrfDecode"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/dataio.py",
        "functions": [
            "CountUntil"
        ],
        "classes": [
            "Reader",
            "Writer",
            "ReaderBuilder",
            "PipedReaderBuilder",
            "Pipe",
            "CounterReader",
            "ReaderWithLimitBase",
            "ReaderWithLimit",
            "ReaderWithTimeLimit",
            "ReaderWithDelay",
            "CompositeReader",
            "CompositeReaderBuilder"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/dataset.py",
        "functions": [
            "Const",
            "execution_step_with_progress"
        ],
        "classes": [
            "_DatasetReader",
            "_DatasetRandomReader",
            "_DatasetWriter",
            "Dataset"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/data_parallel_model.py",
        "functions": [
            "Parallelize_GPU",
            "Parallelize_CPU",
            "Parallelize_iDeep",
            "Parallelize",
            "Parallelize_GPU_BMUF",
            "Parallelize_CPU_BMUF",
            "Parallelize_BMUF",
            "CreateNet",
            "RunInitNet",
            "RunWarmup",
            "RunNet",
            "_AddBarrierToModelNets",
            "_CreateBarrierNet",
            "Synchronize",
            "ConvertNetForDevice",
            "_ForEachDevice",
            "_AddGradientOperators",
            "ExtractPredictorNet",
            "GetCheckpointParams",
            "FinalizeAfterCheckpoint",
            "GetLearningRateBlobNames",
            "_Broadcast",
            "_AllReduce",
            "_SyncAllParams",
            "AddBlobSync",
            "AddDistributedBlobSync",
            "_SyncAllParamsDistributed",
            "_SyncAllParamsSingleHost",
            "_AllReduceBlobs",
            "_PruneParametersForSharing",
            "_RemapParameterBlobsForSharedModel",
            "_AllReduceBlobsDistributed",
            "_AllReduceBlobsSingleHost",
            "_BroadcastComputedParams",
            "_BroadcastComputedParamsDistributed",
            "_BroadcastComputedParamsSingleHost",
            "_GetReverseOrderedGrads",
            "stripBlobName",
            "_AnalyzeOperators",
            "_InferBlobDevice",
            "_IsIDEEPBlob",
            "_IsGPUBlob",
            "_GroupByDevice",
            "_ValidateParams",
            "_ComputeBlobsToSync",
            "_OptimizeGradientMemorySimple",
            "_AddDynamicMemoryOptimization",
            "OptimizeGradientMemory",
            "_CreateOrCloneCommonWorld",
            "_RunComparison",
            "_InterleaveOps",
            "_CPUInterDeviceBatchNormalization",
            "_GPUInterDeviceBatchNormalization"
        ],
        "classes": [
            "CollectivesConcurrencyControl"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/data_parallel_model_test.py",
        "functions": [],
        "classes": [
            "TemporaryDirectory",
            "RecurrentNetworkParallelTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/data_workers.py",
        "functions": [
            "get_worker_ids",
            "init_data_input_workers",
            "enqueuer"
        ],
        "classes": [
            "BatchFeeder",
            "GlobalCoordinator",
            "DataWorker"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/data_workers_test.py",
        "functions": [
            "dummy_fetcher",
            "dummy_fetcher_rnn"
        ],
        "classes": [
            "DataWorkersTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/db_file_reader.py",
        "functions": [],
        "classes": [
            "DBFileReader"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/db_test.py",
        "functions": [],
        "classes": [
            "TestDB"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/device_checker.py",
        "functions": [],
        "classes": [
            "DeviceChecker"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/dyndep.py",
        "functions": [
            "InitOpsLibrary",
            "GetImportedOpsLibraries",
            "_init_impl"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/embedding_generation_benchmark.py",
        "functions": [
            "generate_data",
            "generate_embedding_table",
            "create_model",
            "Caffe2EmbeddingGeneration",
            "GetArgumentParser"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/experiment_util.py",
        "functions": [],
        "classes": [
            "ExternalLogger",
            "ModelTrainerLog"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/extension_loader.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/fakefp16_transform_lib.py",
        "functions": [
            "fakeFp16FuseOps"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/functional.py",
        "functions": [
            "namedtupledict"
        ],
        "classes": [
            "_Functional"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/functional_test.py",
        "functions": [],
        "classes": [
            "TestFunctional"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/fused_8bit_rowwise_conversion_ops_test.py",
        "functions": [
            "bytes_to_floats",
            "floats_to_bytes",
            "fused_rowwise_8bit_quantize_reference",
            "fused_rowwise_8bit_quantize_dequantize_reference"
        ],
        "classes": [
            "TestFused8BitRowwiseQuantizationConversion"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/gradient_checker.py",
        "functions": [
            "getGradientForOp",
            "_get_grad_blob",
            "_get_grad",
            "_assert_close"
        ],
        "classes": [
            "NetGradientChecker",
            "GradientChecker"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/gradient_check_test.py",
        "functions": [],
        "classes": [
            "TestLRN",
            "TestFlatten",
            "TestConcat",
            "TestRelu",
            "TestTanh",
            "TestAbs",
            "TestExp",
            "TestCos",
            "TestSin",
            "TestSigmoid",
            "TestSum",
            "TestMakeTwoClass",
            "TestNetGradientChecker",
            "TestIf",
            "TestWhile"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/gru_cell.py",
        "functions": [],
        "classes": [
            "GRUCell"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/hip_test_util.py",
        "functions": [
            "run_in_hip"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/hsm_util.py",
        "functions": [
            "create_node_with_words",
            "create_node_with_nodes",
            "create_hierarchy"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/hypothesis_test.py",
        "functions": [
            "sigmoid",
            "_tensor_and_indices",
            "_dtypes",
            "_test_binary",
            "_test_binary_broadcast"
        ],
        "classes": [
            "TestOperators"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/hypothesis_test_util.py",
        "functions": [
            "is_sandcastle",
            "is_travis",
            "to_float32",
            "settings",
            "floats",
            "dims",
            "elements_of_type",
            "arrays",
            "tensor",
            "tensor1d",
            "segment_ids",
            "lengths",
            "segmented_tensor",
            "lengths_tensor",
            "sparse_segmented_tensor",
            "sparse_lengths_tensor",
            "tensors",
            "tensors1d",
            "device_checker_device_options",
            "gradient_checker_device_option",
            "runOpBenchmark",
            "runOpOnInput"
        ],
        "classes": [
            "HypothesisTestCase"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/ideep_test_util.py",
        "functions": [
            "device_checker_device_options",
            "gradient_checker_device_option"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/layers_test.py",
        "functions": [],
        "classes": [
            "TestLayers"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layer_model_helper.py",
        "functions": [],
        "classes": [
            "LayerModelHelper"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layer_parameter_sharing_test.py",
        "functions": [],
        "classes": [
            "ParameterSharingTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layer_test_util.py",
        "functions": [],
        "classes": [
            "OpSpec",
            "LayersTestCase"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/lazy.py",
        "functions": [
            "RegisterLazyImport",
            "TriggerLazyImport"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/lazy_dyndep.py",
        "functions": [
            "RegisterOpsLibrary",
            "SetErrorHandler",
            "GetImportedOpsLibraries",
            "_import_lazy"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/lazy_dyndep_test.py",
        "functions": [
            "allcompare_process"
        ],
        "classes": [
            "TemporaryDirectory",
            "TestLazyDynDepAllCompare",
            "TestLazyDynDepError"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/lengths_reducer_fused_8bit_rowwise_ops_test.py",
        "functions": [
            "compare_rowwise"
        ],
        "classes": [
            "TestLengthsReducerOpsFused8BitRowwise"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/lengths_reducer_rowwise_8bit_ops_test.py",
        "functions": [
            "FakeQuantization8BitsRowwise"
        ],
        "classes": [
            "TestQuantize8bits"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/lstm_benchmark.py",
        "functions": [
            "generate_data",
            "create_model",
            "Caffe2LSTM",
            "GetArgumentParser"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/memonger.py",
        "functions": [
            "share_grad_blobs",
            "optimize_inference_for_dag",
            "estimate_memory_usage",
            "release_blobs_when_used",
            "_find_source_nodes",
            "_find_target_nodes",
            "_add_single_target_ifneeded",
            "_get_path",
            "_get_longest_paths",
            "_build_tree",
            "_compute_tree_height",
            "_sort_tree_leaves",
            "topological_sort_traversal_longest_path",
            "topological_sort_traversal",
            "compute_ranges",
            "is_compatible",
            "compute_blob_assignments",
            "_get_max_size",
            "get_memory_usage",
            "compute_assignments_greedy",
            "_get_count",
            "compute_assignments_dp",
            "get_updated_ranges",
            "compute_assignments",
            "verify_assignments",
            "compute_interference_graph",
            "apply_assignments",
            "apply_recurrent_blob_assignments",
            "optimize_inference_fast",
            "optimize_interference",
            "verify_inplace_blobs",
            "verify_graph_equality",
            "blob_nbytes",
            "compute_statistics",
            "collect_blob_sizes"
        ],
        "classes": [
            "AssignmentAlgorithm"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/memonger_test.py",
        "functions": [
            "has_blob",
            "count_blobs"
        ],
        "classes": [
            "MemongerTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/mkl_test_util.py",
        "functions": [
            "device_checker_device_options",
            "gradient_checker_device_option"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/model_device_test.py",
        "functions": [],
        "classes": [
            "TestMiniAlexNet"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/model_helper.py",
        "functions": [
            "ExtractPredictorNet"
        ],
        "classes": [
            "ModelHelper"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/dataio_test.py",
        "functions": [
            "make_source_dataset",
            "make_destination_dataset"
        ],
        "classes": [
            "TestReaderBuilder",
            "TestCompositeReader",
            "TestReaderWithLimit",
            "TestDBFileReader"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/filler_test.py",
        "functions": [],
        "classes": [
            "TestFiller"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layer_model_instantiator.py",
        "functions": [
            "_filter_layers",
            "shrink_output_schema",
            "generate_predict_net",
            "generate_eval_net",
            "_generate_training_net_only",
            "generate_training_nets_forward_only",
            "generate_training_nets"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/model_helper_test.py",
        "functions": [],
        "classes": [
            "ModelHelperTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/numa_benchmark.py",
        "functions": [
            "build_net",
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/predictor_constants.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/regularizer_context.py",
        "functions": [],
        "classes": [
            "RegularizerContext",
            "UseRegularizer"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/modifier_context.py",
        "functions": [],
        "classes": [
            "ModifierContext",
            "UseModifierBase"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/muji.py",
        "functions": [
            "OnGPU",
            "OnCPU",
            "Allreduce",
            "Allreduce2",
            "Allreduce4",
            "Allreduce4Group2",
            "Allreduce8",
            "AllreduceFallback"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/muji_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/net_builder.py",
        "functions": [],
        "classes": [
            "NetBuilder",
            "Operations",
            "_ReporterBuilder",
            "_SetupBuilder",
            "_RunOnce",
            "_StopGuard",
            "_Loop",
            "_RunIf",
            "_RunIfNet",
            "_RunElseNet",
            "_RunWhileNet",
            "_RunWhileCondition"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/net_builder_test.py",
        "functions": [
            "python_op_builder",
            "_test_loop",
            "_test_inner_stop",
            "_test_outer",
            "_test_if"
        ],
        "classes": [
            "PythonOpStats",
            "TestNetBuilder"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/net_drawer.py",
        "functions": [
            "_rectify_operator_and_name",
            "_escape_label",
            "GetOpNodeProducer",
            "GetBlobNodeProducer",
            "GetPydotGraph",
            "GetPydotGraphMinimal",
            "GetOperatorMapForPlan",
            "_draw_nets",
            "_draw_steps",
            "GetPlanGraph",
            "GetGraphInJson",
            "GetGraphPngSafe",
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/net_printer.py",
        "functions": [
            "analyze",
            "_sanitize_str",
            "_arg_val",
            "commonprefix",
            "format_value",
            "factor_prefix",
            "call",
            "format_device_option",
            "_get_step_context",
            "_print_task_output",
            "to_string",
            "debug_net"
        ],
        "classes": [
            "Visitor",
            "Analyzer",
            "Text",
            "Printer"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/net_printer_test.py",
        "functions": [
            "example_loop",
            "example_task",
            "example_job"
        ],
        "classes": [
            "TestNetPrinter"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/nomnigraph.py",
        "functions": [
            "render"
        ],
        "classes": [
            "NNModule"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/nomnigraph_test.py",
        "functions": [],
        "classes": [
            "TestBindings"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/nomnigraph_transformations.py",
        "functions": [
            "transpose_network"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/nomnigraph_transformations_test.py",
        "functions": [],
        "classes": [
            "TestNomnigraphTransformations"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/normalizer.py",
        "functions": [],
        "classes": [
            "Normalizer",
            "BatchNormalizer",
            "LayerNormalizer"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/normalizer_context.py",
        "functions": [],
        "classes": [
            "NormalizerContext",
            "UseNormalizer"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/normalizer_test.py",
        "functions": [],
        "classes": [
            "TestNormalizerContext"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/numa_test.py",
        "functions": [
            "build_test_net"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/observer_test.py",
        "functions": [],
        "classes": [
            "TestObservers"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_fp_exceptions_test.py",
        "functions": [
            "setThrowIfFpExceptions"
        ],
        "classes": [
            "OperatorFPExceptionsTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/optimizer.py",
        "functions": [
            "_get_param_to_device",
            "get_param_device",
            "get_lr_injection",
            "set_lr_injection",
            "_calc_norm_ratio",
            "_build",
            "add_weight_decay",
            "build_sgd",
            "build_multi_precision_sgd",
            "build_fp16_sgd",
            "build_ftrl",
            "build_gftrl",
            "build_adagrad",
            "build_wngrad",
            "build_storm",
            "build_adadelta",
            "build_adam",
            "build_yellowfin",
            "build_rms_prop"
        ],
        "classes": [
            "Optimizer",
            "SgdOptimizer",
            "MultiPrecisionSgdOptimizer",
            "FP16SgdOptimizer",
            "WeightDecayBuilder",
            "AdagradOptimizer",
            "WngradOptimizer",
            "StormOptimizer",
            "AdadeltaOptimizer",
            "FtrlOptimizer",
            "GFtrlOptimizer",
            "AdamOptimizer",
            "YellowFinOptimizer",
            "RmsPropOptimizer"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/optimizer_context.py",
        "functions": [],
        "classes": [
            "OptimizerContext",
            "UseOptimizer"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/optimizer_test.py",
        "functions": [],
        "classes": [
            "TestLars",
            "TestMomentumSgd",
            "TestSgd",
            "TestMultiPrecisionSgd",
            "TestFtrl",
            "TestGFtrl",
            "TestAdagrad",
            "TestRowWiseAdagrad",
            "TestRowWiseAdagradWithCounter",
            "TestWngrad",
            "TestStorm",
            "TestAdadelta",
            "TestAdam",
            "TestSparseRAdam",
            "TestYellowFin",
            "TestRmsProp",
            "TestMultiOptimizers",
            "TestWeightDecay",
            "TestOptimizerContext"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/optimizer_test_util.py",
        "functions": [],
        "classes": [
            "OptimizerTestBase",
            "LRModificationTestBase"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/parallelize_bmuf_distributed_test.py",
        "functions": [
            "bmuf_process"
        ],
        "classes": [
            "DistributedTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/parallel_workers.py",
        "functions": [
            "init_workers",
            "run_worker"
        ],
        "classes": [
            "Metrics",
            "State",
            "WorkerCoordinator",
            "GlobalWorkerCoordinator",
            "Worker"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/parallel_workers_test.py",
        "functions": [
            "create_queue",
            "create_worker",
            "dequeue_value"
        ],
        "classes": [
            "ParallelWorkersTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/pipeline.py",
        "functions": [
            "_init_output",
            "make_processor",
            "normalize_processor_output",
            "pipe",
            "pipe_and_output",
            "processor_name",
            "_runtime_threads_task",
            "_static_threads_task",
            "_pipe_step"
        ],
        "classes": [
            "Output",
            "ProcessingReader",
            "NetProcessor"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/pipeline_test.py",
        "functions": [],
        "classes": [
            "TestPipeline"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/python_op_test.py",
        "functions": [
            "SubFunctionThatThrowsCustomError",
            "MainOpFunctionThatThrowsCustomError",
            "MainOpFunctionThatThrowsCustomErrorInBuilder",
            "op_builder"
        ],
        "classes": [
            "CustomError",
            "PythonOpTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/queue_util.py",
        "functions": [
            "enqueue",
            "dequeue",
            "close_queue"
        ],
        "classes": [
            "_QueueReader",
            "_QueueWriter",
            "QueueWrapper",
            "Queue"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/record_queue.py",
        "functions": [],
        "classes": [
            "_QueueReader",
            "_QueueWriter",
            "RecordQueue"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/recurrent.py",
        "functions": [
            "recurrent_net",
            "set_rnn_executor_config",
            "retrieve_step_blobs"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/regularizer.py",
        "functions": [],
        "classes": [
            "RegularizationBy",
            "Regularizer",
            "L1Norm",
            "LpNorm",
            "L0ApproxNorm",
            "L1NormTrimmed",
            "L2Norm",
            "ElasticNet",
            "ElasticNetL1NormTrimmed",
            "MaxNorm",
            "ConstantNorm",
            "SparseLpNorm",
            "SparseL1Norm",
            "SparseL2Norm",
            "LogBarrier",
            "BoundedGradientProjection",
            "GroupL1Norm"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/regularizer_test.py",
        "functions": [],
        "classes": [
            "TestRegularizerContext",
            "TestRegularizer"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/rnn_cell.py",
        "functions": [
            "_RectifyName",
            "_RectifyNames",
            "_LSTM",
            "GetLSTMParamNames",
            "InitFromLSTMParams",
            "cudnn_LSTM",
            "LSTMWithAttention",
            "_layered_LSTM"
        ],
        "classes": [
            "RNNCell",
            "LSTMInitializer",
            "BasicRNNCell",
            "LSTMCell",
            "LayerNormLSTMCell",
            "MILSTMCell",
            "LayerNormMILSTMCell",
            "DropoutCell",
            "MultiRNNCellInitializer",
            "MultiRNNCell",
            "AttentionCell",
            "LSTMWithAttentionCell",
            "MILSTMWithAttentionCell",
            "UnrolledCell"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/schema.py",
        "functions": [
            "_join_field_name",
            "_normalize_field",
            "Map",
            "MapWithEvicted",
            "NamedTuple",
            "Tuple",
            "RawTuple",
            "from_dtype",
            "from_column_list",
            "from_blob_list",
            "as_record",
            "FetchRecord",
            "FeedRecord",
            "NewRecord",
            "ConstRecord",
            "InitEmptyRecord",
            "is_schema_subset",
            "equal_schemas",
            "schema_check",
            "data_type_for_dtype",
            "dtype_for_core_type",
            "attach_metadata_to_scalars"
        ],
        "classes": [
            "Metadata",
            "Field",
            "List",
            "ListWithEvicted",
            "Struct",
            "Scalar",
            "_SchemaNode"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/schema_test.py",
        "functions": [],
        "classes": [
            "TestField",
            "TestDB"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/scope.py",
        "functions": [
            "CurrentNameScope",
            "CurrentDeviceScope"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/scope_test.py",
        "functions": [
            "thread_runner"
        ],
        "classes": [
            "TestScope"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/session.py",
        "functions": [],
        "classes": [
            "CompiledRunnable",
            "Session",
            "LocalSession"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/session_test.py",
        "functions": [],
        "classes": [
            "TestLocalSession"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/sparse_to_dense_mask_test.py",
        "functions": [],
        "classes": [
            "TestSparseToDenseMask"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/sparse_to_dense_test.py",
        "functions": [],
        "classes": [
            "TestSparseToDense"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/task.py",
        "functions": [
            "_merge_node_kwargs",
            "get_setup_nets",
            "add_setup_steps",
            "final_output"
        ],
        "classes": [
            "Cluster",
            "Node",
            "WorkspaceType",
            "TaskGroup",
            "TaskOutput",
            "TaskOutputList",
            "Task",
            "SetupNets"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/task_test.py",
        "functions": [],
        "classes": [
            "TestTask"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/test_util.py",
        "functions": [
            "rand_array",
            "randBlob",
            "randBlobFloat32",
            "randBlobsFloat32",
            "numOps",
            "str_compare",
            "get_default_test_flags",
            "caffe2_flaky",
            "is_flaky_test_mode"
        ],
        "classes": [
            "TestCase"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/text_file_reader.py",
        "functions": [],
        "classes": [
            "TextFileReader"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/timeout_guard.py",
        "functions": [
            "EuthanizeIfNecessary"
        ],
        "classes": [
            "WatcherThread"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/toy_regression_test.py",
        "functions": [],
        "classes": [
            "TestToyRegression"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/transformations.py",
        "functions": [
            "fuseNNPACKConvRelu",
            "optimizeForMKLDNN",
            "fuseConvBN"
        ],
        "classes": [
            "Transformer"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/transformations_test.py",
        "functions": [],
        "classes": [
            "TestTransformations"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/tt_core.py",
        "functions": [
            "init_tt_cores",
            "matrix_to_tt",
            "tt_svd",
            "fc_net_to_tt_net"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/tt_core_test.py",
        "functions": [],
        "classes": [
            "TestTTSVD"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/utils.py",
        "functions": [
            "OpAlmostEqual",
            "CaffeBlobToNumpyArray",
            "Caffe2TensorToNumpyArray",
            "NumpyArrayToCaffe2Tensor",
            "MakeArgument",
            "TryReadProtoWithClass",
            "GetContentFromProto",
            "GetContentFromProtoString",
            "ConvertProtoToBinary",
            "GetGPUMemoryUsageStats",
            "ResetBlobs",
            "raiseIfNotEqual",
            "debug",
            "BuildUniqueMutexIter",
            "EnumClassKeyVals",
            "ArgsToDict",
            "NHWC2NCHW",
            "NCHW2NHWC"
        ],
        "classes": [
            "DebugMode"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/utils_test.py",
        "functions": [],
        "classes": [
            "TestUtils"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/visualize.py",
        "functions": [
            "ChannelFirst",
            "ChannelLast"
        ],
        "classes": [
            "PatchVisualizer",
            "NHWC",
            "NCHW"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/workspace.py",
        "functions": [
            "FillRandomNetworkInputs",
            "_GetFreeFlaskPort",
            "StartMint",
            "StringifyProto",
            "ResetWorkspace",
            "CreateNet",
            "Predictor",
            "GetOperatorCost",
            "RunOperatorOnce",
            "RunOperatorMultiple",
            "RunOperatorsOnce",
            "ClearGlobalNetObserver",
            "CallWithExceptionIntercept",
            "RunNetOnce",
            "RunNet",
            "RunPlan",
            "RunPlanInBackground",
            "InferShapesAndTypes",
            "_StringifyName",
            "StringifyBlobName",
            "StringifyNetName",
            "GetNetName",
            "FeedBlob",
            "FetchBlobs",
            "FetchBlob",
            "FetchTorch",
            "FetchInt8Blob",
            "FetchInt8BlobRealVal",
            "_Workspace_fetch_int8_blob",
            "ApplyTransform",
            "ApplyTransformIfFaster",
            "GetNameScope",
            "IsImmediate",
            "StartImmediate",
            "StopImmediate",
            "ImmediateBlobs",
            "RunOperatorImmediate",
            "FetchImmediate",
            "FeedImmediate",
            "_Workspace_create_net_with_exception_intercept",
            "_Workspace_run",
            "_Workspace_feed_blob",
            "_Workspace_remove_blob",
            "_Blob_feed",
            "_Tensor_to_torch",
            "_Blob_to_torch"
        ],
        "classes": [
            "_BlobDict"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/workspace_test.py",
        "functions": [],
        "classes": [
            "TestWorkspace",
            "TestMultiWorkspaces",
            "TestImmedibate",
            "TestCppEnforceAsException",
            "TestCWorkspace",
            "TestPredictor",
            "TestTransform",
            "MyModule",
            "TestScriptModuleFromString"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/_import_c_extension.py",
        "functions": [
            "_TensorCPU_shape",
            "_TensorCPU_reshape"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/benchmarks/concat_benchmark.py",
        "functions": [
            "benchmark_concat"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/benchmarks/fused_rowwise_nbit_conversion_bench.py",
        "functions": [
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/benchmarks/sparse_lengths_sum_nbit_benchmark.py",
        "functions": [
            "benchmark_sparse_lengths_sum"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/benchmarks/sparse_normalize_benchmark.py",
        "functions": [
            "benchmark_sparse_normalize"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/docs/formatter.py",
        "functions": [],
        "classes": [
            "Formatter",
            "Markdown"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/docs/generator.py",
        "functions": [],
        "classes": [
            "DocUploader",
            "DocGenerator",
            "OpDocGenerator",
            "OperatorEngine",
            "OperatorDoc"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/docs/github.py",
        "functions": [
            "getCodeLink"
        ],
        "classes": [
            "GHOpDocUploader",
            "GHMarkdown",
            "GHOperatorEngine",
            "GHOperatorDoc",
            "GHOpDocGenerator"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/docs/parser.py",
        "functions": [],
        "classes": [
            "Parser"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/docs/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/examples/char_rnn.py",
        "functions": [
            "CreateNetOnce"
        ],
        "classes": [
            "CharRNN"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/examples/imagenet_trainer.py",
        "functions": [
            "AddImageInput",
            "AddNullInput",
            "SaveModel",
            "LoadModel",
            "RunEpoch",
            "Train",
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/examples/lmdb_create_example.py",
        "functions": [
            "create_db",
            "read_db_with_caffe2",
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/examples/resnet50_trainer.py",
        "functions": [
            "AddImageInput",
            "AddNullInput",
            "SaveModel",
            "LoadModel",
            "RunEpoch",
            "Train",
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/examples/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/fakelowp/init_shared_libs.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/fakelowp/test_utils.py",
        "functions": [
            "print_test_debug_info",
            "print_net",
            "_sigmoid",
            "_tanh",
            "_swish",
            "_gelu_by_sigmoid",
            "_acc_func",
            "_get_ulp16",
            "compute_ulp_error"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/fakelowp/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/helpers/algebra.py",
        "functions": [
            "transpose",
            "sum",
            "reduce_sum",
            "sub",
            "mat_mul",
            "arg_min",
            "batch_mat_mul",
            "sparse_lengths_sum_4bit_rowwise_sparse"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/helpers/arg_scope.py",
        "functions": [
            "get_current_scope"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/helpers/array_helpers.py",
        "functions": [
            "concat",
            "depth_concat"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/helpers/control_ops.py",
        "functions": [
            "cond",
            "loop"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/helpers/conv.py",
        "functions": [
            "_ConvBase",
            "conv_nd",
            "conv",
            "conv_transpose",
            "group_conv",
            "group_conv_deprecated"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/helpers/db_input.py",
        "functions": [
            "db_input"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/helpers/dropout.py",
        "functions": [
            "dropout"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/helpers/elementwise_linear.py",
        "functions": [
            "_elementwise_linear",
            "elementwise_linear"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/helpers/fc.py",
        "functions": [
            "_FC_or_packed_FC",
            "fc",
            "packed_fc",
            "fc_decomp",
            "fc_prune",
            "fc_sparse"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/helpers/nonlinearity.py",
        "functions": [
            "prelu",
            "relu",
            "tanh"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/helpers/normalization.py",
        "functions": [
            "lrn",
            "softmax",
            "instance_norm",
            "spatial_bn",
            "spatial_gn",
            "layer_norm",
            "moments_with_running_stats"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/helpers/pooling.py",
        "functions": [
            "max_pool",
            "average_pool",
            "max_pool_with_index"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/helpers/quantization.py",
        "functions": [
            "fused_8bit_rowwise_quantized_to_float"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/helpers/tools.py",
        "functions": [
            "image_input",
            "video_input"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/helpers/train.py",
        "functions": [
            "_get_weights",
            "iter",
            "accuracy",
            "add_weight_decay"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/helpers/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/ideep/adam_op_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/ideep/blobs_queue_db_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/ideep/channel_shuffle_op_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/ideep/concat_split_op_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/ideep/convfusion_op_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/ideep/conv_op_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/ideep/conv_transpose_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/ideep/copy_op_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/ideep/dropout_op_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/ideep/elementwise_sum_op_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/ideep/expanddims_squeeze_op_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/ideep/fc_op_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/ideep/leaky_relu_op_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/ideep/LRN_op_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/ideep/moment_sgd_op_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/ideep/operator_fallback_op_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/ideep/order_switch_op_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/ideep/pool_op_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/ideep/pre_convert_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/ideep/relu_op_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/ideep/reshape_op_test.py",
        "functions": [
            "_test_reshape"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/ideep/shape_op_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/ideep/sigmoid_op_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/ideep/softmax_op_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/ideep/spatial_bn_op_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/ideep/test_ideep_net.py",
        "functions": [
            "GetArgumentParser",
            "benchmark"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/ideep/transform_ideep_net.py",
        "functions": [
            "pairwise",
            "last_producer",
            "blob_uses",
            "GetArgumentParser",
            "fuse_first_bn",
            "fuse_bn",
            "fuse_first_mul_add",
            "fuse_mul_add",
            "add_tensor",
            "gen_init_net_from_blobs",
            "fuse_conv_relu",
            "Optimize"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/ideep/transpose_op_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/ideep/weightedsum_op_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/ideep/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/fc_with_bootstrap.py",
        "functions": [
            "get_fc_predictor_version"
        ],
        "classes": [
            "FCWithBootstrap"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/adaptive_weight.py",
        "functions": [],
        "classes": [
            "AdaptiveWeight"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/add_bias.py",
        "functions": [],
        "classes": [
            "AddBias"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/arc_cosine_feature_map.py",
        "functions": [],
        "classes": [
            "ArcCosineFeatureMap"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/batch_huber_loss.py",
        "functions": [],
        "classes": [
            "BatchHuberLoss"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/batch_lr_loss.py",
        "functions": [],
        "classes": [
            "BatchLRLoss"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/batch_mse_loss.py",
        "functions": [],
        "classes": [
            "BatchMSELoss"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/batch_normalization.py",
        "functions": [],
        "classes": [
            "BatchNormalization"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/batch_sigmoid_cross_entropy_loss.py",
        "functions": [],
        "classes": [
            "BatchSigmoidCrossEntropyLoss"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/batch_softmax_loss.py",
        "functions": [],
        "classes": [
            "BatchSoftmaxLoss"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/blob_weighted_sum.py",
        "functions": [],
        "classes": [
            "BlobWeightedSum"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/bpr_loss.py",
        "functions": [],
        "classes": [
            "BPRLoss"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/bucket_weighted.py",
        "functions": [],
        "classes": [
            "BucketWeighted"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/build_index.py",
        "functions": [],
        "classes": [
            "MapToRange"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/concat.py",
        "functions": [
            "get_concatenated_feature_to_index"
        ],
        "classes": [
            "Concat"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/constant_weight.py",
        "functions": [],
        "classes": [
            "ConstantWeight"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/conv.py",
        "functions": [],
        "classes": [
            "Conv"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/dropout.py",
        "functions": [],
        "classes": [
            "Dropout"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/fc.py",
        "functions": [
            "get_fc_predictor_version"
        ],
        "classes": [
            "FC"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/fc_without_bias.py",
        "functions": [],
        "classes": [
            "FCWithoutBias"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/feature_sparse_to_dense.py",
        "functions": [],
        "classes": [
            "FeatureSparseToDense"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/functional.py",
        "functions": [],
        "classes": [
            "Functional"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/gather_record.py",
        "functions": [],
        "classes": [
            "GatherRecord"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/homotopy_weight.py",
        "functions": [],
        "classes": [
            "HomotopyWeight"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/label_smooth.py",
        "functions": [],
        "classes": [
            "LabelSmooth"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/last_n_window_collector.py",
        "functions": [],
        "classes": [
            "LastNWindowCollector"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/layers.py",
        "functions": [
            "almost_equal_schemas",
            "get_key",
            "get_categorical_limit",
            "get_avg_length",
            "set_request_only",
            "register_layer",
            "layer_exists",
            "get_layer_class",
            "create_layer",
            "is_request_only_scalar"
        ],
        "classes": [
            "InstantiationContext",
            "LayerParameter",
            "ModelLayer"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/layer_normalization.py",
        "functions": [],
        "classes": [
            "LayerNormalization"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/margin_rank_loss.py",
        "functions": [],
        "classes": [
            "MarginRankLoss"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/merge_id_lists.py",
        "functions": [],
        "classes": [
            "MergeIdLists"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/pairwise_similarity.py",
        "functions": [],
        "classes": [
            "PairwiseSimilarity"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/position_weighted.py",
        "functions": [],
        "classes": [
            "PositionWeighted"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/random_fourier_features.py",
        "functions": [],
        "classes": [
            "RandomFourierFeatures"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/reservoir_sampling.py",
        "functions": [],
        "classes": [
            "ReservoirSampling"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/sampling_train.py",
        "functions": [],
        "classes": [
            "SamplingTrain"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/sampling_trainable_mixin.py",
        "functions": [],
        "classes": [
            "SamplingTrainableMixin"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/select_record_by_context.py",
        "functions": [],
        "classes": [
            "SelectRecordByContext"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/semi_random_features.py",
        "functions": [],
        "classes": [
            "SemiRandomFeatures"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/sparse_dropout_with_replacement.py",
        "functions": [],
        "classes": [
            "SparseDropoutWithReplacement"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/sparse_feature_hash.py",
        "functions": [],
        "classes": [
            "SparseFeatureHash"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/sparse_lookup.py",
        "functions": [
            "get_trainer_version_based_on_optim",
            "get_sparse_lookup_predictor_version",
            "get_sparse_lookup_trainer_version",
            "_is_id_list",
            "_is_id_score_list"
        ],
        "classes": [
            "SparseLookup"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/split.py",
        "functions": [],
        "classes": [
            "Split"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/tags.py",
        "functions": [],
        "classes": [
            "TagContext",
            "Tags"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/uniform_sampling.py",
        "functions": [],
        "classes": [
            "UniformSampling"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/layers/__init__.py",
        "functions": [
            "import_recursive",
            "find_subclasses_recursively"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/mint/app.py",
        "functions": [
            "jsonify_nvd3",
            "visualize_summary",
            "visualize_print_log",
            "visualize_file",
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/mint/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/mkl/mkl_concat_op_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/mkl/mkl_conv_op_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/mkl/mkl_copy_op_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/mkl/mkl_elementwise_add_op_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/mkl/mkl_elementwise_sum_op_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/mkl/mkl_fc_op_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/mkl/mkl_fc_speed_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/mkl/mkl_fill_op_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/mkl/mkl_LRN_op_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/mkl/mkl_LRN_speed_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/mkl/mkl_pool_op_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/mkl/mkl_pool_speed_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/mkl/mkl_relu_op_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/mkl/mkl_sbn_op_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/mkl/mkl_sbn_speed_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/mkl/mkl_sigmoid_op_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/mkl/mkl_speed_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/mkl/mkl_squeeze_op_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/mkl/rewrite_graph.py",
        "functions": [
            "rewrite_init_net_simple",
            "last_producer",
            "fix_BoxWithNMSLimit",
            "rewrite_run_net_simple",
            "rewrite_run_net_simple_xrayocr_lstm",
            "rewrite_model_helper_simple"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/mkl/rewrite_graph_test.py",
        "functions": [
            "deterministic_io",
            "simple_fc",
            "double_matmul",
            "simple_relu",
            "simple_mlp",
            "simple_cnn",
            "alexnet",
            "simple_resnet",
            "complex_resnet"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/mkl/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/modeling/compute_histogram_for_blobs.py",
        "functions": [],
        "classes": [
            "ComputeHistogramForBlobs"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/modeling/compute_histogram_for_blobs_test.py",
        "functions": [],
        "classes": [
            "ComputeHistogramForBlobsTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/modeling/compute_norm_for_blobs.py",
        "functions": [],
        "classes": [
            "ComputeNormForBlobs"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/modeling/compute_norm_for_blobs_test.py",
        "functions": [],
        "classes": [
            "ComputeNormForBlobsTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/modeling/compute_statistics_for_blobs.py",
        "functions": [],
        "classes": [
            "ComputeStatisticsForBlobs"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/modeling/compute_statistics_for_blobs_test.py",
        "functions": [],
        "classes": [
            "ComputeStatisticsForBlobsTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/modeling/get_entry_from_blobs.py",
        "functions": [],
        "classes": [
            "GetEntryFromBlobs"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/modeling/get_entry_from_blobs_test.py",
        "functions": [],
        "classes": [
            "GetEntryFromBlobsTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/modeling/gradient_clipping.py",
        "functions": [],
        "classes": [
            "GradientClipping"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/modeling/gradient_clipping_test.py",
        "functions": [],
        "classes": [
            "GradientClippingTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/modeling/initializers.py",
        "functions": [
            "update_initializer"
        ],
        "classes": [
            "Initializer",
            "ExternalInitializer",
            "PseudoFP16Initializer",
            "ReversePseudoFP16Initializer"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/modeling/initializers_test.py",
        "functions": [],
        "classes": [
            "InitializerTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/modeling/net_modifier.py",
        "functions": [],
        "classes": [
            "NetModifier"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/modeling/parameter_info.py",
        "functions": [],
        "classes": [
            "ParameterTags",
            "ParameterInfo"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/modeling/parameter_sharing.py",
        "functions": [
            "_normalize_namescope"
        ],
        "classes": [
            "ParameterSharingContext"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/modeling/parameter_sharing_test.py",
        "functions": [],
        "classes": [
            "ParameterSharingTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/modeling/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/models/download.py",
        "functions": [
            "signalHandler",
            "deleteDirectory",
            "progressBar",
            "downloadFromURLToFile",
            "getURLFromName",
            "downloadModel",
            "validModelName"
        ],
        "classes": [
            "ModelDownloader"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/models/imagenet_trainer_test_utils.py",
        "functions": [
            "has_blob",
            "count_blobs",
            "count_shared_blobs",
            "test_shared_grads",
            "test_forward_only",
            "test_forward_only_fast_simplenet"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/models/resnet.py",
        "functions": [
            "create_resnet_32x32",
            "create_resnext",
            "create_resnet50"
        ],
        "classes": [
            "ResNetBuilder"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/models/resnet_test.py",
        "functions": [],
        "classes": [
            "ResnetMemongerTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/models/shufflenet.py",
        "functions": [
            "create_shufflenet"
        ],
        "classes": [
            "ShuffleNetV2Builder"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/models/shufflenet_test.py",
        "functions": [],
        "classes": [
            "ShufflenetMemongerTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/models/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/models/__sym_init__.py",
        "functions": [
            "_parseFile"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/models/seq2seq/beam_search.py",
        "functions": [],
        "classes": [
            "BeamSearchForwardOnly"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/models/seq2seq/seq2seq_beam_search_test.py",
        "functions": [],
        "classes": [
            "Seq2SeqBeamSearchTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/models/seq2seq/seq2seq_model_helper.py",
        "functions": [],
        "classes": [
            "Seq2SeqModelHelper"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/models/seq2seq/seq2seq_model_helper_test.py",
        "functions": [],
        "classes": [
            "Seq2SeqModelHelperTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/models/seq2seq/seq2seq_util.py",
        "functions": [
            "gen_vocab",
            "get_numberized_sentence",
            "rnn_unidirectional_layer",
            "rnn_bidirectional_layer",
            "build_embeddings",
            "get_layer_scope",
            "build_embedding_encoder",
            "build_initial_rnn_decoder_states",
            "build_embedding_decoder",
            "output_projection"
        ],
        "classes": [
            "LSTMWithAttentionDecoder"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/models/seq2seq/train.py",
        "functions": [
            "prepare_batch",
            "gen_batches",
            "run_seq2seq_model",
            "main"
        ],
        "classes": [
            "Seq2SeqModelCaffe2"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/models/seq2seq/translate.py",
        "functions": [
            "_weighted_sum",
            "run_seq2seq_beam_decoder",
            "main"
        ],
        "classes": [
            "Seq2SeqModelCaffe2EnsembleDecoderBase",
            "Seq2SeqModelCaffe2EnsembleDecoder"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/models/seq2seq/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/onnx/backend.py",
        "functions": [
            "force_unicode",
            "get_device_option",
            "convertAttributeProto"
        ],
        "classes": [
            "OnnxAttributes",
            "OnnxNode",
            "Caffe2Backend"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/onnx/backend_cpp_rep.py",
        "functions": [],
        "classes": [
            "Caffe2CppRep"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/onnx/backend_rep.py",
        "functions": [],
        "classes": [
            "Caffe2Rep"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/onnx/error.py",
        "functions": [],
        "classes": [
            "BaseException",
            "Unsupported"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/onnx/frontend.py",
        "functions": [],
        "classes": [
            "Caffe2Frontend"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/onnx/helper.py",
        "functions": [
            "c2_native_run_op",
            "c2_native_run_net",
            "load_caffe2_net",
            "save_caffe2_net",
            "benchmark_caffe2_model",
            "benchmark_pytorch_model"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/onnx/onnxifi.py",
        "functions": [
            "onnxifi_caffe2_net"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/onnx/test_onnxifi.py",
        "functions": [
            "_print_net"
        ],
        "classes": [
            "OnnxifiTest",
            "OnnxifiTransformTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/onnx/workspace.py",
        "functions": [],
        "classes": [
            "_WorkspaceCtx",
            "Workspace"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/onnx/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/onnx/bin/conversion.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/onnx/bin/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/onnx/tests/c2_ref_test.py",
        "functions": [],
        "classes": [
            "TestCaffe2Basic",
            "TestCaffe2End2End"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/onnx/tests/conversion_test.py",
        "functions": [],
        "classes": [
            "TestConversion"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/onnx/tests/helper_test.py",
        "functions": [],
        "classes": [
            "TestCaffe2Basic"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/onnx/tests/onnx_backend_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/onnx/tests/ssa_test.py",
        "functions": [],
        "classes": [
            "TestFrontendSSAConversion"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/onnx/tests/test_utils.py",
        "functions": [],
        "classes": [
            "TestCase"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/onnx/tests/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/activation_ops_test.py",
        "functions": [],
        "classes": [
            "TestActivations"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/adadelta_test.py",
        "functions": [],
        "classes": [
            "TestAdadelta"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/adagrad_test.py",
        "functions": [],
        "classes": [
            "TestAdagrad"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/adagrad_test_helper.py",
        "functions": [
            "ref_adagrad",
            "adagrad_sparse_test_helper"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/adam_test.py",
        "functions": [],
        "classes": [
            "TestAdam"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/affine_channel_op_test.py",
        "functions": [],
        "classes": [
            "TestAffineChannelOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/alias_with_name_test.py",
        "functions": [],
        "classes": [
            "TestAliasWithNameOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/apmeter_test.py",
        "functions": [
            "calculate_ap"
        ],
        "classes": [
            "TestAPMeterOps"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/arg_ops_test.py",
        "functions": [],
        "classes": [
            "TestArgOps"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/assert_test.py",
        "functions": [],
        "classes": [
            "TestAssert"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/async_net_barrier_test.py",
        "functions": [],
        "classes": [
            "TestAsyncNetBarrierOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/atomic_ops_test.py",
        "functions": [],
        "classes": [
            "TestAtomicOps"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/basic_rnn_test.py",
        "functions": [
            "basic_rnn_reference"
        ],
        "classes": [
            "BasicRNNCellTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/batch_box_cox_test.py",
        "functions": [],
        "classes": [
            "TestBatchBoxCox"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/batch_bucketize_op_test.py",
        "functions": [],
        "classes": [
            "TestBatchBucketize"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/batch_sparse_to_dense_op_test.py",
        "functions": [],
        "classes": [
            "TestBatchSparseToDense"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/bbox_transform_test.py",
        "functions": [
            "bbox_transform",
            "clip_tiled_boxes",
            "generate_rois",
            "bbox_transform_rotated",
            "clip_tiled_boxes_rotated",
            "generate_rois_rotated"
        ],
        "classes": [
            "TestBBoxTransformOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/bisect_percentile_op_test.py",
        "functions": [],
        "classes": [
            "TestBisectPercentileOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/blobs_queue_db_test.py",
        "functions": [],
        "classes": [
            "BlobsQueueDBTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/boolean_mask_test.py",
        "functions": [],
        "classes": [
            "TestBooleanMaskOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/boolean_unmask_test.py",
        "functions": [],
        "classes": [
            "TestUnmaskOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/box_with_nms_limit_op_test.py",
        "functions": [
            "get_op",
            "gen_boxes",
            "gen_multiple_boxes"
        ],
        "classes": [
            "TestBoxWithNMSLimitOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/bucketize_op_test.py",
        "functions": [],
        "classes": [
            "TestBucketizeOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/cast_op_test.py",
        "functions": [],
        "classes": [
            "TestCastOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/ceil_op_test.py",
        "functions": [],
        "classes": [
            "TestCeil"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/channel_backprop_stats_op_test.py",
        "functions": [],
        "classes": [
            "TestChannelBackpropStats"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/channel_shuffle_test.py",
        "functions": [],
        "classes": [
            "ChannelShuffleOpsTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/channel_stats_op_test.py",
        "functions": [],
        "classes": [
            "TestChannelStatsOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/checkpoint_test.py",
        "functions": [],
        "classes": [
            "CheckpointTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/clip_op_test.py",
        "functions": [],
        "classes": [
            "TestClip"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/clip_tensor_op_test.py",
        "functions": [],
        "classes": [
            "TestClipTensorByScalingOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/concat_split_op_test.py",
        "functions": [],
        "classes": [
            "TestConcatSplitOps"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/conditional_test.py",
        "functions": [],
        "classes": [
            "TestConditionalOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/conftest.py",
        "functions": [
            "pytest_addoption",
            "pytest_configure"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/conv_test.py",
        "functions": [
            "_cudnn_supports",
            "_cudnn_convolution_algo_count"
        ],
        "classes": [
            "TestConvolution"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/conv_transpose_test.py",
        "functions": [],
        "classes": [
            "TestConvolutionTranspose"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/copy_ops_test.py",
        "functions": [],
        "classes": [
            "CopyOpsTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/copy_rows_to_tensor_op_test.py",
        "functions": [
            "get_input_tensors"
        ],
        "classes": [
            "TestCopyRowsToTensor"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/cosine_embedding_criterion_op_test.py",
        "functions": [],
        "classes": [
            "TestCosineEmbeddingCriterion"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/counter_ops_test.py",
        "functions": [],
        "classes": [
            "TestCounterOps"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/crf_test.py",
        "functions": [],
        "classes": [
            "TestCRFOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/cross_entropy_ops_test.py",
        "functions": [
            "sigmoid",
            "sigmoid_cross_entropy_with_logits",
            "sigmoid_cross_entropy_with_logits_grad",
            "sigmoid_cross_entropy_with_logits_with_log_D_trick",
            "sigmoid_cross_entropy_with_logits_with_log_D_trick_grad",
            "unjoined_sigmoid_cross_entropy",
            "unjoined_sigmoid_cross_entropy_grad"
        ],
        "classes": [
            "TestCrossEntropyOps"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/ctc_beam_search_decoder_op_test.py",
        "functions": [],
        "classes": [
            "TestCTCBeamSearchDecoderOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/ctc_greedy_decoder_op_test.py",
        "functions": [],
        "classes": [
            "TestCTCGreedyDecoderOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/cudnn_recurrent_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/dataset_ops_test.py",
        "functions": [
            "_assert_arrays_equal",
            "_assert_records_equal"
        ],
        "classes": [
            "TestDatasetOps"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/deform_conv_test.py",
        "functions": [
            "_cudnn_supports",
            "_conv_1d_output_size",
            "_conv_2d_output_size",
            "_conv_2d_offsets_dims",
            "_conv_2d_random_offsets",
            "_conv_2d_shuffle_offsets"
        ],
        "classes": [
            "TestConvolution"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/dense_vector_to_id_list_op_test.py",
        "functions": [
            "dense_vector_to_id_list_ref"
        ],
        "classes": [
            "TestDenseVectorToIdList"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/depthwise_3x3_conv_test.py",
        "functions": [],
        "classes": [
            "Depthwise3x3ConvOpsTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/detectron_keypoints.py",
        "functions": [
            "heatmaps_to_keypoints",
            "scores_to_probs",
            "approx_heatmap_keypoint"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/distance_op_test.py",
        "functions": [],
        "classes": [
            "DistanceTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/dropout_op_test.py",
        "functions": [],
        "classes": [
            "TestDropout"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/duplicate_operands_test.py",
        "functions": [],
        "classes": [
            "TestDuplicateOperands"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/elementwise_linear_op_test.py",
        "functions": [],
        "classes": [
            "TestElementwiseLinearOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/elementwise_logical_ops_test.py",
        "functions": [
            "mux",
            "rowmux"
        ],
        "classes": [
            "TestWhere",
            "TestRowWhere",
            "TestIsMemberOf"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/elementwise_ops_test.py",
        "functions": [],
        "classes": [
            "TestElementwiseOps"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/elementwise_op_broadcast_test.py",
        "functions": [],
        "classes": [
            "TestElementwiseBroadcast"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/emptysample_ops_test.py",
        "functions": [],
        "classes": [
            "TestEmptySampleOps"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/batch_moments_op_test.py",
        "functions": [],
        "classes": [
            "TestBatchMomentsOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/collect_and_distribute_fpn_rpn_proposals_op_test.py",
        "functions": [
            "boxes_area",
            "map_rois_to_fpn_levels",
            "collect",
            "distribute",
            "collect_and_distribute_fpn_rpn_ref",
            "collect_rpn_ref",
            "distribute_fpn_ref"
        ],
        "classes": [
            "TestCollectAndDistributeFpnRpnProposals"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/data_couple_op_test.py",
        "functions": [],
        "classes": [
            "TestDataCoupleOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/enforce_finite_op_test.py",
        "functions": [],
        "classes": [
            "TestEnforceFinite"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/given_tensor_byte_string_to_uint8_fill_op_test.py",
        "functions": [],
        "classes": [
            "TestGivenTensorByteStringToUInt8FillOps"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/integral_image_ops_test.py",
        "functions": [],
        "classes": [
            "TestIntegralImageOps"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/loss_ops_test.py",
        "functions": [],
        "classes": [
            "TestLossOps"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/ngram_ops_test.py",
        "functions": [],
        "classes": [
            "TestNGramOps"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/rand_quantization_op_speed_test.py",
        "functions": [],
        "classes": [
            "TestSpeedFloatToFusedRandRowwiseQuantized"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/segment_ops_test.py",
        "functions": [
            "sparse_lengths_sum_ref",
            "sparse_lengths_mean_ref",
            "sum_grad",
            "logsumexp",
            "logsumexp_grad",
            "logmeanexp",
            "mean",
            "mean_grad",
            "max_fwd",
            "max_grad",
            "sparse_lengths_weighted_sum_ref",
            "sparse_lengths_weighted_sum_grad_ref"
        ],
        "classes": [
            "TesterBase",
            "SegmentsTester",
            "LengthsTester",
            "TestSegmentOps"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/specialized_segment_ops_test.py",
        "functions": [],
        "classes": [
            "TestSpecializedSegmentOps"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/ensure_clipped_test.py",
        "functions": [],
        "classes": [
            "TestEnsureClipped"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/ensure_cpu_output_op_test.py",
        "functions": [],
        "classes": [
            "TestEnsureCPUOutputOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/erf_op_test.py",
        "functions": [],
        "classes": [
            "TestErfOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/expand_op_test.py",
        "functions": [],
        "classes": [
            "TestExpandOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/fc_operator_test.py",
        "functions": [],
        "classes": [
            "TestFcOperator"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/feature_maps_ops_test.py",
        "functions": [],
        "classes": [
            "TestFeatureMapsOps"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/filler_ops_test.py",
        "functions": [
            "_fill_diagonal"
        ],
        "classes": [
            "TestFillerOperator"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/find_op_test.py",
        "functions": [],
        "classes": [
            "TestFindOperator"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/flatten_op_test.py",
        "functions": [],
        "classes": [
            "TestFlatten"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/flexible_top_k_test.py",
        "functions": [],
        "classes": [
            "TestFlexibleTopK"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/floor_op_test.py",
        "functions": [],
        "classes": [
            "TestFloor"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/fused_nbit_rowwise_conversion_ops_test.py",
        "functions": [
            "bytes_to_half_floats",
            "half_floats_to_bytes",
            "int8_to_bytes",
            "fused_rowwise_nbit_quantize_reference",
            "fused_rowwise_nbit_quantize_dequantize_reference",
            "ErrorThresholdRow"
        ],
        "classes": [
            "TestFusedNBitRowwiseQuantizationConversion",
            "TestNBitFakeFused",
            "TestNBitGreedyFused"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/fused_nbit_rowwise_test_helper.py",
        "functions": [
            "param_search_greedy",
            "_compress_uniform_simplified"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/gather_ops_test.py",
        "functions": [
            "ref_gather_axis0",
            "ref_gather",
            "ref_gather_match_outer"
        ],
        "classes": [
            "TestGatherOps",
            "TestBatchGatherOps",
            "TestGatherFused8BitRowwise"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/gather_ranges_op_test.py",
        "functions": [
            "batched_boarders_and_data",
            "gather_ranges",
            "gather_ranges_to_dense",
            "gather_ranges_to_dense_with_key"
        ],
        "classes": [
            "TestGatherRanges"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/given_tensor_fill_op_test.py",
        "functions": [],
        "classes": [
            "TestGivenTensorFillOps"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/glu_op_test.py",
        "functions": [],
        "classes": [
            "TestGlu"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/group_conv_test.py",
        "functions": [],
        "classes": [
            "TestGroupConvolution"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/group_norm_op_test.py",
        "functions": [],
        "classes": [
            "TestGroupNormOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/gru_test.py",
        "functions": [
            "gru_unit",
            "gru_reference",
            "gru_unit_op_input",
            "gru_input",
            "_prepare_gru_unit_op"
        ],
        "classes": [
            "GRUCellTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/heatmap_max_keypoint_op_test.py",
        "functions": [
            "heatmap_FAIR_keypoint_ref",
            "heatmap_approx_keypoint_ref",
            "c10_op_ref"
        ],
        "classes": [
            "TestHeatmapMaxKeypointOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/histogram_test.py",
        "functions": [],
        "classes": [
            "TestHistogram"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/hsm_test.py",
        "functions": [],
        "classes": [
            "TestHsm"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/hyperbolic_ops_test.py",
        "functions": [],
        "classes": [
            "TestHyperbolicOps"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/im2col_col2im_test.py",
        "functions": [],
        "classes": [
            "TestReduceFrontSum"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/image_input_op_test.py",
        "functions": [
            "verify_apply_bounding_box",
            "verify_rescale",
            "verify_crop",
            "verify_color_normalize",
            "caffe2_img",
            "create_test",
            "run_test"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/index_hash_ops_test.py",
        "functions": [],
        "classes": [
            "TestIndexHashOps"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/index_ops_test.py",
        "functions": [],
        "classes": [
            "TestIndexOps"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/instance_norm_test.py",
        "functions": [],
        "classes": [
            "TestInstanceNorm"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/jsd_ops_test.py",
        "functions": [
            "entropy",
            "jsd",
            "jsd_grad"
        ],
        "classes": [
            "TestJSDOps"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/key_split_ops_test.py",
        "functions": [],
        "classes": [
            "TestKeySplitOps"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/lars_test.py",
        "functions": [],
        "classes": [
            "TestLars"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/layer_norm_op_test.py",
        "functions": [
            "_layer_norm_ref",
            "_layer_norm_with_affine_ref",
            "_layer_norm_grad_ref"
        ],
        "classes": [
            "TestLayerNormOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/leaky_relu_test.py",
        "functions": [],
        "classes": [
            "TestLeakyRelu"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/learning_rate_adaption_op_test.py",
        "functions": [],
        "classes": [
            "TestLearningRateAdaption"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/learning_rate_op_test.py",
        "functions": [],
        "classes": [
            "TestLearningRate"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/lengths_pad_op_test.py",
        "functions": [],
        "classes": [
            "TestLengthsPadOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/lengths_reducer_fused_nbit_rowwise_ops_test.py",
        "functions": [],
        "classes": [
            "TestLengthsReducerOpsFusedNBitRowwise"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/lengths_tile_op_test.py",
        "functions": [],
        "classes": [
            "TestLengthsTileOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/lengths_top_k_ops_test.py",
        "functions": [],
        "classes": [
            "TestLengthsTopKOps"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/length_split_op_test.py",
        "functions": [],
        "classes": [
            "TestLengthSplitOperator"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/listwise_l2r_operator_test.py",
        "functions": [],
        "classes": [
            "TestListwiseL2rOps"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/load_save_test.py",
        "functions": [],
        "classes": [
            "TestLoadSaveBase",
            "TestLoadSave"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/locally_connected_op_test.py",
        "functions": [],
        "classes": [
            "TestLocallyConnectedOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/lpnorm_op_test.py",
        "functions": [],
        "classes": [
            "LpnormTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/map_ops_test.py",
        "functions": [],
        "classes": [
            "TestMap"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/margin_ranking_criterion_op_test.py",
        "functions": [],
        "classes": [
            "TestMarginRankingCriterion"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/math_ops_test.py",
        "functions": [],
        "classes": [
            "TestMathOps"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/matmul_op_test.py",
        "functions": [],
        "classes": [
            "TestMatMul",
            "TestBatchMatMul"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/mean_op_test.py",
        "functions": [],
        "classes": [
            "TestMean"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/merge_id_lists_op_test.py",
        "functions": [
            "merge_id_lists_ref"
        ],
        "classes": [
            "TestMergeIdListsOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/mkl_conv_op_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/mkl_packed_fc_op_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/mod_op_test.py",
        "functions": [],
        "classes": [
            "TestMod"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/moments_op_test.py",
        "functions": [],
        "classes": [
            "TestMomentsOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/momentum_sgd_test.py",
        "functions": [],
        "classes": [
            "TestMomentumSGD"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/mpi_test.py",
        "functions": [
            "SetupMPI"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/mul_gradient_benchmark.py",
        "functions": [
            "benchmark_mul_gradient"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/negate_gradient_op_test.py",
        "functions": [],
        "classes": [
            "TestNegateGradient"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/normalize_op_test.py",
        "functions": [],
        "classes": [
            "TestNormalizeOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/numpy_tile_op_test.py",
        "functions": [],
        "classes": [
            "TestNumpyTile"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/one_hot_ops_test.py",
        "functions": [
            "_one_hots"
        ],
        "classes": [
            "TestOneHotOps"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/onnx_while_test.py",
        "functions": [],
        "classes": [
            "TestONNXWhile"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/order_switch_test.py",
        "functions": [],
        "classes": [
            "OrderSwitchOpsTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/pack_ops_test.py",
        "functions": [],
        "classes": [
            "TestTensorPackOps"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/pack_rnn_sequence_op_test.py",
        "functions": [],
        "classes": [
            "TestPackRNNSequenceOperator"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/pad_test.py",
        "functions": [],
        "classes": [
            "TestPad"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/partition_ops_test.py",
        "functions": [],
        "classes": [
            "TestPartitionOps"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/percentile_op_test.py",
        "functions": [],
        "classes": [
            "TestPercentileOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/piecewise_linear_transform_test.py",
        "functions": [],
        "classes": [
            "TestPiecewiseLinearTransform"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/pooling_test.py",
        "functions": [],
        "classes": [
            "TestPooling"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/prepend_dim_test.py",
        "functions": [],
        "classes": [
            "TestPrependDim"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/python_op_test.py",
        "functions": [],
        "classes": [
            "PythonOpTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/quantile_test.py",
        "functions": [],
        "classes": [
            "TestQuantile"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/rand_quantization_op_test.py",
        "functions": [],
        "classes": [
            "TestFloatToFusedRandRowwiseQuantized"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/rank_loss_operator_test.py",
        "functions": [],
        "classes": [
            "TestPairWiseLossOps"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/rebatching_queue_test.py",
        "functions": [
            "primefac"
        ],
        "classes": [
            "TestReBatchingQueue"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/record_queue_test.py",
        "functions": [],
        "classes": [
            "TestRecordQueue"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/recurrent_network_test.py",
        "functions": [],
        "classes": [
            "RecurrentNetworkTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/recurrent_net_executor_test.py",
        "functions": [],
        "classes": [
            "TestRNNExecutor"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/reduce_ops_test.py",
        "functions": [
            "getNorm"
        ],
        "classes": [
            "TestReduceOps",
            "TestReduceFrontReductions"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/reduction_ops_test.py",
        "functions": [],
        "classes": [
            "TestReductionOps"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/reshape_ops_test.py",
        "functions": [
            "_test_reshape_output_and_gradient"
        ],
        "classes": [
            "TestLengthsToShapeOps"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/resize_op_test.py",
        "functions": [],
        "classes": [
            "TestResize"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/rmac_regions_op_test.py",
        "functions": [],
        "classes": [
            "RMACRegionsOpTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/rms_norm_op_test.py",
        "functions": [],
        "classes": [
            "TestRMSNormOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/rnn_cell_test.py",
        "functions": [
            "lstm_unit",
            "layer_norm_with_scale_and_bias_ref",
            "layer_norm_lstm_reference",
            "lstm_reference",
            "multi_lstm_reference",
            "compute_regular_attention_logits",
            "compute_recurrent_attention_logits",
            "compute_dot_attention_logits",
            "compute_coverage_attention_logits",
            "lstm_with_attention_reference",
            "lstm_with_regular_attention_reference",
            "lstm_with_recurrent_attention_reference",
            "lstm_with_dot_attention_reference",
            "lstm_with_dot_attention_reference_same_dim",
            "lstm_with_dot_attention_reference_different_dim",
            "lstm_with_coverage_attention_reference",
            "milstm_reference",
            "layer_norm_milstm_reference",
            "lstm_input",
            "_prepare_attention",
            "prepare_mul_rnn"
        ],
        "classes": [
            "MulCell",
            "RNNCellTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/roi_align_rotated_op_test.py",
        "functions": [],
        "classes": [
            "RoIAlignRotatedOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/rowwise_counter_test.py",
        "functions": [
            "update_counter_ref"
        ],
        "classes": [
            "TestRowWiseCounter"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/scale_op_test.py",
        "functions": [],
        "classes": [
            "TestScaleOps"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/self_binning_histogram_test.py",
        "functions": [],
        "classes": [
            "TestSelfBinningHistogramBase",
            "TestSelfBinningHistogramLinear",
            "TestSelfBinningHistogramLogarithmic",
            "TestSelfBinningHistogramLinearFloat",
            "TestSelfBinningHistogramLogarithmicFloat",
            "TestSelfBinningHistogramLinearWithAbs",
            "TestSelfBinningHistogramLogarithmicWithAbs",
            "TestSelfBinningHistogramLinearFloatWithAbs",
            "TestSelfBinningHistogramLogarithmicFloatWithAbs",
            "TestSelfBinningHistogramLinearWithNoneAbs",
            "TestSelfBinningHistogramLinearFloatWithNoneAbs"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/selu_op_test.py",
        "functions": [],
        "classes": [
            "TestSelu"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/sequence_ops_test.py",
        "functions": [
            "_gen_test_add_padding",
            "_add_padding_ref",
            "_remove_padding_ref",
            "_gather_padding_ref"
        ],
        "classes": [
            "TestSequenceOps"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/shape_inference_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/sinusoid_position_encoding_op_test.py",
        "functions": [],
        "classes": [
            "TestSinusoidPositionEncodingOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/softmax_ops_test.py",
        "functions": [],
        "classes": [
            "TestSoftmaxOps"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/softplus_op_test.py",
        "functions": [],
        "classes": [
            "TestSoftplus"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/sparse_dropout_with_replacement_op_test.py",
        "functions": [],
        "classes": [
            "SparseDropoutWithReplacementTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/sparse_gradient_checker_test.py",
        "functions": [],
        "classes": [
            "TestSparseGradient"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/sparse_lengths_sum_benchmark.py",
        "functions": [
            "benchmark_sparse_lengths_sum"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/sparse_lp_regularizer_test.py",
        "functions": [],
        "classes": [
            "TestSparseLpNorm"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/sparse_normalize_test.py",
        "functions": [],
        "classes": [
            "TestSparseNormalize"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/sparse_ops_test.py",
        "functions": [],
        "classes": [
            "TestScatterOps"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/sparse_to_dense_mask_op_test.py",
        "functions": [],
        "classes": [
            "TestFcOperator"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/spatial_bn_op_test.py",
        "functions": [],
        "classes": [
            "TestSpatialBN"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/square_root_divide_op_test.py",
        "functions": [
            "_data_and_scale",
            "divide_by_square_root",
            "grad"
        ],
        "classes": [
            "TestSquareRootDivide"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/stats_ops_test.py",
        "functions": [],
        "classes": [
            "TestCounterOps"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/stats_put_ops_test.py",
        "functions": [],
        "classes": [
            "TestPutOps"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/storm_test.py",
        "functions": [],
        "classes": [
            "TestStorm"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/string_ops_test.py",
        "functions": [
            "_string_lists"
        ],
        "classes": [
            "TestStringOps"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/text_file_reader_test.py",
        "functions": [],
        "classes": [
            "TestTextFileReader"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/thresholded_relu_op_test.py",
        "functions": [],
        "classes": [
            "TestThresholdedRelu"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/tile_op_test.py",
        "functions": [],
        "classes": [
            "TestTile"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/top_k_test.py",
        "functions": [],
        "classes": [
            "TestTopK"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/torch_integration_test.py",
        "functions": [
            "generate_rois",
            "generate_rois_rotated",
            "create_bbox_transform_inputs",
            "bytes_to_floats",
            "floats_to_bytes",
            "fused_rowwise_8bit_quantize_reference",
            "fused_rowwise_8bit_quantize_dequantize_reference"
        ],
        "classes": [
            "TorchIntegration"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/transpose_op_test.py",
        "functions": [],
        "classes": [
            "TestTransposeOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/trigonometric_op_test.py",
        "functions": [],
        "classes": [
            "TestTrigonometricOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/unique_ops_test.py",
        "functions": [
            "_unique_ref"
        ],
        "classes": [
            "TestUniqueOps"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/unique_uniform_fill_op_test.py",
        "functions": [],
        "classes": [
            "TestUniqueUniformFillOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/unsafe_coalesce_test.py",
        "functions": [],
        "classes": [
            "TestUnsafeCoalesceOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/upsample_op_test.py",
        "functions": [],
        "classes": [
            "TestUpSample"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/utility_ops_test.py",
        "functions": [],
        "classes": [
            "TestUtilityOps"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/video_input_op_test.py",
        "functions": [],
        "classes": [
            "VideoInputOpTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/weighted_multi_sample_test.py",
        "functions": [],
        "classes": [
            "TestWeightedMultiSample"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/weighted_sample_test.py",
        "functions": [],
        "classes": [
            "TestWeightedSample"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/weighted_sum_test.py",
        "functions": [],
        "classes": [
            "TestWeightedSumOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/weight_scale_test.py",
        "functions": [],
        "classes": [
            "TestWeightScale"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/wngrad_test.py",
        "functions": [
            "ref_wngrad",
            "wngrad_sparse_test_helper"
        ],
        "classes": [
            "TestWngrad"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/operator_test/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/predictor/mobile_exporter.py",
        "functions": [
            "add_tensor",
            "Export"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/predictor/mobile_exporter_test.py",
        "functions": [],
        "classes": [
            "TestMobileExporter"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/predictor/predictor_exporter.py",
        "functions": [
            "get_predictor_exporter_helper",
            "prepare_prediction_net",
            "_global_init_net",
            "get_meta_net_def",
            "set_model_info",
            "save_to_db",
            "load_from_db"
        ],
        "classes": [
            "PredictorExportMeta"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/predictor/predictor_exporter_test.py",
        "functions": [],
        "classes": [
            "MetaNetDefTest",
            "PredictorExporterTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/predictor/predictor_py_utils.py",
        "functions": [
            "create_predict_net",
            "create_predict_init_net",
            "get_comp_name",
            "_ProtoMapGet",
            "GetPlan",
            "GetPlanOriginal",
            "GetBlobs",
            "GetBlobsByTypePrefix",
            "GetNet",
            "GetNetOriginal",
            "GetApplicationSpecificInfo",
            "AddBlobs",
            "ReplaceBlobs",
            "AddPlan",
            "AddNet",
            "SetBlobsOrder",
            "SetPreLoadBlobs",
            "SetRequestOnlyEmbeddings",
            "GetBlobsOrder",
            "SetTensorBoundShapes",
            "SetAOTConfig",
            "GetArgumentByName",
            "AddModelIdArg"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/predictor/predictor_test.py",
        "functions": [],
        "classes": [
            "TestPredictor"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/predictor/serde.py",
        "functions": [
            "serialize_protobuf_struct",
            "deserialize_protobuf_struct"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/predictor/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/rnn/lstm_comparison.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/rnn/rnn_cell_test_util.py",
        "functions": [
            "sigmoid",
            "tanh",
            "_prepare_rnn"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/rnn/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/serialized_test/coverage.py",
        "functions": [
            "gen_serialized_test_coverage",
            "gen_coverage_sets",
            "gen_covered_ops"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/serialized_test/serialized_test_util.py",
        "functions": [
            "given",
            "_getGradientOrNone",
            "_transformList",
            "_prepare_dir",
            "testWithArgs"
        ],
        "classes": [
            "SerializedTestCase"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/serialized_test/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/test/blob_deallocation_test.py",
        "functions": [],
        "classes": [
            "BlobDeallocationTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/test/do_op_test.py",
        "functions": [],
        "classes": [
            "DoOpTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/test/executor_test.py",
        "functions": [],
        "classes": [
            "ExecutorCPUConvNetTest",
            "ExecutorFailingOpTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/test/executor_test_util.py",
        "functions": [
            "executor_test_settings",
            "gen_test_resnet50",
            "conv_model_generators",
            "executor_test_model_names",
            "build_conv_model",
            "build_resnet50_dataparallel_model",
            "run_resnet50_epoch"
        ],
        "classes": [
            "ExecutorTestBase"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/test/fakefp16_transform_test.py",
        "functions": [],
        "classes": [
            "Transformer"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/test/gpu_context_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/test/inference_lstm_op_test.py",
        "functions": [],
        "classes": [
            "TestC2LSTM"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/test/python_protobuf_test.py",
        "functions": [],
        "classes": [
            "TestCrossProtoCalls"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/test/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/trt/test_pt_onnx_trt.py",
        "functions": [
            "allocate_buffers",
            "load_normalized_test_case"
        ],
        "classes": [
            "Test_PT_ONNX_TRT"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/trt/test_trt.py",
        "functions": [
            "_print_net",
            "_base_url",
            "_download_onnx_model"
        ],
        "classes": [
            "TensorRTOpTest",
            "TensorRTTransformTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/python/trt/transform.py",
        "functions": [
            "_dim_values_to_list",
            "_get_output_shapes",
            "check_gpu_",
            "convert_onnx_model_to_trt_op",
            "_infer_shapes",
            "transform_caffe2_net"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/python/trt/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/quantization/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/quantization/server/batch_matmul_dnnlowp_op_test.py",
        "functions": [],
        "classes": [
            "DNNLowPBatchMatMulOpTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/quantization/server/batch_permutation_dnnlowp_op_test.py",
        "functions": [],
        "classes": [
            "DNNLowPBatchPermutationOpTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/quantization/server/channel_shuffle_dnnlowp_op_test.py",
        "functions": [],
        "classes": [
            "DNNLowPChannelShuffleOpsTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/quantization/server/compute_equalization_scale_test.py",
        "functions": [],
        "classes": [
            "TestComputeEqualizationScaleOp"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/quantization/server/concat_dnnlowp_op_test.py",
        "functions": [],
        "classes": [
            "DNNLowPConcatOpTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/quantization/server/conv_depthwise_dnnlowp_op_test.py",
        "functions": [],
        "classes": [
            "DNNLowPOpConvDepthWiseTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/quantization/server/conv_dnnlowp_acc16_op_test.py",
        "functions": [],
        "classes": [
            "DNNLowPOpConvAcc16OpTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/quantization/server/conv_dnnlowp_op_test.py",
        "functions": [],
        "classes": [
            "DNNLowPOpConvTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/quantization/server/conv_groupwise_dnnlowp_acc16_op_test.py",
        "functions": [],
        "classes": [
            "GroupWiseDNNLowPOpConvAcc16OpTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/quantization/server/conv_groupwise_dnnlowp_op_test.py",
        "functions": [],
        "classes": [
            "GroupWiseDNNLowPOpConvTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/quantization/server/dequantize_dnnlowp_op_test.py",
        "functions": [],
        "classes": [
            "DNNLowPDequantizeOpTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/quantization/server/dnnlowp_test_utils.py",
        "functions": [
            "check_quantized_results_close",
            "pairwise",
            "avoid_vpmaddubsw_overflow_fc",
            "avoid_vpmaddubsw_overflow",
            "generate_convnd_inputs",
            "generate_conv_inputs",
            "run_conv_or_fc"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/quantization/server/elementwise_linear_dnnlowp_op_test.py",
        "functions": [],
        "classes": [
            "DNNLowPElementwiseLinearOpTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/quantization/server/elementwise_mul_dnnlowp_op_test.py",
        "functions": [],
        "classes": [
            "DNNLowPMulOpTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/quantization/server/elementwise_sum_dnnlowp_op_test.py",
        "functions": [],
        "classes": [
            "DNNLowPOpSumOpTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/quantization/server/elementwise_add_dnnlowp_op_test.py",
        "functions": [],
        "classes": [
            "DNNLowPAddOpTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/quantization/server/fully_connected_fp16_test.py",
        "functions": [
            "mse"
        ],
        "classes": [
            "FullyConnectedFP16Test"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/quantization/server/observer_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/quantization/server/fully_connected_dnnlowp_acc16_op_test.py",
        "functions": [],
        "classes": [
            "DNNLowPFullyConnectedAcc16OpTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/quantization/server/fully_connected_dnnlowp_op_test.py",
        "functions": [],
        "classes": [
            "DNNLowPFullyConnectedOpTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/quantization/server/fully_connected_rowwise_dnnlowp_op_test.py",
        "functions": [],
        "classes": [
            "RowWiseDNNLowPFullyConnectedOpTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/quantization/server/gather_dnnlowp_op_test.py",
        "functions": [],
        "classes": [
            "DNNLowPGatherOpTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/quantization/server/group_norm_dnnlowp_op_test.py",
        "functions": [],
        "classes": [
            "DNNLowPOpGroupNormTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/quantization/server/int8_gen_quant_params_min_max_test.py",
        "functions": [],
        "classes": [
            "TestInt8GenQuantParamsMinMaxOperator"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/quantization/server/int8_gen_quant_params_test.py",
        "functions": [],
        "classes": [
            "TestInt8GenQuantParamsOperator"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/quantization/server/int8_quant_scheme_blob_fill_test.py",
        "functions": [],
        "classes": [
            "TestInt8QuantSchemeBlobFillOperator"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/quantization/server/lstm_unit_dnnlowp_op_test.py",
        "functions": [],
        "classes": [
            "DNNLowPLSTMUnitOpTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/quantization/server/pool_dnnlowp_op_test.py",
        "functions": [],
        "classes": [
            "DNNLowPOpPoolTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/quantization/server/quantize_dnnlowp_op_test.py",
        "functions": [],
        "classes": [
            "DNNLowPQuantizeOpTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/quantization/server/relu_dnnlowp_op_test.py",
        "functions": [],
        "classes": [
            "DNNLowPReluOpTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/quantization/server/resize_nearest_3d_dnnlowp_op_test.py",
        "functions": [],
        "classes": [
            "DNNLowPResizeNearest3DOpTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/quantization/server/resize_nearest_dnnlowp_op_test.py",
        "functions": [],
        "classes": [
            "DNNLowPResizeNearestOpTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/quantization/server/sigmoid_dnnlowp_op_test.py",
        "functions": [],
        "classes": [
            "DNNLowPSigmoidOpTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/quantization/server/spatial_batch_norm_dnnlowp_op_test.py",
        "functions": [],
        "classes": [
            "DNNLowPOpSpatialBNTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/quantization/server/tanh_dnnlowp_op_test.py",
        "functions": [],
        "classes": [
            "DNNLowPTanhOpTest"
        ]
    },
    {
        "file_path": "../pytorch/caffe2/quantization/server/utils.py",
        "functions": [
            "pairwise",
            "blob_uses",
            "fuse_first_bn",
            "fuse_bn",
            "fuse_first_scale",
            "fuse_scale",
            "fuse_first_relu",
            "fuse_relu",
            "last_producer",
            "swap_first_concat_relu",
            "swap_concat_relu",
            "add_version_to_conv_bias",
            "add_quantization_param_args_",
            "choose_quantization_params",
            "add_quantization_param_args",
            "create_int8_given_tensor_fill",
            "create_int8_bias_tensor_fill"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/caffe2/quantization/server/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/.circleci/ensure-consistency.py",
        "functions": [
            "check_consistency"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/.circleci/generate_config_yml.py",
        "functions": [
            "horizontal_rule",
            "gen_build_workflows_tree",
            "stitch_sources"
        ],
        "classes": [
            "File",
            "FunctionGen",
            "Treegen",
            "Listgen",
            "Header"
        ]
    },
    {
        "file_path": "../pytorch/.circleci/cimodel/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/.circleci/cimodel/data/binary_build_data.py",
        "functions": [
            "get_processor_arch_name"
        ],
        "classes": [
            "TopLevelNode",
            "OSConfigNode",
            "PackageFormatConfigNode",
            "LinuxGccConfigNode",
            "WindowsLibtorchConfigNode",
            "ArchConfigNode",
            "PyVersionConfigNode",
            "LinkingVariantConfigNode",
            "DependencyInclusionConfigNode"
        ]
    },
    {
        "file_path": "../pytorch/.circleci/cimodel/data/binary_build_definitions.py",
        "functions": [
            "get_root",
            "gen_build_env_list",
            "predicate_exclude_macos",
            "get_nightly_uploads",
            "get_post_upload_jobs",
            "get_nightly_tests",
            "get_jobs",
            "get_binary_build_jobs",
            "get_binary_smoke_test_jobs"
        ],
        "classes": [
            "Conf"
        ]
    },
    {
        "file_path": "../pytorch/.circleci/cimodel/data/dimensions.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/.circleci/cimodel/data/pytorch_build_data.py",
        "functions": [
            "get_major_pyver"
        ],
        "classes": [
            "TreeConfigNode",
            "TopLevelNode",
            "DistroConfigNode",
            "PyVerConfigNode",
            "ExperimentalFeatureConfigNode",
            "PureTorchConfigNode",
            "XlaConfigNode",
            "AsanConfigNode",
            "ONNXConfigNode",
            "VulkanConfigNode",
            "ParallelTBBConfigNode",
            "ParallelNativeConfigNode",
            "LibTorchConfigNode",
            "CudaGccOverrideConfigNode",
            "BuildOnlyConfigNode",
            "ShardTestConfigNode",
            "CoverageConfigNode",
            "ImportantConfigNode",
            "XenialCompilerConfigNode",
            "BionicCompilerConfigNode",
            "XenialCompilerVersionConfigNode",
            "BionicCompilerVersionConfigNode"
        ]
    },
    {
        "file_path": "../pytorch/.circleci/cimodel/data/pytorch_build_definitions.py",
        "functions": [
            "gen_dependent_configs",
            "gen_docs_configs",
            "get_root",
            "gen_tree",
            "instantiate_configs",
            "get_workflow_jobs"
        ],
        "classes": [
            "HiddenConf",
            "DocPushConf"
        ]
    },
    {
        "file_path": "../pytorch/.circleci/cimodel/data/windows_build_definitions.py",
        "functions": [
            "FalsePred",
            "TruePred",
            "get_windows_workflows"
        ],
        "classes": [
            "WindowsJob",
            "VcSpec"
        ]
    },
    {
        "file_path": "../pytorch/.circleci/cimodel/data/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/.circleci/cimodel/data/simple/anaconda_prune_defintions.py",
        "functions": [
            "gen_workflow_job",
            "get_workflow_jobs"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/.circleci/cimodel/data/simple/android_definitions.py",
        "functions": [
            "get_workflow_jobs"
        ],
        "classes": [
            "AndroidJob",
            "AndroidGradleJob"
        ]
    },
    {
        "file_path": "../pytorch/.circleci/cimodel/data/simple/bazel_definitions.py",
        "functions": [
            "gen_job_name",
            "get_workflow_jobs"
        ],
        "classes": [
            "BazelJob"
        ]
    },
    {
        "file_path": "../pytorch/.circleci/cimodel/data/simple/binary_smoketest.py",
        "functions": [
            "get_workflow_jobs"
        ],
        "classes": [
            "SmoketestJob"
        ]
    },
    {
        "file_path": "../pytorch/.circleci/cimodel/data/simple/docker_definitions.py",
        "functions": [
            "get_workflow_jobs"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/.circleci/cimodel/data/simple/ge_config_tests.py",
        "functions": [
            "get_workflow_jobs"
        ],
        "classes": [
            "GeConfigTestJob"
        ]
    },
    {
        "file_path": "../pytorch/.circleci/cimodel/data/simple/ios_definitions.py",
        "functions": [
            "get_platform",
            "get_workflow_jobs"
        ],
        "classes": [
            "ArchVariant",
            "IOSJob"
        ]
    },
    {
        "file_path": "../pytorch/.circleci/cimodel/data/simple/macos_definitions.py",
        "functions": [
            "get_workflow_jobs"
        ],
        "classes": [
            "MacOsJob"
        ]
    },
    {
        "file_path": "../pytorch/.circleci/cimodel/data/simple/mobile_definitions.py",
        "functions": [
            "get_workflow_jobs"
        ],
        "classes": [
            "MobileJob"
        ]
    },
    {
        "file_path": "../pytorch/.circleci/cimodel/data/simple/nightly_android.py",
        "functions": [
            "get_workflow_jobs"
        ],
        "classes": [
            "AndroidNightlyJob"
        ]
    },
    {
        "file_path": "../pytorch/.circleci/cimodel/data/simple/nightly_ios.py",
        "functions": [
            "get_workflow_jobs"
        ],
        "classes": [
            "IOSNightlyJob"
        ]
    },
    {
        "file_path": "../pytorch/.circleci/cimodel/data/simple/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/.circleci/cimodel/data/simple/util/branch_filters.py",
        "functions": [
            "gen_filter_dict"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/.circleci/cimodel/data/simple/util/docker_constants.py",
        "functions": [
            "gen_docker_image",
            "gen_docker_image_requires",
            "gen_mobile_docker"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/.circleci/cimodel/data/simple/util/versions.py",
        "functions": [],
        "classes": [
            "MultiPartVersion",
            "CudaVersion"
        ]
    },
    {
        "file_path": "../pytorch/.circleci/cimodel/data/simple/util/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/.circleci/cimodel/lib/conf_tree.py",
        "functions": [
            "X",
            "XImportant",
            "dfs_recurse",
            "dfs"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/.circleci/cimodel/lib/miniutils.py",
        "functions": [
            "quote",
            "sandwich",
            "override"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/.circleci/cimodel/lib/miniyaml.py",
        "functions": [
            "is_dict",
            "is_collection",
            "render"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/.circleci/cimodel/lib/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/.circleci/codegen_validation/normalize_yaml_fragment.py",
        "functions": [
            "regurgitate"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/.circleci/ecr_gc_docker/docker_hub.py",
        "functions": [
            "build_access_token",
            "list_repos",
            "list_tags",
            "save_to_s3"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/.circleci/ecr_gc_docker/gc.py",
        "functions": [
            "save_to_s3",
            "repos",
            "images",
            "chunks",
            "looks_like_git_sha"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/.circleci/scripts/upload_binary_size_to_scuba.py",
        "functions": [
            "get_size",
            "build_message",
            "send_message",
            "report_android_sizes"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/.jenkins/pytorch/print_sccache_log.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/.jenkins/pytorch/perf_test/compare_with_baseline.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/.jenkins/pytorch/perf_test/get_stats.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/.jenkins/pytorch/perf_test/update_commit_hash.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/.jenkins/pytorch/win-test-helpers/run_python_nn_smoketests.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/android/pytorch_android/generate_test_asset.cpp",
        "functions": [
            "main(int argc, char* argv[])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/android/pytorch_android/generate_test_torchscripts.py",
        "functions": [
            "scriptAndSave"
        ],
        "classes": [
            "Test"
        ]
    },
    {
        "file_path": "../pytorch/android/pytorch_android/src/main/cpp/pytorch_jni_common.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/android/pytorch_android/src/main/cpp/pytorch_jni_jit.cpp",
        "functions": [
            "jint JNICALL"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/android/pytorch_android/src/main/cpp/pytorch_jni_lite.cpp",
        "functions": [
            "jint JNICALL"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/android/pytorch_android_torchvision/src/main/cpp/pytorch_vision_jni.cpp",
        "functions": [
            "jint"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/android/test_app/make_assets.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/android/test_app/make_assets_custom.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/android/test_app/app/src/main/cpp/pytorch_testapp_jni.cpp",
        "functions": [
            "jint"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/autocast_mode.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/BatchedFallback.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/BatchedTensorImpl.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/BatchingRegistrations.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/Context.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/CPUGeneratorImpl.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/DLConvertor.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/DynamicLibrary.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/ExpandUtils.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/function_wrapper.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/gen_vulkan_glsl.py",
        "functions": [
            "findAllGlsls",
            "getName",
            "genCppH",
            "parse_arg_env",
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/gen_vulkan_spv.py",
        "functions": [
            "getName",
            "genCppH",
            "parse_arg_env",
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/LegacyTHFunctionsCPU.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/MemoryOverlap.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/NamedTensorUtils.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/ParallelCommon.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/ParallelNative.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/ParallelNativeTBB.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/ParallelOpenMP.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/ParallelThreadPoolNative.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/record_function.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/ScalarOps.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/SequenceNumber.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/SparseTensorImpl.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/SparseTensorUtils.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/TensorGeometry.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/TensorIndexing.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/TensorIterator.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/TensorMeta.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/TensorNames.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/TensorUtils.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/ThreadLocalState.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/Utils.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/Version.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/VmapMode.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/VmapModeRegistrations.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/VmapTransforms.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/benchmarks/quantize_per_channel.cpp",
        "functions": [
            "void",
            "void",
            "void",
            "void",
            "void"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/benchmarks/stateful_conv1d.cpp",
        "functions": [
            "void",
            "void"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/benchmarks/tensor_add.cpp",
        "functions": [
            "void",
            "void"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/ATenGeneral.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp",
        "functions": [
            "{\n  m.fallback(torch::CppFunction::makeFallthrough());\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/blob.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/custom_class.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/DeprecatedTypeProperties.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/DeprecatedTypePropertiesRegistry.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/Dict.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/Dimname.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/Formatting.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/function_schema.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/Generator.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/grad_mode.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/interned_strings.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/ivalue.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/Range.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/register_symbols.cpp",
        "functions": [
            ": sym_to_info_(static_cast<size_t>(_keys::num_symbols))"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/library.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/List.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/List_test.cpp",
        "functions": [
            "{\n    List<string> list;\n    EXPECT_TRUE(list.empty());\n}",
            "{\n    List<string> list({\"3\"});\n    EXPECT_FALSE(list.empty());\n}",
            "{\n    List<string> list;\n    EXPECT_EQ(0, list.size());\n}",
            "{\n    List<string> list({\"3\", \"4\"});\n    EXPECT_EQ(2, list.size());\n}",
            "{\n  List<string> list({\"3\", \"4\"});\n  list.clear();\n  EXPECT_TRUE(list.empty());\n}",
            "{\n  List<string> list({\"3\", \"4\"});\n  EXPECT_EQ(\"3\", list.get(0));\n  EXPECT_EQ(\"4\", list.get(1));\n}",
            "{\n  List<string> list({\"3\", \"4\"});\n  EXPECT_THROW(list.get(2), std::out_of_range);\n}",
            "{\n  List<string> list({\"3\", \"4\"});\n  EXPECT_EQ(\"3\", list.extract(0));\n  EXPECT_EQ(\"4\", list.extract(1));\n}",
            "{\n  List<string> list({\"3\", \"4\"});\n  list.extract(0);\n  EXPECT_EQ(\"\", list.get(0));\n}",
            "{\n  List<string> list({\"3\", \"4\"});\n  EXPECT_THROW(list.extract(2), std::out_of_range);\n}",
            "{\n  List<string> list({\"3\", \"4\"});\n  string value = \"5\";\n  list.set(1, value);\n  EXPECT_EQ(\"3\", list.get(0));\n  EXPECT_EQ(\"5\", list.get(1));\n}",
            "{\n  List<string> list({\"3\", \"4\"});\n  string value = \"5\";\n  list.set(1, std::move(value));\n  EXPECT_EQ(\"3\", list.get(0));\n  EXPECT_EQ(\"5\", list.get(1));\n}",
            "{\n  List<string> list({\"3\", \"4\"});\n  string value = \"5\";\n  EXPECT_THROW(list.set(2, value), std::out_of_range);\n}",
            "{\n  List<string> list({\"3\", \"4\"});\n  string value = \"5\";\n  EXPECT_THROW(list.set(2, std::move(value)), std::out_of_range);\n}",
            "{\n  List<string> list({\"3\", \"4\"});\n  EXPECT_EQ(\"3\", static_cast<string>(list[0]));\n  EXPECT_EQ(\"4\", static_cast<string>(list[1]));\n}",
            "{\n  List<string> list({\"3\", \"4\", \"5\"});\n  list[1] = \"6\";\n  EXPECT_EQ(\"3\", list.get(0));\n  EXPECT_EQ(\"6\", list.get(1));\n  EXPECT_EQ(\"5\", list.get(2));\n}",
            "{\n  List<string> list({\"3\", \"4\", \"5\"});\n  list[1] = list[2];\n  EXPECT_EQ(\"3\", list.get(0));\n  EXPECT_EQ(\"5\", list.get(1));\n  EXPECT_EQ(\"5\", list.get(2));\n}",
            "{\n  List<string> list({\"3\", \"4\", \"5\"});\n  swap(list[1], list[2]);\n  EXPECT_EQ(\"3\", list.get(0));\n  EXPECT_EQ(\"5\", list.get(1));\n  EXPECT_EQ(\"4\", list.get(2));\n}",
            "{\n  List<string> list({\"3\", \"4\"});\n  EXPECT_THROW(list[2], std::out_of_range);\n}",
            "{\n  List<string> list({\"3\", \"4\", \"6\"});\n  string v = \"5\";\n  list.insert(list.begin() + 2, v);\n  EXPECT_EQ(4, list.size());\n  EXPECT_EQ(\"5\", list.get(2));\n}",
            "{\n  List<string> list({\"3\", \"4\", \"6\"});\n  string v = \"5\";\n  list.insert(list.begin() + 2, std::move(v));\n  EXPECT_EQ(4, list.size());\n  EXPECT_EQ(\"5\", list.get(2));\n}",
            "{\n  List<string> list({\"3\", \"4\", \"6\"});\n  string v = \"5\";\n  List<string>::iterator result = list.insert(list.begin() + 2, v);\n  EXPECT_EQ(list.begin() + 2, result);\n}",
            "{\n  List<string> list({\"3\", \"4\", \"6\"});\n  string v = \"5\";\n  List<string>::iterator result = list.insert(list.begin() + 2, std::move(v));\n  EXPECT_EQ(list.begin() + 2, result);\n}",
            "{\n  List<string> list({\"3\", \"4\", \"6\"});\n  string v = \"5\";\n  list.emplace(list.begin() + 2, v);\n  EXPECT_EQ(4, list.size());\n  EXPECT_EQ(\"5\", list.get(2));\n}",
            "{\n  List<string> list({\"3\", \"4\", \"6\"});\n  string v = \"5\";\n  list.emplace(list.begin() + 2, std::move(v));\n  EXPECT_EQ(4, list.size());\n  EXPECT_EQ(\"5\", list.get(2));\n}",
            "{\n  List<string> list({\"3\", \"4\", \"6\"});\n  list.emplace(list.begin() + 2, \"5\"); // const char* is a constructor arg to std::string\n  EXPECT_EQ(4, list.size());\n  EXPECT_EQ(\"5\", list.get(2));\n}",
            "{\n  List<string> list;\n  string v = \"5\";\n  list.push_back(v);\n  EXPECT_EQ(1, list.size());\n  EXPECT_EQ(\"5\", list.get(0));\n}",
            "{\n  List<string> list;\n  string v = \"5\";\n  list.push_back(std::move(v));\n  EXPECT_EQ(1, list.size());\n  EXPECT_EQ(\"5\", list.get(0));\n}",
            "{\n  List<string> list;\n  string v = \"5\";\n  list.emplace_back(v);\n  EXPECT_EQ(1, list.size());\n  EXPECT_EQ(\"5\", list.get(0));\n}",
            "{\n  List<string> list;\n  string v = \"5\";\n  list.emplace_back(std::move(v));\n  EXPECT_EQ(1, list.size());\n  EXPECT_EQ(\"5\", list.get(0));\n}",
            "{\n  List<string> list;\n  list.emplace_back(\"5\");  // const char* is a constructor arg to std::string\n  EXPECT_EQ(1, list.size());\n  EXPECT_EQ(\"5\", list.get(0));\n}",
            "{\n  List<string> list;\n  const List<string> clist;\n  EXPECT_EQ(list.begin(), list.end());\n  EXPECT_EQ(list.begin(), list.end());\n  EXPECT_EQ(clist.begin(), clist.end());\n  EXPECT_EQ(clist.begin(), clist.end());\n}",
            "{\n  List<string> list({\"3\", \"5\"});\n  bool found_first = false;\n  bool found_second = false;\n  for (List<string>::iterator iter = list.begin(); iter != list.end(); ++iter) {\n    if (static_cast<string>(*iter) == \"3\") {\n      EXPECT_FALSE(found_first);\n      found_first = true;\n    } else if (static_cast<string>(*iter) == \"5\") {\n      EXPECT_FALSE(found_second);\n      found_second = true;\n    } else {\n      ADD_FAILURE();\n    }\n  }\n  EXPECT_TRUE(found_first);\n  EXPECT_TRUE(found_second);\n}",
            "{\n  List<string> list({\"3\", \"5\"});\n  bool found_first = false;\n  bool found_second = false;\n  for (const string& elem : list) {\n    if (elem == \"3\") {\n      EXPECT_FALSE(found_first);\n      found_first = true;\n    } else if (elem == \"5\") {\n      EXPECT_FALSE(found_second);\n      found_second = true;\n    } else {\n      ADD_FAILURE();\n    }\n  }\n  EXPECT_TRUE(found_first);\n  EXPECT_TRUE(found_second);\n}",
            "{\n  List<string> list({\"3\"});\n  list.erase(list.begin());\n  EXPECT_TRUE(list.empty());\n}",
            "{\n  List<string> list({\"1\", \"2\", \"3\"});\n  List<string>::iterator iter = list.erase(list.begin() + 1);\n  EXPECT_EQ(list.begin() + 1, iter);\n}",
            "{\n  List<string> list({\"1\", \"2\", \"3\"});\n  list.erase(list.begin(), list.end());\n  EXPECT_TRUE(list.empty());\n}",
            "{\n  List<string> list;\n  list.reserve(100);\n}",
            "{\n  List<string> list1({\"3\", \"4\"});\n\n  List<string> list2(list1);\n\n  EXPECT_EQ(2, list2.size());\n  EXPECT_EQ(\"3\", list2.get(0));\n  EXPECT_EQ(\"4\", list2.get(1));\n}",
            "{\n  List<string> list1({\"3\", \"4\"});\n\n  List<string> list2;\n  list2 = list1;\n\n  EXPECT_EQ(2, list2.size());\n  EXPECT_EQ(\"3\", list2.get(0));\n  EXPECT_EQ(\"4\", list2.get(1));\n}",
            "{\n  List<string> list1({\"3\", \"4\"});\n\n  List<string> list2 = list1.copy();\n\n  EXPECT_EQ(2, list2.size());\n  EXPECT_EQ(\"3\", list2.get(0));\n  EXPECT_EQ(\"4\", list2.get(1));\n}",
            "{\n  List<string> list1({\"3\", \"4\"});\n\n  List<string> list2(std::move(list1));\n\n  EXPECT_EQ(2, list2.size());\n  EXPECT_EQ(\"3\", list2.get(0));\n  EXPECT_EQ(\"4\", list2.get(1));\n}",
            "{\n  List<string> list1({\"3\", \"4\"});\n\n  List<string> list2;\n  list2 = std::move(list1);\n\n  EXPECT_EQ(2, list2.size());\n  EXPECT_EQ(\"3\", list2.get(0));\n  EXPECT_EQ(\"4\", list2.get(1));\n}",
            "{\n  List<string> list1({\"3\", \"4\"});\n\n  List<string> list2(std::move(list1));\n  EXPECT_TRUE(list1.empty());\n}",
            "{\n  List<string> list1({\"3\", \"4\"});\n\n  List<string> list2;\n  list2 = std::move(list1);\n  EXPECT_TRUE(list1.empty());\n}",
            "{\n  List<string> list({\"3\", \"4\"});\n\n  List<string>::iterator iter1 = list.begin();\n  List<string>::iterator iter2 = iter1++;\n  EXPECT_NE(\"3\", static_cast<string>(*iter1));\n  EXPECT_EQ(\"3\", static_cast<string>(*iter2));\n}",
            "{\n  List<string> list({\"3\", \"4\"});\n\n  List<string>::iterator iter1 = list.begin();\n  List<string>::iterator iter2 = ++iter1;\n  EXPECT_NE(\"3\", static_cast<string>(*iter1));\n  EXPECT_NE(\"3\", static_cast<string>(*iter2));\n}",
            "{\n  List<string> list({\"3\", \"4\"});\n\n  List<string>::iterator iter1 = list.end() - 1;\n  List<string>::iterator iter2 = iter1--;\n  EXPECT_NE(\"4\", static_cast<string>(*iter1));\n  EXPECT_EQ(\"4\", static_cast<string>(*iter2));\n}",
            "{\n  List<string> list({\"3\", \"4\"});\n\n  List<string>::iterator iter1 = list.end() - 1;\n  List<string>::iterator iter2 = --iter1;\n  EXPECT_NE(\"4\", static_cast<string>(*iter1));\n  EXPECT_NE(\"4\", static_cast<string>(*iter2));\n}",
            "{\n  List<string> list({\"3\", \"4\", \"5\"});\n\n  List<string>::iterator iter1 = list.begin();\n  List<string>::iterator iter2 = iter1 += 2;\n  EXPECT_EQ(\"5\", static_cast<string>(*iter1));\n  EXPECT_EQ(\"5\", static_cast<string>(*iter2));\n}",
            "{\n  List<string> list({\"3\", \"4\", \"5\"});\n\n  List<string>::iterator iter1 = list.end();\n  List<string>::iterator iter2 = iter1 -= 2;\n  EXPECT_EQ(\"4\", static_cast<string>(*iter1));\n  EXPECT_EQ(\"4\", static_cast<string>(*iter2));\n}",
            "{\n  List<string> list({\"3\", \"4\", \"5\"});\n\n  List<string>::iterator iter1 = list.begin();\n  List<string>::iterator iter2 = iter1 + 2;\n  EXPECT_EQ(\"3\", static_cast<string>(*iter1));\n  EXPECT_EQ(\"5\", static_cast<string>(*iter2));\n}",
            "{\n  List<string> list({\"3\", \"4\", \"5\"});\n\n  List<string>::iterator iter1 = list.end() - 1;\n  List<string>::iterator iter2 = iter1 - 2;\n  EXPECT_EQ(\"5\", static_cast<string>(*iter1));\n  EXPECT_EQ(\"3\", static_cast<string>(*iter2));\n}",
            "{\n  List<string> list({\"3\", \"4\"});\n  EXPECT_EQ(2, list.end() - list.begin());\n}",
            "{\n  List<string> list({\"3\", \"4\"});\n\n  List<string>::iterator iter1 = list.begin();\n  List<string>::iterator iter2 = list.begin();\n  EXPECT_TRUE(iter1 == iter2);\n  EXPECT_FALSE(iter1 != iter2);\n}",
            "{\n  List<string> list({\"3\", \"4\"});\n\n  List<string>::iterator iter1 = list.begin();\n  List<string>::iterator iter2 = list.begin();\n  iter2++;\n\n  EXPECT_FALSE(iter1 == iter2);\n  EXPECT_TRUE(iter1 != iter2);\n}",
            "{\n  List<string> list({\"3\"});\n\n  List<string>::iterator iter = list.begin();\n  EXPECT_EQ(\"3\", static_cast<string>(*iter));\n}",
            "{\n  List<string> list({\"3\"});\n\n  List<string>::iterator iter = list.begin();\n  *iter = \"4\";\n  EXPECT_EQ(\"4\", list.get(0));\n}",
            "{\n  List<string> list({\"3\", \"4\"});\n\n  List<string>::iterator iter = list.begin();\n  *iter = *(iter + 1);\n  EXPECT_EQ(\"4\", list.get(0));\n  EXPECT_EQ(\"4\", list.get(1));\n}",
            "{\n  List<string> list({\"3\", \"4\"});\n\n  List<string>::iterator iter = list.begin();\n  swap(*iter, *(iter + 1));\n  EXPECT_EQ(\"4\", list.get(0));\n  EXPECT_EQ(\"3\", list.get(1));\n}",
            "{\n  List<string> list({\"3\"});\n  list.pop_back();\n  EXPECT_TRUE(list.empty());\n}",
            "{\n  List<string> list;\n  list.resize(2);\n  EXPECT_EQ(2, list.size());\n  EXPECT_EQ(\"\", list.get(0));\n  EXPECT_EQ(\"\", list.get(1));\n}",
            "{\n  List<string> list;\n  list.resize(2, \"value\");\n  EXPECT_EQ(2, list.size());\n  EXPECT_EQ(\"value\", list.get(0));\n  EXPECT_EQ(\"value\", list.get(1));\n}",
            "{\n  List<string> list1;\n  List<string> list2(list1);\n  List<string> list3;\n  list3 = list1;\n\n  list1.push_back(\"three\");\n  EXPECT_EQ(1, list1.size());\n  EXPECT_EQ(1, list2.size());\n  EXPECT_EQ(1, list3.size());\n}",
            "{\n  List<string> list1;\n  List<string> list2(list1.copy());\n  List<string> list3;\n  list3 = list1.copy();\n\n  list1.push_back(\"three\");\n  EXPECT_EQ(1, list1.size());\n  EXPECT_EQ(0, list2.size());\n  EXPECT_EQ(0, list3.size());\n}",
            "{\n  List<string> list1({\"first\", \"second\"});\n  List<string> list2({\"first\", \"second\"});\n\n  EXPECT_EQ(list1, list2);\n}",
            "{\n  List<string> list1({\"first\", \"second\"});\n  List<string> list2({\"first\", \"not_second\"});\n\n  EXPECT_NE(list1, list2);\n}",
            "{\n    List<int64_t> list;\n    EXPECT_TRUE(list.empty());\n}",
            "{\n    List<int64_t> list({3});\n    EXPECT_FALSE(list.empty());\n}",
            "{\n    List<int64_t> list;\n    EXPECT_EQ(0, list.size());\n}",
            "{\n    List<int64_t> list({3, 4});\n    EXPECT_EQ(2, list.size());\n}",
            "{\n  List<int64_t> list({3, 4});\n  list.clear();\n  EXPECT_TRUE(list.empty());\n}",
            "{\n  List<int64_t> list({3, 4});\n  EXPECT_EQ(3, list.get(0));\n  EXPECT_EQ(4, list.get(1));\n}",
            "{\n  List<int64_t> list({3, 4});\n  EXPECT_THROW(list.get(2), std::out_of_range);\n}",
            "{\n  List<int64_t> list({3, 4});\n  EXPECT_EQ(3, list.extract(0));\n  EXPECT_EQ(4, list.extract(1));\n}",
            "{\n  List<int64_t> list({3, 4});\n  EXPECT_THROW(list.extract(2), std::out_of_range);\n}",
            "{\n  List<int64_t> list({3, 4});\n  int64_t value = 5;\n  list.set(1, value);\n  EXPECT_EQ(3, list.get(0));\n  EXPECT_EQ(5, list.get(1));\n}",
            "{\n  List<int64_t> list({3, 4});\n  int64_t value = 5;\n  list.set(1, std::move(value));\n  EXPECT_EQ(3, list.get(0));\n  EXPECT_EQ(5, list.get(1));\n}",
            "{\n  List<int64_t> list({3, 4});\n  int64_t value = 5;\n  EXPECT_THROW(list.set(2, value), std::out_of_range);\n}",
            "{\n  List<int64_t> list({3, 4});\n  int64_t value = 5;\n  EXPECT_THROW(list.set(2, std::move(value)), std::out_of_range);\n}",
            "{\n  List<int64_t> list({3, 4});\n  EXPECT_EQ(3, static_cast<int64_t>(list[0]));\n  EXPECT_EQ(4, static_cast<int64_t>(list[1]));\n}",
            "{\n  List<int64_t> list({3, 4, 5});\n  list[1] = 6;\n  EXPECT_EQ(3, list.get(0));\n  EXPECT_EQ(6, list.get(1));\n  EXPECT_EQ(5, list.get(2));\n}",
            "{\n  List<int64_t> list({3, 4, 5});\n  list[1] = list[2];\n  EXPECT_EQ(3, list.get(0));\n  EXPECT_EQ(5, list.get(1));\n  EXPECT_EQ(5, list.get(2));\n}",
            "{\n  List<int64_t> list({3, 4, 5});\n  swap(list[1], list[2]);\n  EXPECT_EQ(3, list.get(0));\n  EXPECT_EQ(5, list.get(1));\n  EXPECT_EQ(4, list.get(2));\n}",
            "{\n  List<int64_t> list({3, 4});\n  EXPECT_THROW(list[2], std::out_of_range);\n}",
            "{\n  List<int64_t> list({3, 4, 6});\n  int64_t v = 5;\n  list.insert(list.begin() + 2, v);\n  EXPECT_EQ(4, list.size());\n  EXPECT_EQ(5, list.get(2));\n}",
            "{\n  List<int64_t> list({3, 4, 6});\n  int64_t v = 5;\n  list.insert(list.begin() + 2, std::move(v));\n  EXPECT_EQ(4, list.size());\n  EXPECT_EQ(5, list.get(2));\n}",
            "{\n  List<int64_t> list({3, 4, 6});\n  int64_t v = 5;\n  List<int64_t>::iterator result = list.insert(list.begin() + 2, v);\n  EXPECT_EQ(list.begin() + 2, result);\n}",
            "{\n  List<int64_t> list({3, 4, 6});\n  int64_t v = 5;\n  List<int64_t>::iterator result = list.insert(list.begin() + 2, std::move(v));\n  EXPECT_EQ(list.begin() + 2, result);\n}",
            "{\n  List<int64_t> list({3, 4, 6});\n  int64_t v = 5;\n  list.emplace(list.begin() + 2, v);\n  EXPECT_EQ(4, list.size());\n  EXPECT_EQ(5, list.get(2));\n}",
            "{\n  List<int64_t> list({3, 4, 6});\n  int64_t v = 5;\n  list.emplace(list.begin() + 2, std::move(v));\n  EXPECT_EQ(4, list.size());\n  EXPECT_EQ(5, list.get(2));\n}",
            "{\n  List<int64_t> list({3, 4, 6});\n  list.emplace(list.begin() + 2, 5); // const char* is a constructor arg to std::int64_t\n  EXPECT_EQ(4, list.size());\n  EXPECT_EQ(5, list.get(2));\n}",
            "{\n  List<int64_t> list;\n  int64_t v = 5;\n  list.push_back(v);\n  EXPECT_EQ(1, list.size());\n  EXPECT_EQ(5, list.get(0));\n}",
            "{\n  List<int64_t> list;\n  int64_t v = 5;\n  list.push_back(std::move(v));\n  EXPECT_EQ(1, list.size());\n  EXPECT_EQ(5, list.get(0));\n}",
            "{\n  List<int64_t> list;\n  int64_t v = 5;\n  list.emplace_back(v);\n  EXPECT_EQ(1, list.size());\n  EXPECT_EQ(5, list.get(0));\n}",
            "{\n  List<int64_t> list;\n  int64_t v = 5;\n  list.emplace_back(std::move(v));\n  EXPECT_EQ(1, list.size());\n  EXPECT_EQ(5, list.get(0));\n}",
            "{\n  List<int64_t> list;\n  list.emplace_back(5);  // const char* is a constructor arg to std::int64_t\n  EXPECT_EQ(1, list.size());\n  EXPECT_EQ(5, list.get(0));\n}",
            "{\n  List<int64_t> list;\n  const List<int64_t> clist;\n  EXPECT_EQ(list.begin(), list.end());\n  EXPECT_EQ(list.begin(), list.end());\n  EXPECT_EQ(clist.begin(), clist.end());\n  EXPECT_EQ(clist.begin(), clist.end());\n}",
            "{\n  List<int64_t> list({3, 5});\n  bool found_first = false;\n  bool found_second = false;\n  for (List<int64_t>::iterator iter = list.begin(); iter != list.end(); ++iter) {\n    if (static_cast<int64_t>(*iter) == 3) {\n      EXPECT_FALSE(found_first);\n      found_first = true;\n    } else if (static_cast<int64_t>(*iter) == 5) {\n      EXPECT_FALSE(found_second);\n      found_second = true;\n    } else {\n      ADD_FAILURE();\n    }\n  }\n  EXPECT_TRUE(found_first);\n  EXPECT_TRUE(found_second);\n}",
            "{\n  List<int64_t> list({3, 5});\n  bool found_first = false;\n  bool found_second = false;\n  for (const int64_t& elem : list) {\n    if (elem == 3) {\n      EXPECT_FALSE(found_first);\n      found_first = true;\n    } else if (elem == 5) {\n      EXPECT_FALSE(found_second);\n      found_second = true;\n    } else {\n      ADD_FAILURE();\n    }\n  }\n  EXPECT_TRUE(found_first);\n  EXPECT_TRUE(found_second);\n}",
            "{\n  List<int64_t> list({3});\n  list.erase(list.begin());\n  EXPECT_TRUE(list.empty());\n}",
            "{\n  List<int64_t> list({1, 2, 3});\n  List<int64_t>::iterator iter = list.erase(list.begin() + 1);\n  EXPECT_EQ(list.begin() + 1, iter);\n}",
            "{\n  List<int64_t> list({1, 2, 3});\n  list.erase(list.begin(), list.end());\n  EXPECT_TRUE(list.empty());\n}",
            "{\n  List<int64_t> list;\n  list.reserve(100);\n}",
            "{\n  List<int64_t> list1({3, 4});\n\n  List<int64_t> list2(list1);\n\n  EXPECT_EQ(2, list2.size());\n  EXPECT_EQ(3, list2.get(0));\n  EXPECT_EQ(4, list2.get(1));\n}",
            "{\n  List<int64_t> list1({3, 4});\n\n  List<int64_t> list2;\n  list2 = list1;\n\n  EXPECT_EQ(2, list2.size());\n  EXPECT_EQ(3, list2.get(0));\n  EXPECT_EQ(4, list2.get(1));\n}",
            "{\n  List<int64_t> list1({3, 4});\n\n  List<int64_t> list2 = list1.copy();\n\n  EXPECT_EQ(2, list2.size());\n  EXPECT_EQ(3, list2.get(0));\n  EXPECT_EQ(4, list2.get(1));\n}",
            "{\n  List<int64_t> list1({3, 4});\n\n  List<int64_t> list2(std::move(list1));\n\n  EXPECT_EQ(2, list2.size());\n  EXPECT_EQ(3, list2.get(0));\n  EXPECT_EQ(4, list2.get(1));\n}",
            "{\n  List<int64_t> list1({3, 4});\n\n  List<int64_t> list2;\n  list2 = std::move(list1);\n\n  EXPECT_EQ(2, list2.size());\n  EXPECT_EQ(3, list2.get(0));\n  EXPECT_EQ(4, list2.get(1));\n}",
            "{\n  List<int64_t> list1({3, 4});\n\n  List<int64_t> list2(std::move(list1));\n  EXPECT_TRUE(list1.empty());\n}",
            "{\n  List<int64_t> list1({3, 4});\n\n  List<int64_t> list2;\n  list2 = std::move(list1);\n  EXPECT_TRUE(list1.empty());\n}",
            "{\n  List<int64_t> list({3, 4});\n\n  List<int64_t>::iterator iter1 = list.begin();\n  List<int64_t>::iterator iter2 = iter1++;\n  EXPECT_NE(3, static_cast<int64_t>(*iter1));\n  EXPECT_EQ(3, static_cast<int64_t>(*iter2));\n}",
            "{\n  List<int64_t> list({3, 4});\n\n  List<int64_t>::iterator iter1 = list.begin();\n  List<int64_t>::iterator iter2 = ++iter1;\n  EXPECT_NE(3, static_cast<int64_t>(*iter1));\n  EXPECT_NE(3, static_cast<int64_t>(*iter2));\n}",
            "{\n  List<int64_t> list({3, 4});\n\n  List<int64_t>::iterator iter1 = list.end() - 1;\n  List<int64_t>::iterator iter2 = iter1--;\n  EXPECT_NE(4, static_cast<int64_t>(*iter1));\n  EXPECT_EQ(4, static_cast<int64_t>(*iter2));\n}",
            "{\n  List<int64_t> list({3, 4});\n\n  List<int64_t>::iterator iter1 = list.end() - 1;\n  List<int64_t>::iterator iter2 = --iter1;\n  EXPECT_NE(4, static_cast<int64_t>(*iter1));\n  EXPECT_NE(4, static_cast<int64_t>(*iter2));\n}",
            "{\n  List<int64_t> list({3, 4, 5});\n\n  List<int64_t>::iterator iter1 = list.begin();\n  List<int64_t>::iterator iter2 = iter1 += 2;\n  EXPECT_EQ(5, static_cast<int64_t>(*iter1));\n  EXPECT_EQ(5, static_cast<int64_t>(*iter2));\n}",
            "{\n  List<int64_t> list({3, 4, 5});\n\n  List<int64_t>::iterator iter1 = list.end();\n  List<int64_t>::iterator iter2 = iter1 -= 2;\n  EXPECT_EQ(4, static_cast<int64_t>(*iter1));\n  EXPECT_EQ(4, static_cast<int64_t>(*iter2));\n}",
            "{\n  List<int64_t> list({3, 4, 5});\n\n  List<int64_t>::iterator iter1 = list.begin();\n  List<int64_t>::iterator iter2 = iter1 + 2;\n  EXPECT_EQ(3, static_cast<int64_t>(*iter1));\n  EXPECT_EQ(5, static_cast<int64_t>(*iter2));\n}",
            "{\n  List<int64_t> list({3, 4, 5});\n\n  List<int64_t>::iterator iter1 = list.end() - 1;\n  List<int64_t>::iterator iter2 = iter1 - 2;\n  EXPECT_EQ(5, static_cast<int64_t>(*iter1));\n  EXPECT_EQ(3, static_cast<int64_t>(*iter2));\n}",
            "{\n  List<int64_t> list({3, 4});\n  EXPECT_EQ(2, list.end() - list.begin());\n}",
            "{\n  List<int64_t> list({3, 4});\n\n  List<int64_t>::iterator iter1 = list.begin();\n  List<int64_t>::iterator iter2 = list.begin();\n  EXPECT_TRUE(iter1 == iter2);\n  EXPECT_FALSE(iter1 != iter2);\n}",
            "{\n  List<int64_t> list({3, 4});\n\n  List<int64_t>::iterator iter1 = list.begin();\n  List<int64_t>::iterator iter2 = list.begin();\n  iter2++;\n\n  EXPECT_FALSE(iter1 == iter2);\n  EXPECT_TRUE(iter1 != iter2);\n}",
            "{\n  List<int64_t> list({3});\n\n  List<int64_t>::iterator iter = list.begin();\n  EXPECT_EQ(3, static_cast<int64_t>(*iter));\n}",
            "{\n  List<int64_t> list({3});\n\n  List<int64_t>::iterator iter = list.begin();\n  *iter = 4;\n  EXPECT_EQ(4, list.get(0));\n}",
            "{\n  List<int64_t> list({3, 4});\n\n  List<int64_t>::iterator iter = list.begin();\n  *iter = *(iter + 1);\n  EXPECT_EQ(4, list.get(0));\n  EXPECT_EQ(4, list.get(1));\n}",
            "{\n  List<int64_t> list({3, 4});\n\n  List<int64_t>::iterator iter = list.begin();\n  swap(*iter, *(iter + 1));\n  EXPECT_EQ(4, list.get(0));\n  EXPECT_EQ(3, list.get(1));\n}",
            "{\n  List<int64_t> list({3});\n  list.pop_back();\n  EXPECT_TRUE(list.empty());\n}",
            "{\n  List<int64_t> list;\n  list.resize(2);\n  EXPECT_EQ(2, list.size());\n  EXPECT_EQ(0, list.get(0));\n  EXPECT_EQ(0, list.get(1));\n}",
            "{\n  List<int64_t> list;\n  list.resize(2, 5);\n  EXPECT_EQ(2, list.size());\n  EXPECT_EQ(5, list.get(0));\n  EXPECT_EQ(5, list.get(1));\n}",
            "{\n  List<int64_t> list1;\n  List<int64_t> list2(list1);\n  List<int64_t> list3;\n  list3 = list1;\n\n  list1.push_back(3);\n  EXPECT_EQ(1, list1.size());\n  EXPECT_EQ(1, list2.size());\n  EXPECT_EQ(1, list3.size());\n}",
            "{\n  List<int64_t> list1;\n  List<int64_t> list2(list1.copy());\n  List<int64_t> list3;\n  list3 = list1.copy();\n\n  list1.push_back(3);\n  EXPECT_EQ(1, list1.size());\n  EXPECT_EQ(0, list2.size());\n  EXPECT_EQ(0, list3.size());\n}",
            "{\n  List<int64_t> list1({1, 3});\n  List<int64_t> list2({1, 3});\n\n  EXPECT_EQ(list1, list2);\n}",
            "{\n  List<int64_t> list1({1, 3});\n  List<int64_t> list2({1, 2});\n\n  EXPECT_NE(list1, list2);\n}",
            "{\n  List<int64_t> list1({1, 3});\n  const auto list2 = list1;\n\n  EXPECT_TRUE(list1.is(list2));\n}",
            "{\n  List<int64_t> list1({1, 3});\n  const auto list2 = list1.copy();\n\n  EXPECT_FALSE(list1.is(list2));\n}",
            "{\n  List<std::string> list({\"one\", \"two\"});\n  const auto& listRef = list;\n  static_assert(std::is_same<decltype(listRef[1]), const std::string&>::value,\n                \"const List<std::string> acccess should be by const reference\");\n  std::string str = list[1];\n  const std::string& strRef = listRef[1];\n  EXPECT_EQ(\"two\", str);\n  EXPECT_EQ(\"two\", strRef);\n}",
            "{\n  List<c10::optional<std::string>> list({\"one\", \"two\", c10::nullopt});\n  const auto& listRef = list;\n  static_assert(\n      std::is_same<decltype(listRef[1]), c10::optional<std::reference_wrapper<const std::string>>>::value,\n      \"List<c10::optional<std::string>> acccess should be by const reference\");\n  c10::optional<std::string> str1 = list[1];\n  c10::optional<std::string> str2 = list[2];\n  decltype(auto) strRef1 = listRef[1];\n  decltype(auto) strRef2 = listRef[2];\n  EXPECT_EQ(\"two\", str1.value());\n  EXPECT_FALSE(str2.has_value());\n  EXPECT_EQ(\"two\", strRef1.value().get());\n  EXPECT_FALSE(strRef2.has_value());\n}",
            "{\n  List<at::Tensor> list;\n  const auto& listRef = list;\n  static_assert(\n      std::is_same<decltype(listRef[0]), const at::Tensor&>::value,\n      \"List<at::Tensor> access should be by const reference\");\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/NamedRegistrations.cpp",
        "functions": [
            "{\n  m.fallback(CppFunction::makeNamedNotSupported());\n}",
            "{\n  m.impl(\"_bmm\", CppFunction::makeFallthrough());\n  m.impl(\"_bmm.out\", CppFunction::makeFallthrough());\n  m.impl(\"_cdist_forward\", CppFunction::makeFallthrough());\n  m.impl(\"_fused_dropout\", CppFunction::makeFallthrough());\n  m.impl(\"_local_scalar_dense\", CppFunction::makeFallthrough());\n  m.impl(\"_sparse_log_softmax.Dimname\", CppFunction::makeFallthrough());\n  m.impl(\"_sparse_log_softmax.int\", CppFunction::makeFallthrough());\n  m.impl(\"_sparse_softmax.Dimname\", CppFunction::makeFallthrough());\n  m.impl(\"_sparse_softmax.int\", CppFunction::makeFallthrough());\n  m.impl(\"_std\", CppFunction::makeFallthrough());\n  m.impl(\"_var\", CppFunction::makeFallthrough());\n  m.impl(\"abs\", CppFunction::makeFallthrough());\n  m.impl(\"abs.out\", CppFunction::makeFallthrough());\n  m.impl(\"abs_\", CppFunction::makeFallthrough());\n  m.impl(\"absolute\", CppFunction::makeFallthrough());\n  m.impl(\"absolute.out\", CppFunction::makeFallthrough());\n  m.impl(\"absolute_\", CppFunction::makeFallthrough());\n  m.impl(\"acos\", CppFunction::makeFallthrough());\n  m.impl(\"acos.out\", CppFunction::makeFallthrough());\n  m.impl(\"acos_\", CppFunction::makeFallthrough());\n  m.impl(\"acosh\", CppFunction::makeFallthrough());\n  m.impl(\"acosh.out\", CppFunction::makeFallthrough());\n  m.impl(\"acosh_\", CppFunction::makeFallthrough());\n  m.impl(\"add.Scalar\", CppFunction::makeFallthrough());\n  m.impl(\"add.Tensor\", CppFunction::makeFallthrough());\n  m.impl(\"add.out\", CppFunction::makeFallthrough());\n  m.impl(\"add_.Scalar\", CppFunction::makeFallthrough());\n  m.impl(\"add_.Tensor\", CppFunction::makeFallthrough());\n  m.impl(\"_add_relu.Tensor\", CppFunction::makeFallthrough());\n  m.impl(\"_add_relu.out\", CppFunction::makeFallthrough());\n  m.impl(\"_add_relu_.Tensor\", CppFunction::makeFallthrough());\n  m.impl(\"addcdiv\", CppFunction::makeFallthrough());\n  m.impl(\"addcdiv.out\", CppFunction::makeFallthrough());\n  m.impl(\"addcdiv_\", CppFunction::makeFallthrough());\n  m.impl(\"addcmul\", CppFunction::makeFallthrough());\n  m.impl(\"addcmul.out\", CppFunction::makeFallthrough());\n  m.impl(\"addcmul_\", CppFunction::makeFallthrough());\n  m.impl(\"addmm\", CppFunction::makeFallthrough());\n  m.impl(\"addmm.out\", CppFunction::makeFallthrough());\n  m.impl(\"addmm_\", CppFunction::makeFallthrough());\n  m.impl(\"addmv\", CppFunction::makeFallthrough());\n  m.impl(\"addmv.out\", CppFunction::makeFallthrough());\n  m.impl(\"addmv_\", CppFunction::makeFallthrough());\n  m.impl(\"alias\", CppFunction::makeFallthrough());\n  m.impl(\"align_as\", CppFunction::makeFallthrough());\n  m.impl(\"align_tensors\", CppFunction::makeFallthrough());\n  m.impl(\"align_to\", CppFunction::makeFallthrough());\n  m.impl(\"align_to.ellipsis_idx\", CppFunction::makeFallthrough());\n  m.impl(\"all\", CppFunction::makeFallthrough());\n  m.impl(\"angle\", CppFunction::makeFallthrough());\n  m.impl(\"angle.out\", CppFunction::makeFallthrough());\n  m.impl(\"any\", CppFunction::makeFallthrough());\n  m.impl(\"arccosh\", CppFunction::makeFallthrough());\n  m.impl(\"arccosh.out\", CppFunction::makeFallthrough());\n  m.impl(\"arccosh_\", CppFunction::makeFallthrough());\n  m.impl(\"as_strided\", CppFunction::makeFallthrough());\n  m.impl(\"asin\", CppFunction::makeFallthrough());\n  m.impl(\"asin.out\", CppFunction::makeFallthrough());\n  m.impl(\"asin_\", CppFunction::makeFallthrough());\n  m.impl(\"asinh\", CppFunction::makeFallthrough());\n  m.impl(\"asinh.out\", CppFunction::makeFallthrough());\n  m.impl(\"asinh_\", CppFunction::makeFallthrough());\n  m.impl(\"atan\", CppFunction::makeFallthrough());\n  m.impl(\"atan.out\", CppFunction::makeFallthrough());\n  m.impl(\"atan2\", CppFunction::makeFallthrough());\n  m.impl(\"atan2.out\", CppFunction::makeFallthrough());\n  m.impl(\"atan2_\", CppFunction::makeFallthrough());\n  m.impl(\"atan_\", CppFunction::makeFallthrough());\n  m.impl(\"atanh\", CppFunction::makeFallthrough());\n  m.impl(\"atanh.out\", CppFunction::makeFallthrough());\n  m.impl(\"atanh_\", CppFunction::makeFallthrough());\n  m.impl(\"bernoulli\", CppFunction::makeFallthrough());\n  m.impl(\"bernoulli.out\", CppFunction::makeFallthrough());\n  m.impl(\"bernoulli_.Tensor\", CppFunction::makeFallthrough());\n  m.impl(\"bernoulli_.float\", CppFunction::makeFallthrough());\n  m.impl(\"bitwise_not\", CppFunction::makeFallthrough());\n  m.impl(\"bitwise_not.out\", CppFunction::makeFallthrough());\n  m.impl(\"bitwise_not_\", CppFunction::makeFallthrough());\n  m.impl(\"bmm\", CppFunction::makeFallthrough());\n  m.impl(\"bmm.out\", CppFunction::makeFallthrough());\n  m.impl(\"cat\", CppFunction::makeFallthrough());\n  m.impl(\"cat.names\", CppFunction::makeFallthrough());\n  m.impl(\"cat.names_out\", CppFunction::makeFallthrough());\n  m.impl(\"cat.out\", CppFunction::makeFallthrough());\n  m.impl(\"cauchy_\", CppFunction::makeFallthrough());\n  m.impl(\"cdist\", CppFunction::makeFallthrough());\n  m.impl(\"ceil\", CppFunction::makeFallthrough());\n  m.impl(\"ceil.out\", CppFunction::makeFallthrough());\n  m.impl(\"ceil_\", CppFunction::makeFallthrough());\n  m.impl(\"chunk\", CppFunction::makeFallthrough());\n  m.impl(\"clamp\", CppFunction::makeFallthrough());\n  m.impl(\"clamp.out\", CppFunction::makeFallthrough());\n  m.impl(\"clamp_\", CppFunction::makeFallthrough());\n  m.impl(\"clamp_max\", CppFunction::makeFallthrough());\n  m.impl(\"clamp_max.out\", CppFunction::makeFallthrough());\n  m.impl(\"clamp_max_\", CppFunction::makeFallthrough());\n  m.impl(\"clamp_min\", CppFunction::makeFallthrough());\n  m.impl(\"clamp_min.out\", CppFunction::makeFallthrough());\n  m.impl(\"clamp_min_\", CppFunction::makeFallthrough());\n  m.impl(\"clone\", CppFunction::makeFallthrough());\n  m.impl(\"conj\", CppFunction::makeFallthrough());\n  m.impl(\"conj.out\", CppFunction::makeFallthrough());\n  m.impl(\"contiguous\", CppFunction::makeFallthrough());\n  m.impl(\"copy_\", CppFunction::makeFallthrough());\n  m.impl(\"cos\", CppFunction::makeFallthrough());\n  m.impl(\"cos.out\", CppFunction::makeFallthrough());\n  m.impl(\"cos_\", CppFunction::makeFallthrough());\n  m.impl(\"cosh\", CppFunction::makeFallthrough());\n  m.impl(\"cosh.out\", CppFunction::makeFallthrough());\n  m.impl(\"cosh_\", CppFunction::makeFallthrough());\n  m.impl(\"cummax\", CppFunction::makeFallthrough());\n  m.impl(\"cummax.dimname\", CppFunction::makeFallthrough());\n  m.impl(\"cummax.dimname_out\", CppFunction::makeFallthrough());\n  m.impl(\"cummax.out\", CppFunction::makeFallthrough());\n  m.impl(\"cummin\", CppFunction::makeFallthrough());\n  m.impl(\"cummin.dimname\", CppFunction::makeFallthrough());\n  m.impl(\"cummin.dimname_out\", CppFunction::makeFallthrough());\n  m.impl(\"cummin.out\", CppFunction::makeFallthrough());\n  m.impl(\"cumprod\", CppFunction::makeFallthrough());\n  m.impl(\"cumprod.dimname\", CppFunction::makeFallthrough());\n  m.impl(\"cumprod.dimname_out\", CppFunction::makeFallthrough());\n  m.impl(\"cumprod.out\", CppFunction::makeFallthrough());\n  m.impl(\"cumsum\", CppFunction::makeFallthrough());\n  m.impl(\"cumsum.dimname\", CppFunction::makeFallthrough());\n  m.impl(\"cumsum.dimname_out\", CppFunction::makeFallthrough());\n  m.impl(\"cumsum.out\", CppFunction::makeFallthrough());\n  m.impl(\"deg2rad\", CppFunction::makeFallthrough());\n  m.impl(\"deg2rad.out\", CppFunction::makeFallthrough());\n  m.impl(\"deg2rad_\", CppFunction::makeFallthrough());\n  m.impl(\"detach\", CppFunction::makeFallthrough());\n  m.impl(\"detach_\", CppFunction::makeFallthrough());\n  m.impl(\"diagonal\", CppFunction::makeFallthrough());\n  m.impl(\"diagonal.Dimname\", CppFunction::makeFallthrough());\n  m.impl(\"digamma\", CppFunction::makeFallthrough());\n  m.impl(\"digamma.out\", CppFunction::makeFallthrough());\n  m.impl(\"digamma_\", CppFunction::makeFallthrough());\n  m.impl(\"div.Scalar\", CppFunction::makeFallthrough());\n  m.impl(\"div.Tensor\", CppFunction::makeFallthrough());\n  m.impl(\"div.out\", CppFunction::makeFallthrough());\n  m.impl(\"div_.Scalar\", CppFunction::makeFallthrough());\n  m.impl(\"div_.Tensor\", CppFunction::makeFallthrough());\n  m.impl(\"dot\", CppFunction::makeFallthrough());\n  m.impl(\"dot.out\", CppFunction::makeFallthrough());\n  m.impl(\"dropout\", CppFunction::makeFallthrough());\n  m.impl(\"dropout_\", CppFunction::makeFallthrough());\n  m.impl(\"empty_like\", CppFunction::makeFallthrough());\n  m.impl(\"eq.Scalar\", CppFunction::makeFallthrough());\n  m.impl(\"eq.Scalar_out\", CppFunction::makeFallthrough());\n  m.impl(\"eq.Tensor\", CppFunction::makeFallthrough());\n  m.impl(\"eq.Tensor_out\", CppFunction::makeFallthrough());\n  m.impl(\"equal\", CppFunction::makeFallthrough());\n  m.impl(\"erf\", CppFunction::makeFallthrough());\n  m.impl(\"erf.out\", CppFunction::makeFallthrough());\n  m.impl(\"erf_\", CppFunction::makeFallthrough());\n  m.impl(\"erfc\", CppFunction::makeFallthrough());\n  m.impl(\"erfc.out\", CppFunction::makeFallthrough());\n  m.impl(\"erfc_\", CppFunction::makeFallthrough());\n  m.impl(\"erfinv\", CppFunction::makeFallthrough());\n  m.impl(\"erfinv.out\", CppFunction::makeFallthrough());\n  m.impl(\"erfinv_\", CppFunction::makeFallthrough());\n  m.impl(\"exp\", CppFunction::makeFallthrough());\n  m.impl(\"exp.out\", CppFunction::makeFallthrough());\n  m.impl(\"exp_\", CppFunction::makeFallthrough());\n  m.impl(\"expand\", CppFunction::makeFallthrough());\n  m.impl(\"expm1\", CppFunction::makeFallthrough());\n  m.impl(\"expm1.out\", CppFunction::makeFallthrough());\n  m.impl(\"expm1_\", CppFunction::makeFallthrough());\n  m.impl(\"exponential_\", CppFunction::makeFallthrough());\n  m.impl(\"fill_.Scalar\", CppFunction::makeFallthrough());\n  m.impl(\"fill_.Tensor\", CppFunction::makeFallthrough());\n  m.impl(\"flatten.DimnameList\", CppFunction::makeFallthrough());\n  m.impl(\"flatten.named_out_dim\", CppFunction::makeFallthrough());\n  m.impl(\"flatten.using_ints\", CppFunction::makeFallthrough());\n  m.impl(\"flatten.using_names\", CppFunction::makeFallthrough());\n  m.impl(\"floor\", CppFunction::makeFallthrough());\n  m.impl(\"floor.out\", CppFunction::makeFallthrough());\n  m.impl(\"floor_\", CppFunction::makeFallthrough());\n  m.impl(\"floor_divide\", CppFunction::makeFallthrough());\n  m.impl(\"floor_divide.Scalar\", CppFunction::makeFallthrough());\n  m.impl(\"floor_divide.out\", CppFunction::makeFallthrough());\n  m.impl(\"floor_divide_.Scalar\", CppFunction::makeFallthrough());\n  m.impl(\"floor_divide_.Tensor\", CppFunction::makeFallthrough());\n  m.impl(\"frac\", CppFunction::makeFallthrough());\n  m.impl(\"frac.out\", CppFunction::makeFallthrough());\n  m.impl(\"frac_\", CppFunction::makeFallthrough());\n  m.impl(\"full_like\", CppFunction::makeFallthrough());\n  m.impl(\"ge.Scalar\", CppFunction::makeFallthrough());\n  m.impl(\"ge.Scalar_out\", CppFunction::makeFallthrough());\n  m.impl(\"ge.Tensor\", CppFunction::makeFallthrough());\n  m.impl(\"ge.Tensor_out\", CppFunction::makeFallthrough());\n  m.impl(\"geometric_\", CppFunction::makeFallthrough());\n  m.impl(\"gt.Scalar\", CppFunction::makeFallthrough());\n  m.impl(\"gt.Scalar_out\", CppFunction::makeFallthrough());\n  m.impl(\"gt.Tensor\", CppFunction::makeFallthrough());\n  m.impl(\"gt.Tensor_out\", CppFunction::makeFallthrough());\n  m.impl(\"hypot\", CppFunction::makeFallthrough());\n  m.impl(\"hypot.out\", CppFunction::makeFallthrough());\n  m.impl(\"hypot_\", CppFunction::makeFallthrough());\n  m.impl(\"i0\", CppFunction::makeFallthrough());\n  m.impl(\"i0.out\", CppFunction::makeFallthrough());\n  m.impl(\"i0_\", CppFunction::makeFallthrough());\n  m.impl(\"igamma\", CppFunction::makeFallthrough());\n  m.impl(\"igamma.out\", CppFunction::makeFallthrough());\n  m.impl(\"igamma_\", CppFunction::makeFallthrough());\n  m.impl(\"igammac\", CppFunction::makeFallthrough());\n  m.impl(\"igammac.out\", CppFunction::makeFallthrough());\n  m.impl(\"igammac_\", CppFunction::makeFallthrough());\n  m.impl(\"imag\", CppFunction::makeFallthrough());\n  m.impl(\"index_fill.Dimname_Scalar\", CppFunction::makeFallthrough());\n  m.impl(\"index_fill.Dimname_Tensor\", CppFunction::makeFallthrough());\n  m.impl(\"index_fill.int_Scalar\", CppFunction::makeFallthrough());\n  m.impl(\"index_fill.int_Tensor\", CppFunction::makeFallthrough());\n  m.impl(\"index_fill_.Dimname_Scalar\", CppFunction::makeFallthrough());\n  m.impl(\"index_fill_.Dimname_Tensor\", CppFunction::makeFallthrough());\n  m.impl(\"index_fill_.int_Scalar\", CppFunction::makeFallthrough());\n  m.impl(\"index_fill_.int_Tensor\", CppFunction::makeFallthrough());\n  m.impl(\"is_coalesced\", CppFunction::makeFallthrough());\n  m.impl(\"is_complex\", CppFunction::makeFallthrough());\n  m.impl(\"is_floating_point\", CppFunction::makeFallthrough());\n  m.impl(\"is_nonzero\", CppFunction::makeFallthrough());\n  m.impl(\"is_pinned\", CppFunction::makeFallthrough());\n  m.impl(\"is_same_size\", CppFunction::makeFallthrough());\n  m.impl(\"is_signed\", CppFunction::makeFallthrough());\n  m.impl(\"isfinite\", CppFunction::makeFallthrough());\n  m.impl(\"isinf\", CppFunction::makeFallthrough());\n  m.impl(\"isnan\", CppFunction::makeFallthrough());\n  m.impl(\"item\", CppFunction::makeFallthrough());\n  m.impl(\"kthvalue\", CppFunction::makeFallthrough());\n  m.impl(\"kthvalue.dimname\", CppFunction::makeFallthrough());\n  m.impl(\"kthvalue.dimname_out\", CppFunction::makeFallthrough());\n  m.impl(\"kthvalue.values\", CppFunction::makeFallthrough());\n  m.impl(\"le.Scalar\", CppFunction::makeFallthrough());\n  m.impl(\"le.Scalar_out\", CppFunction::makeFallthrough());\n  m.impl(\"le.Tensor\", CppFunction::makeFallthrough());\n  m.impl(\"le.Tensor_out\", CppFunction::makeFallthrough());\n  m.impl(\"lgamma\", CppFunction::makeFallthrough());\n  m.impl(\"lgamma.out\", CppFunction::makeFallthrough());\n  m.impl(\"lgamma_\", CppFunction::makeFallthrough());\n  m.impl(\"log\", CppFunction::makeFallthrough());\n  m.impl(\"log.out\", CppFunction::makeFallthrough());\n  m.impl(\"log10\", CppFunction::makeFallthrough());\n  m.impl(\"log10.out\", CppFunction::makeFallthrough());\n  m.impl(\"log10_\", CppFunction::makeFallthrough());\n  m.impl(\"log1p\", CppFunction::makeFallthrough());\n  m.impl(\"log1p.out\", CppFunction::makeFallthrough());\n  m.impl(\"log1p_\", CppFunction::makeFallthrough());\n  m.impl(\"log2\", CppFunction::makeFallthrough());\n  m.impl(\"log2.out\", CppFunction::makeFallthrough());\n  m.impl(\"log2_\", CppFunction::makeFallthrough());\n  m.impl(\"log_\", CppFunction::makeFallthrough());\n  m.impl(\"log_normal_\", CppFunction::makeFallthrough());\n  m.impl(\"log_softmax.Dimname\", CppFunction::makeFallthrough());\n  m.impl(\"log_softmax.int\", CppFunction::makeFallthrough());\n  m.impl(\"logaddexp\", CppFunction::makeFallthrough());\n  m.impl(\"logaddexp.out\", CppFunction::makeFallthrough());\n  m.impl(\"logaddexp2\", CppFunction::makeFallthrough());\n  m.impl(\"logaddexp2.out\", CppFunction::makeFallthrough());\n  m.impl(\"logcumsumexp\", CppFunction::makeFallthrough());\n  m.impl(\"logcumsumexp.dimname\", CppFunction::makeFallthrough());\n  m.impl(\"logcumsumexp.dimname_out\", CppFunction::makeFallthrough());\n  m.impl(\"logcumsumexp.out\", CppFunction::makeFallthrough());\n  m.impl(\"logical_and\", CppFunction::makeFallthrough());\n  m.impl(\"logical_and.out\", CppFunction::makeFallthrough());\n  m.impl(\"logical_and_\", CppFunction::makeFallthrough());\n  m.impl(\"logical_not\", CppFunction::makeFallthrough());\n  m.impl(\"logical_not.out\", CppFunction::makeFallthrough());\n  m.impl(\"logical_not_\", CppFunction::makeFallthrough());\n  m.impl(\"logical_or\", CppFunction::makeFallthrough());\n  m.impl(\"logical_or.out\", CppFunction::makeFallthrough());\n  m.impl(\"logical_or_\", CppFunction::makeFallthrough());\n  m.impl(\"logical_xor\", CppFunction::makeFallthrough());\n  m.impl(\"logical_xor.out\", CppFunction::makeFallthrough());\n  m.impl(\"logical_xor_\", CppFunction::makeFallthrough());\n  m.impl(\"logsumexp\", CppFunction::makeFallthrough());\n  m.impl(\"logsumexp.names\", CppFunction::makeFallthrough());\n  m.impl(\"logsumexp.names_out\", CppFunction::makeFallthrough());\n  m.impl(\"logsumexp.out\", CppFunction::makeFallthrough());\n  m.impl(\"lt.Scalar\", CppFunction::makeFallthrough());\n  m.impl(\"lt.Scalar_out\", CppFunction::makeFallthrough());\n  m.impl(\"lt.Tensor\", CppFunction::makeFallthrough());\n  m.impl(\"lt.Tensor_out\", CppFunction::makeFallthrough());\n  m.impl(\"masked_fill.Scalar\", CppFunction::makeFallthrough());\n  m.impl(\"masked_fill.Tensor\", CppFunction::makeFallthrough());\n  m.impl(\"masked_fill_.Scalar\", CppFunction::makeFallthrough());\n  m.impl(\"masked_fill_.Tensor\", CppFunction::makeFallthrough());\n  m.impl(\"masked_select\", CppFunction::makeFallthrough());\n  m.impl(\"masked_select.out\", CppFunction::makeFallthrough());\n  m.impl(\"matmul\", CppFunction::makeFallthrough());\n  m.impl(\"matmul.out\", CppFunction::makeFallthrough());\n  m.impl(\"max\", CppFunction::makeFallthrough());\n  m.impl(\"max.dim\", CppFunction::makeFallthrough());\n  m.impl(\"max.dim_max\", CppFunction::makeFallthrough());\n  m.impl(\"max.names_dim\", CppFunction::makeFallthrough());\n  m.impl(\"max.names_dim_max\", CppFunction::makeFallthrough());\n  m.impl(\"max_pool1d\", CppFunction::makeFallthrough());\n  m.impl(\"max_pool1d_with_indices\", CppFunction::makeFallthrough());\n  m.impl(\"max_pool2d\", CppFunction::makeFallthrough());\n  m.impl(\"max_pool2d_with_indices\", CppFunction::makeFallthrough());\n  m.impl(\"max_pool3d\", CppFunction::makeFallthrough());\n  m.impl(\"max_pool3d_with_indices\", CppFunction::makeFallthrough());\n  m.impl(\"mean\", CppFunction::makeFallthrough());\n  m.impl(\"mean.dim\", CppFunction::makeFallthrough());\n  m.impl(\"mean.names_dim\", CppFunction::makeFallthrough());\n  m.impl(\"mean.names_out\", CppFunction::makeFallthrough());\n  m.impl(\"mean.out\", CppFunction::makeFallthrough());\n  m.impl(\"median\", CppFunction::makeFallthrough());\n  m.impl(\"median.dim\", CppFunction::makeFallthrough());\n  m.impl(\"median.dim_values\", CppFunction::makeFallthrough());\n  m.impl(\"median.names_dim\", CppFunction::makeFallthrough());\n  m.impl(\"median.names_dim_values\", CppFunction::makeFallthrough());\n  m.impl(\"nanmedian\", CppFunction::makeFallthrough());\n  m.impl(\"nanmedian.dim\", CppFunction::makeFallthrough());\n  m.impl(\"nanmedian.dim_values\", CppFunction::makeFallthrough());\n  m.impl(\"nanmedian.names_dim\", CppFunction::makeFallthrough());\n  m.impl(\"nanmedian.names_dim_values\", CppFunction::makeFallthrough());\n  m.impl(\"min\", CppFunction::makeFallthrough());\n  m.impl(\"min.dim\", CppFunction::makeFallthrough());\n  m.impl(\"min.dim_min\", CppFunction::makeFallthrough());\n  m.impl(\"min.names_dim\", CppFunction::makeFallthrough());\n  m.impl(\"min.names_dim_min\", CppFunction::makeFallthrough());\n  m.impl(\"mm\", CppFunction::makeFallthrough());\n  m.impl(\"mm.out\", CppFunction::makeFallthrough());\n  m.impl(\"mode\", CppFunction::makeFallthrough());\n  m.impl(\"mode.dimname\", CppFunction::makeFallthrough());\n  m.impl(\"mode.dimname_out\", CppFunction::makeFallthrough());\n  m.impl(\"mode.values\", CppFunction::makeFallthrough());\n  m.impl(\"mul.Tensor\", CppFunction::makeFallthrough());\n  m.impl(\"mul.out\", CppFunction::makeFallthrough());\n  m.impl(\"mul_.Tensor\", CppFunction::makeFallthrough());\n  m.impl(\"mv\", CppFunction::makeFallthrough());\n  m.impl(\"mv.out\", CppFunction::makeFallthrough());\n  m.impl(\"narrow\", CppFunction::makeFallthrough());\n  m.impl(\"narrow.Tensor\", CppFunction::makeFallthrough());\n  m.impl(\"ne.Scalar\", CppFunction::makeFallthrough());\n  m.impl(\"ne.Scalar_out\", CppFunction::makeFallthrough());\n  m.impl(\"ne.Tensor\", CppFunction::makeFallthrough());\n  m.impl(\"ne.Tensor_out\", CppFunction::makeFallthrough());\n  m.impl(\"neg\", CppFunction::makeFallthrough());\n  m.impl(\"neg.out\", CppFunction::makeFallthrough());\n  m.impl(\"neg_\", CppFunction::makeFallthrough());\n  m.impl(\"nextafter\", CppFunction::makeFallthrough());\n  m.impl(\"nextafter.out\", CppFunction::makeFallthrough());\n  m.impl(\"nextafter_\", CppFunction::makeFallthrough());\n  m.impl(\"normal_\", CppFunction::makeFallthrough());\n  m.impl(\"ones_like\", CppFunction::makeFallthrough());\n  m.impl(\"output_nr\", CppFunction::makeFallthrough());\n  m.impl(\"polygamma\", CppFunction::makeFallthrough());\n  m.impl(\"polygamma.out\", CppFunction::makeFallthrough());\n  m.impl(\"polygamma_\", CppFunction::makeFallthrough());\n  m.impl(\"pow.Scalar\", CppFunction::makeFallthrough());\n  m.impl(\"pow.Scalar_out\", CppFunction::makeFallthrough());\n  m.impl(\"pow.Tensor_Scalar\", CppFunction::makeFallthrough());\n  m.impl(\"pow.Tensor_Scalar_out\", CppFunction::makeFallthrough());\n  m.impl(\"pow.Tensor_Tensor\", CppFunction::makeFallthrough());\n  m.impl(\"pow.Tensor_Tensor_out\", CppFunction::makeFallthrough());\n  m.impl(\"pow_.Scalar\", CppFunction::makeFallthrough());\n  m.impl(\"pow_.Tensor\", CppFunction::makeFallthrough());\n  m.impl(\"prod\", CppFunction::makeFallthrough());\n  m.impl(\"prod.Dimname_out\", CppFunction::makeFallthrough());\n  m.impl(\"prod.dim_Dimname\", CppFunction::makeFallthrough());\n  m.impl(\"prod.dim_int\", CppFunction::makeFallthrough());\n  m.impl(\"prod.int_out\", CppFunction::makeFallthrough());\n  m.impl(\"rad2deg\", CppFunction::makeFallthrough());\n  m.impl(\"rad2deg.out\", CppFunction::makeFallthrough());\n  m.impl(\"rad2deg_\", CppFunction::makeFallthrough());\n  m.impl(\"rand_like\", CppFunction::makeFallthrough());\n  m.impl(\"randn_like\", CppFunction::makeFallthrough());\n  m.impl(\"random_\", CppFunction::makeFallthrough());\n  m.impl(\"random_.from\", CppFunction::makeFallthrough());\n  m.impl(\"random_.to\", CppFunction::makeFallthrough());\n  m.impl(\"real\", CppFunction::makeFallthrough());\n  m.impl(\"reciprocal\", CppFunction::makeFallthrough());\n  m.impl(\"reciprocal.out\", CppFunction::makeFallthrough());\n  m.impl(\"reciprocal_\", CppFunction::makeFallthrough());\n  m.impl(\"refine_names\", CppFunction::makeFallthrough());\n  m.impl(\"relu\", CppFunction::makeFallthrough());\n  m.impl(\"relu_\", CppFunction::makeFallthrough());\n  m.impl(\"rename\", CppFunction::makeFallthrough());\n  m.impl(\"rename_\", CppFunction::makeFallthrough());\n  m.impl(\"reshape\", CppFunction::makeFallthrough());\n  m.impl(\"resize_\", CppFunction::makeFallthrough());\n  m.impl(\"resize_as_\", CppFunction::makeFallthrough());\n  m.impl(\"result_type.Scalar\", CppFunction::makeFallthrough());\n  m.impl(\"result_type.Scalar_Tensor\", CppFunction::makeFallthrough());\n  m.impl(\"result_type.Tensor\", CppFunction::makeFallthrough());\n  m.impl(\"round\", CppFunction::makeFallthrough());\n  m.impl(\"round.out\", CppFunction::makeFallthrough());\n  m.impl(\"round_\", CppFunction::makeFallthrough());\n  m.impl(\"rsqrt\", CppFunction::makeFallthrough());\n  m.impl(\"rsqrt.out\", CppFunction::makeFallthrough());\n  m.impl(\"rsqrt_\", CppFunction::makeFallthrough());\n  m.impl(\"rsub.Scalar\", CppFunction::makeFallthrough());\n  m.impl(\"rsub.Tensor\", CppFunction::makeFallthrough());\n  m.impl(\"select.Dimname\", CppFunction::makeFallthrough());\n  m.impl(\"select.int\", CppFunction::makeFallthrough());\n  m.impl(\"sigmoid\", CppFunction::makeFallthrough());\n  m.impl(\"sigmoid.out\", CppFunction::makeFallthrough());\n  m.impl(\"sigmoid_\", CppFunction::makeFallthrough());\n  m.impl(\"sign\", CppFunction::makeFallthrough());\n  m.impl(\"sign.out\", CppFunction::makeFallthrough());\n  m.impl(\"sign_\", CppFunction::makeFallthrough());\n  m.impl(\"signbit\", CppFunction::makeFallthrough());\n  m.impl(\"signbit.out\", CppFunction::makeFallthrough());\n  m.impl(\"sin\", CppFunction::makeFallthrough());\n  m.impl(\"sin.out\", CppFunction::makeFallthrough());\n  m.impl(\"sin_\", CppFunction::makeFallthrough());\n  m.impl(\"sinh\", CppFunction::makeFallthrough());\n  m.impl(\"sinh.out\", CppFunction::makeFallthrough());\n  m.impl(\"sinh_\", CppFunction::makeFallthrough());\n  m.impl(\"size.Dimname\", CppFunction::makeFallthrough());\n  m.impl(\"size.int\", CppFunction::makeFallthrough());\n  m.impl(\"slice.Tensor\", CppFunction::makeFallthrough());\n  m.impl(\"softmax.Dimname\", CppFunction::makeFallthrough());\n  m.impl(\"softmax.int\", CppFunction::makeFallthrough());\n  m.impl(\"split.Tensor\", CppFunction::makeFallthrough());\n  m.impl(\"split_with_sizes\", CppFunction::makeFallthrough());\n  m.impl(\"sqrt\", CppFunction::makeFallthrough());\n  m.impl(\"sqrt.out\", CppFunction::makeFallthrough());\n  m.impl(\"sqrt_\", CppFunction::makeFallthrough());\n  m.impl(\"square\", CppFunction::makeFallthrough());\n  m.impl(\"square_\", CppFunction::makeFallthrough());\n  m.impl(\"squeeze\", CppFunction::makeFallthrough());\n  m.impl(\"squeeze.dim\", CppFunction::makeFallthrough());\n  m.impl(\"squeeze.dimname\", CppFunction::makeFallthrough());\n  m.impl(\"std\", CppFunction::makeFallthrough());\n  m.impl(\"std.dim\", CppFunction::makeFallthrough());\n  m.impl(\"std.names_dim\", CppFunction::makeFallthrough());\n  m.impl(\"std.names_out\", CppFunction::makeFallthrough());\n  m.impl(\"std.out\", CppFunction::makeFallthrough());\n  m.impl(\"std_mean\", CppFunction::makeFallthrough());\n  m.impl(\"std_mean.dim\", CppFunction::makeFallthrough());\n  m.impl(\"std_mean.names_dim\", CppFunction::makeFallthrough());\n  m.impl(\"stride.Dimname\", CppFunction::makeFallthrough());\n  m.impl(\"stride.int\", CppFunction::makeFallthrough());\n  m.impl(\"sub.Scalar\", CppFunction::makeFallthrough());\n  m.impl(\"sub.Tensor\", CppFunction::makeFallthrough());\n  m.impl(\"sub.out\", CppFunction::makeFallthrough());\n  m.impl(\"sub_.Scalar\", CppFunction::makeFallthrough());\n  m.impl(\"sub_.Tensor\", CppFunction::makeFallthrough());\n  m.impl(\"sum\", CppFunction::makeFallthrough());\n  m.impl(\"sum.DimnameList_out\", CppFunction::makeFallthrough());\n  m.impl(\"sum.IntList_out\", CppFunction::makeFallthrough());\n  m.impl(\"sum.dim_DimnameList\", CppFunction::makeFallthrough());\n  m.impl(\"sum.dim_IntList\", CppFunction::makeFallthrough());\n  m.impl(\"t\", CppFunction::makeFallthrough());\n  m.impl(\"tan\", CppFunction::makeFallthrough());\n  m.impl(\"tan.out\", CppFunction::makeFallthrough());\n  m.impl(\"tan_\", CppFunction::makeFallthrough());\n  m.impl(\"tanh\", CppFunction::makeFallthrough());\n  m.impl(\"tanh.out\", CppFunction::makeFallthrough());\n  m.impl(\"tanh_\", CppFunction::makeFallthrough());\n  m.impl(\"tensor_split.indices\", CppFunction::makeFallthrough());\n  m.impl(\"tensor_split.sections\", CppFunction::makeFallthrough());\n  m.impl(\"tensor_split.tensor_indices_or_sections\", CppFunction::makeFallthrough());\n  m.impl(\"threshold\", CppFunction::makeFallthrough());\n  m.impl(\"threshold.out\", CppFunction::makeFallthrough());\n  m.impl(\"threshold_\", CppFunction::makeFallthrough());\n  m.impl(\"to.device\", CppFunction::makeFallthrough());\n  m.impl(\"to.dtype\", CppFunction::makeFallthrough());\n  m.impl(\"to.dtype_layout\", CppFunction::makeFallthrough());\n  m.impl(\"transpose.Dimname\", CppFunction::makeFallthrough());\n  m.impl(\"transpose.int\", CppFunction::makeFallthrough());\n  m.impl(\"true_divide.Scalar\", CppFunction::makeFallthrough());\n  m.impl(\"true_divide.Tensor\", CppFunction::makeFallthrough());\n  m.impl(\"true_divide.out\", CppFunction::makeFallthrough());\n  m.impl(\"true_divide_.Scalar\", CppFunction::makeFallthrough());\n  m.impl(\"true_divide_.Tensor\", CppFunction::makeFallthrough());\n  m.impl(\"trunc\", CppFunction::makeFallthrough());\n  m.impl(\"trunc.out\", CppFunction::makeFallthrough());\n  m.impl(\"trunc_\", CppFunction::makeFallthrough());\n  m.impl(\"unbind.Dimname\", CppFunction::makeFallthrough());\n  m.impl(\"unbind.int\", CppFunction::makeFallthrough());\n  m.impl(\"unflatten.Dimname\", CppFunction::makeFallthrough());\n  m.impl(\"unflatten.int\", CppFunction::makeFallthrough());\n  m.impl(\"uniform_\", CppFunction::makeFallthrough());\n  m.impl(\"unsafe_chunk\", CppFunction::makeFallthrough());\n  m.impl(\"unsafe_split.Tensor\", CppFunction::makeFallthrough());\n  m.impl(\"unsafe_split_with_sizes\", CppFunction::makeFallthrough());\n  m.impl(\"vander\", CppFunction::makeFallthrough());\n  m.impl(\"var\", CppFunction::makeFallthrough());\n  m.impl(\"var.dim\", CppFunction::makeFallthrough());\n  m.impl(\"var.names_dim\", CppFunction::makeFallthrough());\n  m.impl(\"var.names_out\", CppFunction::makeFallthrough());\n  m.impl(\"var.out\", CppFunction::makeFallthrough());\n  m.impl(\"var_mean\", CppFunction::makeFallthrough());\n  m.impl(\"var_mean.dim\", CppFunction::makeFallthrough());\n  m.impl(\"var_mean.names_dim\", CppFunction::makeFallthrough());\n  m.impl(\"zero_\", CppFunction::makeFallthrough());\n  m.impl(\"zeros_like\", CppFunction::makeFallthrough());\n\n  // These weren't marked as supporting named tensors but were implicitly\n  // supported because they were manually registered.  I'm not sure\n  // if these registrations are right or not, but they preserve old behavior\n  // (and some of them are exercised by the test suite).\n  m.impl(\"_backward\", CppFunction::makeFallthrough());\n  m.impl(\"set_data\", CppFunction::makeFallthrough());\n  m.impl(\"data\", CppFunction::makeFallthrough());\n  m.impl(\"is_leaf\", CppFunction::makeFallthrough());\n  m.impl(\"_version\", CppFunction::makeFallthrough());\n  m.impl(\"requires_grad_\", CppFunction::makeFallthrough());\n  m.impl(\"retain_grad\", CppFunction::makeFallthrough());\n  m.impl(\"_fw_primal\", CppFunction::makeFallthrough());\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/NamedTensor.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/operator_name.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/Tensor.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/TensorImpl_test.cpp",
        "functions": [
            "{\n  caffe2::Tensor tensor(caffe2::CPU);\n  ASSERT_EQ(tensor.strides()[0], 1);\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/type.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/VariableHooksInterface.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/Vitals.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/boxing/KernelFunction.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/boxing/KernelFunction_test.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/boxing/impl/kernel_function_legacy_test.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/boxing/impl/kernel_function_test.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/boxing/impl/kernel_lambda_legacy_test.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/boxing/impl/kernel_lambda_test.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/boxing/impl/kernel_stackbased_test.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/boxing/impl/make_boxed_from_unboxed_functor_test.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/dispatch/backend_fallback_test.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/dispatch/CppSignature_test.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/dispatch/Dispatcher.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/dispatch/DispatchKeyExtractor.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/dispatch/ObservedOperators.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/dispatch/OperatorEntry.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/op_registration/infer_schema.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/op_registration/op_registration.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/op_registration/op_registration_test.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/core/op_registration/op_whitelist_test.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/cpu/FlushDenormal.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/cudnn/AutocastRNN.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/cudnn/Descriptors.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/cudnn/Handle.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/cudnn/Types.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/detail/CPUGuardImpl.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/detail/CUDAHooksInterface.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/detail/HIPHooksInterface.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/hip/impl/HIPCachingAllocatorMasqueradingAsCUDA.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/hip/impl/HIPGuardImplMasqueradingAsCUDA.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/miopen/Descriptors.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/miopen/Handle.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/miopen/Types.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/Activation.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/AdaptiveAveragePooling.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/AdaptiveAveragePooling3d.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/AdaptiveMaxPooling2d.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/AdaptiveMaxPooling3d.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/AffineGridGenerator.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/AutogradComposite.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/AveragePool2d.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/AveragePool3d.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/Batching.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/BatchLinearAlgebraKernel.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/BinaryOps.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/Blas.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/BlasKernel.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/Bucketization.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/ChanelShuffle.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/Col2Im.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/ConstantPadNd.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/Convolution.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/ConvolutionMM2d.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/ConvolutionMM3d.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/ConvolutionTBC.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/Copy.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/CPUBlas.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/Cross.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/DilatedMaxPool2d.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/DilatedMaxPool3d.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/DispatchStub.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/Distance.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/Distributions.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/Dropout.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/Embedding.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/EmbeddingBag.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/Fill.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/ForeachOpsKernels.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/FractionalMaxPool2d.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/FractionalMaxPool3d.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/FunctionOfAMatrixUtils.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/GatedLinearUnit.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/GridSampler.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/group_norm.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/Im2Col.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/RNN.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/IndexingUtils.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/Integration.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/Itertools.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/layer_norm.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/LegacyBridge.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/LegacyNNDefinitions.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/Lerp.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/Linear.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/LinearAlgebra.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/Loss.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/LossCTC.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/LossMultiLabelMargin.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/LossMultiMargin.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/LossNLL.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/LossNLL2d.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/MaxPooling.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/MaxUnpooling.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/Memory.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/MetaTensor.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/NaiveConvolutionTranspose2d.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/NaiveConvolutionTranspose3d.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/NaiveDilatedConvolution.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/NamedTensor.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/NNPACK.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/Normalization.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/Onehot.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/PackedSequence.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/PixelShuffle.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/PointwiseOps.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/Pooling.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/Pow.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/QuantizedLinear.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/RangeFactories.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/ReduceAllOps.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/ReduceOps.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/ReflectionPad.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/Repeat.cpp",
        "functions": [
            "void"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/ReplicationPadding.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/Resize.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/RowwisePrune.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/Scalar.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/SobolEngineOps.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/SobolEngineOpsUtils.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/SoftMax.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/Sorting.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/SpectralOps.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/SummaryOps.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/TensorCompare.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/TensorConversions.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/TensorFactories.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/TensorIteratorReduce.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/TensorProperties.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/TensorShape.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/TensorTransformations.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/TestOps.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/TriangularOps.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/TypeProperties.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/UnaryOps.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/Unfold2d.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/Unfold3d.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/UnfoldBackward.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/Unique.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/UpSample.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/UpSampleBicubic2d.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/UpSampleBilinear2d.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/UpSampleLinear1d.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/UpSampleNearest1d.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/UpSampleNearest2d.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/UpSampleNearest3d.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/UpSampleTrilinear3d.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/VariableMethodStubs.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/WeightNorm.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cpu/Activation.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cpu/AdaptiveAvgPoolKernel.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cpu/batch_norm_kernel.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cpu/BinaryOpsKernel.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cpu/BlasKernel.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cpu/CatKernel.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cpu/ComplexKernel.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cpu/CopyKernel.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cpu/CrossKernel.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cpu/DepthwiseConvKernel.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cpu/DistanceOpsKernel.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cpu/FillKernel.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cpu/FunctionOfAMatrixUtilsKernel.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cpu/GridSamplerKernel.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cpu/group_norm_kernel.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cpu/layer_norm_kernel.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cpu/LerpKernel.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cpu/LinearAlgebraKernel.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cpu/MaxPooling.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cpu/MultinomialKernel.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cpu/PointwiseOpsKernel.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cpu/PowKernel.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cpu/RangeFactoriesKernel.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cpu/ReduceAllOpsKernel.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cpu/ReduceOpsKernel.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cpu/ScatterGatherKernel.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cpu/SoftMaxKernel.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cpu/SortingKernel.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cpu/StackKernel.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cpu/SumKernel.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cpu/TensorCompareKernel.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cpu/UnaryOpsKernel.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cpu/Unfold2d.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cpu/UnfoldBackwardKernel.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cpu/UpSampleKernel.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cpu/UpSampleMoreKernel.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cpu/IndexKernel.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cuda/LegacyDefinitions.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cuda/TensorShapeCUDA.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cudnn/AffineGridGenerator.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cudnn/BatchNorm.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cudnn/ConvPlaceholders.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cudnn/ConvShared.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cudnn/Conv_v7.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cudnn/Conv_v8.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cudnn/GridSampler.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cudnn/LossCTC.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/cudnn/RNN.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/metal/MetalGuardImpl.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/metal/MetalPrepackOpRegister.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/affine_quantizer.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/affine_quantizer_base.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/Copy.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/fake_quant_per_channel_affine.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/fake_quant_per_tensor_affine.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/library.cpp",
        "functions": [
            "{\n  register_linear_params();\n  register_conv_params<2>();\n  register_conv_params<3>();\n  register_embedding_params();\n\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::add(Tensor qa, Tensor qb, float scale, int zero_point) -> Tensor qc\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::add.out(Tensor qa, Tensor qb, Tensor(a!) out) -> Tensor(a!) out\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::add.Scalar(Tensor qa, Scalar b) -> Tensor qc\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::add.Scalar2(Scalar b, Tensor qa) -> Tensor qc\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::add.Scalar_out(Tensor qa, Scalar b, Tensor(a!) out) -> Tensor(a!) out\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::add_relu(Tensor qa, Tensor qb, float scale, int zero_point) -> Tensor qc\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::add_relu.Scalar(Tensor qa, Scalar b) -> Tensor qc\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::add_relu.Scalar2(Scalar b, Tensor qa) -> Tensor qc\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::add_relu.out(Tensor qa, Tensor qb, Tensor(a!) out) -> Tensor(a!) out\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::add_relu.Scalar_out(Tensor qa, Scalar b, Tensor(a!) out) -> Tensor(a!) out\"));\n  // deprecated functions, kept for backward compatibility\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::add_out(Tensor qa, Tensor qb, Tensor(a!) out) -> Tensor(a!) out\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::add_relu_out(Tensor qa, Tensor qb, Tensor(a!) out) -> Tensor(a!) out\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::add_scalar(Tensor qa, Scalar b) -> Tensor qc\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::add_scalar_relu(Tensor qa, Scalar b) -> Tensor qc\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::add_scalar_out(Tensor qa, Scalar b, Tensor(a!) out) -> Tensor(a!) out\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::add_scalar_relu_out(Tensor qa, Scalar b, Tensor(a!) out) -> Tensor(a!) out\"));\n  // TODO: remove after broadcasting is supported\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::add_scalar_out.Tensor(Tensor qa, Tensor b, Tensor(a!) out) -> Tensor(a!) out\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::add_scalar.Tensor(Tensor qa, Tensor b) -> Tensor qc\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::add_scalar_relu.Tensor(Tensor qa, Tensor b) -> Tensor qc\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::add_scalar_relu_out.Tensor(Tensor qa, Tensor b, Tensor(a!) out) -> Tensor(a!) out\"));\n  // This is needed for graph mode quantization, when we fuse\n  // dequant - aten::batch_norm - quant into quantized::batch_norm\n  // and dimension is unknown given only the aten op call\n  // quantized::batch_norm supports both 2d and 3d batch norm right now\n  // it should also support 1d batch_norm after quantized::batch_norm1d is\n  // implemented\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::batch_norm(Tensor qx, Tensor? weight, Tensor? bias, Tensor mean, Tensor var, float eps, float output_scale, int output_zero_point) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::batch_norm_relu(Tensor qx, Tensor? weight, Tensor? bias, Tensor mean, Tensor var, float eps, float output_scale, int output_zero_point) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::batch_norm1d(Tensor qx, Tensor? weight, Tensor? bias, Tensor mean, Tensor var, float eps, float output_scale, int output_zero_point) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::batch_norm1d_relu(Tensor qx, Tensor? weight, Tensor? bias, Tensor mean, Tensor var, float eps, float output_scale, int output_zero_point) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::batch_norm2d(Tensor qx, Tensor? weight, Tensor? bias, Tensor mean, Tensor var, float eps, float output_scale, int output_zero_point) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::batch_norm2d_relu(Tensor qx, Tensor? weight, Tensor? bias, Tensor mean, Tensor var, float eps, float output_scale, int output_zero_point) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::batch_norm3d(Tensor qx, Tensor? weight, Tensor? bias, Tensor mean, Tensor var, float eps, float output_scale, int output_zero_point) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::batch_norm3d_relu(Tensor qx, Tensor? weight, Tensor? bias, Tensor mean, Tensor var, float eps, float output_scale, int output_zero_point) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::clamp(Tensor qx, Scalar? min=None, Scalar? max=None) -> Tensor qy\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::threshold(Tensor qx, Scalar threshold, Scalar value) -> Tensor qy\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::cat(Tensor[] qx, int dim, float? scale, int? zero_point) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::cat_relu(Tensor[] qx, int dim, float? scale, int? zero_point) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::cat_out(Tensor[] qx, int dim, Tensor(a!) out) -> Tensor(a!)\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::cat_relu_out(Tensor[] qx, int dim, Tensor(a!) out) -> Tensor(a!)\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv1d(Tensor qx, __torch__.torch.classes.quantized.Conv2dPackedParamsBase packed_weight, float output_scale, int output_zero_point) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv1d_relu(Tensor qx, __torch__.torch.classes.quantized.Conv2dPackedParamsBase packed_weight, float output_scale, int output_zero_point) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv2d.new(Tensor qx, __torch__.torch.classes.quantized.Conv2dPackedParamsBase packed_weight, float output_scale, int output_zero_point) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv2d_relu.new(Tensor qx, __torch__.torch.classes.quantized.Conv2dPackedParamsBase packed_weight, float output_scale, int output_zero_point) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv3d.new(Tensor qx, __torch__.torch.classes.quantized.Conv3dPackedParamsBase packed_weight, float output_scale, int output_zero_point) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv3d_relu.new(Tensor qx, __torch__.torch.classes.quantized.Conv3dPackedParamsBase packed_weight, float output_scale, int output_zero_point) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv2d(Tensor qx, __torch__.torch.classes.quantized.Conv2dPackedParamsBase weight, int[] stride, int[] padding, int[] dilation, int groups, float output_scale, int output_zero_point) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv2d_relu(Tensor qx, __torch__.torch.classes.quantized.Conv2dPackedParamsBase weight, int[] stride, int[] padding, int[] dilation, int groups, float output_scale, int output_zero_point) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv3d(Tensor qx, __torch__.torch.classes.quantized.Conv3dPackedParamsBase weight, int[] stride, int[] padding, int[] dilation, int groups, float output_scale, int output_zero_point) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv3d_relu(Tensor qx, __torch__.torch.classes.quantized.Conv3dPackedParamsBase weight, int[] stride, int[] padding, int[] dilation, int groups, float output_scale, int output_zero_point) -> Tensor\"));\n  // conv_prepack is deprecated, please use conv2d_prepack for 2D conv.\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv_prepack(Tensor weight, Tensor? bias, int[] stride, int[] padding, int[] dilation, int groups) -> __torch__.torch.classes.quantized.Conv2dPackedParamsBase\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv1d_prepack(Tensor weight, Tensor? bias, int[] stride, int[] padding, int[] dilation, int groups) -> __torch__.torch.classes.quantized.Conv2dPackedParamsBase\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv2d_prepack(Tensor weight, Tensor? bias, int[] stride, int[] padding, int[] dilation, int groups) -> __torch__.torch.classes.quantized.Conv2dPackedParamsBase\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv3d_prepack(Tensor weight, Tensor? bias, int[] stride, int[] padding, int[] dilation, int groups) -> __torch__.torch.classes.quantized.Conv3dPackedParamsBase\"));\n  // conv_unpack is deprecated, please use conv2d_unpack for 2D conv.\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv_unpack(__torch__.torch.classes.quantized.Conv2dPackedParamsBase packed_weights) -> (Tensor unpacked_weights, Tensor? B_origin)\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv1d_unpack(__torch__.torch.classes.quantized.Conv2dPackedParamsBase packed_weights) -> (Tensor unpacked_weights, Tensor? B_origin)\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv2d_unpack(__torch__.torch.classes.quantized.Conv2dPackedParamsBase packed_weights) -> (Tensor unpacked_weights, Tensor? B_origin)\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv3d_unpack(__torch__.torch.classes.quantized.Conv3dPackedParamsBase packed_weights) -> (Tensor unpacked_weights, Tensor? B_origin)\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv2d_stride(__torch__.torch.classes.quantized.Conv2dPackedParamsBase packed_weights) -> int[]\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv2d_padding(__torch__.torch.classes.quantized.Conv2dPackedParamsBase packed_weights) -> int[]\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv2d_output_padding(__torch__.torch.classes.quantized.Conv2dPackedParamsBase packed_weights) -> int[]\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv2d_dilation(__torch__.torch.classes.quantized.Conv2dPackedParamsBase packed_weights) -> int[]\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv2d_groups(__torch__.torch.classes.quantized.Conv2dPackedParamsBase packed_weights) -> int\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv2d_transpose(__torch__.torch.classes.quantized.Conv2dPackedParamsBase packed_weights) -> int\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv3d_stride(__torch__.torch.classes.quantized.Conv3dPackedParamsBase packed_weights) -> int[]\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv3d_padding(__torch__.torch.classes.quantized.Conv3dPackedParamsBase packed_weights) -> int[]\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv3d_output_padding(__torch__.torch.classes.quantized.Conv3dPackedParamsBase packed_weights) -> int[]\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv3d_dilation(__torch__.torch.classes.quantized.Conv3dPackedParamsBase packed_weights) -> int[]\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv3d_groups(__torch__.torch.classes.quantized.Conv3dPackedParamsBase packed_weights) -> int\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv3d_transpose(__torch__.torch.classes.quantized.Conv3dPackedParamsBase packed_weights) -> int\"));\n  // conv_tranpsose\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv_transpose1d(Tensor qx, __torch__.torch.classes.quantized.Conv2dPackedParamsBase packed_weight, float output_scale, int output_zero_point) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv_transpose2d(Tensor qx, __torch__.torch.classes.quantized.Conv2dPackedParamsBase packed_weight, float output_scale, int output_zero_point) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv_transpose3d(Tensor qx, __torch__.torch.classes.quantized.Conv3dPackedParamsBase packed_weight, float output_scale, int output_zero_point) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv_transpose1d_prepack(Tensor weight, Tensor? bias, int[] stride, int[] padding, int[] output_padding, int[] dilation, int groups) -> __torch__.torch.classes.quantized.Conv2dPackedParamsBase\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv_transpose1d_unpack(__torch__.torch.classes.quantized.Conv2dPackedParamsBase packed_weights) -> (Tensor unpacked_weights, Tensor? B_origin)\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv_transpose2d_prepack(Tensor weight, Tensor? bias, int[] stride, int[] padding, int[] output_padding, int[] dilation, int groups) -> __torch__.torch.classes.quantized.Conv2dPackedParamsBase\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv_transpose2d_unpack(__torch__.torch.classes.quantized.Conv2dPackedParamsBase packed_weights) -> (Tensor unpacked_weights, Tensor? B_origin)\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv_transpose2d_stride(__torch__.torch.classes.quantized.Conv2dPackedParamsBase packed_weights) -> int[]\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv_transpose2d_padding(__torch__.torch.classes.quantized.Conv2dPackedParamsBase packed_weights) -> int[]\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv_transpose2d_output_padding(__torch__.torch.classes.quantized.Conv2dPackedParamsBase packed_weights) -> int[]\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv_transpose2d_dilation(__torch__.torch.classes.quantized.Conv2dPackedParamsBase packed_weights) -> int[]\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv_transpose2d_groups(__torch__.torch.classes.quantized.Conv2dPackedParamsBase packed_weights) -> int\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv_transpose2d_transpose(__torch__.torch.classes.quantized.Conv2dPackedParamsBase packed_weights) -> int\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv_transpose3d_prepack(Tensor weight, Tensor? bias, int[] stride, int[] padding, int[] output_padding, int[] dilation, int groups) -> __torch__.torch.classes.quantized.Conv3dPackedParamsBase\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv_transpose3d_unpack(__torch__.torch.classes.quantized.Conv3dPackedParamsBase packed_weights) -> (Tensor unpacked_weights, Tensor? B_origin)\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv_transpose3d_stride(__torch__.torch.classes.quantized.Conv3dPackedParamsBase packed_weights) -> int[]\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv_transpose3d_padding(__torch__.torch.classes.quantized.Conv3dPackedParamsBase packed_weights) -> int[]\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv_transpose3d_output_padding(__torch__.torch.classes.quantized.Conv3dPackedParamsBase packed_weights) -> int[]\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv_transpose3d_dilation(__torch__.torch.classes.quantized.Conv3dPackedParamsBase packed_weights) -> int[]\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv_transpose3d_groups(__torch__.torch.classes.quantized.Conv3dPackedParamsBase packed_weights) -> int\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::conv_transpose3d_transpose(__torch__.torch.classes.quantized.Conv3dPackedParamsBase packed_weights) -> int\"));\n\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::elu(Tensor self, float output_scale, int output_zero_point, Scalar alpha=1, Scalar scale=1, Scalar input_scale=1) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::embedding_bag_prepack(Tensor weight) -> __torch__.torch.classes.quantized.EmbeddingPackedParamsBase W_prepack\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::embedding_bag_unpack(__torch__.torch.classes.quantized.EmbeddingPackedParamsBase W_prepack) -> Tensor W_origin\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::embedding_bag_byte_prepack(Tensor weight) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::embedding_bag_byte_unpack(Tensor weight) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::embedding_bag_4bit_prepack(Tensor weight, bool optimized_qparams=False) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::embedding_bag_4bit_unpack(Tensor weight) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::embedding_bag_2bit_prepack(Tensor weight, bool optimized_qparams=False) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::embedding_bag_2bit_unpack(Tensor weight) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::embedding_bag_byte_rowwise_offsets(Tensor weight, Tensor indices, Tensor? offsets=None, bool scale_grad_by_freq=False, int mode=0, bool pruned_weights=False, Tensor? per_sample_weights=None, Tensor? compressed_indices_mapping=None, bool include_last_offset=False) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::embedding_bag_4bit_rowwise_offsets(Tensor weight, Tensor indices, Tensor? offsets=None, bool scale_grad_by_freq=False, int mode=0, bool pruned_weights=False, Tensor? per_sample_weights=None, Tensor? compressed_indices_mapping=None, bool include_last_offset=False) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::embedding_bag_byte(__torch__.torch.classes.quantized.EmbeddingPackedParamsBase weight, Tensor indices, Tensor? offsets=None, bool scale_grad_by_freq=False, int mode=0, bool pruned_weights=False, Tensor? per_sample_weights=None, Tensor? compressed_indices_mapping=None, bool include_last_offset=False) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::embedding_bag_4bit(__torch__.torch.classes.quantized.EmbeddingPackedParamsBase weight, Tensor indices, Tensor? offsets=None, bool scale_grad_by_freq=False, int mode=0, bool pruned_weights=False, Tensor? per_sample_weights=None, Tensor? compressed_indices_mapping=None, bool include_last_offset=False) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::embedding_byte(__torch__.torch.classes.quantized.EmbeddingPackedParamsBase weight, Tensor indices, bool pruned_weights=False) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::celu(Tensor self, float output_scale, int output_zero_point, Scalar alpha=1) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::group_norm(Tensor input, int num_groups, Tensor? weight, Tensor? bias, float eps, float output_scale, int output_zero_point) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::hardswish(Tensor input, float output_scale, int output_zero_point) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::instance_norm(Tensor input, Tensor? weight, Tensor? bias, float eps, float output_scale, int output_zero_point) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::layer_norm(Tensor input, int[] normalized_shape, Tensor? weight, Tensor? bias, float eps, float output_scale, int output_zero_point) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::linear(Tensor X, __torch__.torch.classes.quantized.LinearPackedParamsBase W_prepack, float Y_scale_i, int Y_zero_point_i) -> Tensor Y\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::linear_relu(Tensor X, __torch__.torch.classes.quantized.LinearPackedParamsBase W_prepack, float Y_scale_i, int Y_zero_point_i) -> Tensor Y\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::linear_dynamic(Tensor X, __torch__.torch.classes.quantized.LinearPackedParamsBase W_prepack, bool reduce_range=False) -> Tensor Y\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::linear_relu_dynamic(Tensor X, __torch__.torch.classes.quantized.LinearPackedParamsBase W_prepack, bool reduce_range=False) -> Tensor Y\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::linear_dynamic_fp16(Tensor X, __torch__.torch.classes.quantized.LinearPackedParamsBase W_prepack) -> Tensor Y\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::linear_prepack(Tensor W, Tensor? B=None) -> __torch__.torch.classes.quantized.LinearPackedParamsBase W_prepack\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::linear_prepack_fp16(Tensor W, Tensor? B=None) -> __torch__.torch.classes.quantized.LinearPackedParamsBase W_prepack\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::linear_prepack_legacy(Tensor W, Tensor? B=None) -> Tensor W_prepack\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::linear_prepack_fp16_legacy(Tensor W, Tensor? B=None) -> Tensor W_prepack\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::linear_unpack(__torch__.torch.classes.quantized.LinearPackedParamsBase W_prepack) -> (Tensor W_origin, Tensor? B_origin)\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::linear_unpack_fp16(__torch__.torch.classes.quantized.LinearPackedParamsBase W_prepack) -> (Tensor W_origin, Tensor? B_origin)\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::linear_unpack.legacy(Tensor W_prepack) -> (Tensor W_origin, Tensor? B_origin)\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::linear_unpack_fp16.legacy(Tensor W_prepack) -> (Tensor W_origin, Tensor? B_origin)\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::mul(Tensor qa, Tensor qb, float scale, int zero_point)-> Tensor qc\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::mul.out(Tensor qa, Tensor qb, Tensor(a!) out)-> Tensor(a!) out\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::mul.Scalar(Tensor qa, Scalar b)-> Tensor qc\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::mul.Scalar2(Scalar b, Tensor qa)-> Tensor qc\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::mul.Scalar_out(Tensor qa, Scalar b, Tensor(a!) out)-> Tensor(a!) out\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::mul_relu(Tensor qa, Tensor qb, float scale, int zero_point)-> Tensor qc\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::mul_relu.out(Tensor qa, Tensor qb, Tensor(a!) out)-> Tensor(a!) out\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::mul_relu.Scalar(Tensor qa, Scalar b)-> Tensor qc\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::mul_relu.Scalar2(Scalar b, Tensor qa)-> Tensor qc\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::mul_relu.Scalar_out(Tensor qa, Scalar b, Tensor(a!) out)-> Tensor(a!) out\"));\n  // deprecated functions, kept for backward compatibility\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::mul_out(Tensor qa, Tensor qb, Tensor(a!) out)-> Tensor(a!) out\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::mul_relu_out(Tensor qa, Tensor qb, Tensor(a!) out)-> Tensor(a!) out\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::mul_scalar(Tensor qa, Scalar b)-> Tensor qc\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::mul_scalar_relu(Tensor qa, Scalar b)-> Tensor qc\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::mul_scalar_out(Tensor qa, Scalar b, Tensor(a!) out)-> Tensor(a!) out\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::mul_scalar_relu_out(Tensor qa, Scalar b, Tensor(a!) out)-> Tensor(a!) out\"));\n  // TODO: remove after broadcasting is supported\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::mul_scalar.Tensor(Tensor qa, Tensor b)-> Tensor qc\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::mul_scalar_relu.Tensor(Tensor qa, Tensor b)-> Tensor qc\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::mul_scalar_out.Tensor(Tensor qa, Tensor b, Tensor(a!) out)-> Tensor(a!) out\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::mul_scalar_relu_out.Tensor(Tensor qa, Tensor b, Tensor(a!) out)-> Tensor(a!) out\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::max_pool1d(Tensor qx, int[] kernel_size, int[] stride, int[] padding, int[] dilation, bool ceil_mode) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::max_pool2d(Tensor qx, int[] kernel_size, int[] stride, int[] padding, int[] dilation, bool ceil_mode) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::relu6(Tensor qx, bool inplace=False) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::leaky_relu(Tensor qx, Scalar negative_slope, bool inplace, float output_scale, int output_zero_point) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"quantized::sigmoid(Tensor qx, float output_scale, int output_zero_point) -> Tensor\"));\n}",
            "{\n  m.def(TORCH_SELECTIVE_SCHEMA(\"_quantized::add(Tensor qa, Tensor qb, float scale, int zero_point) -> Tensor qc\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"_quantized::conv2d(Tensor qx, __torch__.torch.classes.quantized.Conv2dPackedParamsBase packed_weight, float output_scale, int output_zero_point) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"_quantized::conv2d_relu(Tensor qx, __torch__.torch.classes.quantized.Conv2dPackedParamsBase packed_weight, float output_scale, int output_zero_point) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"_quantized::conv2d_prepack(Tensor weight, Tensor? bias, int[] stride, int[] padding, int[] dilation, int groups) -> __torch__.torch.classes.quantized.Conv2dPackedParamsBase\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"_quantized::conv_transpose1d(Tensor qx, __torch__.torch.classes.quantized.Conv2dPackedParamsBase packed_weight, float output_scale, int output_zero_point) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"_quantized::conv_transpose2d(Tensor qx, __torch__.torch.classes.quantized.Conv2dPackedParamsBase packed_weight, float output_scale, int output_zero_point) -> Tensor\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"_quantized::conv_transpose1d_prepack(Tensor weight, Tensor? bias, int[] stride, int[] padding, int[] output_padding, int[] dilation, int groups) -> __torch__.torch.classes.quantized.Conv2dPackedParamsBase\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"_quantized::conv_transpose2d_prepack(Tensor weight, Tensor? bias, int[] stride, int[] padding, int[] output_padding, int[] dilation, int groups) -> __torch__.torch.classes.quantized.Conv2dPackedParamsBase\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"_quantized::conv_transpose3d_prepack(Tensor weight, Tensor? bias, int[] stride, int[] padding, int[] output_padding, int[] dilation, int groups) -> __torch__.torch.classes.quantized.Conv3dPackedParamsBase\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"_quantized::linear(Tensor X, __torch__.torch.classes.quantized.LinearPackedParamsBase W_prepack, float Y_scale_i, int Y_zero_point_i) -> Tensor Y\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"_quantized::linear_dynamic(Tensor X, __torch__.torch.classes.quantized.LinearPackedParamsBase W_prepack, bool reduce_range=False) -> Tensor Y\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"_quantized::linear_prepack(Tensor W, Tensor? B=None) -> __torch__.torch.classes.quantized.LinearPackedParamsBase W_prepack\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"_quantized::linear_prepack_fp16(Tensor W, Tensor? B=None) -> __torch__.torch.classes.quantized.LinearPackedParamsBase W_prepack\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"_quantized::linear_prepack_legacy(Tensor W, Tensor? B=None) -> Tensor W_prepack\"));\n  m.def(TORCH_SELECTIVE_SCHEMA(\"_quantized::linear_prepack_fp16_legacy(Tensor W, Tensor? B=None) -> Tensor W_prepack\"));\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/QTensor.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/TensorCompare.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/TensorFactories.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/fbgemm_utils.cpp",
        "functions": [
            "register_linear_params()",
            "register_embedding_params()"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/init_qnnpack.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/int_repr_quant.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/make_per_tensor_quantized_tensor.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qadd.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qbatch_norm.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qchannel_shuffle.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qclamp.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qconcat.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qconv.cpp",
        "functions": [
            "int64_t"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qconv_prepack.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qconv_unpack.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qelu.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qembeddingbag.cpp",
        "functions": [
            "PackedEmbeddingBagWeight::embeddingbag_byte(\n    const at::Tensor& indices,\n    const c10::optional<at::Tensor>& offsets_in,\n    bool pruned_weights,\n    const c10::optional<at::Tensor>& per_sample_weights_,\n    const c10::optional<at::Tensor>& compressed_indices_mapping,\n    bool include_last_offset,\n    bool is_embedding_op)",
            "PackedEmbeddingBagWeight::embeddingbag_4bit(\n    const at::Tensor& indices,\n    const c10::optional<at::Tensor>& offsets_in,\n    bool pruned_weights,\n    const c10::optional<at::Tensor>& per_sample_weights_,\n    const c10::optional<at::Tensor>& compressed_indices_mapping,\n    bool include_last_offset)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qembeddingbag_prepack.cpp",
        "functions": [
            "PackedEmbeddingBagWeight::prepack(\n    at::Tensor qweight)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qembeddingbag_unpack.cpp",
        "functions": [
            "PackedEmbeddingBagWeight::unpack()"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qhardsigmoid.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qhardswish.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qlinear.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qlinear_dynamic.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qlinear_prepack.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qlinear_unpack.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qmul.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnormalization.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qpool.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qreduction.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qrelu.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qsigmoid.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qsort.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qtanh.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qthreshold.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qupsample_bilinear2d.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qupsample_nearest2d.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qupsample_nearest3d.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/q_adaavgpool.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/q_avgpool.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/q_avgpool3d.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/tensor_operators.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/configure.py",
        "functions": [
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/generate-wrapper.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/deps/clog/configure.py",
        "functions": [
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/deps/clog/src/clog.c",
        "functions": [
            "clog_vlog_fatal(const char* module, const char* format, va_list args)",
            "clog_vlog_error(const char* module, const char* format, va_list args)",
            "clog_vlog_warning(const char* module, const char* format, va_list args)",
            "clog_vlog_info(const char* module, const char* format, va_list args)",
            "clog_vlog_debug(const char* module, const char* format, va_list args)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/add.c",
        "functions": [
            "pytorch_qnnp_create_add_nc_q8(\n    size_t channels,\n    uint8_t a_zero_point,\n    float a_scale,\n    uint8_t b_zero_point,\n    float b_scale,\n    uint8_t sum_zero_point,\n    float sum_scale,\n    uint8_t sum_min,\n    uint8_t sum_max,\n    uint32_t flags,\n    pytorch_qnnp_operator_t* add_out)",
            "pytorch_qnnp_setup_add_nc_q8(\n    pytorch_qnnp_operator_t add_op,\n    size_t batch_size,\n    const uint8_t* a,\n    size_t a_stride,\n    const uint8_t* b,\n    size_t b_stride,\n    uint8_t* sum,\n    size_t sum_stride)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/average-pooling.c",
        "functions": [
            "inline",
            "pytorch_qnnp_create_average_pooling2d_nhwc_q8(\n    uint32_t input_padding_top,\n    uint32_t input_padding_right,\n    uint32_t input_padding_bottom,\n    uint32_t input_padding_left,\n    uint32_t pooling_height,\n    uint32_t pooling_width,\n    uint32_t stride_height,\n    uint32_t stride_width,\n    size_t channels,\n    uint8_t input_zero_point,\n    float input_scale,\n    uint8_t output_zero_point,\n    float output_scale,\n    uint8_t output_min,\n    uint8_t output_max,\n    uint32_t flags,\n    pytorch_qnnp_operator_t* average_pooling_out)",
            "pytorch_qnnp_setup_average_pooling2d_nhwc_q8(\n    pytorch_qnnp_operator_t average_pooling,\n    size_t batch_size,\n    size_t input_height,\n    size_t input_width,\n    const uint8_t* input,\n    size_t input_pixel_stride,\n    uint8_t* output,\n    size_t output_pixel_stride,\n    pthreadpool_t threadpool)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/channel-shuffle.c",
        "functions": [
            "pytorch_qnnp_create_channel_shuffle_nc_x8(\n    size_t groups,\n    size_t group_channels,\n    uint32_t flags,\n    pytorch_qnnp_operator_t* channel_shuffle_out)",
            "pytorch_qnnp_setup_channel_shuffle_nc_x8(\n    pytorch_qnnp_operator_t channel_shuffle_op,\n    size_t batch_size,\n    const uint8_t* input,\n    size_t input_stride,\n    uint8_t* output,\n    size_t output_stride)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/clamp.c",
        "functions": [
            "pytorch_qnnp_create_clamp_nc_u8(\n    size_t channels,\n    uint8_t output_min,\n    uint8_t output_max,\n    uint32_t flags,\n    pytorch_qnnp_operator_t* clamp_out)",
            "pytorch_qnnp_setup_clamp_nc_u8(\n    pytorch_qnnp_operator_t clamp,\n    size_t batch_size,\n    const uint8_t* input,\n    size_t input_stride,\n    uint8_t* output,\n    size_t output_stride)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/convolution.c",
        "functions": [
            "inline",
            "pytorch_qnnp_create_convolution2d_nhwc_q8(\n    uint32_t input_padding_top,\n    uint32_t input_padding_right,\n    uint32_t input_padding_bottom,\n    uint32_t input_padding_left,\n    uint32_t kernel_height,\n    uint32_t kernel_width,\n    uint32_t subsampling_height,\n    uint32_t subsampling_width,\n    uint32_t dilation_height,\n    uint32_t dilation_width,\n    uint32_t groups,\n    size_t group_input_channels,\n    size_t group_output_channels,\n    uint8_t input_zero_point,\n    const uint8_t* kernel_zero_points,\n    const uint8_t* kernel,\n    const int32_t* bias,\n    uint8_t output_zero_point,\n    uint8_t output_min,\n    uint8_t output_max,\n    uint32_t flags,\n    const float* requantization_scales,\n    bool per_channel,\n    pytorch_qnnp_operator_t* convolution_out)",
            "pytorch_qnnp_setup_convolution2d_nhwc_q8(\n    pytorch_qnnp_operator_t convolution,\n    size_t batch_size,\n    size_t input_height,\n    size_t input_width,\n    const uint8_t* input,\n    size_t input_pixel_stride,\n    uint8_t* output,\n    size_t output_pixel_stride,\n    pthreadpool_t threadpool)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/deconvolution.c",
        "functions": [
            "inline",
            "pytorch_qnnp_create_deconvolution2d_nhwc_q8(\n    uint32_t input_padding_top,\n    uint32_t input_padding_right,\n    uint32_t input_padding_bottom,\n    uint32_t input_padding_left,\n    uint32_t adjustment_height,\n    uint32_t adjustment_width,\n    uint32_t kernel_height,\n    uint32_t kernel_width,\n    uint32_t stride_height,\n    uint32_t stride_width,\n    uint32_t dilation_height,\n    uint32_t dilation_width,\n    uint32_t groups,\n    size_t group_input_channels,\n    size_t group_output_channels,\n    uint8_t input_zero_point,\n    const uint8_t* kernel_zero_points,\n    const uint8_t* kernel,\n    const int32_t* bias,\n    uint8_t output_zero_point,\n    uint8_t output_min,\n    uint8_t output_max,\n    uint32_t flags,\n    const float* requantization_scales,\n    pytorch_qnnp_operator_t* deconvolution_out)",
            "pytorch_qnnp_setup_deconvolution2d_nhwc_q8(\n    pytorch_qnnp_operator_t deconvolution,\n    size_t batch_size,\n    size_t input_height,\n    size_t input_width,\n    const uint8_t* input,\n    size_t input_pixel_stride,\n    uint8_t* output,\n    size_t output_pixel_stride,\n    pthreadpool_t threadpool)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/fully-connected-sparse.c",
        "functions": [
            "pytorch_qnnp_create_fully_connected_sparse_dq_nc_q8(\n    size_t input_channels,\n    size_t output_channels,\n    uint8_t input_zero_point,\n    const uint8_t* kernel_zero_points,\n    const uint32_t* kernel_col_indices,\n    const uint32_t* kernel_row_values,\n    const uint8_t* kernel_values,\n    const uint32_t kernel_col_block_size,\n    uint8_t output_zero_point,\n    uint8_t output_min,\n    uint8_t output_max,\n    uint32_t flags,\n    const float* requantization_scales,\n    bool use_prepack_kernel,\n    pytorch_qnnp_operator_t* fully_connected_out)",
            "pytorch_qnnp_setup_fully_connected_sparse_dq_nc_q8(\n    pytorch_qnnp_operator_t fully_connected,\n    size_t batch_size,\n    const uint8_t* input,\n    size_t input_stride,\n    const float* bias,\n    float* output,\n    size_t output_stride)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/fully-connected.c",
        "functions": [
            "pytorch_qnnp_create_fully_connected_nc_q8(\n    size_t input_channels,\n    size_t output_channels,\n    uint8_t input_zero_point,\n    const uint8_t* kernel_zero_points,\n    const uint8_t* kernel,\n    const int32_t* bias,\n    uint8_t output_zero_point,\n    uint8_t output_min,\n    uint8_t output_max,\n    uint32_t flags,\n    const float* requantization_scales,\n    pytorch_qnnp_operator_t* fully_connected_out)",
            "pytorch_qnnp_setup_fully_connected_nc_q8(\n    pytorch_qnnp_operator_t fully_connected,\n    size_t batch_size,\n    const uint8_t* input,\n    size_t input_stride,\n    uint8_t* output,\n    size_t output_stride)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/global-average-pooling.c",
        "functions": [
            "pytorch_qnnp_create_global_average_pooling_nwc_q8(\n    size_t channels,\n    uint8_t input_zero_point,\n    float input_scale,\n    uint8_t output_zero_point,\n    float output_scale,\n    uint8_t output_min,\n    uint8_t output_max,\n    uint32_t flags,\n    pytorch_qnnp_operator_t* global_average_pooling_out)",
            "pytorch_qnnp_setup_global_average_pooling_nwc_q8(\n    pytorch_qnnp_operator_t global_average_pooling_op,\n    size_t batch_size,\n    size_t width,\n    const uint8_t* input,\n    size_t input_stride,\n    uint8_t* output,\n    size_t output_stride)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/hardsigmoid.c",
        "functions": [
            "pytorch_qnnp_create_hardsigmoid_nc_q8(\n    size_t channels,\n    uint8_t input_zero_point,\n    float input_scale,\n    uint8_t output_zero_point,\n    float output_scale,\n    uint8_t output_min,\n    uint8_t output_max,\n    uint32_t flags,\n    pytorch_qnnp_operator_t* hardsigmoid_out)",
            "pytorch_qnnp_setup_hardsigmoid_nc_q8(\n    pytorch_qnnp_operator_t hardsigmoid,\n    size_t batch_size,\n    const uint8_t* input,\n    size_t input_stride,\n    uint8_t* output,\n    size_t output_stride)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/hardswish.c",
        "functions": [
            "pytorch_qnnp_create_hardswish_nc_q8(\n    size_t channels,\n    uint8_t input_zero_point,\n    float input_scale,\n    uint8_t output_zero_point,\n    float output_scale,\n    uint8_t output_min,\n    uint8_t output_max,\n    uint32_t flags,\n    pytorch_qnnp_operator_t* hardswish_out)",
            "pytorch_qnnp_setup_hardswish_nc_q8(\n    pytorch_qnnp_operator_t hardswish,\n    size_t batch_size,\n    const uint8_t* input,\n    size_t input_stride,\n    uint8_t* output,\n    size_t output_stride)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/indirection.c",
        "functions": [
            "pytorch_qnnp_indirection_init_conv2d(\n    pytorch_qnnp_operator_t op,\n    size_t output_tile_size,\n    size_t tiled_output_size)",
            "pytorch_qnnp_indirection_init_dwconv2d(\n    pytorch_qnnp_operator_t op,\n    size_t batch_start,\n    size_t step_height,\n    size_t step_width)",
            "pytorch_qnnp_indirection_init_deconv2d(\n    pytorch_qnnp_operator_t op,\n    size_t output_tile_size,\n    size_t tiled_output_size)",
            "pytorch_qnnp_indirection_init_maxpool2d(\n    pytorch_qnnp_operator_t op,\n    size_t batch_start,\n    size_t step_height,\n    size_t step_width)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/init.c",
        "functions": [
            "void",
            "pytorch_qnnp_initialize(void)",
            "pytorch_qnnp_deinitialize(void)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/leaky-relu.c",
        "functions": [
            "pytorch_qnnp_create_leaky_relu_nc_q8(\n    size_t channels,\n    float negative_slope,\n    uint8_t input_zero_point,\n    float input_scale,\n    uint8_t output_zero_point,\n    float output_scale,\n    uint8_t output_min,\n    uint8_t output_max,\n    uint32_t flags,\n    pytorch_qnnp_operator_t* leaky_relu_out)",
            "pytorch_qnnp_setup_leaky_relu_nc_q8(\n    pytorch_qnnp_operator_t leaky_relu,\n    size_t batch_size,\n    const uint8_t* input,\n    size_t input_stride,\n    uint8_t* output,\n    size_t output_stride)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/max-pooling.c",
        "functions": [
            "inline",
            "pytorch_qnnp_create_max_pooling2d_nhwc_u8(\n    uint32_t input_padding_top,\n    uint32_t input_padding_right,\n    uint32_t input_padding_bottom,\n    uint32_t input_padding_left,\n    uint32_t pooling_height,\n    uint32_t pooling_width,\n    uint32_t stride_height,\n    uint32_t stride_width,\n    uint32_t dilation_height,\n    uint32_t dilation_width,\n    size_t channels,\n    uint8_t output_min,\n    uint8_t output_max,\n    uint32_t flags,\n    pytorch_qnnp_operator_t* max_pooling_out)",
            "pytorch_qnnp_setup_max_pooling2d_nhwc_u8(\n    pytorch_qnnp_operator_t max_pooling,\n    size_t batch_size,\n    size_t input_height,\n    size_t input_width,\n    const uint8_t* input,\n    size_t input_pixel_stride,\n    uint8_t* output,\n    size_t output_pixel_stride,\n    pthreadpool_t threadpool)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/operator-delete.c",
        "functions": [
            "pytorch_qnnp_delete_operator(\n    pytorch_qnnp_operator_t op)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/operator-run.c",
        "functions": [
            "void",
            "void",
            "void",
            "void",
            "void",
            "void",
            "void",
            "void",
            "void",
            "void",
            "void",
            "void",
            "void",
            "void",
            "void",
            "void",
            "void",
            "void",
            "void",
            "void",
            "void",
            "void",
            "void",
            "pytorch_qnnp_run_operator(\n    pytorch_qnnp_operator_t op,\n    pthreadpool_t threadpool)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/sigmoid.c",
        "functions": [
            "pytorch_qnnp_create_sigmoid_nc_q8(\n    size_t channels,\n    uint8_t input_zero_point,\n    float input_scale,\n    uint8_t output_zero_point,\n    float output_scale,\n    uint8_t output_min,\n    uint8_t output_max,\n    uint32_t flags,\n    pytorch_qnnp_operator_t* sigmoid_out)",
            "pytorch_qnnp_setup_sigmoid_nc_q8(\n    pytorch_qnnp_operator_t sigmoid,\n    size_t batch_size,\n    const uint8_t* input,\n    size_t input_stride,\n    uint8_t* output,\n    size_t output_stride)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/softargmax.c",
        "functions": [
            "pytorch_qnnp_create_softargmax_nc_q8(\n    size_t channels,\n    float input_scale,\n    uint8_t output_zero_point,\n    float output_scale,\n    uint32_t flags,\n    pytorch_qnnp_operator_t* softargmax_out)",
            "pytorch_qnnp_setup_softargmax_nc_q8(\n    pytorch_qnnp_operator_t softargmax,\n    size_t batch_size,\n    const uint8_t* input,\n    size_t input_stride,\n    uint8_t* output,\n    size_t output_stride)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/tanh.c",
        "functions": [
            "pytorch_qnnp_create_tanh_nc_q8(\n    size_t channels,\n    uint8_t input_zero_point,\n    float input_scale,\n    uint8_t output_zero_point,\n    float output_scale,\n    uint8_t output_min,\n    uint8_t output_max,\n    uint32_t flags,\n    pytorch_qnnp_operator_t* tanh_out)",
            "pytorch_qnnp_setup_tanh_nc_q8(\n    pytorch_qnnp_operator_t tanh,\n    size_t batch_size,\n    const uint8_t* input,\n    size_t input_stride,\n    uint8_t* output,\n    size_t output_stride)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/hgemm/8x8-neonfp16arith.c",
        "functions": [
            "pytorch_hgemm_ukernel_8x8__neonfp16arith(\n    size_t mr,\n    size_t nr,\n    size_t k,\n    const void* restrict a,\n    size_t a_stride,\n    const void* restrict w,\n    void* restrict c,\n    size_t c_stride,\n    const struct pytorch_qnnp_fp16_clamping_params\n        clamping_params[restrict static 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8avgpool/mp8x9p8q-neon.c",
        "functions": [
            "pytorch_q8avgpool_ukernel_mp8x9p8q__neon(\n    size_t n,\n    size_t ks,\n    size_t kc,\n    const uint8_t** input,\n    const uint8_t* zero,\n    int32_t* buffer,\n    uint8_t* output,\n    size_t input_increment,\n    size_t output_increment,\n    const union pytorch_qnnp_avgpool_quantization_params\n        quantization_params[restrict static 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8avgpool/mp8x9p8q-sse2.c",
        "functions": [
            "pytorch_q8avgpool_ukernel_mp8x9p8q__sse2(\n    size_t n,\n    size_t ks,\n    size_t kc,\n    const uint8_t** input,\n    const uint8_t* zero,\n    int32_t* buffer,\n    uint8_t* output,\n    size_t input_increment,\n    size_t output_increment,\n    const union pytorch_qnnp_avgpool_quantization_params\n        quantization_params[RESTRICT_STATIC 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8avgpool/up8x9-neon.c",
        "functions": [
            "pytorch_q8avgpool_ukernel_up8x9__neon(\n    size_t n,\n    size_t ks,\n    size_t kc,\n    const uint8_t** input,\n    const uint8_t* zero,\n    uint8_t* output,\n    size_t input_increment,\n    size_t output_increment,\n    const union pytorch_qnnp_avgpool_quantization_params\n        quantization_params[restrict static 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8avgpool/up8x9-sse2.c",
        "functions": [
            "pytorch_q8avgpool_ukernel_up8x9__sse2(\n    size_t n,\n    size_t ks,\n    size_t kc,\n    const uint8_t** input,\n    const uint8_t* zero,\n    uint8_t* output,\n    size_t input_increment,\n    size_t output_increment,\n    const union pytorch_qnnp_avgpool_quantization_params\n        quantization_params[RESTRICT_STATIC 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8avgpool/up8xm-neon.c",
        "functions": [
            "pytorch_q8avgpool_ukernel_up8xm__neon(\n    size_t n,\n    size_t ks,\n    size_t kc,\n    const uint8_t** input,\n    const uint8_t* zero,\n    uint8_t* output,\n    size_t input_increment,\n    size_t output_increment,\n    const union pytorch_qnnp_avgpool_quantization_params\n        quantization_params[restrict static 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8avgpool/up8xm-sse2.c",
        "functions": [
            "pytorch_q8avgpool_ukernel_up8xm__sse2(\n    size_t n,\n    size_t ks,\n    size_t kc,\n    const uint8_t** input,\n    const uint8_t* zero,\n    uint8_t* output,\n    size_t input_increment,\n    size_t output_increment,\n    const union pytorch_qnnp_avgpool_quantization_params\n        quantization_params[RESTRICT_STATIC 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8conv/4x4c2-sse2.c",
        "functions": [
            "pytorch_q8conv_ukernel_4x4c2__sse2(\n    size_t mr,\n    size_t nr,\n    size_t kc,\n    size_t ks,\n    const uint8_t** restrict a,\n    const void* restrict w,\n    uint8_t* restrict c,\n    size_t c_stride,\n    size_t output_channel_index,\n    const union pytorch_qnnp_conv_quantization_params\n        quantization_params[RESTRICT_STATIC 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8conv/4x8-neon.c",
        "functions": [
            "pytorch_q8conv_ukernel_4x8__neon(\n    size_t mr,\n    size_t nr,\n    size_t kc,\n    size_t ks,\n    const uint8_t** restrict a,\n    const void* restrict w,\n    uint8_t* restrict c,\n    size_t c_stride,\n    size_t output_channel_index,\n    const union pytorch_qnnp_conv_quantization_params\n        quantization_params[restrict static 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8conv/8x8-neon.c",
        "functions": [
            "pytorch_q8conv_ukernel_8x8__neon(\n    size_t mr,\n    size_t nr,\n    size_t kc,\n    size_t ks,\n    const uint8_t** restrict a,\n    const void* restrict w,\n    uint8_t* restrict c,\n    size_t c_stride,\n    size_t output_channel_index,\n    const union pytorch_qnnp_conv_quantization_params\n        quantization_params[restrict static 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8dwconv/mp8x25-neon-per-channel.c",
        "functions": [
            "pytorch_q8dwconv_ukernel_mp8x25_per_channel__neon(\n    size_t channels,\n    size_t output_width,\n    const uint8_t** input,\n    const void* weights,\n    int32_t* outacc32,\n    uint8_t* output,\n    size_t input_stride,\n    size_t output_increment,\n    const union pytorch_qnnp_conv_quantization_params\n        quantization_params[restrict static 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8dwconv/mp8x25-neon.c",
        "functions": [
            "pytorch_q8dwconv_ukernel_mp8x25__neon(\n    size_t channels,\n    size_t output_width,\n    const uint8_t** input,\n    const void* weights,\n    int32_t* outacc32,\n    uint8_t* output,\n    size_t input_stride,\n    size_t output_increment,\n    const union pytorch_qnnp_conv_quantization_params\n        quantization_params[restrict static 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8dwconv/mp8x25-sse2-per-channel.c",
        "functions": [
            "pytorch_q8dwconv_ukernel_mp8x25_per_channel__sse2(\n    size_t channels,\n    size_t output_width,\n    const uint8_t** input,\n    const void* weights,\n    int32_t* outacc32,\n    uint8_t* output,\n    size_t input_stride,\n    size_t output_increment,\n    const union pytorch_qnnp_conv_quantization_params\n        quantization_params[RESTRICT_STATIC 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8dwconv/mp8x25-sse2.c",
        "functions": [
            "pytorch_q8dwconv_ukernel_mp8x25__sse2(\n    size_t channels,\n    size_t output_width,\n    const uint8_t** input,\n    const void* weights,\n    int32_t* outacc32,\n    uint8_t* output,\n    size_t input_stride,\n    size_t output_increment,\n    const union pytorch_qnnp_conv_quantization_params\n        quantization_params[RESTRICT_STATIC 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8dwconv/up8x9-neon-per-channel.c",
        "functions": [
            "pytorch_q8dwconv_ukernel_up8x9_per_channel__neon(\n    size_t channels,\n    size_t output_width,\n    const uint8_t** input,\n    const void* weights,\n    uint8_t* output,\n    size_t input_stride,\n    size_t output_increment,\n    const union pytorch_qnnp_conv_quantization_params\n        quantization_params[restrict static 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8dwconv/up8x9-neon.c",
        "functions": [
            "pytorch_q8dwconv_ukernel_up8x9__neon(\n    size_t channels,\n    size_t output_width,\n    const uint8_t** input,\n    const void* weights,\n    uint8_t* output,\n    size_t input_stride,\n    size_t output_increment,\n    const union pytorch_qnnp_conv_quantization_params\n        quantization_params[restrict static 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8dwconv/up8x9-sse2-per-channel.c",
        "functions": [
            "pytorch_q8dwconv_ukernel_up8x9_per_channel__sse2(\n    size_t channels,\n    size_t output_width,\n    const uint8_t** input,\n    const void* weights,\n    uint8_t* output,\n    size_t input_stride,\n    size_t output_increment,\n    const union pytorch_qnnp_conv_quantization_params\n        quantization_params[RESTRICT_STATIC 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8dwconv/up8x9-sse2.c",
        "functions": [
            "pytorch_q8dwconv_ukernel_up8x9__sse2(\n    size_t channels,\n    size_t output_width,\n    const uint8_t** input,\n    const void* weights,\n    uint8_t* output,\n    size_t input_stride,\n    size_t output_increment,\n    const union pytorch_qnnp_conv_quantization_params\n        quantization_params[RESTRICT_STATIC 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8gavgpool/mp8x7p7q-neon.c",
        "functions": [
            "pytorch_q8gavgpool_ukernel_mp8x7p7q__neon(\n    size_t m,\n    size_t n,\n    const uint8_t* input,\n    size_t input_stride,\n    const uint8_t* zero,\n    int32_t* buffer,\n    uint8_t* output,\n    const union pytorch_qnnp_avgpool_quantization_params\n        quantization_params[restrict static 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8gavgpool/mp8x7p7q-sse2.c",
        "functions": [
            "pytorch_q8gavgpool_ukernel_mp8x7p7q__sse2(\n    size_t m,\n    size_t n,\n    const uint8_t* input,\n    size_t input_stride,\n    const uint8_t* zero,\n    int32_t* buffer,\n    uint8_t* output,\n    const union pytorch_qnnp_avgpool_quantization_params\n        quantization_params[RESTRICT_STATIC 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8gavgpool/up8x7-neon.c",
        "functions": [
            "pytorch_q8gavgpool_ukernel_up8x7__neon(\n    size_t m,\n    size_t n,\n    const uint8_t* input,\n    size_t input_stride,\n    const uint8_t* zero,\n    uint8_t* output,\n    const union pytorch_qnnp_avgpool_quantization_params\n        quantization_params[restrict static 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8gavgpool/up8x7-sse2.c",
        "functions": [
            "pytorch_q8gavgpool_ukernel_up8x7__sse2(\n    size_t m,\n    size_t n,\n    const uint8_t* input,\n    size_t input_stride,\n    const uint8_t* zero,\n    uint8_t* output,\n    const union pytorch_qnnp_avgpool_quantization_params\n        quantization_params[RESTRICT_STATIC 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8gavgpool/up8xm-neon.c",
        "functions": [
            "pytorch_q8gavgpool_ukernel_up8xm__neon(\n    size_t m,\n    size_t n,\n    const uint8_t* input,\n    size_t input_stride,\n    const uint8_t* zero,\n    uint8_t* output,\n    const union pytorch_qnnp_avgpool_quantization_params\n        quantization_params[restrict static 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8gavgpool/up8xm-sse2.c",
        "functions": [
            "pytorch_q8gavgpool_ukernel_up8xm__sse2(\n    size_t m,\n    size_t n,\n    const uint8_t* input,\n    size_t input_stride,\n    const uint8_t* zero,\n    uint8_t* output,\n    const union pytorch_qnnp_avgpool_quantization_params\n        quantization_params[RESTRICT_STATIC 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8gemm/2x4c8-sse2.c",
        "functions": [
            "inline",
            "pytorch_q8gemm_ukernel_2x4c8__sse2(\n    size_t mr,\n    size_t nr,\n    size_t k,\n    const uint8_t* restrict a,\n    size_t a_stride,\n    const void* restrict w,\n    uint8_t* restrict c,\n    size_t c_stride,\n    size_t output_channel_index,\n    const union pytorch_qnnp_conv_quantization_params\n        quantization_params[RESTRICT_STATIC 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8gemm/4x-sumrows-neon.c",
        "functions": [
            "pytorch_q8sumrows_ukernel_4x__neon(\n    const uint8_t* restrict a,\n    size_t m,\n    size_t k,\n    size_t stride,\n    const int32_t multiplier,\n    int32_t* restrict a_sum)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8gemm/4x4c2-dq-sse2.c",
        "functions": [
            "pytorch_q8gemm_dq_ukernel_4x4c2__sse2(\n    size_t mr,\n    size_t nr,\n    size_t k,\n    const uint8_t* restrict a,\n    size_t a_stride,\n    const void* restrict w,\n    const float* restrict b,\n    float* restrict c,\n    size_t c_stride,\n    size_t output_channel_index,\n    const struct pytorch_qnnp_conv_dynamic_quantization_params\n        quantization_params[RESTRICT_STATIC 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8gemm/4x4c2-sse2.c",
        "functions": [
            "pytorch_q8gemm_ukernel_4x4c2__sse2(\n    size_t mr,\n    size_t nr,\n    size_t k,\n    const uint8_t* restrict a,\n    size_t a_stride,\n    const void* restrict w,\n    uint8_t* restrict c,\n    size_t c_stride,\n    size_t output_channel_index,\n    const union pytorch_qnnp_conv_quantization_params\n        quantization_params[RESTRICT_STATIC 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8gemm/4x8-dq-neon.c",
        "functions": [
            "pytorch_q8gemm_dq_ukernel_4x8__neon(\n    size_t mr,\n    size_t nr,\n    size_t k,\n    const uint8_t* restrict a,\n    size_t a_stride,\n    const void* restrict w,\n    const float* restrict b,\n    float* restrict c,\n    size_t c_stride,\n    size_t output_channel_index,\n    const struct pytorch_qnnp_conv_dynamic_quantization_params\n        quantization_params[RESTRICT_STATIC 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8gemm/4x8-neon.c",
        "functions": [
            "pytorch_q8gemm_ukernel_4x8__neon(\n    size_t mr,\n    size_t nr,\n    size_t k,\n    const uint8_t* restrict a,\n    size_t a_stride,\n    const void* restrict w,\n    uint8_t* restrict c,\n    size_t c_stride,\n    size_t output_channel_index,\n    const union pytorch_qnnp_conv_quantization_params\n        quantization_params[restrict static 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8gemm/4x8c2-xzp-neon.c",
        "functions": [
            "pytorch_q8gemm_xzp_ukernel_4x8c2__neon(\n    size_t mr,\n    size_t nr,\n    size_t k,\n    const uint8_t* restrict a,\n    size_t a_stride,\n    const int32_t* restrict a_sum,\n    const void* restrict w,\n    uint8_t* restrict c,\n    size_t c_stride,\n    const union pytorch_qnnp_q31_requantization_params\n        requantization_params[restrict static 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8gemm/6x4-neon.c",
        "functions": [
            "pytorch_q8gemm_ukernel_6x4__neon(\n    size_t mr,\n    size_t nr,\n    size_t k,\n    const uint8_t* restrict a,\n    size_t a_stride,\n    const void* restrict w,\n    uint8_t* restrict c,\n    size_t c_stride,\n    size_t output_channel_index,\n    const union pytorch_qnnp_conv_quantization_params\n        quantization_params[restrict static 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8gemm/8x8-neon.c",
        "functions": [
            "pytorch_q8gemm_ukernel_8x8__neon(\n    size_t mr,\n    size_t nr,\n    size_t k,\n    const uint8_t* restrict a,\n    size_t a_stride,\n    const void* restrict w,\n    uint8_t* restrict c,\n    size_t c_stride,\n    size_t output_channel_index,\n    const union pytorch_qnnp_conv_quantization_params\n        quantization_params[restrict static 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8gemm_sparse/8x4-packA-sse2.c",
        "functions": [
            "pytorch_q8gemm_sparse_packA_ukernel_8x4__sse2(\n    const size_t mr,\n    const size_t K,\n    const uint8_t* a,\n    const size_t a_stride,\n    uint8_t* a_packed)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8gemm_sparse/8x4c1x4-dq-packedA-sse2.c",
        "functions": [
            "pytorch_q8gemm_dq_sparse_1x4_ukernel_8x4_packedA__sse2(\n    size_t mr,\n    size_t nr,\n    const uint8_t* a_packed,\n    const uint8_t* packed_w,\n    const uint32_t* w_row_ptr,\n    const uint32_t* w_block_ids_ptr,\n    const float* b,\n    float* c,\n    size_t c_stride,\n    size_t output_channel_index,\n    const struct pytorch_qnnp_conv_dynamic_quantization_params\n        quantization_params[RESTRICT_STATIC 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8gemm_sparse/8x4c1x4-dq-sse2.c",
        "functions": [
            "__m128i",
            "pytorch_q8gemm_dq_sparse_1x4_ukernel_8x4__sse2(\n    size_t mr,\n    size_t nr,\n    const uint8_t* a,\n    size_t a_stride,\n    const uint8_t* packed_w,\n    const uint32_t* w_row_ptr,\n    const uint32_t* w_block_ids_ptr,\n    const float* b,\n    float* c,\n    size_t c_stride,\n    size_t output_channel_index,\n    const struct pytorch_qnnp_conv_dynamic_quantization_params\n        quantization_params[RESTRICT_STATIC 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8vadd/neon.c",
        "functions": [
            "pytorch_q8vadd_ukernel__neon(\n    size_t n,\n    const uint8_t* a,\n    const uint8_t* b,\n    uint8_t* y,\n    const union pytorch_qnnp_add_quantization_params\n        quantization_params[restrict static 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/q8vadd/sse2.c",
        "functions": [
            "pytorch_q8vadd_ukernel__sse2(\n    size_t n,\n    const uint8_t* a,\n    const uint8_t* b,\n    uint8_t* y,\n    const union pytorch_qnnp_add_quantization_params\n        quantization_params[RESTRICT_STATIC 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization/fp32-neon.c",
        "functions": [
            "pytorch_qnnp_requantize_fp32__neon(\n    size_t n,\n    const int32_t* input,\n    float scale,\n    uint8_t zero_point,\n    uint8_t qmin,\n    uint8_t qmax,\n    uint8_t* output)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization/fp32-psimd.c",
        "functions": [
            "pytorch_qnnp_requantize_fp32__psimd(\n    size_t n,\n    const int32_t* input,\n    float scale,\n    uint8_t zero_point,\n    uint8_t qmin,\n    uint8_t qmax,\n    uint8_t* output)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization/fp32-scalar.c",
        "functions": [
            "pytorch_qnnp_requantize_fp32__scalar_lrintf(\n    size_t n,\n    const int32_t* input,\n    float scale,\n    uint8_t zero_point,\n    uint8_t qmin,\n    uint8_t qmax,\n    uint8_t* output)",
            "pytorch_qnnp_requantize_fp32__scalar_magic(\n    size_t n,\n    const int32_t* input,\n    float scale,\n    uint8_t zero_point,\n    uint8_t qmin,\n    uint8_t qmax,\n    uint8_t* output)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization/fp32-sse2.c",
        "functions": [
            "pytorch_qnnp_requantize_fp32__sse2(\n    size_t n,\n    const int32_t* input,\n    float scale,\n    uint8_t zero_point,\n    uint8_t qmin,\n    uint8_t qmax,\n    uint8_t* output)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization/gemmlowp-neon.c",
        "functions": [
            "pytorch_qnnp_requantize_gemmlowp__neon(\n    size_t n,\n    const int32_t* input,\n    float scale,\n    uint8_t zero_point,\n    uint8_t qmin,\n    uint8_t qmax,\n    uint8_t* output)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization/gemmlowp-scalar.c",
        "functions": [
            "pytorch_qnnp_requantize_gemmlowp__scalar(\n    size_t n,\n    const int32_t* input,\n    float scale,\n    uint8_t zero_point,\n    uint8_t qmin,\n    uint8_t qmax,\n    uint8_t* output)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization/gemmlowp-sse2.c",
        "functions": [
            "pytorch_qnnp_requantize_gemmlowp__sse2(\n    size_t n,\n    const int32_t* input,\n    float scale,\n    uint8_t zero_point,\n    uint8_t qmin,\n    uint8_t qmax,\n    uint8_t* output)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization/gemmlowp-sse4.c",
        "functions": [
            "pytorch_qnnp_requantize_gemmlowp__sse4(\n    size_t n,\n    const int32_t* input,\n    float scale,\n    uint8_t zero_point,\n    uint8_t qmin,\n    uint8_t qmax,\n    uint8_t* output)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization/gemmlowp-ssse3.c",
        "functions": [
            "pytorch_qnnp_requantize_gemmlowp__ssse3(\n    size_t n,\n    const int32_t* input,\n    float scale,\n    uint8_t zero_point,\n    uint8_t qmin,\n    uint8_t qmax,\n    uint8_t* output)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization/precise-neon.c",
        "functions": [
            "pytorch_qnnp_requantize_precise__neon(\n    size_t n,\n    const int32_t* input,\n    float scale,\n    uint8_t zero_point,\n    uint8_t qmin,\n    uint8_t qmax,\n    uint8_t* output)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization/precise-psimd.c",
        "functions": [
            "pytorch_qnnp_requantize_precise__psimd(\n    size_t n,\n    const int32_t* input,\n    float scale,\n    uint8_t zero_point,\n    uint8_t qmin,\n    uint8_t qmax,\n    uint8_t* output)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization/precise-scalar.c",
        "functions": [
            "pytorch_qnnp_requantize_precise__scalar_unsigned32(\n    size_t n,\n    const int32_t* input,\n    float scale,\n    uint8_t zero_point,\n    uint8_t qmin,\n    uint8_t qmax,\n    uint8_t* output)",
            "pytorch_qnnp_requantize_precise__scalar_unsigned64(\n    size_t n,\n    const int32_t* input,\n    float scale,\n    uint8_t zero_point,\n    uint8_t qmin,\n    uint8_t qmax,\n    uint8_t* output)",
            "pytorch_qnnp_requantize_precise__scalar_signed64(\n    size_t n,\n    const int32_t* input,\n    float scale,\n    uint8_t zero_point,\n    uint8_t qmin,\n    uint8_t qmax,\n    uint8_t* output)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization/precise-sse2.c",
        "functions": [
            "pytorch_qnnp_requantize_precise__sse2(\n    size_t n,\n    const int32_t* input,\n    float scale,\n    uint8_t zero_point,\n    uint8_t qmin,\n    uint8_t qmax,\n    uint8_t* output)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization/precise-sse4.c",
        "functions": [
            "pytorch_qnnp_requantize_precise__sse4(\n    size_t n,\n    const int32_t* input,\n    float scale,\n    uint8_t zero_point,\n    uint8_t qmin,\n    uint8_t qmax,\n    uint8_t* output)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization/precise-ssse3.c",
        "functions": [
            "pytorch_qnnp_requantize_precise__ssse3(\n    size_t n,\n    const int32_t* input,\n    float scale,\n    uint8_t zero_point,\n    uint8_t qmin,\n    uint8_t qmax,\n    uint8_t* output)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization/q31-neon.c",
        "functions": [
            "pytorch_qnnp_requantize_q31__neon(\n    size_t n,\n    const int32_t* input,\n    float scale,\n    uint8_t zero_point,\n    uint8_t qmin,\n    uint8_t qmax,\n    uint8_t* output)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization/q31-scalar.c",
        "functions": [
            "pytorch_qnnp_requantize_q31__scalar(\n    size_t n,\n    const int32_t* input,\n    float scale,\n    uint8_t zero_point,\n    uint8_t qmin,\n    uint8_t qmax,\n    uint8_t* output)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization/q31-sse2.c",
        "functions": [
            "pytorch_qnnp_requantize_q31__sse2(\n    size_t n,\n    const int32_t* input,\n    float scale,\n    uint8_t zero_point,\n    uint8_t qmin,\n    uint8_t qmax,\n    uint8_t* output)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization/q31-sse4.c",
        "functions": [
            "pytorch_qnnp_requantize_q31__sse4(\n    size_t n,\n    const int32_t* input,\n    float scale,\n    uint8_t zero_point,\n    uint8_t qmin,\n    uint8_t qmax,\n    uint8_t* output)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/requantization/q31-ssse3.c",
        "functions": [
            "pytorch_qnnp_requantize_q31__ssse3(\n    size_t n,\n    const int32_t* input,\n    float scale,\n    uint8_t zero_point,\n    uint8_t qmin,\n    uint8_t qmax,\n    uint8_t* output)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/sconv/6x8-psimd.c",
        "functions": [
            "pytorch_sconv_ukernel_6x8__psimd(\n    size_t mr,\n    size_t nr,\n    size_t kc,\n    size_t ks,\n    const float** restrict a,\n    const float* restrict w,\n    float* restrict c,\n    size_t c_stride,\n    const struct pytorch_qnnp_fp32_clamping_params\n        clamping_params[restrict static 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/sdwconv/up4x9-psimd.c",
        "functions": [
            "pytorch_sdwconv_ukernel_up4x9__psimd(\n    size_t channels,\n    size_t output_width,\n    const float** input,\n    const float* weights,\n    float* output,\n    size_t input_stride,\n    size_t output_increment,\n    const struct pytorch_qnnp_fp32_clamping_params\n        clamping_params[restrict static 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/sgemm/5x8-neon.c",
        "functions": [
            "pytorch_sgemm_ukernel_5x8__neon(\n    size_t mr,\n    size_t nr,\n    size_t k,\n    const float* restrict a,\n    size_t a_stride,\n    const float* restrict w,\n    float* restrict c,\n    size_t c_stride,\n    const struct pytorch_qnnp_fp32_clamping_params\n        clamping_params[restrict static 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/sgemm/6x8-neon.c",
        "functions": [
            "pytorch_sgemm_ukernel_6x8__neon(\n    size_t mr,\n    size_t nr,\n    size_t k,\n    const float* restrict a,\n    size_t a_stride,\n    const float* restrict w,\n    float* restrict c,\n    size_t c_stride,\n    const struct pytorch_qnnp_fp32_clamping_params\n        clamping_params[restrict static 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/sgemm/6x8-psimd.c",
        "functions": [
            "pytorch_sgemm_ukernel_6x8__psimd(\n    size_t mr,\n    size_t nr,\n    size_t k,\n    const float* restrict a,\n    size_t a_stride,\n    const float* restrict w,\n    float* restrict c,\n    size_t c_stride,\n    const struct pytorch_qnnp_fp32_clamping_params\n        clamping_params[restrict static 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/u8clamp/neon.c",
        "functions": [
            "pytorch_u8clamp_ukernel__neon(\n    size_t n,\n    const uint8_t* x,\n    uint8_t* y,\n    const union pytorch_qnnp_u8_clamping_params params[restrict static 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/u8clamp/sse2.c",
        "functions": [
            "pytorch_u8clamp_ukernel__sse2(\n    size_t n,\n    const uint8_t* x,\n    uint8_t* y,\n    const union pytorch_qnnp_u8_clamping_params params[RESTRICT_STATIC 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/u8lut32norm/scalar.c",
        "functions": [
            "inline",
            "pytorch_u8lut32norm_ukernel__scalar(\n    size_t n,\n    const uint8_t* x,\n    const uint32_t* t,\n    uint8_t* y)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/u8maxpool/16x9p8q-neon.c",
        "functions": [
            "pytorch_u8maxpool_ukernel_16x9p8q__neon(\n    size_t n,\n    size_t ks,\n    size_t kc,\n    const uint8_t** input,\n    uint8_t* output,\n    size_t input_increment,\n    size_t output_increment,\n    const union pytorch_qnnp_u8_clamping_params params[restrict static 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/u8maxpool/16x9p8q-sse2.c",
        "functions": [
            "pytorch_u8maxpool_ukernel_16x9p8q__sse2(\n    size_t n,\n    size_t ks,\n    size_t kc,\n    const uint8_t** input,\n    uint8_t* output,\n    size_t input_increment,\n    size_t output_increment,\n    const union pytorch_qnnp_u8_clamping_params params[RESTRICT_STATIC 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/u8maxpool/sub16-neon.c",
        "functions": [
            "pytorch_u8maxpool_ukernel_sub16__neon(\n    size_t n,\n    size_t ks,\n    size_t kc,\n    const uint8_t** input,\n    uint8_t* output,\n    size_t input_increment,\n    size_t output_increment,\n    const union pytorch_qnnp_u8_clamping_params params[restrict static 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/u8maxpool/sub16-sse2.c",
        "functions": [
            "pytorch_u8maxpool_ukernel_sub16__sse2(\n    size_t n,\n    size_t ks,\n    size_t kc,\n    const uint8_t** input,\n    uint8_t* output,\n    size_t input_increment,\n    size_t output_increment,\n    const union pytorch_qnnp_u8_clamping_params params[RESTRICT_STATIC 1])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/u8rmax/neon.c",
        "functions": [
            "pytorch_u8rmax_ukernel__neon(size_t n, const uint8_t* x)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/u8rmax/sse2.c",
        "functions": [
            "pytorch_u8rmax_ukernel__sse2(size_t n, const uint8_t* x)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/x8lut/scalar.c",
        "functions": [
            "pytorch_x8lut_ukernel__scalar(\n    size_t n,\n    const uint8_t* x,\n    const uint8_t t[RESTRICT_STATIC 256],\n    uint8_t* y)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/x8zip/x2-neon.c",
        "functions": [
            "pytorch_qnnp_x8zip_x2__neon(size_t n, const void* input, void* output)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/x8zip/x2-sse2.c",
        "functions": [
            "pytorch_qnnp_x8zip_x2__sse2(size_t n, const void* input, void* output)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/x8zip/x3-neon.c",
        "functions": [
            "pytorch_qnnp_x8zip_x3__neon(size_t n, const void* input, void* output)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/x8zip/x3-sse2.c",
        "functions": [
            "pytorch_qnnp_x8zip_x3__sse2(size_t n, const void* input, void* output)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/x8zip/x4-neon.c",
        "functions": [
            "pytorch_qnnp_x8zip_x4__neon(size_t n, const void* input, void* output)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/x8zip/x4-sse2.c",
        "functions": [
            "pytorch_qnnp_x8zip_x4__sse2(size_t n, const void* input, void* output)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/x8zip/xm-neon.c",
        "functions": [
            "pytorch_qnnp_x8zip_xm__neon(\n    size_t n,\n    size_t m,\n    const void* input,\n    void* output)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/src/x8zip/xm-sse2.c",
        "functions": [
            "pytorch_qnnp_x8zip_xm__sse2(\n    size_t n,\n    size_t m,\n    const void* input,\n    void* output)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/dummy.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8avgpool/mp8x9p8q-neon.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8avgpool/mp8x9p8q-sse2.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8avgpool/up8x9-neon.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8avgpool/up8x9-sse2.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8avgpool/up8xm-neon.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8avgpool/up8xm-sse2.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8conv/4x4c2-sse2.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8conv/4x8-neon.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8conv/8x8-neon.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8dwconv/mp8x25-neon-per-channel.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8dwconv/mp8x25-neon.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8dwconv/mp8x25-sse2-per-channel.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8dwconv/mp8x25-sse2.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8dwconv/up8x9-neon-per-channel.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8dwconv/up8x9-neon.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8dwconv/up8x9-sse2-per-channel.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8dwconv/up8x9-sse2.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8gavgpool/mp8x7p7q-neon.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8gavgpool/mp8x7p7q-sse2.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8gavgpool/up8x7-neon.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8gavgpool/up8x7-sse2.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8gavgpool/up8xm-neon.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8gavgpool/up8xm-sse2.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8gemm/2x4c8-sse2.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8gemm/4x-sumrows-neon.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8gemm/4x4c2-dq-sse2.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8gemm/4x4c2-sse2.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8gemm/4x8-dq-neon.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8gemm/4x8-neon.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8gemm/4x8c2-xzp-neon.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8gemm/6x4-neon.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8gemm/8x8-neon.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8gemm_sparse/8x4c1x4-dq-sse2.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8gemm_sparse/8x4c1x4-packed-sse2.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8vadd/neon.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/q8vadd/sse2.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/requantization/fp32-neon.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/requantization/fp32-psimd.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/requantization/fp32-scalar.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/requantization/fp32-sse2.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/requantization/gemmlowp-neon.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/requantization/gemmlowp-scalar.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/requantization/gemmlowp-sse2.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/requantization/gemmlowp-sse4.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/requantization/gemmlowp-ssse3.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/requantization/precise-neon.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/requantization/precise-psimd.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/requantization/precise-scalar.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/requantization/precise-sse2.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/requantization/precise-sse4.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/requantization/precise-ssse3.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/requantization/q31-neon.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/requantization/q31-scalar.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/requantization/q31-sse2.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/requantization/q31-sse4.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/requantization/q31-ssse3.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/sgemm/5x8-neon.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/sgemm/6x8-neon.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/sgemm/6x8-psimd.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/u8clamp/neon.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/u8clamp/sse2.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/u8lut32norm/scalar.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/u8maxpool/16x9p8q-neon.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/u8maxpool/16x9p8q-sse2.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/u8maxpool/sub16-neon.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/u8maxpool/sub16-sse2.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/u8rmax/neon.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/u8rmax/sse2.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/x8lut/scalar.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/x8zip/x2-neon.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/x8zip/x2-sse2.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/x8zip/x3-neon.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/x8zip/x3-sse2.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/x8zip/x4-neon.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/x8zip/x4-sse2.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/x8zip/xm-neon.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/wrappers/x8zip/xm-sse2.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/quantized/cpu/kernels/QuantizedOpKernels.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/sparse/ParamUtils.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/sparse/SoftMax.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/sparse/SparseMatMul.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/sparse/SparseTensor.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/sparse/SparseTensorMath.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/sparse/cuda/SparseCUDATensor.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/utils/Factory.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/miopen/BatchNorm_miopen.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/miopen/Conv_miopen.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/miopen/RNN_miopen.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/mkl/LinearAlgebra.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/mkl/SpectralOps.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/mkldnn/BinaryOps.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/mkldnn/Conv.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/mkldnn/IDeepRegistration.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/mkldnn/Linear.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/mkldnn/MKLDNNCommon.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/mkldnn/MKLDNNConversions.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/mkldnn/MkldnnTensorMath.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/mkldnn/Normalization.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/mkldnn/Pooling.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/mkldnn/Relu.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/mkldnn/SoftMax.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/mkldnn/TensorFactories.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/mkldnn/TensorShape.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/mkldnn/UnaryOps.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/mkldnn/Utils.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/vulkan/Vulkan.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/vulkan/VulkanAten.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/vulkan/VulkanConvolution.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/vulkan/VulkanGuardImpl.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/vulkan/VulkanOpContext.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/vulkan/VulkanOps.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/vulkan/VulkanRegisterOpContextClass.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/vulkan/api/Allocator.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/vulkan/api/Command.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/vulkan/api/Common.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/vulkan/api/Context.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/vulkan/api/Descriptor.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/vulkan/api/Pipeline.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/vulkan/api/Resource.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/vulkan/api/Runtime.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/vulkan/api/Shader.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/vulkan/ops/Add.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/vulkan/ops/Clamp.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/vulkan/ops/Convolution.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/vulkan/ops/Copy.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/vulkan/ops/Factory.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/vulkan/ops/Mean.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/vulkan/ops/Mm.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/vulkan/ops/Mul.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/vulkan/ops/Persistent.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/vulkan/ops/Pool.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/vulkan/ops/Register.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/vulkan/ops/Shape.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/vulkan/ops/Tensor.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/vulkan/ops/Upsample.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/xnnpack/ChannelShuffle.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/xnnpack/Convolution.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/xnnpack/Init.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/xnnpack/Linear.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/xnnpack/MaxPooling.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/xnnpack/OpContext.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/xnnpack/RegisterOpContextClass.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/native/xnnpack/Shim.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/nnapi/codegen.py",
        "functions": [
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/nnapi/nnapi_bind.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/nnapi/nnapi_model_loader.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/nnapi/nnapi_wrapper.cpp",
        "functions": [
            "check__getDeviceCount(uint32_t* numDevices)",
            "check__getDevice(uint32_t devIndex, ANeuralNetworksDevice** device)",
            "check_Device_getName(const ANeuralNetworksDevice* device, const char** name)",
            "check_Device_getVersion(const ANeuralNetworksDevice* device, const char** version)",
            "check_Device_getFeatureLevel(const ANeuralNetworksDevice* device, int64_t* featureLevel)",
            "check_Model_getSupportedOperationsForDevices( const ANeuralNetworksModel* model, const ANeuralNetworksDevice* const* devices, uint32_t numDevices, bool* supportedOps)",
            "check_Compilation_createForDevices(ANeuralNetworksModel* model, const ANeuralNetworksDevice* const* devices, uint32_t numDevices, ANeuralNetworksCompilation** compilation)",
            "check_Execution_compute(ANeuralNetworksExecution* execution)",
            "check_Memory_createFromFd(size_t size, int protect, int fd, size_t offset, ANeuralNetworksMemory** memory)",
            "check_Memory_free(ANeuralNetworksMemory* memory)",
            "check_Model_create(ANeuralNetworksModel** model)",
            "check_Model_free(ANeuralNetworksModel* model)",
            "check_Model_finish(ANeuralNetworksModel* model)",
            "check_Model_addOperand(ANeuralNetworksModel* model, const ANeuralNetworksOperandType* type)",
            "check_Model_setOperandValue(ANeuralNetworksModel* model, int32_t index, const void* buffer, size_t length)",
            "check_Model_setOperandValueFromMemory(ANeuralNetworksModel* model, int32_t index, const ANeuralNetworksMemory* memory, size_t offset, size_t length)",
            "check_Model_addOperation(ANeuralNetworksModel* model, ANeuralNetworksOperationType type, uint32_t inputCount, const uint32_t* inputs, uint32_t outputCount, const uint32_t* outputs)",
            "check_Model_identifyInputsAndOutputs(ANeuralNetworksModel* model, uint32_t inputCount, const uint32_t* inputs, uint32_t outputCount, const uint32_t* outputs)",
            "check_Model_relaxComputationFloat32toFloat16(ANeuralNetworksModel* model, bool allow)",
            "check_Compilation_create(ANeuralNetworksModel* model, ANeuralNetworksCompilation** compilation)",
            "check_Compilation_free(ANeuralNetworksCompilation* compilation)",
            "check_Compilation_setPreference(ANeuralNetworksCompilation* compilation, int32_t preference)",
            "check_Compilation_finish(ANeuralNetworksCompilation* compilation)",
            "check_Execution_create(ANeuralNetworksCompilation* compilation, ANeuralNetworksExecution** execution)",
            "check_Execution_free(ANeuralNetworksExecution* execution)",
            "check_Execution_setInput(ANeuralNetworksExecution* execution, int32_t index, const ANeuralNetworksOperandType* type, const void* buffer, size_t length)",
            "check_Execution_setInputFromMemory(ANeuralNetworksExecution* execution, int32_t index, const ANeuralNetworksOperandType* type, const ANeuralNetworksMemory* memory, size_t offset, size_t length)",
            "check_Execution_setOutput(ANeuralNetworksExecution* execution, int32_t index, const ANeuralNetworksOperandType* type, void* buffer, size_t length)",
            "check_Execution_setOutputFromMemory(ANeuralNetworksExecution* execution, int32_t index, const ANeuralNetworksOperandType* type, const ANeuralNetworksMemory* memory, size_t offset, size_t length)",
            "check_Execution_startCompute(ANeuralNetworksExecution* execution, ANeuralNetworksEvent** event)",
            "check_Event_wait(ANeuralNetworksEvent* event)",
            "check_Event_free(ANeuralNetworksEvent* event)",
            "check_Execution_getOutputOperandRank(ANeuralNetworksExecution* execution, int32_t index, uint32_t* rank)",
            "check_Execution_getOutputOperandDimensions(ANeuralNetworksExecution* execution, int32_t index, uint32_t* dimensions)",
            "nnapi_wrapper_load(struct nnapi_wrapper** nnapi, struct nnapi_wrapper** check_nnapi)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/cuda/CUDABlas.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/cuda/CUDAContext.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/cuda/CUDAGeneratorImpl.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/cuda/CUDAGraph.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/cuda/CUDASolver.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/cuda/CusolverDnHandlePool.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/cuda/CuSparseHandlePool.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/cuda/LegacyTHFunctionsCUDA.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/cuda/PinnedMemoryAllocator.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/cuda/detail/CUDAHooks.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/cuda/detail/LazyNVRTC.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/cuda/nvrtc_stub/ATenNVRTC.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/metal/Context.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/quantized/QTensorImpl.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/quantized/Quantizer.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/templates/ATenOpList.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/templates/Functions.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/templates/LegacyTHFunctions.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/templates/RegisterBackendSelect.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/templates/RegisterDispatchKey.cpp",
        "functions": [
            "$legacy_th_headers\n\nnamespace"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/templates/RegisterSchema.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/templates/TensorMethods.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/apply_utils_test.cpp",
        "functions": [
            "fill_tensor(int64_t scalar, Tensor& t_)",
            "test(DeprecatedTypeProperties& type, IntArrayRef shape, int64_t a = 0, int64_t b = 1)",
            "{\n  manual_seed(123);\n  test(CPU(kDouble), {2, 1}, -1, -1);\n}",
            "{\n  manual_seed(123);\n  test(CPU(kDouble), {2, 1});\n}",
            "{\n  manual_seed(123);\n  test(CPU(kDouble), {20, 10});\n}",
            "{\n  manual_seed(123);\n  test(CPU(kDouble), {3, 4, 2});\n}",
            "{\n  manual_seed(123);\n  test(CPU(kDouble), {3, 40, 2});\n}",
            "{\n  manual_seed(123);\n  test(CPU(kDouble), {3, 4, 2, 5, 2, 1, 3, 4, 2, 3});\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/atest.cpp",
        "functions": [
            "trace()",
            "{\n  int a = 0b10101011;\n  int b = 0b01111011;\n\n  auto a_tensor = tensor({a});\n  auto b_tensor = tensor({b});\n\n  ASSERT_TRUE(tensor({~a}).equal(~a_tensor));\n  ASSERT_TRUE(tensor({a | b}).equal(a_tensor | b_tensor));\n  ASSERT_TRUE(tensor({a & b}).equal(a_tensor & b_tensor));\n  ASSERT_TRUE(tensor({a ^ b}).equal(a_tensor ^ b_tensor));\n}",
            "{\n  auto exp_tensor = tensor({0, 1, 0, 1, 0});\n  run_binary_ops_test(\n      logical_and_out, x_logical, y_logical, exp_tensor, INTBOOL);\n}",
            "{\n  auto exp_tensor = tensor({1, 1, 0, 1, 1});\n  run_binary_ops_test(\n      logical_or_out, x_logical, y_logical, exp_tensor, INTBOOL);\n}",
            "{\n  auto exp_tensor = tensor({1, 0, 0, 0, 1});\n  run_binary_ops_test(\n      logical_xor_out, x_logical, y_logical, exp_tensor, INTBOOL);\n}",
            "{\n  auto exp_tensor = tensor({0, 0, 0, 0, 1});\n  run_binary_ops_test<\n      at::Tensor& (*)(at::Tensor&, const at::Tensor&, const at::Tensor&)>(\n      lt_out, x_logical, y_logical, exp_tensor, INTBOOL);\n}",
            "{\n  auto exp_tensor = tensor({0, 1, 1, 1, 1});\n  run_binary_ops_test<\n      at::Tensor& (*)(at::Tensor&, const at::Tensor&, const at::Tensor&)>(\n      le_out, x_logical, y_logical, exp_tensor, INTBOOL);\n}",
            "{\n  auto exp_tensor = tensor({1, 0, 0, 0, 0});\n  run_binary_ops_test<\n      at::Tensor& (*)(at::Tensor&, const at::Tensor&, const at::Tensor&)>(\n      gt_out, x_logical, y_logical, exp_tensor, INTBOOL);\n}",
            "{\n  auto exp_tensor = tensor({1, 1, 1, 1, 0});\n  run_binary_ops_test<\n      at::Tensor& (*)(at::Tensor&, const at::Tensor&, const at::Tensor&)>(\n      ge_out, x_logical, y_logical, exp_tensor, INTBOOL);\n}",
            "{\n  auto exp_tensor = tensor({0, 1, 1, 1, 0});\n  run_binary_ops_test<\n      at::Tensor& (*)(at::Tensor&, const at::Tensor&, const at::Tensor&)>(\n      eq_out, x_logical, y_logical, exp_tensor, INTBOOL);\n}",
            "{\n  auto exp_tensor = tensor({1, 0, 0, 0, 1});\n  run_binary_ops_test<\n      at::Tensor& (*)(at::Tensor&, const at::Tensor&, const at::Tensor&)>(\n      ne_out, x_logical, y_logical, exp_tensor, INTBOOL);\n}",
            "{\n  auto exp_tensor = tensor({-10, 1, 0, -1, 10});\n  run_binary_ops_test(add_out, x_tensor, y_tensor, exp_tensor, INTBOOL, 2);\n}",
            "{\n  auto exp_tensor = tensor({10, 1, 0, 1, 10});\n  run_binary_ops_test<\n      at::Tensor& (*)(at::Tensor&, const at::Tensor&, const at::Tensor&)>(\n      max_out, x_tensor, y_tensor, exp_tensor, INTBOOLFLOAT);\n}",
            "{\n  auto exp_tensor = tensor({-10, -1, 0, -1, -10});\n  run_binary_ops_test<\n      at::Tensor& (*)(at::Tensor&, const at::Tensor&, const at::Tensor&)>(\n      min_out, x_tensor, y_tensor, exp_tensor, INTBOOLFLOAT);\n}",
            "{\n  auto exp_tensor = tensor({-1100, 0, 0, -2, 900});\n  // only test with type Float\n  run_binary_ops_test<\n      at::Tensor& (*)(at::Tensor&, const at::Tensor&, const at::Tensor&)>(\n      sigmoid_backward_out, x_tensor, y_tensor, exp_tensor, FLOAT);\n}",
            "{\n  auto exp_tensor = tensor({0.0, 0.2, 5.6, 7.0, 12.0});\n  run_binary_ops_test<\n      at::Tensor& (*)(at::Tensor&, const at::Tensor&, const at::Tensor&)>(\n      fmod_out, x_float, y_float, exp_tensor, INTFLOAT);\n}",
            "{\n  manual_seed(123);\n\n  auto foo = rand({12, 6});\n\n  ASSERT_EQ(foo.size(0), 12);\n  ASSERT_EQ(foo.size(1), 6);\n\n  foo = foo + foo * 3;\n  foo -= 4;\n\n  Scalar a = 4;\n  float b = a.to<float>();\n  ASSERT_EQ(b, 4);\n\n  foo = ((foo * foo) == (foo.pow(3))).to(kByte);\n  foo = 2 + (foo + 1);\n  // foo = foo[3];\n  auto foo_v = foo.accessor<uint8_t, 2>();\n\n  for (int i = 0; i < foo_v.size(0); i++) {\n    for (int j = 0; j < foo_v.size(1); j++) {\n      foo_v[i][j]++;\n    }\n  }\n\n  ASSERT_TRUE(foo.equal(4 * ones({12, 6}, kByte)));\n\n  trace();\n\n  float data[] = {1, 2, 3, 4, 5, 6};\n\n  auto f = from_blob(data, {1, 2, 3});\n  auto f_a = f.accessor<float, 3>();\n\n  ASSERT_EQ(f_a[0][0][0], 1.0);\n  ASSERT_EQ(f_a[0][1][1], 5.0);\n\n  ASSERT_EQ(f.strides()[0], 6);\n  ASSERT_EQ(f.strides()[1], 3);\n  ASSERT_EQ(f.strides()[2], 1);\n  ASSERT_EQ(f.sizes()[0], 1);\n  ASSERT_EQ(f.sizes()[1], 2);\n  ASSERT_EQ(f.sizes()[2], 3);\n\n  // TODO(ezyang): maybe do a more precise exception type.\n  ASSERT_THROW(f.resize_({3, 4, 5}), std::exception);\n  {\n    int isgone = 0;\n    {\n      auto f2 = from_blob(data, {1, 2, 3}, [&](void*) { isgone++; });\n    }\n    ASSERT_EQ(isgone, 1);\n  }\n  {\n    int isgone = 0;\n    Tensor a_view;\n    {\n      auto f2 = from_blob(data, {1, 2, 3}, [&](void*) { isgone++; });\n      a_view = f2.view({3, 2, 1});\n    }\n    ASSERT_EQ(isgone, 0);\n    a_view.reset();\n    ASSERT_EQ(isgone, 1);\n  }\n\n  if (at::hasCUDA()) {\n    int isgone = 0;\n    {\n      auto base = at::empty({1, 2, 3}, TensorOptions(kCUDA));\n      auto f2 = from_blob(base.data_ptr(), {1, 2, 3}, [&](void*) { isgone++; });\n    }\n    ASSERT_EQ(isgone, 1);\n\n    // Attempt to specify the wrong device in from_blob\n    auto t = at::empty({1, 2, 3}, TensorOptions(kCUDA, 0));\n    EXPECT_ANY_THROW(from_blob(t.data_ptr(), {1, 2, 3}, at::Device(kCUDA, 1)));\n\n    // Infers the correct device\n    auto t_ = from_blob(t.data_ptr(), {1, 2, 3}, kCUDA);\n    ASSERT_EQ(t_.device(), at::Device(kCUDA, 0));\n  }\n}"
        ],
        "classes": [
            "atest"
        ]
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/basic.cpp",
        "functions": [
            "TestResize(DeprecatedTypeProperties& type)",
            "TestOnesAndDot(DeprecatedTypeProperties& type)",
            "TestSort(DeprecatedTypeProperties& type)",
            "TestRandperm(DeprecatedTypeProperties& type)",
            "SendContext()",
            "TestAdd(DeprecatedTypeProperties& type)",
            "TestZeros(DeprecatedTypeProperties& type)",
            "TestLoadsOfAdds(DeprecatedTypeProperties& type)",
            "TestLoadOfAddsWithCopy(DeprecatedTypeProperties& type)",
            "TestIsContiguous(DeprecatedTypeProperties& type)",
            "TestPermute(DeprecatedTypeProperties& type)",
            "TestMm(DeprecatedTypeProperties& type)",
            "TestSqueeze(DeprecatedTypeProperties& type)",
            "TestCopy(DeprecatedTypeProperties& type)",
            "TestCopyBroadcasting(DeprecatedTypeProperties& type)",
            "TestAbsValue(DeprecatedTypeProperties& type)",
            "TestAddingAValueWithScalar(DeprecatedTypeProperties& type)",
            "TestSelect(DeprecatedTypeProperties& type)",
            "TestZeroDim(DeprecatedTypeProperties& type)",
            "TestToCFloat()",
            "TestToString()",
            "TestIndexingByScalar()",
            "TestIndexingByZerodimTensor()",
            "TestIndexingMixedDevice(DeprecatedTypeProperties& type)",
            "TestDispatch()",
            "TestNegativeDim(DeprecatedTypeProperties& type)",
            "TestView(DeprecatedTypeProperties& type)",
            "TestIntArrayRefExpansion(DeprecatedTypeProperties& type)",
            "test(DeprecatedTypeProperties& type)",
            "{\n  manual_seed(123);\n\n  test(CPU(kFloat));\n}",
            "{\n  manual_seed(234);\n\n  test(CPU(kHalf));\n}",
            "{\n  manual_seed(123);\n\n  if (at::hasCUDA()) {\n    test(CUDA(kFloat));\n  }\n}",
            "{\n  // Test default values\n  at::Tensor tensor0 = at::empty({4});\n  ASSERT_EQ(tensor0.dtype(), at::kFloat);\n  ASSERT_EQ(tensor0.layout(), at::kStrided);\n  ASSERT_EQ(tensor0.device(), at::kCPU);\n  ASSERT_FALSE(tensor0.requires_grad());\n  ASSERT_FALSE(tensor0.is_pinned());\n\n  // Test setting requires_grad to false.\n  tensor0 = at::empty({4}, at::TensorOptions().requires_grad(false));\n  ASSERT_EQ(tensor0.dtype(), at::kFloat);\n  ASSERT_EQ(tensor0.layout(), at::kStrided);\n  ASSERT_EQ(tensor0.device(), at::kCPU);\n  ASSERT_FALSE(tensor0.requires_grad());\n  ASSERT_FALSE(tensor0.is_pinned());\n\n  // Test setting requires_grad to true.\n  // This is a bug. Requires_grad was set to TRUE but this is not implemented.\n  EXPECT_ANY_THROW(at::empty({4}, at::TensorOptions().requires_grad(true)));\n\n  // Test setting dtype\n  at::Tensor tensor1 = at::empty({4}, at::TensorOptions().dtype(at::kHalf));\n  ASSERT_EQ(tensor1.dtype(), at::kHalf);\n  ASSERT_EQ(tensor1.layout(), at::kStrided);\n  ASSERT_EQ(tensor1.device(), at::kCPU);\n  ASSERT_FALSE(tensor1.requires_grad());\n  ASSERT_FALSE(tensor1.is_pinned());\n\n  if (torch::cuda::is_available()) {\n    // Test setting pin memory\n    tensor1 = at::empty({4}, at::TensorOptions().pinned_memory(true));\n    ASSERT_EQ(tensor1.dtype(), at::kFloat);\n    ASSERT_EQ(tensor1.layout(), at::kStrided);\n    ASSERT_EQ(tensor1.device(), at::kCPU);\n    ASSERT_EQ(tensor1.requires_grad(), false);\n    ASSERT_FALSE(tensor1.device().is_cuda());\n    ASSERT_TRUE(tensor1.is_pinned());\n\n    // Test setting device\n    tensor1 = at::empty({4}, at::TensorOptions().device(at::kCUDA));\n    ASSERT_EQ(tensor1.dtype(), at::kFloat);\n    ASSERT_EQ(tensor1.layout(), at::kStrided);\n    ASSERT_TRUE(tensor1.device().is_cuda());\n    ASSERT_FALSE(tensor1.requires_grad());\n    ASSERT_FALSE(tensor1.is_pinned());\n\n    // Test set everything\n    tensor1 = at::empty({4}, at::TensorOptions().dtype(at::kHalf).device(at::kCUDA).layout(at::kSparse).requires_grad(false));\n    ASSERT_EQ(tensor1.dtype(), at::kHalf);\n    ASSERT_EQ(tensor1.layout(), at::kSparse);\n    ASSERT_TRUE(tensor1.device().is_cuda());\n    ASSERT_THROWS(tensor1.nbytes());\n\n    // This is a bug\n    // Issue https://github.com/pytorch/pytorch/issues/30405\n    ASSERT_FALSE(tensor1.requires_grad());\n\n    // This will cause an exception\n    // Issue https://github.com/pytorch/pytorch/issues/30405\n    ASSERT_ANY_THROW(tensor1.is_pinned());\n  }\n\n  // Test _like variants\n  if (torch::cuda::is_available()) {\n    // Issue https://github.com/pytorch/pytorch/issues/28093\n    at::Tensor proto = at::empty({1}, at::kDouble);\n    tensor0 = at::empty_like(proto, at::kCUDA);\n    ASSERT_EQ(tensor0.dtype(), at::kDouble);\n    ASSERT_EQ(tensor0.layout(), at::kStrided);\n    ASSERT_TRUE(tensor0.device().is_cuda());\n    ASSERT_FALSE(tensor0.requires_grad());\n    ASSERT_FALSE(tensor0.is_pinned());\n  }\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/broadcast_test.cpp",
        "functions": [
            "TestEmptyTensor(DeprecatedTypeProperties& T)",
            "TestOut2Basic(DeprecatedTypeProperties& T)",
            "TestOut2WithScalar(DeprecatedTypeProperties& T)",
            "TestOut2OldFallback(DeprecatedTypeProperties& T)",
            "TestOut2MismatchedSizes(DeprecatedTypeProperties& T)",
            "TestOut3Basic(DeprecatedTypeProperties& T)",
            "TestOut3WithScalar(DeprecatedTypeProperties& T)",
            "TestOut3OldFallback(DeprecatedTypeProperties& T)",
            "TestOut3MismatchedSizes(DeprecatedTypeProperties& T)",
            "TestIn2Basic(DeprecatedTypeProperties& T)",
            "TestIn2WithScalar(DeprecatedTypeProperties& T)",
            "TestIn2ExpandError(DeprecatedTypeProperties& T)",
            "TestIn3Basic(DeprecatedTypeProperties& T)",
            "TestIn3WithScalar(DeprecatedTypeProperties& T)",
            "TestIn3ExpandError(DeprecatedTypeProperties& T)",
            "TestExplicitDimBasic(DeprecatedTypeProperties& T)",
            "TestExplicitDimWithScalar(DeprecatedTypeProperties& T)",
            "TestExplicitDimWithMismatchedSizes(DeprecatedTypeProperties& T)",
            "{\n  manual_seed(123);\n  DeprecatedTypeProperties& T = CPU(kFloat);\n\n  TestEmptyTensor(T);\n\n  TestOut2Basic(T);\n  TestOut2WithScalar(T);\n  TestOut2OldFallback(T);\n  TestOut2MismatchedSizes(T);\n\n  TestOut3Basic(T);\n  TestOut3WithScalar(T);\n  TestOut3OldFallback(T);\n  TestOut3MismatchedSizes(T);\n\n  TestIn2Basic(T);\n  TestIn2WithScalar(T);\n  TestIn2ExpandError(T);\n\n  TestIn3Basic(T);\n  TestIn3WithScalar(T);\n  TestIn3ExpandError(T);\n\n  TestExplicitDimBasic(T);\n  TestExplicitDimWithScalar(T);\n  TestExplicitDimWithMismatchedSizes(T);\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/cpu_caching_allocator_test.cpp",
        "functions": [
            "{\n  c10::CPUCachingAllocator caching_allocator;\n  c10::WithCPUCachingAllocatorGuard cachine_allocator_guard(\n      &caching_allocator);\n  at::Tensor a = at::rand({23, 23});\n  float* data_ptr = a.data_ptr<float>();\n  a.reset();\n  a = at::rand({23, 23});\n  ASSERT_TRUE(data_ptr == a.data_ptr<float>());\n}",
            "{\n  c10::CPUCachingAllocator caching_allocator;\n  at::Tensor a = at::rand({23, 23});\n  {\n    c10::WithCPUCachingAllocatorGuard cachine_allocator_guard(\n        &caching_allocator);\n    float* data_ptr = a.data_ptr<float>();\n    a.reset();\n    a = at::rand({23, 23});\n  }\n}",
            "{\n  c10::CPUCachingAllocator caching_allocator;\n  at::Tensor a;\n  {\n    c10::WithCPUCachingAllocatorGuard cachine_allocator_guard(\n        &caching_allocator);\n    a = at::rand({23, 23});\n  }\n  a.reset();\n}",
            "main(int argc, char* argv[])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/cpu_generator_test.cpp",
        "functions": [
            "{\n  // Test Description: Check dynamic cast for CPU\n  auto foo = at::detail::createCPUGenerator();\n  auto result = check_generator<CPUGeneratorImpl>(foo);\n  ASSERT_EQ(typeid(CPUGeneratorImpl*).hash_code(), typeid(result).hash_code());\n}",
            "{\n  // Test Description: \n  // Check if default generator is created only once\n  // address of generator should be same in all calls\n  auto foo = at::detail::getDefaultCPUGenerator();\n  auto bar = at::detail::getDefaultCPUGenerator();\n  ASSERT_EQ(foo, bar);\n}",
            "{\n  // Test Description: \n  // Check cloning of new generators.\n  // Note that we don't allow cloning of other\n  // generator states into default generators.\n  auto gen1 = at::detail::createCPUGenerator();\n  auto cpu_gen1 = check_generator<CPUGeneratorImpl>(gen1);\n  cpu_gen1->random(); // advance gen1 state\n  cpu_gen1->random();\n  auto gen2 = at::detail::createCPUGenerator();\n  gen2 = gen1.clone();\n  auto cpu_gen2 = check_generator<CPUGeneratorImpl>(gen2);\n  ASSERT_EQ(cpu_gen1->random(), cpu_gen2->random());\n}",
            "thread_func_get_engine_op(CPUGeneratorImpl* generator)",
            "{\n  // Test Description: \n  // Check CPUGeneratorImpl is reentrant and the engine state\n  // is not corrupted when multiple threads request for \n  // random samples.\n  // See Note [Acquire lock when using random generators]\n  auto gen1 = at::detail::createCPUGenerator();\n  auto cpu_gen1 = check_generator<CPUGeneratorImpl>(gen1);\n  auto gen2 = at::detail::createCPUGenerator();\n  {\n    std::lock_guard<std::mutex> lock(gen1.mutex());\n    gen2 = gen1.clone(); // capture the current state of default generator\n  }\n  std::thread t0{thread_func_get_engine_op, cpu_gen1};\n  std::thread t1{thread_func_get_engine_op, cpu_gen1};\n  std::thread t2{thread_func_get_engine_op, cpu_gen1};\n  t0.join();\n  t1.join();\n  t2.join();\n  std::lock_guard<std::mutex> lock(gen2.mutex());\n  auto cpu_gen2 = check_generator<CPUGeneratorImpl>(gen2);\n  cpu_gen2->random();\n  cpu_gen2->random();\n  cpu_gen2->random();\n  ASSERT_EQ(cpu_gen1->random(), cpu_gen2->random());\n}",
            "{\n  // Test Description: \n  // Test current seed getter and setter\n  // See Note [Acquire lock when using random generators]\n  auto foo = at::detail::getDefaultCPUGenerator();\n  std::lock_guard<std::mutex> lock(foo.mutex());\n  foo.set_current_seed(123);\n  auto current_seed = foo.current_seed();\n  ASSERT_EQ(current_seed, 123);\n}",
            "thread_func_get_set_current_seed(Generator generator)",
            "{\n  // Test Description: \n  // Test current seed getter and setter are thread safe\n  // See Note [Acquire lock when using random generators]\n  auto gen1 = at::detail::getDefaultCPUGenerator();\n  auto initial_seed = gen1.current_seed();\n  std::thread t0{thread_func_get_set_current_seed, gen1};\n  std::thread t1{thread_func_get_set_current_seed, gen1};\n  std::thread t2{thread_func_get_set_current_seed, gen1};\n  t0.join();\n  t1.join();\n  t2.join();\n  ASSERT_EQ(gen1.current_seed(), initial_seed+3);\n}",
            "{\n  // Test Description: \n  // Test that state of a generator can be frozen and\n  // restored\n  // See Note [Acquire lock when using random generators]\n  auto default_gen = at::detail::getDefaultCPUGenerator();\n  auto current_gen = at::detail::createCPUGenerator();\n  {\n    std::lock_guard<std::mutex> lock(default_gen.mutex());\n    current_gen = default_gen.clone(); // capture the current state of default generator\n  }\n  auto target_value = at::randn({1000});\n  // Dramatically alter the internal state of the main generator\n  auto x = at::randn({100000});\n  auto forked_value = at::randn({1000}, current_gen);\n  ASSERT_EQ(target_value.sum().item<double>(), forked_value.sum().item<double>());\n}",
            "{\n  // Test Description:\n  //   Tests if same inputs give same results.\n  //   launch on same thread index and create two engines.\n  //   Given same seed, idx and offset, assert that the engines\n  //   should be aligned and have the same sequence.\n  at::Philox4_32_10 engine1(0, 0, 4);\n  at::Philox4_32_10 engine2(0, 0, 4);\n  ASSERT_EQ(engine1(), engine2());\n}",
            "{\n  // Test Description:\n  //   Tests offsetting in same thread index.\n  //   make one engine skip the first 8 values and\n  //   make another engine increment to until the\n  //   first 8 values. Assert that the first call\n  //   of engine2 and the 9th call of engine1 are equal.\n  at::Philox4_32_10 engine1(123, 1, 0);\n  // Note: offset is a multiple of 4.\n  // So if you want to skip 8 values, offset would\n  // be 2, since 2*4=8.\n  at::Philox4_32_10 engine2(123, 1, 2);\n  for(int i = 0; i < 8; i++){\n    // Note: instead of using the engine() call 8 times\n    // we could have achieved the same functionality by\n    // calling the incr() function twice.\n    engine1();\n  }\n  ASSERT_EQ(engine1(), engine2());\n}",
            "{\n  // Test Description:\n  //   Tests edge case at the end of the 2^190th value of the generator.\n  //   launch on same thread index and create two engines.\n  //   make engine1 skip to the 2^64th 128 bit while being at thread 0\n  //   make engine2 skip to the 2^64th 128 bit while being at 2^64th thread\n  //   Assert that engine2 should be increment_val+1 steps behind engine1.\n  unsigned long long increment_val = std::numeric_limits<uint64_t>::max();\n  at::Philox4_32_10 engine1(123, 0, increment_val);\n  at::Philox4_32_10 engine2(123, increment_val, increment_val);\n\n  engine2.incr_n(increment_val);\n  engine2.incr();\n  ASSERT_EQ(engine1(), engine2());\n}",
            "{\n  // Test Description:\n  //   Tests edge case in between thread indices.\n  //   launch on same thread index and create two engines.\n  //   make engine1 skip to the 2^64th 128 bit while being at thread 0\n  //   start engine2 at thread 1, with offset 0\n  //   Assert that engine1 is 1 step behind engine2.\n  unsigned long long increment_val = std::numeric_limits<uint64_t>::max();\n  at::Philox4_32_10 engine1(123, 0, increment_val);\n  at::Philox4_32_10 engine2(123, 1, 0);\n  engine1.incr();\n  ASSERT_EQ(engine1(), engine2());\n}",
            "{\n  // Test Description:\n  //   Tests if thread indexing is working properly.\n  //   create two engines with different thread index but same offset.\n  //   Assert that the engines have different sequences.\n  at::Philox4_32_10 engine1(123456, 0, 4);\n  at::Philox4_32_10 engine2(123456, 1, 4);\n  ASSERT_NE(engine1(), engine2());\n}",
            "{\n  // Test Description:\n  //   Tests if same inputs give same results when compared\n  //   to std.\n  \n  // test with zero seed\n  at::mt19937 engine1(0);\n  std::mt19937 engine2(0);\n  for(int i = 0; i < 10000; i++) {\n    ASSERT_EQ(engine1(), engine2());\n  }\n\n  // test with large seed\n  engine1 = at::mt19937(2147483647);\n  engine2 = std::mt19937(2147483647);\n  for(int i = 0; i < 10000; i++) {\n    ASSERT_EQ(engine1(), engine2());\n  }\n\n  // test with random seed\n  std::random_device rd;\n  auto seed = rd();\n  engine1 = at::mt19937(seed);\n  engine2 = std::mt19937(seed);\n  for(int i = 0; i < 10000; i++) {\n    ASSERT_EQ(engine1(), engine2());\n  }\n  \n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/cpu_profiling_allocator_test.cpp",
        "functions": [
            "run_with_control_flow(\n    at::Tensor input,\n    at::Tensor conv_weight,\n    at::Tensor linear_weight,\n    bool cond,\n    std::vector<void*>& pointers,\n    bool record = false,\n    bool validate = false)",
            "{\n  at::Tensor a = at::rand({23, 16, 16, 16});\n  at::Tensor conv_weight = at::rand({16, 16, 3, 3});\n  // output shape\n  // 23, 16, 14, 14\n  // Flattened shape = 23, 3136\n  at::Tensor linear_weight = at::rand({32, 3136});\n  at::Tensor output, ref_output;\n  std::vector<void*> pointers;\n\n  auto valid_allocation_plan = [&]() {\n    c10::AllocationPlan plan;\n    {\n      c10::WithProfileAllocationsGuard profile_guard(&plan);\n      ref_output = run_with_control_flow(\n          a, conv_weight, linear_weight, true, pointers);\n    }\n  };\n  ASSERT_NO_THROW(valid_allocation_plan());\n\n  auto validate_allocation_plan =\n    [&](bool record_mode, bool validation_mode) -> bool {\n    c10::AllocationPlan plan;\n    {\n      c10::WithProfileAllocationsGuard profile_guard(&plan);\n      ref_output =\n        run_with_control_flow(a, conv_weight, linear_weight, record_mode, pointers);\n    }\n    bool success{true};\n    for (uint64_t i = 0; i < 10; ++i) {\n      bool validation_success;\n      {\n        c10::WithValidateAllocationPlanGuard\n          validation_guard(&plan, &validation_success);\n        output = run_with_control_flow(\n            a, conv_weight, linear_weight, validation_mode, pointers);\n      }\n      success = success && validation_success;\n    }\n    return success;\n  };\n  ASSERT_FALSE(validate_allocation_plan(false, true));\n  ASSERT_FALSE(validate_allocation_plan(true, false));\n  ASSERT_TRUE(validate_allocation_plan(true, true));\n  ASSERT_TRUE(validate_allocation_plan(false, false));\n}",
            "{\n  at::Tensor a = at::rand({23, 16, 16, 16});\n  at::Tensor conv_weight = at::rand({16, 16, 3, 3});\n  // output shape\n  // 23, 16, 14, 14\n  // Flattened shape = 23, 3136\n  at::Tensor linear_weight = at::rand({32, 3136});\n  at::Tensor output, ref_output;\n  std::vector<void*> pointers;\n\n  auto valid_allocation_plan = [&]() {\n    c10::AllocationPlan plan;\n    {\n      c10::WithProfileAllocationsGuard profile_guard(&plan);\n      ref_output = run_with_control_flow(\n          a, conv_weight, linear_weight, false, pointers);\n    }\n  };\n  ASSERT_NO_THROW(valid_allocation_plan());\n\n  auto validate_allocation_plan =\n    [&](bool record_mode,\n        bool validation_mode,\n        bool validate_pointers) {\n      pointers.clear();\n      c10::AllocationPlan plan;\n      {\n        c10::WithProfileAllocationsGuard profile_guard(&plan);\n        ref_output = run_with_control_flow(\n            a,\n            conv_weight,\n            linear_weight,\n            record_mode,\n            pointers,\n            false,\n            false);\n      }\n      c10::CPUProfilingAllocator profiling_allocator;\n      {\n        c10::WithProfilingAllocatorGuard\n          profiling_allocator_guard(&profiling_allocator, &plan);\n        output = run_with_control_flow(\n            a,\n            conv_weight,\n            linear_weight,\n            validation_mode,\n            pointers,\n            validate_pointers,\n            false);\n      }\n      for (uint64_t i = 0; i < 10; ++i) {\n        {\n          c10::WithProfilingAllocatorGuard\n            profiling_allocator_guard(&profiling_allocator, &plan);\n          output = run_with_control_flow(\n              a,\n              conv_weight,\n              linear_weight,\n              validation_mode,\n              pointers,\n              false,\n              validate_pointers);\n        }\n      }\n  };\n  // When control flow conditions are same between profiling and evaluation\n  // profiling allocator should not throw.\n  ASSERT_NO_THROW(validate_allocation_plan(true, true, false));\n  ASSERT_TRUE(ref_output.equal(output));\n  ASSERT_NO_THROW(validate_allocation_plan(false, false, false));\n  ASSERT_TRUE(ref_output.equal(output));\n  // Furthermore profiling allocator should return the same pointers\n  // back for the intermediate tensors\n  ASSERT_NO_THROW(validate_allocation_plan(true, true, true));\n  ASSERT_TRUE(ref_output.equal(output));\n  ASSERT_NO_THROW(validate_allocation_plan(false, false, true));\n  ASSERT_TRUE(ref_output.equal(output));\n\n  // When control flow conditions are different between profiling and evaluation\n  // profiling allocator should throw.\n  ASSERT_THROW(validate_allocation_plan(true, false, false), c10::Error);\n  ASSERT_THROW(validate_allocation_plan(false, true, false), c10::Error);\n}",
            "main(int argc, char* argv[])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/cpu_rng_test.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/cuda_apply_test.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/cuda_dlconvertor_test.cpp",
        "functions": [
            "{\n  manual_seed(123);\n\n  Tensor a = rand({3, 4}, at::kCUDA);\n  DLManagedTensor* dlMTensor = toDLPack(a);\n\n  Tensor b = fromDLPack(dlMTensor);\n\n  ASSERT_TRUE(a.equal(b));\n}",
            "{\n  manual_seed(123);\n\n  Tensor a = rand({3, 4}, at::kCUDA);\n  DLManagedTensor* dlMTensor = toDLPack(a);\n  dlMTensor->dl_tensor.strides = nullptr;\n\n  Tensor b = fromDLPack(dlMTensor);\n\n  ASSERT_TRUE(a.equal(b));\n}",
            "{\n  if (!at::cuda::is_available())\n    return;\n  manual_seed(123);\n\n  Tensor a = rand({3, 4}, at::kCUDA);\n  DLManagedTensor* dlMTensor = toDLPack(a);\n\n#if AT_ROCM_ENABLED()\n  ASSERT_TRUE(dlMTensor->dl_tensor.ctx.device_type == DLDeviceType::kDLROCM);\n#else\n  ASSERT_TRUE(dlMTensor->dl_tensor.ctx.device_type == DLDeviceType::kDLGPU);\n#endif\n\n  Tensor b = fromDLPack(dlMTensor);\n\n  ASSERT_TRUE(a.equal(b));\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/cuda_stream_test.cpp",
        "functions": [
            "{\n  if (!at::cuda::is_available()) return;\n  int32_t device = -1;\n  cudaStream_t cuda_stream;\n\n  // Tests that copying works as expected and preserves the stream\n  at::cuda::CUDAStream copyStream = at::cuda::getStreamFromPool();\n  {\n    auto s = at::cuda::getStreamFromPool();\n    device = s.device_index();\n    cuda_stream = s.stream();\n\n    copyStream = s;\n\n    ASSERT_EQ_CUDA(copyStream.device_index(), device);\n    ASSERT_EQ_CUDA(copyStream.stream(), cuda_stream);\n  }\n\n  ASSERT_EQ_CUDA(copyStream.device_index(), device);\n  ASSERT_EQ_CUDA(copyStream.stream(), cuda_stream);\n\n  // Tests that moving works as expected and preserves the stream\n  at::cuda::CUDAStream moveStream = at::cuda::getStreamFromPool();\n  {\n    auto s = at::cuda::getStreamFromPool();\n    device = s.device_index();\n    cuda_stream = s.stream();\n\n    moveStream = std::move(s);\n\n    ASSERT_EQ_CUDA(moveStream.device_index(), device);\n    ASSERT_EQ_CUDA(moveStream.stream(), cuda_stream);\n  }\n\n  ASSERT_EQ_CUDA(moveStream.device_index(), device);\n  ASSERT_EQ_CUDA(moveStream.stream(), cuda_stream);\n}",
            "{\n  if (!at::cuda::is_available()) return;\n  at::cuda::CUDAStream myStream = at::cuda::getStreamFromPool();\n\n  // Sets and gets\n  at::cuda::setCurrentCUDAStream(myStream);\n  at::cuda::CUDAStream curStream = at::cuda::getCurrentCUDAStream();\n\n  ASSERT_EQ_CUDA(myStream, curStream);\n\n  // Gets, sets, and gets default stream\n  at::cuda::CUDAStream defaultStream = at::cuda::getDefaultCUDAStream();\n  at::cuda::setCurrentCUDAStream(defaultStream);\n  curStream = at::cuda::getCurrentCUDAStream();\n\n  ASSERT_NE_CUDA(defaultStream, myStream);\n  ASSERT_EQ_CUDA(curStream, defaultStream);\n}",
            "thread_fun(at::optional<at::cuda::CUDAStream>& cur_thread_stream)",
            "{\n  if (!at::cuda::is_available()) return;\n  at::optional<at::cuda::CUDAStream> s0, s1;\n\n  std::thread t0{thread_fun, std::ref(s0)};\n  std::thread t1{thread_fun, std::ref(s1)};\n  t0.join();\n  t1.join();\n\n  at::cuda::CUDAStream cur_stream = at::cuda::getCurrentCUDAStream();\n  at::cuda::CUDAStream default_stream = at::cuda::getDefaultCUDAStream();\n\n  ASSERT_EQ_CUDA(cur_stream, default_stream);\n  ASSERT_NE_CUDA(cur_stream, *s0);\n  ASSERT_NE_CUDA(cur_stream, *s1);\n  ASSERT_NE_CUDA(s0, s1);\n}",
            "{\n  if (!at::cuda::is_available()) return;\n  if (at::cuda::getNumGPUs() < 2) {\n    return;\n  }\n\n  // -- begin setup\n\n  ASSERT_EQ_CUDA(at::cuda::current_device(), 0);\n  std::vector<at::cuda::CUDAStream> streams0 = {\n      at::cuda::getDefaultCUDAStream(), at::cuda::getStreamFromPool()};\n  ASSERT_EQ_CUDA(streams0[0].device_index(), 0);\n  ASSERT_EQ_CUDA(streams0[1].device_index(), 0);\n  at::cuda::setCurrentCUDAStream(streams0[0]);\n\n  std::vector<at::cuda::CUDAStream> streams1;\n  {\n    at::cuda::CUDAGuard device_guard(1);\n    streams1.push_back(at::cuda::getDefaultCUDAStream());\n    streams1.push_back(at::cuda::getStreamFromPool());\n  }\n  ASSERT_EQ_CUDA(streams1[0].device_index(), 1);\n  ASSERT_EQ_CUDA(streams1[1].device_index(), 1);\n  at::cuda::setCurrentCUDAStream(streams1[0]);\n\n  ASSERT_EQ_CUDA(at::cuda::current_device(), 0);\n\n  // -- end setup\n\n  // Test that all original streams are recorded.\n  {\n    at::cuda::CUDAMultiStreamGuard guard;\n    ASSERT_EQ_CUDA(guard.original_streams().size(), at::cuda::getNumGPUs());\n    ASSERT_EQ_CUDA(guard.original_streams()[0], streams0[0]);\n    ASSERT_EQ_CUDA(guard.original_streams()[1], streams1[0]);\n  }\n\n  // Setting a stream changes the current device and the stream on that device\n  {\n    at::cuda::CUDAStreamGuard guard(streams1[1]);\n    ASSERT_EQ_CUDA(guard.current_device(), at::Device(at::kCUDA, 1));\n    ASSERT_EQ_CUDA(at::cuda::current_device(), 1);\n    ASSERT_EQ_CUDA(at::cuda::getCurrentCUDAStream(1), streams1[1]);\n  }\n\n  // Device and stream are now reset\n  ASSERT_EQ_CUDA(at::cuda::current_device(), 0);\n  ASSERT_EQ_CUDA(at::cuda::getCurrentCUDAStream(1), streams1[0]);\n\n  // Setting only the device changes only the current device and not the stream\n  {\n    at::cuda::CUDAGuard guard(/*device=*/1);\n    ASSERT_EQ_CUDA(guard.current_device(), at::Device(at::kCUDA, 1));\n    ASSERT_EQ_CUDA(at::cuda::current_device(), 1);\n    ASSERT_EQ_CUDA(at::cuda::getCurrentCUDAStream(1), streams1[0]);\n  }\n\n  ASSERT_EQ_CUDA(at::cuda::current_device(), 0);\n  ASSERT_EQ_CUDA(at::cuda::getCurrentCUDAStream(0), streams0[0]);\n}",
            "{\n  if (!at::cuda::is_available()) return;\n  std::vector<at::cuda::CUDAStream> streams{};\n  for (int i = 0; i < 200; ++i) {\n    streams.emplace_back(at::cuda::getStreamFromPool());\n  }\n\n  std::unordered_set<cudaStream_t> stream_set{};\n  bool hasDuplicates = false;\n  for (auto i = decltype(streams.size()){0}; i < streams.size(); ++i) {\n    cudaStream_t cuda_stream = streams[i];\n    auto result_pair = stream_set.insert(cuda_stream);\n    if (!result_pair.second)\n      hasDuplicates = true;\n  }\n\n  ASSERT_TRUE(hasDuplicates);\n}",
            "{\n  if (!at::cuda::is_available()) return;\n  if (at::cuda::getNumGPUs() < 2)\n    return;\n\n  at::cuda::CUDAStream s0 = at::cuda::getStreamFromPool(true, 0);\n  at::cuda::CUDAStream s1 = at::cuda::getStreamFromPool(false, 1);\n\n  at::cuda::setCurrentCUDAStream(s0);\n  at::cuda::setCurrentCUDAStream(s1);\n\n  ASSERT_EQ_CUDA(s0, at::cuda::getCurrentCUDAStream());\n\n  at::cuda::CUDAGuard device_guard{1};\n  ASSERT_EQ_CUDA(s1, at::cuda::getCurrentCUDAStream());\n}",
            "{\n  if (!at::cuda::is_available()) return;\n  const auto stream = at::cuda::getStreamFromPool();\n  at::cuda::CUDAEvent event;\n\n  ASSERT_TRUE(event.query());\n\n  event.recordOnce(stream);\n\n  const auto wait_stream0 = at::cuda::getStreamFromPool();\n  const auto wait_stream1 = at::cuda::getStreamFromPool();\n\n  event.block(wait_stream0);\n  event.block(wait_stream1);\n\n  cudaStreamSynchronize(wait_stream0);\n  ASSERT_TRUE(event.query());\n}",
            "{\n  if (!at::cuda::is_available()) return;\n  if (at::cuda::getNumGPUs() < 2)\n    return;\n\n  const auto stream0 = at::cuda::getStreamFromPool();\n  at::cuda::CUDAEvent event0;\n\n  at::cuda::set_device(1);\n  const auto stream1 = at::cuda::getStreamFromPool();\n  at::cuda::CUDAEvent event1;\n\n  event0.record(stream0);\n  event1.record(stream1);\n\n  event0 = std::move(event1);\n\n  ASSERT_EQ_CUDA(event0.device(), at::Device(at::kCUDA, 1));\n\n  event0.block(stream0);\n\n  cudaStreamSynchronize(stream0);\n  ASSERT_TRUE(event0.query());\n}",
            "{\n  if (!at::cuda::is_available()) return;\n\n  c10::impl::InlineEvent<c10::cuda::impl::CUDAGuardImpl> event{c10::DeviceType::CUDA};\n  c10::Stream stream = at::cuda::getStreamFromPool();\n\n  event.record(stream);\n\n  const c10::Stream wait_stream0 = at::cuda::getStreamFromPool();\n  const c10::Stream wait_stream1 = at::cuda::getStreamFromPool();\n\n  event.block(wait_stream0);\n  event.block(wait_stream1);\n\n  const at::cuda::CUDAStream cuda_stream{wait_stream0};\n  cudaStreamSynchronize(cuda_stream);\n\n  ASSERT_TRUE(event.query());\n}",
            "{\n  if (!at::cuda::is_available()) return;\n\n  c10::Event event{c10::DeviceType::CUDA};\n  c10::Stream stream = at::cuda::getStreamFromPool();\n\n  event.recordOnce(stream);\n\n  const c10::Stream wait_stream0 = at::cuda::getStreamFromPool();\n  const c10::Stream wait_stream1 = at::cuda::getStreamFromPool();\n\n  wait_stream0.wait(event);\n  wait_stream1.wait(event);\n\n  const at::cuda::CUDAStream cuda_stream{wait_stream0};\n  cudaStreamSynchronize(cuda_stream);\n\n  ASSERT_TRUE(event.query());\n  ASSERT_TRUE(event.flag() == c10::EventFlag::PYTORCH_DEFAULT);\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/cuda_tensor_interop_test.cpp",
        "functions": [
            "{\n  if (!at::cuda::is_available()) return;\n  caffe2::Tensor c2_tensor(caffe2::CUDA);\n  c2_tensor.Resize(4, 4);\n  auto data = c2_tensor.mutable_data<int64_t>();\n  {\n    caffe2::CUDAContext context;\n    caffe2::math::Set<int64_t>(16, 777, data, &context);\n  }\n  at::Tensor at_tensor(c2_tensor);\n  ASSERT_TRUE(at_tensor.is_cuda());\n\n  auto at_cpu = at_tensor.cpu();\n  auto it = at_cpu.data_ptr<int64_t>();\n  for (int64_t i = 0; i < 16; i++) {\n    ASSERT_EQ(it[i], 777);\n  }\n}",
            "{\n  if (!at::cuda::is_available()) return;\n  caffe2::Tensor c2_tensor =\n      caffe2::empty({4, 4}, at::dtype<int64_t>().device(caffe2::CUDA));\n  auto data = c2_tensor.mutable_data<int64_t>();\n  {\n    caffe2::CUDAContext context;\n    caffe2::math::Set<int64_t>(16, 777, data, &context);\n  }\n  at::Tensor at_tensor(c2_tensor);\n  ASSERT_TRUE(at_tensor.is_cuda());\n\n  auto at_cpu = at_tensor.cpu();\n  auto it = at_cpu.data_ptr<int64_t>();\n  for (int64_t i = 0; i < 16; i++) {\n    ASSERT_EQ(it[i], 777);\n  }\n}",
            "{\n  if (!at::cuda::is_available()) return;\n  caffe2::Tensor c2_tensor =\n      caffe2::empty({3, 3}, at::dtype<int64_t>().device(caffe2::CUDA));\n  auto data = c2_tensor.mutable_data<int64_t>();\n  {\n    caffe2::CUDAContext context;\n    caffe2::math::Set<int64_t>(9, 111, data, &context);\n  }\n  at::Tensor at_tensor(c2_tensor);\n  ASSERT_TRUE(at_tensor.is_cuda());\n\n  ASSERT_EQ(at::sum(at_tensor).item<int64_t>(), 999);\n}",
            "{\n  if (!at::cuda::is_available()) return;\n  caffe2::Workspace workspace;\n  caffe2::NetDef net;\n\n  auto at_tensor_a = at::ones({5, 5}, at::dtype(at::kFloat).device(at::kCUDA));\n  auto at_tensor_b = at::ones({5, 5}, at::dtype(at::kFloat).device(at::kCUDA));\n  auto at_tensor_c = at::ones({5, 5}, at::dtype(at::kFloat).device(at::kCUDA));\n\n  auto* c2_tensor_a = BlobSetTensor(workspace.CreateBlob(\"a\"), caffe2::Tensor(at_tensor_a));\n  auto* c2_tensor_b = BlobSetTensor(workspace.CreateBlob(\"b\"), caffe2::Tensor(at_tensor_b));\n\n  // Test Alias\n  {\n    caffe2::Tensor c2_tensor_from_aten(at_tensor_c);\n    BlobSetTensor(workspace.CreateBlob(\"c\"), c2_tensor_from_aten.Alias());\n  }\n\n  {\n    auto op = net.add_op();\n    op->set_type(\"Sum\");\n    op->add_input(\"a\");\n    op->add_input(\"b\");\n    op->add_input(\"c\");\n    op->add_output(\"d\");\n    op->mutable_device_option()->set_device_type(caffe2::PROTO_CUDA);\n  }\n\n  workspace.RunNetOnce(net);\n\n  const auto& result = workspace.GetBlob(\"d\")->Get<caffe2::Tensor>();\n  ASSERT_EQ(result.GetDeviceType(), caffe2::CUDA);\n\n  auto data = result.data<float>();\n  for (int64_t i = 0; i < 25; i++) {\n    ASSERT_EQ(cuda_get(data + i), 3.0);\n  }\n  at::Tensor at_result(result);\n  ASSERT_TRUE(at_result.is_cuda());\n  ASSERT_EQ(at::sum(at_result).item<float>(), 75);\n}",
            "{\n  if (!at::cuda::is_available()) return;\n  auto at_tensor_a = at::ones({5, 5}, at::dtype(at::kFloat).device(at::kCUDA));\n  auto at_tensor_b = at_tensor_a.view({25});\n\n  caffe2::Tensor c2_tensor_a(at_tensor_a);\n  caffe2::Tensor c2_tensor_b(at_tensor_b);\n\n  // change is visible everywhere\n  cuda_set<float>(c2_tensor_a.mutable_data<float>() + 1, 123);\n  ASSERT_EQ(cuda_get(c2_tensor_b.mutable_data<float>() + 1), 123);\n  ASSERT_EQ(at_tensor_a[0][1].item().to<float>(), 123);\n  ASSERT_EQ(at_tensor_b[1].item().to<float>(), 123);\n}",
            "{\n  if (!at::cuda::is_available()) return;\n  auto at_tensor = at::ones({5, 5}, at::dtype(at::kFloat).device(at::kCUDA));\n\n  caffe2::Tensor c2_tensor(at_tensor);\n\n  // change is visible\n  cuda_set<float>(c2_tensor.mutable_data<float>(), 123);\n  ASSERT_EQ(at_tensor[0][0].item().to<float>(), 123);\n\n  // resize PT tensor in smaller direction - storage is preserved\n  at_tensor.resize_({4, 4});\n  cuda_set<float>(c2_tensor.mutable_data<float>() + 1, 234);\n  ASSERT_EQ(at_tensor[0][1].item().to<float>(), 234);\n\n  // resize PT tensor in larger direction - storage is preserved\n  at_tensor.resize_({6, 6});\n  cuda_set<float>(c2_tensor.mutable_data<float>() + 2, 345);\n  ASSERT_EQ(at_tensor[0][2].item().to<float>(), 345);\n  ASSERT_EQ(c2_tensor.sizes()[0], 6);\n  ASSERT_EQ(c2_tensor.sizes()[1], 6);\n\n  // resize Caffe2 tensor - semantics are to NOT preserve the data, but the\n  // TensorImpl is still shared\n  c2_tensor.Resize(7, 7);\n  cuda_set<float>(c2_tensor.mutable_data<float>() + 3, 456);\n  ASSERT_EQ(at_tensor[0][3].item().to<float>(), 456);\n  ASSERT_EQ(at_tensor.sizes()[0], 7);\n  ASSERT_EQ(at_tensor.sizes()[1], 7);\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/Dict_test.cpp",
        "functions": [
            "{\n    Dict<int64_t, string> dict;\n    EXPECT_TRUE(dict.empty());\n}",
            "{\n    Dict<int64_t, string> dict;\n    dict.insert(3, \"value\");\n    EXPECT_FALSE(dict.empty());\n}",
            "{\n    Dict<int64_t, string> dict;\n    EXPECT_EQ(0, dict.size());\n}",
            "{\n    Dict<int64_t, string> dict;\n    dict.insert(3, \"value\");\n    dict.insert(4, \"value2\");\n    EXPECT_EQ(2, dict.size());\n}",
            "{\n  Dict<int64_t, string> dict;\n  dict.insert(3, \"value\");\n  dict.insert(4, \"value2\");\n  dict.clear();\n  EXPECT_TRUE(dict.empty());\n}",
            "{\n  Dict<int64_t, string> dict;\n  std::pair<Dict<int64_t, string>::iterator, bool> result = dict.insert(3, \"value\");\n  EXPECT_TRUE(result.second);\n  EXPECT_EQ(3, result.first->key());\n  EXPECT_EQ(\"value\", result.first->value());\n}",
            "{\n  Dict<int64_t, string> dict;\n  dict.insert(3, \"old_value\");\n  std::pair<Dict<int64_t, string>::iterator, bool> result = dict.insert(3, \"new_value\");\n  EXPECT_FALSE(result.second);\n  EXPECT_EQ(3, result.first->key());\n  EXPECT_EQ(\"old_value\", result.first->value());\n}",
            "{\n  Dict<int64_t, string> dict;\n  dict.insert(3, \"old_value\");\n  dict.insert(3, \"new_value\");\n  EXPECT_EQ(1, dict.size());\n  EXPECT_EQ(3, dict.begin()->key());\n  EXPECT_EQ(\"old_value\", dict.begin()->value());\n}",
            "{\n  Dict<int64_t, string> dict;\n  std::pair<Dict<int64_t, string>::iterator, bool> result = dict.insert_or_assign(3, \"value\");\n  EXPECT_TRUE(result.second);\n  EXPECT_EQ(3, result.first->key());\n  EXPECT_EQ(\"value\", result.first->value());\n}",
            "{\n  Dict<int64_t, string> dict;\n  dict.insert(3, \"old_value\");\n  std::pair<Dict<int64_t, string>::iterator, bool> result = dict.insert_or_assign(3, \"new_value\");\n  EXPECT_FALSE(result.second);\n  EXPECT_EQ(3, result.first->key());\n  EXPECT_EQ(\"new_value\", result.first->value());\n}",
            "{\n  Dict<int64_t, string> dict;\n  dict.insert(3, \"old_value\");\n  dict.insert_or_assign(3, \"new_value\");\n  EXPECT_EQ(1, dict.size());\n  EXPECT_EQ(3, dict.begin()->key());\n  EXPECT_EQ(\"new_value\", dict.begin()->value());\n}",
            "{\n  Dict<int64_t, string> dict;\n  EXPECT_EQ(dict.begin(), dict.end());\n}",
            "{\n  Dict<int64_t, string> dict;\n  dict.insert(3, \"3\");\n  dict.insert(5, \"5\");\n  bool found_first = false;\n  bool found_second = false;\n  for (Dict<int64_t, string>::iterator iter = dict.begin(); iter != dict.end(); ++iter) {\n    if (iter->key() == 3) {\n      EXPECT_EQ(\"3\", iter->value());\n      EXPECT_FALSE(found_first);\n      found_first = true;\n    } else if (iter->key() == 5) {\n      EXPECT_EQ(\"5\", iter->value());\n      EXPECT_FALSE(found_second);\n      found_second = true;\n    } else {\n      ADD_FAILURE();\n    }\n  }\n  EXPECT_TRUE(found_first);\n  EXPECT_TRUE(found_second);\n}",
            "{\n  Dict<int64_t, string> dict;\n  dict.insert(3, \"3\");\n  dict.insert(5, \"5\");\n  bool found_first = false;\n  bool found_second = false;\n  for (const auto& elem : dict) {\n    if (elem.key() == 3) {\n      EXPECT_EQ(\"3\", elem.value());\n      EXPECT_FALSE(found_first);\n      found_first = true;\n    } else if (elem.key() == 5) {\n      EXPECT_EQ(\"5\", elem.value());\n      EXPECT_FALSE(found_second);\n      found_second = true;\n    } else {\n      ADD_FAILURE();\n    }\n  }\n  EXPECT_TRUE(found_first);\n  EXPECT_TRUE(found_second);\n}",
            "{\n  Dict<int64_t, string> dict_;\n  dict_.insert(3, \"3\");\n  dict_.insert(5, \"5\");\n  const Dict<int64_t, string>& dict = dict_;\n  bool found_first = false;\n  bool found_second = false;\n  for (Dict<int64_t, string>::iterator iter = dict.begin(); iter != dict.end(); ++iter) {\n    if (iter->key() == 3) {\n      EXPECT_EQ(\"3\", iter->value());\n      EXPECT_FALSE(found_first);\n      found_first = true;\n    } else if (iter->key() == 5) {\n      EXPECT_EQ(\"5\", iter->value());\n      EXPECT_FALSE(found_second);\n      found_second = true;\n    } else {\n      ADD_FAILURE();\n    }\n  }\n  EXPECT_TRUE(found_first);\n  EXPECT_TRUE(found_second);\n}",
            "{\n  Dict<int64_t, string> dict_;\n  dict_.insert(3, \"3\");\n  dict_.insert(5, \"5\");\n  const Dict<int64_t, string>& dict = dict_;\n  bool found_first = false;\n  bool found_second = false;\n  for (const auto& elem : dict) {\n    if (elem.key() == 3) {\n      EXPECT_EQ(\"3\", elem.value());\n      EXPECT_FALSE(found_first);\n      found_first = true;\n    } else if (elem.key() == 5) {\n      EXPECT_EQ(\"5\", elem.value());\n      EXPECT_FALSE(found_second);\n      found_second = true;\n    } else {\n      ADD_FAILURE();\n    }\n  }\n  EXPECT_TRUE(found_first);\n  EXPECT_TRUE(found_second);\n}",
            "{\n  Dict<int64_t, string> dict;\n  dict.insert(3, \"old_value\");\n  dict.begin()->setValue(\"new_value\");\n  EXPECT_EQ(\"new_value\", dict.begin()->value());\n}",
            "{\n  Dict<int64_t, string> dict;\n  dict.insert(3, \"3\");\n  dict.erase(dict.begin());\n  EXPECT_TRUE(dict.empty());\n}",
            "{\n  Dict<int64_t, string> dict;\n  dict.insert(3, \"3\");\n  bool result = dict.erase(3);\n  EXPECT_EQ(1, result);\n  EXPECT_TRUE(dict.empty());\n}",
            "{\n  Dict<int64_t, string> dict;\n  dict.insert(3, \"3\");\n  bool result = dict.erase(4);\n  EXPECT_EQ(0, result);\n  EXPECT_EQ(1, dict.size());\n}",
            "{\n  Dict<int64_t, string> dict;\n  dict.insert(3, \"3\");\n  dict.insert(4, \"4\");\n  EXPECT_EQ(\"4\", dict.at(4));\n}",
            "{\n  Dict<int64_t, string> dict;\n  dict.insert(3, \"3\");\n  dict.insert(4, \"4\");\n  EXPECT_THROW(dict.at(5), std::out_of_range);\n}",
            "{\n  Dict<int64_t, string> dict;\n  dict.insert(3, \"3\");\n  dict.insert(4, \"4\");\n  Dict<int64_t, string>::iterator found = dict.find(3);\n  EXPECT_EQ(3, found->key());\n  EXPECT_EQ(\"3\", found->value());\n}",
            "{\n  Dict<int64_t, string> dict;\n  dict.insert(3, \"3\");\n  dict.insert(4, \"4\");\n  Dict<int64_t, string>::iterator found = dict.find(5);\n  EXPECT_EQ(dict.end(), found);\n}",
            "{\n  Dict<int64_t, string> dict_;\n  dict_.insert(3, \"3\");\n  dict_.insert(4, \"4\");\n  const Dict<int64_t, string>& dict = dict_;\n  Dict<int64_t, string>::iterator found = dict.find(3);\n  EXPECT_EQ(3, found->key());\n  EXPECT_EQ(\"3\", found->value());\n}",
            "{\n  Dict<int64_t, string> dict_;\n  dict_.insert(3, \"3\");\n  dict_.insert(4, \"4\");\n  const Dict<int64_t, string>& dict = dict_;\n  Dict<int64_t, string>::iterator found = dict.find(5);\n  EXPECT_EQ(dict.end(), found);\n}",
            "{\n  Dict<int64_t, string> dict;\n  dict.insert(3, \"3\");\n  dict.insert(4, \"4\");\n  EXPECT_TRUE(dict.contains(3));\n}",
            "{\n  Dict<int64_t, string> dict;\n  dict.insert(3, \"3\");\n  dict.insert(4, \"4\");\n  EXPECT_FALSE(dict.contains(5));\n}",
            "{\n  Dict<int64_t, string> dict;\n  dict.reserve(100);\n}",
            "{\n  Dict<int64_t, string> dict1;\n  dict1.insert(3, \"3\");\n  dict1.insert(4, \"4\");\n\n  Dict<int64_t, string> dict2(dict1);\n\n  EXPECT_EQ(2, dict2.size());\n  EXPECT_EQ(\"3\", dict2.at(3));\n  EXPECT_EQ(\"4\", dict2.at(4));\n}",
            "{\n  Dict<int64_t, string> dict1;\n  dict1.insert(3, \"3\");\n  dict1.insert(4, \"4\");\n\n  Dict<int64_t, string> dict2;\n  dict2 = dict1;\n\n  EXPECT_EQ(2, dict2.size());\n  EXPECT_EQ(\"3\", dict2.at(3));\n  EXPECT_EQ(\"4\", dict2.at(4));\n}",
            "{\n  Dict<int64_t, string> dict1;\n  dict1.insert(3, \"3\");\n  dict1.insert(4, \"4\");\n\n  Dict<int64_t, string> dict2 = dict1.copy();\n\n  EXPECT_EQ(2, dict2.size());\n  EXPECT_EQ(\"3\", dict2.at(3));\n  EXPECT_EQ(\"4\", dict2.at(4));\n}",
            "{\n  Dict<int64_t, string> dict1;\n  dict1.insert(3, \"3\");\n  dict1.insert(4, \"4\");\n\n  Dict<int64_t, string> dict2(std::move(dict1));\n\n  EXPECT_EQ(2, dict2.size());\n  EXPECT_EQ(\"3\", dict2.at(3));\n  EXPECT_EQ(\"4\", dict2.at(4));\n}",
            "{\n  Dict<int64_t, string> dict1;\n  dict1.insert(3, \"3\");\n  dict1.insert(4, \"4\");\n\n  Dict<int64_t, string> dict2;\n  dict2 = std::move(dict1);\n\n  EXPECT_EQ(2, dict2.size());\n  EXPECT_EQ(\"3\", dict2.at(3));\n  EXPECT_EQ(\"4\", dict2.at(4));\n}",
            "{\n  Dict<int64_t, string> dict1;\n  dict1.insert(3, \"3\");\n  dict1.insert(4, \"4\");\n\n  Dict<int64_t, string> dict2(std::move(dict1));\n  EXPECT_TRUE(dict1.empty());\n}",
            "{\n  Dict<int64_t, string> dict1;\n  dict1.insert(3, \"3\");\n  dict1.insert(4, \"4\");\n\n  Dict<int64_t, string> dict2;\n  dict2 = std::move(dict1);\n  EXPECT_TRUE(dict1.empty());\n}",
            "{\n  Dict<int64_t, string> dict;\n  dict.insert(3, \"3\");\n  dict.insert(4, \"4\");\n\n  Dict<int64_t, string>::iterator iter1 = dict.begin();\n  Dict<int64_t, string>::iterator iter2 = iter1++;\n  EXPECT_NE(dict.begin()->key(), iter1->key());\n  EXPECT_EQ(dict.begin()->key(), iter2->key());\n}",
            "{\n  Dict<int64_t, string> dict;\n  dict.insert(3, \"3\");\n  dict.insert(4, \"4\");\n\n  Dict<int64_t, string>::iterator iter1 = dict.begin();\n  Dict<int64_t, string>::iterator iter2 = ++iter1;\n  EXPECT_NE(dict.begin()->key(), iter1->key());\n  EXPECT_NE(dict.begin()->key(), iter2->key());\n}",
            "{\n  Dict<int64_t, string> dict;\n  dict.insert(3, \"3\");\n  dict.insert(4, \"4\");\n\n  Dict<int64_t, string>::iterator iter1 = dict.begin();\n  Dict<int64_t, string>::iterator iter2 = dict.begin();\n  EXPECT_TRUE(iter1 == iter2);\n  EXPECT_FALSE(iter1 != iter2);\n}",
            "{\n  Dict<int64_t, string> dict;\n  dict.insert(3, \"3\");\n  dict.insert(4, \"4\");\n\n  Dict<int64_t, string>::iterator iter1 = dict.begin();\n  Dict<int64_t, string>::iterator iter2 = dict.begin();\n  iter2++;\n\n  EXPECT_FALSE(iter1 == iter2);\n  EXPECT_TRUE(iter1 != iter2);\n}",
            "{\n  Dict<int64_t, string> dict;\n  dict.insert(3, \"3\");\n\n  Dict<int64_t, string>::iterator iter = dict.begin();\n  EXPECT_EQ(3, (*iter).key());\n  EXPECT_EQ(\"3\", (*iter).value());\n  EXPECT_EQ(3, iter->key());\n  EXPECT_EQ(\"3\", iter->value());\n}",
            "{\n  Dict<int64_t, string> dict;\n  dict.insert(3, \"3\");\n\n  Dict<int64_t, string>::iterator iter = dict.begin();\n\n  (*iter).setValue(\"new_value\");\n  EXPECT_EQ(\"new_value\", dict.begin()->value());\n\n  iter->setValue(\"new_value_2\");\n  EXPECT_EQ(\"new_value_2\", dict.begin()->value());\n}",
            "{\n  Dict<int64_t, string> dict;\n  dict.insert(3, \"3\");\n  dict.insert(4, \"4\");\n  dict.insert(5, \"5\");\n\n  (*dict.find(3)).setValue(dict.find(4)->value());\n  EXPECT_EQ(\"4\", dict.find(3)->value());\n\n  dict.find(3)->setValue(dict.find(5)->value());\n  EXPECT_EQ(\"5\", dict.find(3)->value());\n}",
            "{\n  Dict<int64_t, string> dict1;\n  Dict<int64_t, string> dict2(dict1);\n  Dict<int64_t, string> dict3;\n  dict3 = dict1;\n\n  dict1.insert(3, \"three\");\n  EXPECT_EQ(1, dict1.size());\n  EXPECT_EQ(1, dict2.size());\n  EXPECT_EQ(1, dict3.size());\n}",
            "{\n  Dict<int64_t, string> dict1;\n  Dict<int64_t, string> dict2(dict1.copy());\n  Dict<int64_t, string> dict3;\n  dict3 = dict1.copy();\n\n  dict1.insert(3, \"three\");\n  EXPECT_EQ(1, dict1.size());\n  EXPECT_EQ(0, dict2.size());\n  EXPECT_EQ(0, dict3.size());\n}",
            "{\n  Dict<at::Tensor, string> dict;\n  at::Tensor key1 = at::tensor(3);\n  at::Tensor key2 = at::tensor(4);\n  dict.insert(key1, \"three\");\n  dict.insert(key2, \"four\");\n\n  EXPECT_EQ(2, dict.size());\n\n  Dict<at::Tensor, string>::iterator found_key1 = dict.find(key1);\n  ASSERT_EQUAL(key1, found_key1->key());\n  EXPECT_EQ(\"three\", found_key1->value());\n\n  Dict<at::Tensor, string>::iterator found_nokey1 = dict.find(at::tensor(3));\n  Dict<at::Tensor, string>::iterator found_nokey2 = dict.find(at::tensor(5));\n  EXPECT_EQ(dict.end(), found_nokey1);\n  EXPECT_EQ(dict.end(), found_nokey2);\n}",
            "{\n  Dict<string, int64_t> dict;\n  dict.insert(\"one\", 1);\n  dict.insert(\"two\", 2);\n\n  Dict<string, int64_t> dictSameValue;\n  dictSameValue.insert(\"one\", 1);\n  dictSameValue.insert(\"two\", 2);\n\n  Dict<string, int64_t> dictNotEqual;\n  dictNotEqual.insert(\"foo\", 1);\n  dictNotEqual.insert(\"bar\", 2);\n\n  Dict<string, int64_t> dictRef = dict;\n\n  EXPECT_EQ(dict, dictSameValue);\n  EXPECT_NE(dict, dictNotEqual);\n  EXPECT_NE(dictSameValue, dictNotEqual);\n  EXPECT_FALSE(dict.is(dictSameValue));\n  EXPECT_TRUE(dict.is(dictRef));\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/Dimname_test.cpp",
        "functions": [
            "{\n  ASSERT_TRUE(Dimname::isValidName(\"a\"));\n  ASSERT_TRUE(Dimname::isValidName(\"batch\"));\n  ASSERT_TRUE(Dimname::isValidName(\"N\"));\n  ASSERT_TRUE(Dimname::isValidName(\"CHANNELS\"));\n  ASSERT_TRUE(Dimname::isValidName(\"foo_bar_baz\"));\n  ASSERT_TRUE(Dimname::isValidName(\"batch1\"));\n  ASSERT_TRUE(Dimname::isValidName(\"batch_9\"));\n  ASSERT_TRUE(Dimname::isValidName(\"_\"));\n  ASSERT_TRUE(Dimname::isValidName(\"_1\"));\n\n  ASSERT_FALSE(Dimname::isValidName(\"\"));\n  ASSERT_FALSE(Dimname::isValidName(\" \"));\n  ASSERT_FALSE(Dimname::isValidName(\" a \"));\n  ASSERT_FALSE(Dimname::isValidName(\"1batch\"));\n  ASSERT_FALSE(Dimname::isValidName(\"?\"));\n  ASSERT_FALSE(Dimname::isValidName(\"-\"));\n  ASSERT_FALSE(Dimname::isValidName(\"1\"));\n  ASSERT_FALSE(Dimname::isValidName(\"01\"));\n}",
            "{\n  Dimname wildcard = Dimname::wildcard();\n  ASSERT_EQ(wildcard.type(), NameType::WILDCARD);\n  ASSERT_EQ(wildcard.symbol(), Symbol::dimname(\"*\"));\n}",
            "{\n  auto foo = Symbol::dimname(\"foo\");\n  auto dimname = Dimname::fromSymbol(foo);\n  ASSERT_EQ(dimname.type(), NameType::BASIC);\n  ASSERT_EQ(dimname.symbol(), foo);\n  ASSERT_THROW(Dimname::fromSymbol(Symbol::dimname(\"inva.lid\")), c10::Error);\n  ASSERT_THROW(Dimname::fromSymbol(Symbol::dimname(\"1invalid\")), c10::Error);\n}",
            "void",
            "{\n  check_unify_and_match(\"a\", \"a\", \"a\");\n  check_unify_and_match(\"a\", \"*\", \"a\");\n  check_unify_and_match(\"*\", \"a\", \"a\");\n  check_unify_and_match(\"*\", \"*\", \"*\");\n  check_unify_and_match(\"a\", \"b\", c10::nullopt);\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/dlconvertor_test.cpp",
        "functions": [
            "{\n  manual_seed(123);\n\n  Tensor a = rand({3, 4});\n  DLManagedTensor* dlMTensor = toDLPack(a);\n\n  Tensor b = fromDLPack(dlMTensor);\n\n  ASSERT_TRUE(a.equal(b));\n}",
            "{\n  manual_seed(123);\n\n  Tensor a = rand({3, 4});\n  DLManagedTensor* dlMTensor = toDLPack(a);\n  dlMTensor->dl_tensor.strides = nullptr;\n\n  Tensor b = fromDLPack(dlMTensor);\n\n  ASSERT_TRUE(a.equal(b));\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/extension_backend_test.cpp",
        "functions": [
            "empty_override(IntArrayRef size, c10::optional<ScalarType> dtype, c10::optional<Layout> layout,\n                      c10::optional<Device> device, c10::optional<bool> pin_memory, c10::optional<MemoryFormat> optional_memory_format)",
            "add_override(const Tensor & a, const Tensor & b , Scalar c)",
            "empty_strided_override(\n  IntArrayRef size,\n  IntArrayRef stride,\n  c10::optional<c10::ScalarType> dtype,\n  c10::optional<c10::Layout> layout,\n  c10::optional<c10::Device> device,\n  c10::optional<bool> pin_memory)",
            "{\n  m.impl(\"aten::empty.memory_format\",  empty_override);\n  m.impl(\"aten::empty_strided\",        empty_strided_override);\n  m.impl(\"aten::add.Tensor\",           add_override);\n}",
            "{\n  Tensor a = empty({5, 5}, at::kMSNPU);\n  ASSERT_EQ(a.device().type(), at::kMSNPU);\n  ASSERT_EQ(a.device().index(), 1);\n  ASSERT_EQ(a.dtype(), caffe2::TypeMeta::Make<float>());\n  ASSERT_EQ(test_int, 1);\n\n  Tensor b = empty_like(a, at::kMSNPU);\n  ASSERT_EQ(b.device().type(), at::kMSNPU);\n  ASSERT_EQ(b.device().index(), 1);\n  ASSERT_EQ(b.dtype(), caffe2::TypeMeta::Make<float>());\n\n  add(a, b);\n  ASSERT_EQ(test_int, 2);\n\n  // Ensure that non-MSNPU operator still works\n  Tensor d = empty({5, 5}, at::kCPU);\n  ASSERT_EQ(d.device().type(), at::kCPU);\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/half_test.cpp",
        "functions": [
            "{\n  Half zero = 0;\n  Half one = 1;\n  ASSERT_EQ(zero + one, one);\n  ASSERT_EQ(zero + zero, zero);\n  ASSERT_EQ(zero * one, zero);\n  ASSERT_EQ(one * one, one);\n  ASSERT_EQ(one / one, one);\n  ASSERT_EQ(one - one, zero);\n  ASSERT_EQ(one - zero, one);\n  ASSERT_EQ(zero - one, -one);\n  ASSERT_EQ(one + one, Half(2));\n  ASSERT_EQ(one + one, 2);\n}",
            "{\n  Half zero = 0;\n  Half one = 1;\n  ASSERT_LT(zero, one);\n  ASSERT_LT(zero, 1);\n  ASSERT_GT(1, zero);\n  ASSERT_GE(0, zero);\n  ASSERT_NE(0, one);\n  ASSERT_EQ(zero, 0);\n  ASSERT_EQ(zero, zero);\n  ASSERT_EQ(zero, -zero);\n}",
            "{\n  Half value = 1.5f;\n  ASSERT_EQ((int)value, 1);\n  ASSERT_EQ((short)value, 1);\n  ASSERT_EQ((long long)value, 1LL);\n  ASSERT_EQ((float)value, 1.5f);\n  ASSERT_EQ((double)value, 1.5);\n  ASSERT_EQ((bool)value, true);\n  ASSERT_EQ((bool)Half(0.0f), false);\n}",
            "{\n  ASSERT_EQ(Half((short)3), Half(3.0f));\n  ASSERT_EQ(Half((unsigned short)3), Half(3.0f));\n  ASSERT_EQ(Half(3), Half(3.0f));\n  ASSERT_EQ(Half(3U), Half(3.0f));\n  ASSERT_EQ(Half(3LL), Half(3.0f));\n  ASSERT_EQ(Half(3ULL), Half(3.0f));\n  ASSERT_EQ(Half(3.5), Half(3.5f));\n}",
            "std::string",
            "{\n  ASSERT_EQ(to_string(Half(3.5f)), \"3.5\");\n  ASSERT_EQ(to_string(Half(-100.0f)), \"-100\");\n}",
            "{\n  using limits = std::numeric_limits<Half>;\n  ASSERT_EQ(limits::lowest(), -65504.0f);\n  ASSERT_EQ(limits::max(), 65504.0f);\n  ASSERT_GT(limits::min(), 0);\n  ASSERT_LT(limits::min(), 1);\n  ASSERT_GT(limits::denorm_min(), 0);\n  ASSERT_EQ(limits::denorm_min() / 2, 0);\n  ASSERT_EQ(limits::infinity(), std::numeric_limits<float>::infinity());\n  ASSERT_NE(limits::quiet_NaN(), limits::quiet_NaN());\n  ASSERT_NE(limits::signaling_NaN(), limits::signaling_NaN());\n}",
            "{\n  float threshold = 0.00001;\n  assert(std::abs(std::lgamma(Half(10.0)) - std::lgamma(10.0f)) <= threshold);\n  assert(std::abs(std::exp(Half(1.0)) - std::exp(1.0f)) <= threshold);\n  assert(std::abs(std::log(Half(1.0)) - std::log(1.0f)) <= threshold);\n  assert(std::abs(std::log10(Half(1000.0)) - std::log10(1000.0f)) <= threshold);\n  assert(std::abs(std::log1p(Half(0.0)) - std::log1p(0.0f)) <= threshold);\n  assert(std::abs(std::log2(Half(1000.0)) - std::log2(1000.0f)) <= threshold);\n  assert(std::abs(std::expm1(Half(1.0)) - std::expm1(1.0f)) <= threshold);\n  assert(std::abs(std::cos(Half(0.0)) - std::cos(0.0f)) <= threshold);\n  assert(std::abs(std::sin(Half(0.0)) - std::sin(0.0f)) <= threshold);\n  assert(std::abs(std::sqrt(Half(100.0)) - std::sqrt(100.0f)) <= threshold);\n  assert(std::abs(std::ceil(Half(2.4)) - std::ceil(2.4f)) <= threshold);\n  assert(std::abs(std::floor(Half(2.7)) - std::floor(2.7f)) <= threshold);\n  assert(std::abs(std::trunc(Half(2.7)) - std::trunc(2.7f)) <= threshold);\n  assert(std::abs(std::acos(Half(-1.0)) - std::acos(-1.0f)) <= threshold);\n  assert(std::abs(std::cosh(Half(1.0)) - std::cosh(1.0f)) <= threshold);\n  assert(std::abs(std::acosh(Half(1.0)) - std::acosh(1.0f)) <= threshold);\n  assert(std::abs(std::asin(Half(1.0)) - std::asin(1.0f)) <= threshold);\n  assert(std::abs(std::sinh(Half(1.0)) - std::sinh(1.0f)) <= threshold);\n  assert(std::abs(std::asinh(Half(1.0)) - std::asinh(1.0f)) <= threshold);\n  assert(std::abs(std::tan(Half(0.0)) - std::tan(0.0f)) <= threshold);\n  assert(std::abs(std::atan(Half(1.0)) - std::atan(1.0f)) <= threshold);\n  assert(std::abs(std::tanh(Half(1.0)) - std::tanh(1.0f)) <= threshold);\n  assert(std::abs(std::erf(Half(10.0)) - std::erf(10.0f)) <= threshold);\n  assert(std::abs(std::erfc(Half(10.0)) - std::erfc(10.0f)) <= threshold);\n  assert(std::abs(std::abs(Half(-3.0)) - std::abs(-3.0f)) <= threshold);\n  assert(std::abs(std::round(Half(2.3)) - std::round(2.3f)) <= threshold);\n  assert(\n      std::abs(std::pow(Half(2.0), Half(10.0)) - std::pow(2.0f, 10.0f)) <=\n      threshold);\n  assert(\n      std::abs(std::atan2(Half(7.0), Half(0.0)) - std::atan2(7.0f, 0.0f)) <=\n      threshold);\n#ifdef __APPLE__\n  // @TODO: can macos do implicit conversion of Half?\n  assert(\n      std::abs(std::isnan(static_cast<float>(Half(0.0))) - std::isnan(0.0f)) <=\n      threshold);\n  assert(\n      std::abs(std::isinf(static_cast<float>(Half(0.0))) - std::isinf(0.0f)) <=\n      threshold);\n#else\n  assert(std::abs(std::isnan(Half(0.0)) - std::isnan(0.0f)) <= threshold);\n  assert(std::abs(std::isinf(Half(0.0)) - std::isinf(0.0f)) <= threshold);\n#endif\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/ivalue_test.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/math_kernel_test.cpp",
        "functions": [
            "allClose(const at::Tensor& t1, const at::Tensor& t2, double rtol=1e-5, double atol=1e-8)",
            "{\n  int num_channels = 6;\n  int N = 2;\n  int H = 2, W = 2;\n  int HxW = H * W;\n\n  const auto input = randn({N, num_channels, H, W});\n  const auto weight = randn({num_channels});\n  const auto bias = randn({num_channels});\n  double eps = 1e-05;\n  for (bool undef_weight: {true, false}) {\n    for (int num_groups: {3, 6, 1}) {\n      Tensor undef;\n      auto out = at::native::native_group_norm(\n            input, undef_weight ? undef : weight, undef_weight ? undef : bias,\n            N, num_channels, HxW, num_groups, eps);\n      auto math_out = at::native::math_group_norm(\n            input, undef_weight ? undef : weight, undef_weight ? undef : bias,\n            N, num_channels, HxW, num_groups, eps);\n      ASSERT_ALLCLOSE_TOLERANCES(std::get<0>(out), std::get<0>(math_out), 1e-4, 1e-6);\n      ASSERT_ALLCLOSE_TOLERANCES(std::get<1>(out), std::get<1>(math_out), 1e-4, 1e-6);\n      ASSERT_ALLCLOSE_TOLERANCES(std::get<2>(out), std::get<2>(math_out), 1e-4, 1e-6);\n    }\n  }\n}",
            "{\n  const auto input = rand({20, 10, 10, 10});\n  const auto input_shape = input.sizes();\n  const auto input_ndim = input.dim();\n\n  double eps = 1e-05;\n  for (bool undef_weight: {true, false}) {\n    for (int normalized_size: {2, 3}) {\n      Tensor undef;\n      std::vector<int64_t> normalized_shape(normalized_size, 10);\n      const auto weight = rand(normalized_shape);\n      const auto bias = rand(normalized_shape);\n\n      auto out = at::native_layer_norm(\n            input, normalized_shape, undef_weight ? undef : weight, undef_weight ? undef : bias,\n            eps);\n      auto math_out = at::native::math_native_layer_norm(\n            input, normalized_shape, undef_weight ? undef : weight, undef_weight ? undef : bias,\n            eps);\n      ASSERT_ALLCLOSE_TOLERANCES(std::get<0>(out), std::get<0>(math_out), 1e-3, 1e-5);\n      ASSERT_ALLCLOSE_TOLERANCES(std::get<1>(out), std::get<1>(math_out), 1e-3, 1e-5);\n      ASSERT_ALLCLOSE_TOLERANCES(std::get<2>(out), std::get<2>(math_out), 1e-3, 1e-5);\n    }\n  }\n}",
            "{\n  const auto vec1 = arange(1., 4.);\n  const auto vec2 = arange(1., 3.);\n  const auto M = zeros({3, 2});\n\n  for (float beta: {1., 1.2, 0.}) {\n    // nans and infs are not propagated to the output when beta == 0\n    if (beta == 0) {\n      M[0][0] = std::numeric_limits<float>::infinity();\n      M[2][0] = std::numeric_limits<float>::quiet_NaN();\n    }\n    for (float alpha: {1., 2., 0.}) {\n      auto out = at::native::addr(M, vec1, vec2, beta, alpha);\n      auto math_out = at::native::math_addr(M, vec1, vec2, beta, alpha);\n      ASSERT_ALLCLOSE_TOLERANCES(out, math_out, 1e-4, 1e-6);\n    }\n  }\n}",
            "{\n  const auto input = rand({20, 10});\n  const auto grad_output = rand({20, 10});\n  auto out = at::native::silu_backward(grad_output, input);\n  auto math_out = at::native::math_silu_backward(grad_output, input);\n  ASSERT_ALLCLOSE_TOLERANCES(out, math_out, 1e-4, 1e-6);\n}",
            "{\n  auto x = rand({5, 8, 7});\n  for (int64_t dim = 0; dim < 3; ++dim) {\n    const int64_t start = 1, length = 4;\n    auto y_ref = x.narrow(dim, start, length);\n    auto y_test = at::native::narrow_copy_dense(x, dim, start, length);\n    ASSERT_ALLCLOSE_TOLERANCES(y_ref, y_test, 0, 0);\n  }\n}",
            "{\n  auto test_bmm = [](int64_t last_dim) {\n    auto x = rand({1, 4, 4}, at::kFloat);\n    auto y = rand({1, 4, last_dim}, at::kDouble);\n    EXPECT_THROW(auto z = at::bmm(x, y), std::exception);\n  };\n\n  test_bmm(5);\n  test_bmm(1000);\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/memory_format_test.cpp",
        "functions": [
            "{\n  for (auto size : sizes) {\n    Tensor t = at::rand(size);\n    for (auto memory_format : {at::MemoryFormat::ChannelsLast, at::MemoryFormat::Contiguous}) {\n      t.resize_(size, memory_format);\n      EXPECT_TRUE(t.suggest_memory_format() == memory_format);\n    }\n  }\n\n  Tensor t = at::rand({4, 1, 1, 1});\n  EXPECT_TRUE(t.suggest_memory_format() == at::MemoryFormat::Contiguous);\n  t.resize_({4, 1, 1, 1}, at::MemoryFormat::ChannelsLast);\n  // TODO: Should be able to handle this after accumulated permutation is implemented;\n  // Ambiguous case where we fallback to Contiguous;\n  // This should be `EXPECT_TRUE(t.suggest_memory_format() == at::MemoryFormat::ChannelsLast);`\n  EXPECT_TRUE(t.suggest_memory_format() == at::MemoryFormat::Contiguous);\n}",
            "{\n  Tensor t = at::rand({2, 3, 4, 5});\n  EXPECT_TRUE(t.suggest_memory_format() == at::MemoryFormat::Contiguous);\n  t.transpose_(1, 3);\n  EXPECT_TRUE(t.suggest_memory_format() != at::MemoryFormat::ChannelsLast);\n  t.transpose_(2, 3);\n  EXPECT_TRUE(t.suggest_memory_format() == at::MemoryFormat::ChannelsLast);\n  t = at::rand({2, 3, 4, 5});\n  t.transpose_(1, 2);\n  EXPECT_TRUE(t.suggest_memory_format() != at::MemoryFormat::ChannelsLast);\n  t = at::rand({2, 3, 4, 5});\n  t.transpose_(2, 3);\n  EXPECT_TRUE(t.suggest_memory_format() != at::MemoryFormat::ChannelsLast);\n\n  // corner cases:\n  t = at::rand({1, 4, 1, 4});\n  t.transpose_(1, 3);\n  EXPECT_TRUE(t.suggest_memory_format() != at::MemoryFormat::ChannelsLast);\n  t = at::rand({1, 4, 1, 4});\n  t.transpose_(1, 2);\n  EXPECT_TRUE(t.suggest_memory_format() != at::MemoryFormat::ChannelsLast);\n  t = at::rand({1, 4, 1, 4});\n  t.transpose_(2, 3);\n  EXPECT_TRUE(t.suggest_memory_format() != at::MemoryFormat::ChannelsLast);\n  t = at::rand({1, 4, 1, 4});\n  t.transpose_(2, 3);\n  t.transpose_(1, 2);\n  EXPECT_TRUE(t.suggest_memory_format() == at::MemoryFormat::ChannelsLast);\n\n  t = at::rand({1, 4, 4, 1});\n  t.transpose_(1, 3);\n  EXPECT_TRUE(t.suggest_memory_format() != at::MemoryFormat::ChannelsLast);\n  t = at::rand({1, 4, 4, 1});\n  t.transpose_(1, 2);\n  EXPECT_TRUE(t.suggest_memory_format() != at::MemoryFormat::ChannelsLast);\n  t = at::rand({1, 4, 4, 1});\n  t.transpose_(2, 3);\n  EXPECT_TRUE(t.suggest_memory_format() != at::MemoryFormat::ChannelsLast);\n  t = at::rand({1, 4, 4, 1});\n  t.transpose_(2, 3);\n  t.transpose_(1, 2);\n  EXPECT_TRUE(t.suggest_memory_format() == at::MemoryFormat::ChannelsLast);\n}",
            "void",
            "{\n  Tensor t = at::rand({4, 4, 4, 4});\n  sliceStepTwo(t, 1, MemoryFormat::Contiguous);\n  sliceStepTwo(t, 2, MemoryFormat::Contiguous);\n  sliceStepTwo(t, 3, MemoryFormat::Contiguous);\n\n  t = at::rand({4, 4, 4, 4});\n  sliceStepTwo(t, 2, MemoryFormat::Contiguous);\n  sliceStepTwo(t, 3, MemoryFormat::Contiguous);\n  sliceStepTwo(t, 1, MemoryFormat::Contiguous);\n\n  t = at::rand({4, 4, 4, 4});\n  t.resize_({4, 4, 4, 4}, at::MemoryFormat::ChannelsLast);\n  sliceStepTwo(t, 1, MemoryFormat::ChannelsLast);\n  sliceStepTwo(t, 2, MemoryFormat::ChannelsLast);\n  sliceStepTwo(t, 3, MemoryFormat::ChannelsLast);\n\n  t = at::rand({4, 4, 4, 4});\n  t.resize_({4, 4, 4, 4}, at::MemoryFormat::ChannelsLast);\n  sliceStepTwo(t, 2, MemoryFormat::ChannelsLast);\n  sliceStepTwo(t, 3, MemoryFormat::ChannelsLast);\n  sliceStepTwo(t, 1, MemoryFormat::ChannelsLast);\n\n  t = at::rand({4, 4, 1, 1});\n  sliceStepTwo(t, 1, MemoryFormat::Contiguous);\n  t = at::rand({4, 4, 1, 1});\n  t.resize_({4, 4, 1, 1}, at::MemoryFormat::ChannelsLast);\n  t = t.slice(1, 0, 3, 2);\n  EXPECT_TRUE(t.suggest_memory_format() == MemoryFormat::ChannelsLast);\n  t = t.slice(1, 0, 3, 2);\n  // TODO: Should be able to handle this after accumulated permutation is implemented;\n  // won't be able to tell how we ended up here\n  // [4, 1, 1, 4]@[4, 4, 4, 1] slice twice at dim3\n  // [4, 4, 1, 1]@[4, 1, 4, 4] slice twice at dim1\n  // EXPECT_TRUE(t.suggest_memory_format() == MemoryFormat::ChannelsLast);\n  EXPECT_TRUE(t.suggest_memory_format() == MemoryFormat::Contiguous);\n\n  t = at::rand({4, 1, 4, 4});\n  sliceStepTwo(t, 2, MemoryFormat::Contiguous);\n  sliceStepTwo(t, 3, MemoryFormat::Contiguous);\n  t = at::rand({4, 1, 4, 4});\n  t.resize_({4, 1, 4, 4}, at::MemoryFormat::ChannelsLast);\n  sliceStepTwo(t, 2, MemoryFormat::ChannelsLast);\n  sliceStepTwo(t, 3, MemoryFormat::ChannelsLast);\n\n  t = at::rand({4, 1, 1, 4});\n  sliceStepTwo(t, 3, MemoryFormat::Contiguous);\n  t = at::rand({4, 1, 1, 4});\n  t.resize_({4, 1, 1, 4}, at::MemoryFormat::ChannelsLast);\n  sliceStepTwo(t, 3, MemoryFormat::ChannelsLast);\n\n  t = at::rand({4, 1, 4, 1});\n  sliceStepTwo(t, 2, MemoryFormat::Contiguous);\n  t = at::rand({4, 1, 4, 1});\n  t.resize_({4, 1, 4, 1}, at::MemoryFormat::ChannelsLast);\n  sliceStepTwo(t, 2, MemoryFormat::ChannelsLast);\n}",
            "void",
            "{\n  Tensor t = at::rand({4, 4, 4, 4});\n  sliceFirst(t, 1, MemoryFormat::Contiguous);\n  sliceFirst(t, 2, MemoryFormat::Contiguous);\n  sliceFirst(t, 3, MemoryFormat::Contiguous);\n\n  t = at::rand({4, 4, 4, 4});\n  sliceFirst(t, 2, MemoryFormat::Contiguous);\n  sliceFirst(t, 3, MemoryFormat::Contiguous);\n  sliceFirst(t, 1, MemoryFormat::Contiguous);\n\n  t = at::rand({4, 4, 4, 4});\n  t.resize_({4, 4, 4, 4}, at::MemoryFormat::ChannelsLast);\n  sliceFirst(t, 1, MemoryFormat::ChannelsLast);\n  sliceFirst(t, 2, MemoryFormat::ChannelsLast);\n  sliceFirst(t, 3, MemoryFormat::ChannelsLast);\n\n  t = at::rand({4, 4, 4, 4});\n  t.resize_({4, 4, 4, 4}, at::MemoryFormat::ChannelsLast);\n  sliceFirst(t, 2, MemoryFormat::ChannelsLast);\n  sliceFirst(t, 3, MemoryFormat::ChannelsLast);\n  sliceFirst(t, 1, MemoryFormat::ChannelsLast);\n\n  t = at::rand({4, 4, 1, 1});\n  sliceFirst(t, 1, MemoryFormat::Contiguous);\n  t = at::rand({4, 4, 1, 1});\n  t.resize_({4, 4, 1, 1}, at::MemoryFormat::ChannelsLast);\n  sliceFirst(t, 1, MemoryFormat::ChannelsLast);\n\n  t = at::rand({4, 1, 4, 4});\n  sliceFirst(t, 2, MemoryFormat::Contiguous);\n  sliceFirst(t, 3, MemoryFormat::Contiguous);\n  t = at::rand({4, 1, 4, 4});\n  t.resize_({4, 1, 4, 4}, at::MemoryFormat::ChannelsLast);\n  sliceFirst(t, 2, MemoryFormat::ChannelsLast);\n  sliceFirst(t, 3, MemoryFormat::ChannelsLast);\n\n  t = at::rand({4, 1, 1, 4});\n  sliceFirst(t, 3, MemoryFormat::Contiguous);\n  t = at::rand({4, 1, 1, 4});\n  t.resize_({4, 1, 1, 4}, at::MemoryFormat::ChannelsLast);\n  sliceFirst(t, 3, MemoryFormat::ChannelsLast);\n\n  t = at::rand({4, 1, 4, 1});\n  sliceFirst(t, 2, MemoryFormat::Contiguous);\n  t = at::rand({4, 1, 4, 1});\n  t.resize_({4, 1, 4, 1}, at::MemoryFormat::ChannelsLast);\n  // TODO: Should be able to handle this after accumulated permutation is implemented;\n  // [4, 1, 4, 1]@[4, 1, 1, 1] after slice becomes [4, 1, 1, 1]@[4, 1, 1, 1]\n  // sliceFirst(t, 2, MemoryFormat::ChannelsLast);\n  sliceFirst(t, 2, MemoryFormat::Contiguous);\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/memory_overlapping_test.cpp",
        "functions": [
            "{\n  for (auto size : sizes) {\n    Tensor t = at::ones({1}).expand(size);\n    EXPECT_FALSE(t.is_contiguous());\n    EXPECT_FALSE(t.is_non_overlapping_and_dense());\n  }\n}",
            "{\n  for (auto size : sizes) {\n    Tensor t = at::tensor(1).expand(size);\n    EXPECT_FALSE(t.is_contiguous());\n    EXPECT_FALSE(t.is_non_overlapping_and_dense());\n  }\n}",
            "{\n  for (auto size : sizes) {\n    Tensor t = at::rand(size).transpose(1, 2).transpose(0, 2);\n    if (!t.is_contiguous()) {\n      EXPECT_TRUE(t.is_non_overlapping_and_dense());\n    }\n  }\n}",
            "{\n  for (auto size : sizes) {\n    Tensor t = at::rand(size).transpose(1, 2).transpose(0, 2);\n    if (!t.is_contiguous()) {\n      for (auto size_to_add : {1, 2, 3, 4}) {\n        auto transpose_size = t.sizes().vec();\n        std::vector<int64_t> expanded_size(transpose_size);\n        expanded_size.insert(expanded_size.begin(), size_to_add);\n        auto expanded = t.expand(expanded_size);\n        EXPECT_FALSE(t.is_contiguous());\n        if (size_to_add == 1) {\n          EXPECT_TRUE(expanded.is_non_overlapping_and_dense());\n        } else {\n          EXPECT_FALSE(expanded.is_non_overlapping_and_dense());\n        }\n      }\n    }\n  }\n}",
            "{\n  for (auto size : sizes) {\n    Tensor t = at::rand(size);\n    EXPECT_TRUE(t.is_contiguous());\n    EXPECT_TRUE(t.is_non_overlapping_and_dense());\n  }\n}",
            "{\n  for (auto size : sizes) {\n    Tensor t = at::rand(size);\n    for (auto size_to_add : {1, 2, 3, 4}) {\n      std::vector<int64_t> expanded_size(size);\n      expanded_size.insert(expanded_size.begin(), size_to_add);\n      auto expanded = t.expand(expanded_size);\n      EXPECT_TRUE(t.is_contiguous());\n      EXPECT_TRUE(t.is_non_overlapping_and_dense());\n    }\n  }\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/mobile_memory_cleanup.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/native_test.cpp",
        "functions": [
            "requireEqualTensorList(TensorList t1, TensorList t2)",
            "TestSplit(TensorOptions T, Tensor& t)",
            "TestChunk(TensorOptions T, Tensor& t)",
            "_test_stack(TensorList inputs, int64_t dim, StackFunc stack_func)",
            "TestStack(TensorOptions T, Tensor& t)",
            "TestSize(TensorOptions T, Tensor& t)",
            "TestMatmul(TensorOptions T, Tensor& t, TensorOptions AccT)",
            "TestStandardGammaGrad(TensorOptions T, Tensor& t)",
            "TestWhere(TensorOptions T, Tensor& t)",
            "test(TensorOptions T, TensorOptions AccT)",
            "{\n  manual_seed(123);\n\n  test(at::device(kCPU).dtype(kFloat),\n       at::device(kCPU).dtype(kDouble));\n}",
            "{\n  manual_seed(123);\n\n  if (at::hasCUDA()) {\n    test(at::device(kCUDA).dtype(kFloat),\n         at::device(kCUDA).dtype(kDouble));\n  }\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/pow_test.cpp",
        "functions": [
            "{\n  tensor_pow_scalar(ints, non_neg_ints, kInt, kInt);\n  tensor_pow_scalar(ints, non_neg_longs, kInt, kInt);\n  tensor_pow_scalar(ints, floats, kInt, kFloat);\n  tensor_pow_scalar(ints, doubles, kInt, kDouble);\n}",
            "{\n  tensor_pow_scalar(longs, non_neg_ints, kLong, kLong);\n  tensor_pow_scalar(longs, non_neg_longs, kLong, kLong);\n  tensor_pow_scalar(longs, floats, kLong, kFloat);\n  tensor_pow_scalar(longs, doubles, kLong, kDouble);\n}",
            "{\n  tensor_pow_scalar(floats, ints, kFloat, kDouble);\n  tensor_pow_scalar(floats, longs, kFloat, kDouble);\n  tensor_pow_scalar(floats, floats, kFloat, kFloat);\n  tensor_pow_scalar(floats, doubles, kFloat, kDouble);\n}",
            "{\n  tensor_pow_scalar(doubles, ints, kDouble, kDouble);\n  tensor_pow_scalar(doubles, longs, kDouble, kDouble);\n  tensor_pow_scalar(doubles, floats, kDouble, kDouble);\n  tensor_pow_scalar(doubles, doubles, kDouble, kDouble);\n}",
            "{\n  scalar_pow_tensor(ints, c10::kInt, ints, c10::kInt);\n  scalar_pow_tensor(ints, c10::kInt, longs, c10::kLong);\n  scalar_pow_tensor(ints, c10::kInt, floats, c10::kFloat);\n  scalar_pow_tensor(ints, c10::kInt, doubles, c10::kDouble);\n}",
            "{\n  scalar_pow_tensor(longs, c10::kLong, longs, c10::kLong);\n  scalar_pow_tensor(longs, c10::kLong, floats, c10::kFloat);\n  scalar_pow_tensor(longs, c10::kLong, doubles, c10::kDouble);\n}",
            "{\n  scalar_pow_tensor(floats, c10::kFloat, floats, c10::kFloat);\n  scalar_pow_tensor(floats, c10::kFloat, doubles, c10::kDouble);\n}",
            "{\n  scalar_pow_tensor(doubles, c10::kDouble, doubles, c10::kDouble);\n}",
            "{\n  tensor_pow_tensor(ints, c10::kInt, ints, c10::kInt);\n}",
            "{\n  tensor_pow_tensor(longs, c10::kLong, longs, c10::kLong);\n}",
            "{\n  tensor_pow_tensor(floats, c10::kFloat, floats, c10::kFloat);\n}",
            "{\n  tensor_pow_tensor(doubles, c10::kDouble, doubles, c10::kDouble);\n}",
            "{\n  test_pow_one(longs);\n  test_pow_one(ints);\n\n  test_squared(longs);\n  test_squared(ints);\n\n  test_cubed(longs);\n  test_cubed(ints);\n\n  test_inverse(longs);\n  test_inverse(ints);\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/quantized_test.cpp",
        "functions": [
            "{\n  auto num_elements = 10;\n  Tensor r = at::ones({num_elements});\n  const double scale = 1.0;\n  const int64_t zero_point = 2;\n  const Tensor qr = at::quantize_per_tensor(r, scale, zero_point, kQUInt8);\n  ASSERT_EQ(qr.q_scale(), scale);\n  ASSERT_EQ(qr.q_zero_point(), zero_point);\n  ASSERT_TRUE(qr.is_quantized());\n  ASSERT_FALSE(r.is_quantized());\n\n  // int_repr\n  Tensor int_repr = qr.int_repr();\n  auto* int_repr_data = int_repr.data_ptr<uint8_t>();\n  for (auto i = 0; i < num_elements; ++i) {\n    ASSERT_EQ(int_repr_data[i], 3);\n  }\n\n  // Check for correct quantization\n  auto r_data = r.data_ptr<float>();\n  auto qr_data = qr.data_ptr<quint8>();\n  for (auto i = 0; i < num_elements; ++i) {\n    ASSERT_EQ(\n        native::quantize_val<quint8>(scale, zero_point, r_data[i]).val_,\n        qr_data[i].val_);\n  }\n\n  // Check for correct dequantization\n  Tensor rqr = qr.dequantize();\n  auto rqr_data = rqr.data_ptr<float>();\n  for (auto i = 0; i < num_elements; ++i) {\n    ASSERT_EQ(r_data[i], rqr_data[i]);\n  }\n  for (auto i = 0; i < num_elements; ++i) {\n    ASSERT_EQ(\n        r_data[i],\n        native::dequantize_val(qr.q_scale(), qr.q_zero_point(), qr_data[i]));\n  }\n\n  // Check for correct requantization\n  double new_scale = 2.0;\n  int64_t new_zero_point = 1;\n  Tensor reqr = at::quantize_per_tensor(r, new_scale, new_zero_point, kQInt8);\n  auto reqr_data = reqr.data_ptr<qint8>();\n  for (auto i = 0; i < num_elements; ++i) {\n    reqr_data[i].val_ =\n        native::requantize_val<quint8, qint8>(\n            scale, zero_point, new_scale, new_zero_point, qr_data[i])\n            .val_;\n    const qint8 expected =\n        native::quantize_val<qint8>(new_scale, new_zero_point, rqr_data[i]);\n    ASSERT_EQ(expected.val_, reqr_data[i].val_);\n  }\n}",
            "{\n  // We assume that quantization is defined as:\n  //   qx = clamp(zero_point + round(x / scale))\n  // If the zero_point is added before rounding, the result will be wrong.\n  int32_t zero_point = 5;\n  std::vector<float> x_values{\n      -5.5, -4.5, -3.5, -2.5, -1.5, -0.5, 0.5, 1.5, 2.5, 3.5, 4.5, 5.5};\n  std::vector<uint8_t> qx_expect{\n      0, 1, 1, 3, 3, 5, 5, 7, 7, 9, 9, 11}; // scale = 1.0\n\n  Tensor x = from_blob(x_values.data(), x_values.size());\n  Tensor qx = at::quantize_per_tensor(x, /*scale=*/1.0, zero_point, kQUInt8);\n\n  auto qx_data = qx.data_ptr<quint8>();\n  for (size_t idx = 0; idx < x_values.size(); ++idx) {\n    ASSERT_EQ(qx_expect[idx], qx_data[idx].val_)\n        << \"Tie breaking during rounding element \" << idx << \" failed!\";\n  }\n}",
            "{\n  Tensor r = at::ones({1});\n  const float scale = 1;\n  const int32_t zero_point = 2;\n  Tensor qr = at::quantize_per_tensor(r, scale, zero_point, kQUInt8);\n  ASSERT_EQ(r.item().to<float>(), qr.item().to<float>());\n}",
            "{\n  float scale = 0.5;\n  int zero_point = 10;\n  int val = 100;\n  int numel = 10;\n  Tensor q = at::_empty_affine_quantized(\n      {numel}, at::device(at::kCPU).dtype(kQUInt8), scale, zero_point);\n  // Assigning to QTensor\n  auto* q_data = q.data_ptr<quint8>();\n  for (int i = 0; i < numel; ++i) {\n    q_data[i].val_ = val;\n  }\n\n  // dequantize\n  auto r = q.dequantize();\n  auto* r_data = r.data_ptr<float>();\n  for (int i = 0; i < numel; ++i) {\n    ASSERT_EQ(r_data[i], (val - zero_point) * scale);\n  }\n}",
            "{\n  int numel = 10;\n  auto scales = rand({numel}).toType(kDouble);\n  auto zero_points = randint(10, {10}).toType(kLong);\n  int val = 100;\n  int ch_axis = 0;\n  Tensor q = at::_empty_per_channel_affine_quantized(\n      {numel},\n      scales,\n      zero_points,\n      ch_axis,\n      at::device(at::kCPU).dtype(kQUInt8));\n  // Assigning to QTensor\n  auto* q_data = q.data_ptr<quint8>();\n  for (int i = 0; i < numel; ++i) {\n    q_data[i].val_ = val;\n  }\n\n  // dequantize\n  auto r = q.dequantize();\n  auto* r_data = r.data_ptr<float>();\n  for (int i = 0; i < numel; ++i) {\n    ASSERT_EQ(\n        r_data[i],\n        (val - zero_points[i].item().to<int>()) * scales[i].item().to<float>());\n  }\n}",
            "{\n  int C = 64, H = 10, W = 10;\n  auto scales = rand({C}).toType(kDouble);\n  auto zero_points = randint(10, {C}).toType(kLong);\n  int ch_axis = 1;\n  // create 4d tensor where each H x W image is a range(0, H*W)\n  Tensor tensor = at::empty({1, C, H, W}, at::device(at::kCPU).dtype(kFloat));\n  auto* tensor_data = tensor.data_ptr<float>();\n  for (int c = 0, i = 0; c < C; ++c) {\n    for (int e = 0; e < H * W; ++e, ++i) {\n      tensor_data[i] = e;\n    }\n  }\n  // quantize and check values\n  Tensor q = at::native::quantize_per_channel_cpu(\n      tensor, scales, zero_points, ch_axis, kQUInt8);\n  auto* q_data = (uint8_t*)q.data_ptr<quint8>();\n  for (int c = 0, i = 0; c < C; ++c) {\n    float inv_scale = 1.0f / static_cast<float>(scales[c].item<double>());\n    int64_t zero_point = zero_points[c].item<int64_t>();\n    for (int e = 0; e < H * W; ++e, ++i) {\n      // downsize qval to 255 if val is greater than max uint8_t value\n      int qval = std::min<int>(zero_point + std::nearbyint(e * inv_scale), 255);\n      ASSERT_EQ((int)q_data[i], qval);\n    }\n  }\n}",
            "{\n  int C = 64, H = 10, W = 10;\n  auto scales = rand({C}).toType(kDouble);\n  auto zero_points = randint(10, {C}).toType(kLong);\n  int ch_axis = 1;\n  // create 4d tensor where each H x W image is a range(0, H*W)\n  Tensor tensor = at::empty(\n      {1, C, H, W},\n      at::device(at::kCPU).dtype(kFloat).memory_format(\n          at::MemoryFormat::ChannelsLast));\n  auto* tensor_data = tensor.data_ptr<float>();\n  for (int e = 0, i = 0; e < H * W; ++e) {\n    for (int c = 0; c < C; ++c, ++i) {\n      tensor_data[i] = e;\n    }\n  }\n\n  // quantize and check values\n  Tensor q = at::native::quantize_per_channel_cpu(\n      tensor, scales, zero_points, ch_axis, kQUInt8);\n  auto* q_data = (uint8_t*)q.data_ptr<quint8>();\n  for (int e = 0, i = 0; e < H * W; ++e) {\n    for (int c = 0; c < C; ++c, ++i) {\n      float inv_scale = 1.0f / static_cast<float>(scales[c].item<double>());\n      int64_t zero_point = zero_points[c].item<int64_t>();\n      // downsize qval to 255 if val is greater than max uint8_t value\n      int qval = std::min<int>(zero_point + std::nearbyint(e * inv_scale), 255);\n      ASSERT_EQ((int)q_data[i], qval);\n    }\n  }\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/reduce_ops_test.cpp",
        "functions": [
            "{\n  const int W = 10;\n  const int H = 10;\n  if (hasCUDA()) {\n    for (const auto dtype : {kHalf, kFloat, kDouble, kShort, kInt, kLong}) {\n      auto a = at::rand({H, W}, TensorOptions(kCUDA).dtype(at::kHalf));\n      ASSERT_FLOAT_EQ(\n        a.amax(c10::IntArrayRef{0, 1}).item<double>(),\n        a.max().item<double>()\n      );\n      ASSERT_FLOAT_EQ(\n        a.amin(c10::IntArrayRef{0, 1}).item<double>(),\n        a.min().item<double>()\n      );\n    }\n  }\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/scalar_tensor_test.cpp",
        "functions": [
            "require_equal_size_dim(const Tensor &lhs, const Tensor &rhs)",
            "should_expand(const IntArrayRef &from_size, const IntArrayRef &to_size)",
            "test(DeprecatedTypeProperties &T)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/scalar_test.cpp",
        "functions": [
            "test_overflow()",
            "{\n  manual_seed(123);\n\n  Scalar what = 257;\n  Scalar bar = 3.0;\n  Half h = bar.toHalf();\n  Scalar h2 = h;\n  cout << \"H2: \" << h2.toDouble() << \" \" << what.toFloat() << \" \"\n       << bar.toDouble() << \" \" << what.isIntegral(false) << \"\\n\";\n  auto gen = at::detail::getDefaultCPUGenerator();\n  {\n    // See Note [Acquire lock when using random generators]\n    std::lock_guard<std::mutex> lock(gen.mutex());\n    ASSERT_NO_THROW(gen.set_current_seed(std::random_device()()));\n  }\n  auto&& C = at::globalContext();\n  if (at::hasCUDA()) {\n    auto t2 = zeros({4, 4}, at::kCUDA);\n    cout << &t2 << \"\\n\";\n  }\n  auto t = ones({4, 4});\n\n  auto wha2 = zeros({4, 4}).add(t).sum();\n  ASSERT_EQ(wha2.item<double>(), 16.0);\n\n  ASSERT_EQ(t.sizes()[0], 4);\n  ASSERT_EQ(t.sizes()[1], 4);\n  ASSERT_EQ(t.strides()[0], 4);\n  ASSERT_EQ(t.strides()[1], 1);\n\n  TensorOptions options = dtype(kFloat);\n  Tensor x = randn({1, 10}, options);\n  Tensor prev_h = randn({1, 20}, options);\n  Tensor W_h = randn({20, 20}, options);\n  Tensor W_x = randn({20, 10}, options);\n  Tensor i2h = at::mm(W_x, x.t());\n  Tensor h2h = at::mm(W_h, prev_h.t());\n  Tensor next_h = i2h.add(h2h);\n  next_h = next_h.tanh();\n\n  ASSERT_ANY_THROW(Tensor{}.item());\n\n  test_overflow();\n\n  if (at::hasCUDA()) {\n    auto r = next_h.to(at::Device(kCUDA), kFloat, /*non_blocking=*/ false, /*copy=*/ true);\n    ASSERT_TRUE(r.to(at::Device(kCPU), kFloat, /*non_blocking=*/ false, /*copy=*/ true).equal(next_h));\n  }\n  ASSERT_NO_THROW(randn({10, 10, 2}, options));\n\n  // check Scalar.toTensor on Scalars backed by different data types\n  ASSERT_EQ(scalar_to_tensor(bar).scalar_type(), kDouble);\n  ASSERT_EQ(scalar_to_tensor(what).scalar_type(), kLong);\n  ASSERT_EQ(scalar_to_tensor(ones({}).item()).scalar_type(), kDouble);\n\n  if (x.scalar_type() != ScalarType::Half) {\n    AT_DISPATCH_ALL_TYPES(x.scalar_type(), \"foo\", [&] {\n      scalar_t s = 1;\n      std::stringstream ss;\n      ASSERT_NO_THROW(\n          ss << \"hello, dispatch\" << x.toString() << s << \"\\n\");\n      auto data = (scalar_t*)x.data_ptr();\n      (void)data;\n    });\n  }\n\n  // test direct C-scalar type conversions\n  {\n    auto x = ones({1, 2}, options);\n    ASSERT_ANY_THROW(x.item<float>());\n  }\n  auto float_one = ones({}, options);\n  ASSERT_EQ(float_one.item<float>(), 1);\n  ASSERT_EQ(float_one.item<int32_t>(), 1);\n  ASSERT_EQ(float_one.item<at::Half>(), 1);\n}",
            "{\n  Scalar int_scalar = 257;\n  Scalar float_scalar = 3.0;\n  Scalar complex_scalar = c10::complex<double>(2.3, 3.5);\n\n  ASSERT_EQ(int_scalar.conj().toInt(), 257);\n  ASSERT_EQ(float_scalar.conj().toDouble(), 3.0);\n  ASSERT_EQ(complex_scalar.conj().toComplexDouble(), c10::complex<double>(2.3, -3.5));\n}",
            "{\n  ASSERT_FALSE(Scalar(1.0).equal(false));\n  ASSERT_FALSE(Scalar(1.0).equal(true));\n  ASSERT_FALSE(Scalar(true).equal(1.0));\n  ASSERT_TRUE(Scalar(true).equal(true));\n\n  ASSERT_TRUE(Scalar(c10::complex<double>{2.0, 5.0}).equal(c10::complex<double>{2.0, 5.0}));\n  ASSERT_TRUE(Scalar(c10::complex<double>{2.0, 0}).equal(2.0));\n  ASSERT_TRUE(Scalar(c10::complex<double>{2.0, 0}).equal(2));\n\n  ASSERT_TRUE(Scalar(2.0).equal(c10::complex<double>{2.0, 0.0}));\n  ASSERT_FALSE(Scalar(2.0).equal(c10::complex<double>{2.0, 4.0}));\n  ASSERT_FALSE(Scalar(2.0).equal(3.0));\n  ASSERT_TRUE(Scalar(2.0).equal(2));\n\n  ASSERT_TRUE(Scalar(2).equal(c10::complex<double>{2.0, 0}));\n  ASSERT_TRUE(Scalar(2).equal(2));\n  ASSERT_TRUE(Scalar(2).equal(2.0));\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/tensor_interop_test.cpp",
        "functions": [
            "{\n  caffe2::Tensor c2_tensor(caffe2::CPU);\n  c2_tensor.Resize(4, 4);\n  auto data = c2_tensor.mutable_data<int64_t>();\n  for (int64_t i = 0; i < 16; i++) {\n    data[i] = i;\n  }\n  at::Tensor at_tensor(c2_tensor);\n\n  auto it = at_tensor.data_ptr<int64_t>();\n  for (int64_t i = 0; i < 16; i++) {\n    ASSERT_EQ(it[i], i);\n  }\n}",
            "{\n  caffe2::Tensor c2_tensor = caffe2::empty({4, 4}, at::kLong);\n  auto data = c2_tensor.mutable_data<int64_t>();\n  for (int64_t i = 0; i < 16; i++) {\n    data[i] = i;\n  }\n  at::Tensor at_tensor(c2_tensor);\n\n  auto it = at_tensor.data_ptr<int64_t>();\n  for (int64_t i = 0; i < 16; i++) {\n    ASSERT_EQ(it[i], i);\n  }\n}",
            "{\n  caffe2::Tensor c2_tensor = caffe2::empty({4, 4}, at::kLong);\n  int64_t buf[16];\n  for (int64_t i = 0; i < 16; i++) {\n    buf[i] = i;\n  }\n  c2_tensor.ShareExternalPointer(buf, 16 * sizeof(int64_t));\n\n  // If the buffer is allocated externally, we can still pass tensor around,\n  // but we can't resize its storage using PT APIs\n  at::Tensor at_tensor(c2_tensor);\n  at_tensor.permute({1, 0});\n  at_tensor.permute({1, 0});\n  auto it = at_tensor.data_ptr<int64_t>();\n  for (int64_t i = 0; i < 16; i++) {\n    ASSERT_EQ(it[i], i);\n  }\n  ASSERT_FALSE(at_tensor.storage().resizable());\n  ASSERT_ANY_THROW(at_tensor.resize_({7,7}));\n}",
            "{\n  caffe2::Tensor c2_tensor(caffe2::CPU);\n  c2_tensor.Resize(3, 3);\n  auto data = c2_tensor.mutable_data<int64_t>();\n  for (int64_t i = 0; i < 9; i++) {\n    data[i] = i;\n  }\n  at::Tensor at_tensor(c2_tensor);\n\n  ASSERT_EQ(at::sum(at_tensor).item<int64_t>(), 36);\n}",
            "{\n  // These APIs for partially initialized tensors should go away soon, in the\n  // meantime ensure they are caught\n  {\n    // no dtype, no storage\n    caffe2::Tensor c2_tensor(caffe2::CPU);\n    ASSERT_ANY_THROW(at::Tensor at_tensor(c2_tensor));\n  }\n  {\n    // storage, no dtype\n    caffe2::Tensor c2_tensor(caffe2::CPU);\n    c2_tensor.Resize(4,4);\n    ASSERT_ANY_THROW(at::Tensor at_tensor(c2_tensor));\n  }\n  {\n    // dtype, no storage\n    caffe2::Tensor c2_tensor(caffe2::CPU);\n    c2_tensor.Resize(4,4);\n    c2_tensor.mutable_data<float>();\n    c2_tensor.FreeMemory();\n    ASSERT_ANY_THROW(at::Tensor at_tensor(c2_tensor));\n  }\n}",
            "{\n  caffe2::Tensor c2_tensor = caffe2::empty({5, 5}, at::kFloat);\n  auto data = c2_tensor.mutable_data<float>();\n  for (int64_t i = 0; i < 25; i++) {\n    data[i] = 0;\n  }\n\n  at::Tensor at_tensor(c2_tensor);\n\n  // change is visible\n  at_tensor[0][0] = 123;\n  ASSERT_EQ(c2_tensor.mutable_data<float>()[0], 123);\n\n  // resize PT tensor in smaller direction - storage is preserved\n  at_tensor.resize_({4, 4});\n  c2_tensor.mutable_data<float>()[1] = 234;\n  ASSERT_EQ(at_tensor[0][1].item().to<float>(), 234);\n\n  // resize PT tensor in larger direction - storage is preserved\n  at_tensor.resize_({6, 6});\n  c2_tensor.mutable_data<float>()[2] = 345;\n  ASSERT_EQ(at_tensor[0][2].item().to<float>(), 345);\n  ASSERT_EQ(c2_tensor.sizes()[0], 6);\n  ASSERT_EQ(c2_tensor.sizes()[1], 6);\n\n  // resize Caffe2 tensor - semantics are to NOT preserve the data, but the\n  // TensorImpl is still shared\n  c2_tensor.Resize(7, 7);\n  c2_tensor.mutable_data<float>()[3] = 456;\n  ASSERT_EQ(at_tensor[0][3].item().to<float>(), 456);\n  ASSERT_EQ(at_tensor.sizes()[0], 7);\n  ASSERT_EQ(at_tensor.sizes()[1], 7);\n}",
            "{\n  caffe2::Workspace workspace;\n  caffe2::NetDef net;\n\n  auto at_tensor_a = at::ones({5, 5}, at::dtype(at::kFloat));\n  auto at_tensor_b = at::ones({5, 5}, at::dtype(at::kFloat));\n  auto at_tensor_c = at::ones({5, 5}, at::dtype(at::kFloat));\n\n  auto* c2_tensor_a = BlobSetTensor(workspace.CreateBlob(\"a\"), caffe2::Tensor(at_tensor_a));\n  auto* c2_tensor_b = BlobSetTensor(workspace.CreateBlob(\"b\"), caffe2::Tensor(at_tensor_b));\n\n  // Test Alias\n  {\n    caffe2::Tensor c2_tensor_from_aten(at_tensor_c);\n    BlobSetTensor(workspace.CreateBlob(\"c\"), c2_tensor_from_aten.Alias());\n  }\n\n  {\n    auto op = net.add_op();\n    op->set_type(\"Sum\");\n    op->add_input(\"a\");\n    op->add_input(\"b\");\n    op->add_input(\"c\");\n    op->add_output(\"d\");\n  }\n\n  workspace.RunNetOnce(net);\n\n  auto result = XBlobGetMutableTensor(workspace.CreateBlob(\"d\"), {5, 5}, at::kCPU);\n\n  auto it = result.data<float>();\n  for (int64_t i = 0; i < 25; i++) {\n    ASSERT_EQ(it[i], 3.0);\n  }\n  at::Tensor at_result(result);\n  ASSERT_EQ(at::sum(at_result).item<float>(), 75);\n}",
            "{\n  caffe2::Workspace workspace;\n  caffe2::NetDef net;\n\n  auto at_tensor_a = at::ones({5, 5}, at::dtype(at::kFloat));\n  auto at_tensor_b = at_tensor_a.view({5, 5});\n\n  auto* c2_tensor_a = BlobSetTensor(workspace.CreateBlob(\"a\"), caffe2::Tensor(at_tensor_a));\n  auto* c2_tensor_b = BlobSetTensor(workspace.CreateBlob(\"b\"), caffe2::Tensor(at_tensor_b));\n\n  {\n    auto op = net.add_op();\n    op->set_type(\"Add\");\n    op->add_input(\"a\");\n    op->add_input(\"b\");\n    op->add_output(\"c\");\n  }\n\n  workspace.RunNetOnce(net);\n\n  auto result = XBlobGetMutableTensor(workspace.CreateBlob(\"c\"), {5, 5}, at::kCPU);\n  auto it = result.data<float>();\n  for (int64_t i = 0; i < 25; i++) {\n    ASSERT_EQ(it[i], 2.0);\n  }\n  at::Tensor at_result(result);\n  ASSERT_EQ(at::sum(at_result).item<float>(), 50);\n}",
            "{\n  auto at_tensor_a = at::ones({5, 5}, at::dtype(at::kFloat));\n  auto at_tensor_b = at_tensor_a.view({25});\n\n  caffe2::Tensor c2_tensor_a(at_tensor_a);\n  caffe2::Tensor c2_tensor_b(at_tensor_b);\n\n  // change is visible everywhere\n  c2_tensor_a.mutable_data<float>()[1] = 123;\n  ASSERT_EQ(c2_tensor_b.mutable_data<float>()[1], 123);\n  ASSERT_EQ(at_tensor_a[0][1].item().to<float>(), 123);\n  ASSERT_EQ(at_tensor_b[1].item().to<float>(), 123);\n}",
            "{\n  auto at_tensor = at::ones({5, 5}, at::dtype(at::kFloat));\n\n  caffe2::Tensor c2_tensor(at_tensor);\n\n  // change is visible\n  c2_tensor.mutable_data<float>()[0] = 123;\n  ASSERT_EQ(at_tensor[0][0].item().to<float>(), 123);\n\n  // resize PT tensor in smaller direction - storage is preserved\n  at_tensor.resize_({4, 4});\n  c2_tensor.mutable_data<float>()[1] = 234;\n  ASSERT_EQ(at_tensor[0][1].item().to<float>(), 234);\n\n  // resize PT tensor in larger direction - storage is preserved\n  at_tensor.resize_({6, 6});\n  c2_tensor.mutable_data<float>()[2] = 345;\n  ASSERT_EQ(at_tensor[0][2].item().to<float>(), 345);\n  ASSERT_EQ(c2_tensor.sizes()[0], 6);\n  ASSERT_EQ(c2_tensor.sizes()[1], 6);\n\n  // resize Caffe2 tensor - semantics are to NOT preserve the data, but the\n  // TensorImpl is still shared\n  c2_tensor.Resize(7, 7);\n  c2_tensor.mutable_data<float>()[3] = 456;\n  ASSERT_EQ(at_tensor[0][3].item().to<float>(), 456);\n  ASSERT_EQ(at_tensor.sizes()[0], 7);\n  ASSERT_EQ(at_tensor.sizes()[1], 7);\n}",
            "{\n  auto at_tensor = at::ones({5, 5}, at::dtype(at::kFloat)).t();\n  ASSERT_ANY_THROW(caffe2::Tensor c2_tensor(at_tensor));\n  // but calling contiguous is fine\n  caffe2::Tensor c2_tensor(at_tensor.contiguous());\n  for (int64_t i = 0; i < 25; i++) {\n    ASSERT_EQ(c2_tensor.data<float>()[i], 1.0);\n  }\n}",
            "{\n  auto at_tensor = at::zeros({2, 5}, at::dtype(at::kFloat));\n  caffe2::Tensor c2_tensor(at_tensor);\n  ASSERT_EQ(c2_tensor.sizes()[0], 2);\n  ASSERT_EQ(c2_tensor.sizes()[1], 5);\n\n  c2_tensor.mutable_data<float>()[1] = 234;\n  ASSERT_EQ(at_tensor[0][1].item().to<float>(), 234);\n\n  at_tensor.t_();\n  ASSERT_EQ(c2_tensor.sizes()[0], 5);\n  ASSERT_EQ(c2_tensor.sizes()[1], 2);\n  // This is BROKEN situation, however checking is_contiguous on every data\n  // access is expensive. We rely on user to not do crazy stuff.\n  ASSERT_EQ(at_tensor[1][0].item().to<float>(), 234);\n  ASSERT_EQ(c2_tensor.data<float>()[1], 234);\n}",
            "{\n  at::Tensor at_tensor =\n      at::empty({2, 3}, at::dtype<float>().layout(at::kSparse));\n  ASSERT_TRUE(at_tensor.is_sparse());\n  ASSERT_ANY_THROW(caffe2::Tensor c2_tensor(at_tensor));\n}",
            "{\n  caffe2::Tensor c2_tensor = caffe2::empty({1}, at::dtype<std::string>());\n  auto data = c2_tensor.mutable_data<std::string>();\n  *data = \"test\";\n  ASSERT_ANY_THROW(at::Tensor at_tensor(c2_tensor));\n}",
            "{\n  caffe2::Tensor c2_tensor;\n  ASSERT_FALSE(c2_tensor.defined());\n  at::Tensor at_tensor(c2_tensor);\n  ASSERT_FALSE(at_tensor.defined());\n}",
            "{\n  at::Tensor at_tensor;\n  ASSERT_FALSE(at_tensor.defined());\n  caffe2::Tensor c2_tensor(at_tensor);\n  ASSERT_FALSE(c2_tensor.defined());\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/tensor_iterator_test.cpp",
        "functions": [
            "{\n  if (!at::hasCUDA()) return;\n  Tensor out;\n  auto x = at::randn({5, 5}, kCUDA);\n  auto y = at::ones(1, kCPU).squeeze();\n  auto iter = TensorIterator::binary_op(out, x, y);\n  EXPECT_TRUE(iter.device(0).is_cuda()) << \"result should be CUDA\";\n  EXPECT_TRUE(iter.device(1).is_cuda()) << \"x should be CUDA\";\n  EXPECT_TRUE(iter.device(2).is_cpu()) << \"y should be CPU\";\n}",
            "{\n  if (!at::hasCUDA()) return;\n  Tensor out = at::empty({5, 5}, kCUDA);\n  auto x = at::ones(1, kCPU).squeeze();\n  auto y = at::ones(1, kCPU).squeeze();\n  ASSERT_ANY_THROW(TensorIterator::binary_op(out, x, y));\n}",
            "{\n  if (!at::hasCUDA()) return;\n  Tensor out;\n  auto x = at::randn({5, 5}, kCUDA);\n  auto y = at::ones({5}, kCPU);\n  ASSERT_ANY_THROW(TensorIterator::binary_op(out, x, y));\n}",
            "random_tensor_for_type(at::ScalarType scalar_type)",
            "{\n  std::thread::id thread_id = std::this_thread::get_id();\n  Tensor out;\n  auto x = at::zeros({50000}, at::TensorOptions(kCPU).dtype(kInt));\n  auto iter = TensorIterator::unary_op(out, x);\n  at::native::cpu_serial_kernel(iter, [=](int a) -> int {\n    std::thread::id lambda_thread_id = std::this_thread::get_id();\n    EXPECT_TRUE(lambda_thread_id == thread_id);\n    return a + 1;\n  });\n}",
            "{\n  auto iter = at::TensorIteratorConfig()\n      .check_all_same_dtype(false)\n      .add_output(at::ones({1, 1}, at::dtype(at::kBool)))\n      .add_input(at::ones({1, 1}, at::dtype(at::kFloat)))\n      .add_input(at::ones({1, 1}, at::dtype(at::kDouble)))\n      .build();\n  EXPECT_TRUE(iter.input_dtype() == at::kFloat);\n  EXPECT_TRUE(iter.input_dtype(0) == at::kFloat);\n  EXPECT_TRUE(iter.input_dtype(1) == at::kDouble);\n}",
            "{\n  auto iter = at::TensorIteratorConfig()\n      .add_output(at::ones({1, 1}, at::dtype(at::kBool)))\n      .add_input(at::ones({1, 1}, at::dtype(at::kFloat)))\n      .add_input(at::ones({1, 1}, at::dtype(at::kDouble)))\n      .promote_inputs_to_common_dtype(true)\n      .build();\n  EXPECT_TRUE(iter.dtype(0) == at::kBool);\n  EXPECT_TRUE(iter.dtype(1) == at::kDouble);\n  EXPECT_TRUE(iter.dtype(2) == at::kDouble);\n  EXPECT_TRUE(iter.common_dtype() == at::kDouble);\n}",
            "{\n  auto iter = at::TensorIteratorConfig()\n      .check_all_same_dtype(false)\n      .add_output(at::ones({1, 1}, at::dtype(at::kLong)))\n      .add_input(at::ones({1, 1}, at::dtype(at::kFloat)))\n      .add_input(at::ones({1, 1}, at::dtype(at::kDouble)))\n      .build();\n  EXPECT_TRUE(iter.dtype(0) == at::kLong);\n  EXPECT_TRUE(iter.dtype(1) == at::kFloat);\n  EXPECT_TRUE(iter.dtype(2) == at::kDouble);\n}",
            "{\n  Tensor out;\n  at::TensorIteratorConfig config;\n  config.add_output(out);\n  config.add_input(at::ones({1,1}, at::dtype(at::kDouble)));\n  config.add_input(at::ones({1,1}, at::dtype(at::kInt)));\n  ASSERT_ANY_THROW(config.build());\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/test_parallel.cpp",
        "functions": [
            "{\n  manual_seed(123);\n  set_num_threads(1);\n\n  Tensor a = rand({1, 3});\n  a[0][0] = 1;\n  a[0][1] = 0;\n  a[0][2] = 0;\n  Tensor as = rand({3});\n  as[0] = 1;\n  as[1] = 0;\n  as[2] = 0;\n  ASSERT_TRUE(a.sum(0).equal(as));\n}",
            "{\n  Tensor a = ones({1024, 1024});\n  auto expected = a.sum();\n  // check that calling sum() from within a parallel block computes the same result\n  at::parallel_for(0, 10, 1, [&](int64_t begin, int64_t end) {\n    if (begin == 0) {\n      ASSERT_TRUE(a.sum().equal(expected));\n    }\n  });\n}",
            "{\n  // parallel case\n  ASSERT_THROW(\n    at::parallel_for(0, 10, 1, [&](int64_t begin, int64_t end) {\n      throw std::runtime_error(\"exception\");\n    }),\n    std::runtime_error);\n\n  // non-parallel case\n  ASSERT_THROW(\n    at::parallel_for(0, 1, 1000, [&](int64_t begin, int64_t end) {\n      throw std::runtime_error(\"exception\");\n    }),\n    std::runtime_error);\n}",
            "{\n  int v1 = 0;\n  int v2 = 0;\n\n  auto fut1 = at::intraop_launch_future([&v1](){\n    v1 = 1;\n  });\n\n  auto fut2 = at::intraop_launch_future([&v2](){\n    v2 = 2;\n  });\n\n  fut1->wait();\n  fut2->wait();\n\n  ASSERT_TRUE(v1 == 1 && v2 == 2);\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/thread_init_test.cpp",
        "functions": [
            "test(int given_num_threads)",
            "main()"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/type_test.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/undefined_tensor_test.cpp",
        "functions": [
            "{\n  manual_seed(123);\n\n  // mainly test ops on undefined tensors don't segfault and give a reasonable errror message.\n  Tensor und;\n  Tensor ft = ones({1}, CPU(kFloat));\n\n  std::stringstream ss;\n  ss << und << std::endl;\n  ASSERT_FALSE(und.defined());\n  ASSERT_EQ(std::string(\"UndefinedType\"), und.toString());\n\n  ASSERT_ANY_THROW(und.strides());\n  ASSERT_EQ(und.dim(), 1);\n  ASSERT_ANY_THROW([]() { return Tensor(); }() = Scalar(5));\n  ASSERT_ANY_THROW(und.add(und));\n  ASSERT_ANY_THROW(und.add(ft));\n  ASSERT_ANY_THROW(ft.add(und));\n  ASSERT_ANY_THROW(und.add(5));\n  ASSERT_ANY_THROW(und.mm(und));\n\n  // public variable API\n  ASSERT_ANY_THROW(und.variable_data());\n  ASSERT_ANY_THROW(und.tensor_data());\n  ASSERT_ANY_THROW(und.is_view());\n  ASSERT_ANY_THROW(und._base());\n  ASSERT_ANY_THROW(und.name());\n  ASSERT_ANY_THROW(und.grad_fn());\n  ASSERT_ANY_THROW(und.remove_hook(0));\n  ASSERT_ANY_THROW(und.register_hook([](const Tensor& x) -> Tensor { return x; }));\n\n  // copy_\n  ASSERT_ANY_THROW(und.copy_(und));\n  ASSERT_ANY_THROW(und.copy_(ft));\n  ASSERT_ANY_THROW(ft.copy_(und));\n\n  ASSERT_ANY_THROW(und.toBackend(Backend::CPU));\n  ASSERT_ANY_THROW(ft.toBackend(Backend::Undefined));\n\n  Tensor to_move = ones({1}, CPU(kFloat));\n  Tensor m(std::move(to_move));\n  ASSERT_FALSE(to_move.defined());\n  ASSERT_EQ(to_move.unsafeGetTensorImpl(), UndefinedTensorImpl::singleton());\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/variant_test.cpp",
        "functions": [
            "func(c10::variant<testns::enumtype::Enum1, testns::enumtype::Enum2, testns::enumtype::Enum3> v)",
            "{\n  ASSERT_EQ(func(testns::kEnum1), \"Enum1\");\n  ASSERT_EQ(func(testns::kEnum2), \"Enum2\");\n  ASSERT_EQ(func(testns::kEnum3), \"Enum3\");\n\n  c10::variant<testns::enumtype::Enum1, testns::enumtype::Enum2, testns::enumtype::Enum3> v;\n  {\n    v = testns::kEnum1;\n    ASSERT_EQ(c10::visit(testns::enum_name{}, v), \"Enum1\");\n  }\n  {\n    v = testns::kEnum2;\n    ASSERT_EQ(c10::visit(testns::enum_name{}, v), \"Enum2\");\n  }\n  {\n    v = testns::kEnum3;\n    ASSERT_EQ(c10::visit(testns::enum_name{}, v), \"Enum3\");\n  }\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/vec256_test_all_types.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/verify_api_visibility.cpp",
        "functions": [
            "main() -> int"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/vitals.cpp",
        "functions": [
            "{\n  std::stringstream buffer;\n\n  std::streambuf* sbuf = std::cout.rdbuf();\n  std::cout.rdbuf(buffer.rdbuf());\n  {\n#ifdef _WIN32\n    _putenv(\"TORCH_VITAL=1\");\n#else\n    setenv(\"TORCH_VITAL\", \"1\", 1);\n#endif\n    TORCH_VITAL_DEFINE(Testing);\n    TORCH_VITAL(Testing, Attribute0) << 1;\n    TORCH_VITAL(Testing, Attribute1) << \"1\";\n    TORCH_VITAL(Testing, Attribute2) << 1.0f;\n    TORCH_VITAL(Testing, Attribute3) << 1.0;\n    auto t = at::ones({1, 1});\n    TORCH_VITAL(Testing, Attribute4) << t;\n  }\n  std::cout.rdbuf(sbuf);\n\n  auto s = buffer.str();\n  ASSERT_TRUE(s.find(\"Testing.Attribute0\\t\\t 1\") != std::string::npos);\n  ASSERT_TRUE(s.find(\"Testing.Attribute1\\t\\t 1\") != std::string::npos);\n  ASSERT_TRUE(s.find(\"Testing.Attribute2\\t\\t 1\") != std::string::npos);\n  ASSERT_TRUE(s.find(\"Testing.Attribute3\\t\\t 1\") != std::string::npos);\n  ASSERT_TRUE(s.find(\"Testing.Attribute4\\t\\t  1\") != std::string::npos);\n}",
            "{\n  std::stringstream buffer;\n\n  std::streambuf* sbuf = std::cout.rdbuf();\n  std::cout.rdbuf(buffer.rdbuf());\n  {\n#ifdef _WIN32\n    _putenv(\"TORCH_VITAL=1\");\n#else\n    setenv(\"TORCH_VITAL\", \"1\", 1);\n#endif\n    TORCH_VITAL_DEFINE(Testing);\n    TORCH_VITAL(Testing, Attribute0) << 1 << \" of \" << 2;\n    TORCH_VITAL(Testing, Attribute1) << 1;\n    TORCH_VITAL(Testing, Attribute1) << \" of \";\n    TORCH_VITAL(Testing, Attribute1) << 2;\n  }\n  std::cout.rdbuf(sbuf);\n\n  auto s = buffer.str();\n  ASSERT_TRUE(s.find(\"Testing.Attribute0\\t\\t 1 of 2\") != std::string::npos);\n  ASSERT_TRUE(s.find(\"Testing.Attribute1\\t\\t 1 of 2\") != std::string::npos);\n}",
            "{\n  for (auto i = 0; i < 2; ++i) {\n    std::stringstream buffer;\n\n    std::streambuf* sbuf = std::cout.rdbuf();\n    std::cout.rdbuf(buffer.rdbuf());\n    {\n#ifdef _WIN32\n      if (i) {\n        _putenv(\"TORCH_VITAL=1\");\n      } else {\n        _putenv(\"TORCH_VITAL=0\");\n      }\n#else\n      setenv(\"TORCH_VITAL\", i ? \"1\" : \"\", 1);\n#endif\n      TORCH_VITAL_DEFINE(Testing);\n      TORCH_VITAL(Testing, Attribute0) << 1;\n    }\n    std::cout.rdbuf(sbuf);\n\n    auto s = buffer.str();\n    auto f = s.find(\"Testing.Attribute0\\t\\t 1\");\n    if (i) {\n      ASSERT_TRUE(f != std::string::npos);\n    } else {\n      ASSERT_TRUE(f == std::string::npos);\n    }\n  }\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/vmap_test.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/vulkan_api_test.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/vulkan_test.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/cuda_cudnn_test.cpp",
        "functions": [
            "{\n  if (!at::cuda::is_available()) return;\n  manual_seed(123);\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/NamedTensor_test.cpp",
        "functions": [
            "Dimname",
            "{\n  auto tensor = at::zeros({3, 2, 5, 7});\n  ASSERT_FALSE(tensor.has_names());\n\n  tensor = at::zeros({3, 2, 5, 7});\n  ASSERT_FALSE(tensor.has_names());\n\n  tensor = at::zeros({3, 2, 5, 7});\n  auto N = dimnameFromString(\"N\");\n  auto C = dimnameFromString(\"C\");\n  auto H = dimnameFromString(\"H\");\n  auto W = dimnameFromString(\"W\");\n  std::vector<Dimname> names = { N, C, H, W };\n  at::internal_set_names_inplace(tensor, names);\n  ASSERT_TRUE(tensor.has_names());\n}",
            "bool",
            "{\n  auto tensor = at::zeros({3, 2, 5, 7});\n  auto N = dimnameFromString(\"N\");\n  auto C = dimnameFromString(\"C\");\n  auto H = dimnameFromString(\"H\");\n  auto W = dimnameFromString(\"W\");\n  std::vector<Dimname> names = { N, C, H, W };\n\n  at::internal_set_names_inplace(tensor, names);\n\n  const auto retrieved_meta = tensor.get_named_tensor_meta();\n  ASSERT_TRUE(dimnames_equal(retrieved_meta->names(), names));\n\n  // Test dropping metadata\n  tensor.unsafeGetTensorImpl()->set_named_tensor_meta(nullptr);\n  ASSERT_FALSE(tensor.has_names());\n}",
            "{\n  auto tensor = at::zeros({3, 2, 5, 7});\n  auto N = dimnameFromString(\"N\");\n  auto C = dimnameFromString(\"C\");\n  auto H = dimnameFromString(\"H\");\n  auto W = dimnameFromString(\"W\");\n  std::vector<Dimname> names = { N, C, H, W };\n  ASSERT_FALSE(tensor.has_names());\n\n  // Set names\n  at::internal_set_names_inplace(tensor, names);\n  const auto retrieved_names = tensor.opt_names().value();\n  ASSERT_TRUE(dimnames_equal(retrieved_names, names));\n\n  // Drop names\n  at::internal_set_names_inplace(tensor, at::nullopt);\n  ASSERT_TRUE(tensor.get_named_tensor_meta() == nullptr);\n  ASSERT_TRUE(tensor.opt_names() == at::nullopt);\n}",
            "{\n  auto N = Dimname::fromSymbol(Symbol::dimname(\"N\"));\n  auto C = Dimname::fromSymbol(Symbol::dimname(\"C\"));\n  auto H = Dimname::fromSymbol(Symbol::dimname(\"H\"));\n  auto W = Dimname::fromSymbol(Symbol::dimname(\"W\"));\n  std::vector<Dimname> names = { N, C, H, W };\n\n  auto tensor = at::empty({});\n  ASSERT_EQ(tensor.opt_names(), at::nullopt);\n\n  tensor = at::empty({1, 2, 3});\n  ASSERT_EQ(tensor.opt_names(), at::nullopt);\n\n  tensor = at::empty({1, 2, 3, 4}, names);\n  ASSERT_TRUE(dimnames_equal(tensor.opt_names().value(), names));\n\n  ASSERT_THROW(at::empty({1, 2, 3}, names), c10::Error);\n}",
            "{\n  auto N = dimnameFromString(\"N\");\n  auto C = dimnameFromString(\"C\");\n  auto H = dimnameFromString(\"H\");\n  auto W = dimnameFromString(\"W\");\n  std::vector<Dimname> names = { N, C, H, W };\n\n  auto tensor = at::empty({1, 1, 1});\n  ASSERT_THROW(dimname_to_position(tensor, N), c10::Error);\n\n  tensor = at::empty({1, 1, 1, 1}, names);\n  ASSERT_EQ(dimname_to_position(tensor, H), 2);\n}",
            "std::vector<Dimname>",
            "void",
            "void",
            "{\n  auto N = dimnameFromString(\"N\");\n  auto C = dimnameFromString(\"C\");\n  auto H = dimnameFromString(\"H\");\n  auto W = dimnameFromString(\"W\");\n  auto None = dimnameFromString(\"*\");\n\n  std::vector<Dimname> names = { N, C };\n\n  check_unify({ N, C, H, W }, { N, C, H, W }, { N, C, H, W });\n  check_unify({ W }, { C, H, W }, { C, H, W });\n  check_unify({ None, W }, { C, H, W }, { C, H, W });\n  check_unify({ None, None, H, None }, { C, None, W }, { None, C, H, W });\n\n  check_unify_error({ W, H }, { W, C });\n  check_unify_error({ W, H }, { C, H });\n  check_unify_error({ None, H }, { H, None });\n  check_unify_error({ H, None, C }, { H });\n}",
            "{\n  // tensor.alias is not exposed in Python so we test its name propagation here\n  auto N = dimnameFromString(\"N\");\n  auto C = dimnameFromString(\"C\");\n  std::vector<Dimname> names = { N, C };\n\n  auto tensor = at::empty({2, 3}, std::vector<Dimname>{ N, C });\n  auto aliased = tensor.alias();\n  ASSERT_TRUE(dimnames_equal(tensor.opt_names().value(), aliased.opt_names().value()));\n}",
            "{\n  auto N = dimnameFromString(\"N\");\n  auto C = dimnameFromString(\"C\");\n  std::vector<Dimname> names = { N, C };\n\n  auto tensor = at::empty({2, 3}, names);\n  ASSERT_TRUE(at::NamesMode::is_enabled());\n  {\n    at::NoNamesGuard guard;\n    ASSERT_FALSE(at::NamesMode::is_enabled());\n    ASSERT_FALSE(tensor.opt_names());\n    ASSERT_FALSE(at::impl::get_opt_names(tensor.unsafeGetTensorImpl()));\n  }\n  ASSERT_TRUE(at::NamesMode::is_enabled());\n}",
            "std::vector<Dimname>",
            "{\n  auto names = nchw();\n  {\n    auto N = TensorName(names, 0);\n    ASSERT_EQ(\n        c10::str(N),\n        \"'N' (index 0 of ['N', 'C', 'H', 'W'])\");\n  }\n  {\n    auto H = TensorName(names, 2);\n    ASSERT_EQ(\n        c10::str(H),\n        \"'H' (index 2 of ['N', 'C', 'H', 'W'])\");\n  }\n}",
            "{\n  auto names = nchw();\n  {\n    // smoke test to check that this doesn't throw\n    TensorNames(names).checkUnique(\"op_name\");\n  }\n  {\n    std::vector<Dimname> nchh = { names[0], names[1], names[2], names[2] };\n    auto tensornames = TensorNames(nchh);\n    ASSERT_THROW(tensornames.checkUnique(\"op_name\"), c10::Error);\n  }\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/weakref_test.cpp",
        "functions": [
            "{\n  IValue a = at::ones({2, 2});\n  WeakIValue b = a;\n  a = IValue();\n  ASSERT_TRUE(b.lock().isNone());\n}",
            "{\n  IValue a = at::ones({2, 2});\n  WeakIValue b = a;\n  auto c = b.lock();\n  ASSERT_TRUE(c.isTensor());\n\n  a = IValue();\n  ASSERT_TRUE(!b.lock().isNone());\n  c = IValue();\n  ASSERT_TRUE(b.lock().isNone());\n}",
            "{\n  at::Tensor a = at::ones({2, 2});\n  ASSERT_EQ(a.use_count(), 1);\n  ASSERT_EQ(a.weak_use_count(), 1);\n  {\n    WeakIValue b = IValue(a);\n    ASSERT_EQ(a.use_count(), 1);\n    ASSERT_EQ(a.weak_use_count(), 2);\n  }\n  ASSERT_EQ(a.use_count(), 1);\n  ASSERT_EQ(a.weak_use_count(), 1);\n  {\n    WeakIValue b = IValue(a);\n    ASSERT_EQ(a.use_count(), 1);\n    auto locked = b.lock();\n    ASSERT_FALSE(locked.isNone());\n    ASSERT_EQ(a.use_count(), 2);\n  }\n  ASSERT_EQ(a.use_count(), 1);\n  ASSERT_EQ(a.weak_use_count(), 1);\n  {\n    WeakIValue b = IValue(a);\n    ASSERT_EQ(a.use_count(), 1);\n    ASSERT_EQ(a.weak_use_count(), 2);\n    a.reset();\n    ASSERT_EQ(b.use_count(), 0);\n    ASSERT_EQ(b.weak_use_count(), 1);\n  }\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/wrapdim_test.cpp",
        "functions": [
            "TestSimpleCase(DeprecatedTypeProperties& T)",
            "TestExpressionSpecification(DeprecatedTypeProperties& T)",
            "TestEmptyTensor(DeprecatedTypeProperties& T)",
            "TestScalarVs1Dim1Size(DeprecatedTypeProperties& T)",
            "{\n  manual_seed(123);\n  DeprecatedTypeProperties& T = CPU(kFloat);\n\n  TestSimpleCase(T);\n  TestEmptyTensor(T);\n  TestScalarVs1Dim1Size(T);\n  TestExpressionSpecification(T);\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/xla_tensor_test.cpp",
        "functions": [
            "XLAFree(void *ptr)",
            "* XLAMalloc(ptrdiff_t size)",
            "{\n  XLAAllocator allocator;\n  auto tensor_impl = c10::make_intrusive<TensorImpl, UndefinedTensorImpl>(\n      DispatchKey::XLA,\n      caffe2::TypeMeta::Make<float>(),\n      at::Device(DeviceType::XLA, 0));\n  at::Tensor t(std::move(tensor_impl));\n  ASSERT_TRUE(t.device() == at::Device(DeviceType::XLA, 0));\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/test/test_install/main.cpp",
        "functions": [
            "main()"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/ATen/vulkan/Context.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/TH/THAllocator.cpp",
        "functions": [
            "* getTHDefaultAllocator()",
            "void",
            "void",
            "* THMapAllocator::fromDataPtr(const at::DataPtr& dptr)",
            "* THRefcountedMapAllocator::fromDataPtr(const at::DataPtr& dptr)",
            "THMapAllocator::makeDataPtr(const char *filename, int flags, size_t size, size_t* actual_size_out)",
            "THMapAllocator::makeDataPtr(WithFd, const char *filename, int fd, int flags, size_t size, size_t* actual_size_out)",
            "THRefcountedMapAllocator::makeDataPtr(const char *filename, int flags, size_t size, size_t* actual_size_out)",
            "THRefcountedMapAllocator::makeDataPtr(WithFd, const char *filename, int fd, int flags, size_t size, size_t* actual_size_out)",
            "* THRefcountedMapAllocator::data() const",
            "{\n  close();\n  c10::reportMemoryUsageToProfiler(base_ptr_, -size_, c10::Device(c10::DeviceType::CPU));\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/TH/THBlas.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/TH/THGeneral.cpp",
        "functions": [
            "void",
            "_THError(const char *file, const int line, const char *fmt, ...)",
            "_THAssertionFailed(const char *file, const int line, const char *exp, const char *fmt, ...)",
            "THSetErrorHandler(THErrorHandlerFunction new_handler, void *data)",
            "THSetDefaultErrorHandler(THErrorHandlerFunction new_handler, void *data)",
            "void",
            "_THArgCheck(const char *file, int line, int condition, int argNumber, const char *fmt, ...)",
            "THSetArgErrorHandler(THArgErrorHandlerFunction new_handler, void *data)",
            "THSetDefaultArgErrorHandler(THArgErrorHandlerFunction new_handler, void *data)",
            "THSetGCHandler( void (*torchGCFunction_)(void *data), void *data )",
            "* THAlloc(ptrdiff_t size)",
            "* THRealloc(void *ptr, ptrdiff_t size)",
            "THFree(void *ptr)",
            "_THSizeDesc(const int64_t *size, const int64_t ndim)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/TH/THLapack.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/TH/THStorageFunctions.cpp",
        "functions": [
            "* THStorage_new()",
            "THStorage_free(THStorage* storage)",
            "THStorage_retain(THStorage *storage)",
            "THStorage_resizeBytes(THStorage* storage, ptrdiff_t size_bytes)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/TH/THTensor.cpp",
        "functions": [
            "THTensor_free(THTensor *self)",
            "THTensor_setStorage(THTensor *self, THStorage *storage_, ptrdiff_t storageOffset_, at::IntArrayRef size_, at::IntArrayRef stride_)",
            "THTensor_resize(THTensor *self, at::IntArrayRef size, at::IntArrayRef stride)",
            "THTensor_resizeNd(THTensor *self, int nDimension, const int64_t *size, const int64_t *stride)",
            "THTensor_stealAndSetStoragePtr(THTensor* tensor, THStorage* storage)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/TH/THTensorEvenMoreMath.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/TH/THTensorLapack.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/TH/THTensorMath.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/TH/THTensorMoreMath.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/TH/THTensorRandom.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/TH/THVector.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/TH/generic/THBlas.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/TH/generic/THLapack.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/TH/generic/THStorage.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/TH/generic/THStorageCopy.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/TH/generic/THTensor.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/TH/generic/THTensorEvenMoreMath.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/TH/generic/THTensorLapack.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/TH/generic/THTensorMath.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/TH/generic/THTensorMoreMath.cpp",
        "functions": [
            "THTensor_(numel)(THTensor *t)",
            "THTensor_(preserveReduceDimSemantics)(\n    THTensor *r_, int in_dims, int reduce_dimension, int keepdim)",
            "void"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/TH/generic/THTensorRandom.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/TH/generic/THVectorDefault.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/TH/generic/THVectorDispatch.cpp",
        "functions": [
            "THVector_(fill)(scalar_t *x, const scalar_t c, const ptrdiff_t n)",
            "THVector_(muls)(scalar_t *y, const scalar_t *x, const scalar_t c, const ptrdiff_t n)",
            "(startup)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/TH/vector/AVX.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/TH/vector/NEON.cpp",
        "functions": [
            "void",
            "void"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/TH/vector/VSX.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/THC/THCTensor.cpp",
        "functions": [
            "THCTensor_nDimension(THCState *state, const THCTensor *self)",
            "THCTensor_nDimensionLegacyNoScalars(THCState *state, const THCTensor *self)",
            "THCTensor_nDimensionLegacyAll(THCState *state, const THCTensor *self)",
            "THCTensor_size(THCState *state, const THCTensor *self, int dim)",
            "THCTensor_sizeLegacyNoScalars(THCState *state, const THCTensor *self, int dim)",
            "THCTensor_stride(THCState *state, const THCTensor *self, int dim)",
            "THCTensor_strideLegacyNoScalars(THCState *state, const THCTensor *self, int dim)",
            "*THCTensor_new(THCState *state, caffe2::TypeMeta type_meta)",
            "THCTensor_resize(THCState *state, THCTensor *self, at::IntArrayRef size, at::IntArrayRef stride)",
            "THCTensor_resizeAs(THCState *state, THCTensor *self, THCTensor *src)",
            "THCTensor_resizeNd(THCState *state, THCTensor *self, int nDimension, const int64_t *size, const int64_t *stride)",
            "THCTensor_set(THCState *state, THCTensor *self, THCTensor *src)",
            "THCTensor_setStorage(THCState *state, THCTensor *self, THCStorage *storage_, ptrdiff_t storageOffset_, at::IntArrayRef size_, at::IntArrayRef stride_)",
            "THCTensor_squeeze1d(THCState *state, THCTensor *self, THCTensor *src, int dimension)",
            "THCTensor_unsqueeze1d(THCState *state, THCTensor *self, THCTensor *src, int dimension)",
            "THCTensor_allContiguous(THCState *state, THCTensor **inputs, int numInputs)",
            "THCTensor_nElement(THCState *state, const THCTensor *self)",
            "THCTensor_retain(THCState *state, THCTensor *self)",
            "THCTensor_free(THCState *state, THCTensor *self)",
            "THCTensor_getDevice(THCState* state, const THCTensor* tensor)",
            "THCTensor_allSameDevice(THCState* state, THCTensor ** inputs, int numInputs)",
            "THCTensor_canUse32BitIndexMath(THCState* state, const THCTensor* t, ptrdiff_t max_elem)",
            "THCTensor_all32BitIndexable(THCState* state, THCTensor** inputs, int numInputs)",
            "THCTensor_preserveReduceDimSemantics(THCState *state, THCTensor *tensor,\n                                          int in_dims, int64_t dimension, int keepdim)",
            "THCTensor_maybeOverlappingIndices(THCState* state, const THCTensor* t)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/THC/THCAllocator.cpp",
        "functions": [
            "{}",
            "deleteTHCIpcDeleter(void* ptr)",
            "THCIpcDeleter::makeDataPtr(std::shared_ptr<void> basePtr, void* data)",
            ": basePtr_(std::move(basePtr))"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/THC/THCCachingHostAllocator.cpp",
        "functions": [
            "THCCachingHostAllocator_recordEvent(void *ptr, at::cuda::CUDAStream stream)",
            "THCCachingHostAllocator_emptyCache()",
            "void",
            "* getTHCCachingHostAllocator()"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/THC/THCGeneral.cpp",
        "functions": [
            "THCState_free(THCState* state)",
            "* THCState_alloc(void)",
            "THCudaInit(THCState* state)",
            "THCudaShutdown(THCState* state)",
            "THCState_getPeerToPeerAccess(THCState* state, int dev, int devToAccess)",
            "* THCState_getCudaHostAllocator(THCState* state)",
            "* THCState_getDeviceResourcePtr(\n  THCState *state, int device)",
            "THCState_getCurrentDeviceScratchSpaceSize(THCState* state)",
            "__THCudaCheck(cudaError_t err, const char *file, const int line)",
            "__THCudaCheckWarn(cudaError_t err, const char *file, const int line)",
            "__THCublasCheck(cublasStatus_t status, const char *file, const int line)",
            "__THCusparseCheck(cusparseStatus_t status, const char *file, const int line)",
            "* THCudaMalloc(THCState *state, size_t size)",
            "THCudaFree(THCState *state, void* ptr)",
            "THCudaHostAlloc(THCState *state, size_t size)",
            "THCudaHostRecord(THCState *state, void *ptr)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/THC/THCStorage.cpp",
        "functions": [
            "THCStorage_resizeBytes(\n    THCState* state,\n    THCStorage* self,\n    ptrdiff_t size_bytes)",
            "THCStorage_getDevice(THCState* state, const THCStorage* storage)",
            "* THCStorage_new(THCState* state)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/THC/THCStorageCopy.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/THC/generic/THCStorage.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/THC/generic/THCStorageCopy.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/aten/src/THC/generic/THCTensor.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/compare-fastrnn-results.py",
        "functions": [
            "construct_name",
            "get_times"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/upload_scribe.py",
        "functions": [],
        "classes": [
            "ScribeUploader",
            "PytorchBenchmarkUploader"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/cpp/tensorexpr/bench_approx.cpp",
        "functions": [
            "optimizeSleef(tensorexpr::LoopNest* ln, tensorexpr::Tensor* target)",
            "optimizePointwise(tensorexpr::LoopNest* ln, tensorexpr::Tensor* target)",
            "void",
            "void",
            "void",
            "void",
            "void",
            "void",
            "void",
            "void",
            "void",
            "void"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/cpp/tensorexpr/bench_compile.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/cpp/tensorexpr/bench_fuser_overhead.cpp",
        "functions": [
            "void",
            "void"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/cpp/tensorexpr/bench_gemm.cpp",
        "functions": [
            "{\n  for (auto _ : state) {\n    torch::mm_out(C, A, B);\n  }\n}",
            "{\n  te::KernelScope ks;\n\n  te::Placeholder AP(te::BufHandle(\"A\", {M, K}, te::kFloat));\n  te::Placeholder BP(te::BufHandle(\"B\", {K, N}, te::kFloat));\n  te::Tensor* CT = te::Reduce(\n      \"gemm\",\n      {{M, \"M\"}, {N, \"N\"}},\n      te::Sum(),\n      [&](const te::ExprHandle& m,\n          const te::ExprHandle& n,\n          const te::ExprHandle& k) { return AP.load(m, k) * BP.load(k, n); },\n      {{K, \"K\"}});\n  te::LoopNest loop({CT});\n  loop.prepareForCodegen();\n  te::Stmt* s = loop.root_stmt();\n  s = te::IRSimplifier::simplify(s);\n  auto cg = CreateCodeGen(\"llvm_codegen\", s, {AP, BP, CT});\n\n  for (auto _ : state) {\n    cg->call({A.data_ptr<float>(), B.data_ptr<float>(), C.data_ptr<float>()});\n  }\n}",
            "{\n  te::KernelScope ks;\n\n  te::Placeholder AP(te::BufHandle(\"A\", {M, K}, te::kFloat));\n  te::Placeholder BP(te::BufHandle(\"B\", {K, N}, te::kFloat));\n  te::Tensor* CT = te::Reduce(\n      \"gemm\",\n      {{M, \"M\"}, {N, \"N\"}},\n      te::Sum(),\n      [&](const te::ExprHandle& m,\n          const te::ExprHandle& n,\n          const te::ExprHandle& k) { return AP.load(m, k) * BP.load(k, n); },\n      {{K, \"K\"}});\n  te::LoopNest loop({CT});\n\n  {\n    auto const& loops = loop.getLoopStmtsFor(CT);\n    te::For* m = loops[0];\n    te::For* mo;\n    te::For* mi;\n    loop.splitWithMask(m, 32, &mo, &mi);\n  }\n  {\n    auto const& loops = loop.getLoopStmtsFor(CT);\n    te::For* n = loops[2];\n    te::For* no;\n    te::For* ni;\n    loop.splitWithMask(n, 32, &no, &ni);\n  }\n  // mo, mi, no, ni, k ->\n  // mo, no, mi, ni, k\n  {\n    auto const& loops = loop.getLoopStmtsFor(CT);\n    te::For* mi = loops[1];\n    te::For* no = loops[2];\n    loop.reorderAxis(mi, no);\n  }\n  // mo, no, mi, ni, k ->\n  // mo, no, mi, k, ni\n  {\n    auto const& loops = loop.getLoopStmtsFor(CT);\n    te::For* ni = loops[3];\n    te::For* k = loops[4];\n    loop.reorderAxis(ni, k);\n  }\n  // mo, no, mi, k, ni ->\n  // mo, no, k, mi, ni\n  {\n    auto const& loops = loop.getLoopStmtsFor(CT);\n    te::For* mi = loops[2];\n    te::For* k = loops[3];\n    loop.reorderAxis(mi, k);\n  }\n\n  loop.prepareForCodegen();\n  te::Stmt* s = loop.root_stmt();\n  s = te::IRSimplifier::simplify(s);\n  auto cg = CreateCodeGen(\"llvm_codegen\", s, {AP, BP, CT});\n\n  for (auto _ : state) {\n    cg->call({A.data_ptr<float>(), B.data_ptr<float>(), C.data_ptr<float>()});\n  }\n}",
            "{\n  te::KernelScope ks;\n\n  te::Placeholder AP(te::BufHandle(\"A\", {M, K}, te::kFloat));\n  te::Placeholder BP(te::BufHandle(\"B\", {K, N}, te::kFloat));\n  te::Tensor* CT = te::Reduce(\n      \"gemm\",\n      {{M, \"M\"}, {N, \"N\"}},\n      te::Sum(),\n      [&](const te::ExprHandle& m,\n          const te::ExprHandle& n,\n          const te::ExprHandle& k) { return AP.load(m, k) * BP.load(k, n); },\n      {{K, \"K\"}});\n  te::LoopNest loop({CT});\n\n  {\n    auto const& loops = loop.getLoopStmtsFor(CT);\n    te::For* m = loops[0];\n    te::For* mo;\n    te::For* mi;\n    loop.splitWithMask(m, 4, &mo, &mi);\n  }\n  {\n    auto const& loops = loop.getLoopStmtsFor(CT);\n    te::For* n = loops[2];\n    te::For* no;\n    te::For* ni;\n    loop.splitWithMask(n, 16, &no, &ni);\n  }\n  // mo, mi, no, ni, k ->\n  // mo, no, mi, ni, k\n  {\n    auto const& loops = loop.getLoopStmtsFor(CT);\n    te::For* mi = loops[1];\n    te::For* no = loops[2];\n    loop.reorderAxis(mi, no);\n  }\n  // mo, no, mi, ni, k ->\n  // mo, no, mi, k, ni\n  {\n    auto const& loops = loop.getLoopStmtsFor(CT);\n    te::For* ni = loops[3];\n    te::For* k = loops[4];\n    loop.reorderAxis(ni, k);\n  }\n  // mo, no, mi, k, ni ->\n  // mo, no, k, mi, ni\n  {\n    auto const& loops = loop.getLoopStmtsFor(CT);\n    te::For* mi = loops[2];\n    te::For* k = loops[3];\n    loop.reorderAxis(mi, k);\n  }\n\n  loop.prepareForCodegen();\n  te::Stmt* s = loop.root_stmt();\n  s = te::IRSimplifier::simplify(s);\n  auto cg = CreateCodeGen(\"llvm_codegen\", s, {AP, BP, CT});\n\n  for (auto _ : state) {\n    cg->call({A.data_ptr<float>(), B.data_ptr<float>(), C.data_ptr<float>()});\n  }\n}",
            "{\n  te::KernelScope ks;\n\n  te::Placeholder AP(te::BufHandle(\"A\", {M, K}, te::kFloat));\n  te::Placeholder BP(te::BufHandle(\"B\", {K, N}, te::kFloat));\n  te::Tensor* CT = te::Reduce(\n      \"gemm\",\n      {{M, \"M\"}, {N, \"N\"}},\n      te::Sum(),\n      [&](const te::ExprHandle& m,\n          const te::ExprHandle& n,\n          const te::ExprHandle& k) { return AP.load(m, k) * BP.load(k, n); },\n      {{K, \"K\"}});\n  te::LoopNest loop({CT});\n\n  {\n    auto const& loops = loop.getLoopStmtsFor(CT);\n    te::For* m = loops[0];\n    te::For* mo;\n    te::For* mi;\n    loop.splitWithMask(m, 4, &mo, &mi);\n  }\n  {\n    auto const& loops = loop.getLoopStmtsFor(CT);\n    te::For* n = loops[2];\n    te::For* no;\n    te::For* ni;\n    loop.splitWithMask(n, 16, &no, &ni);\n  }\n  // mo, mi, no, ni, k ->\n  // mo, no, mi, ni, k\n  {\n    auto const& loops = loop.getLoopStmtsFor(CT);\n    te::For* mi = loops[1];\n    te::For* no = loops[2];\n    loop.reorderAxis(mi, no);\n  }\n  // mo, no, mi, ni, k ->\n  // mo, no, mi, k, ni\n  {\n    auto const& loops = loop.getLoopStmtsFor(CT);\n    te::For* ni = loops[3];\n    te::For* k = loops[4];\n    loop.reorderAxis(ni, k);\n  }\n  // mo, no, mi, k, ni ->\n  // mo, no, k, mi, ni\n  {\n    auto const& loops = loop.getLoopStmtsFor(CT);\n    te::For* mi = loops[2];\n    te::For* k = loops[3];\n    loop.reorderAxis(mi, k);\n  }\n  {\n    auto const& loops = loop.getLoopStmtsFor(CT);\n    te::For* mi = loops[3];\n    te::For* ni = loops[4];\n    te::Stmt* unrolled;\n    loop.vectorize(ni);\n    loop.unroll(mi, &unrolled);\n  }\n\n  loop.prepareForCodegen();\n  te::Stmt* s = loop.root_stmt();\n  s = te::IRSimplifier::simplify(s);\n  auto cg = CreateCodeGen(\"llvm_codegen\", s, {AP, BP, CT});\n\n  for (auto _ : state) {\n    cg->call({A.data_ptr<float>(), B.data_ptr<float>(), C.data_ptr<float>()});\n  }\n}",
            "{\n  te::KernelScope ks;\n\n  te::Placeholder AP(te::BufHandle(\"A\", {M, K}, te::kFloat));\n  te::Placeholder BP(te::BufHandle(\"B\", {K, N}, te::kFloat));\n  te::Tensor* CT = te::Reduce(\n      \"gemm\",\n      {{M, \"M\"}, {N, \"N\"}},\n      te::Sum(),\n      [&](const te::ExprHandle& m,\n          const te::ExprHandle& n,\n          const te::ExprHandle& k) { return AP.load(m, k) * BP.load(k, n); },\n      {{K, \"K\"}});\n  te::LoopNest loop({CT});\n\n  {\n    auto const& loops = loop.getLoopStmtsFor(CT);\n    te::For* m = loops[0];\n    te::For* mo;\n    te::For* mi;\n    loop.splitWithMask(m, 4, &mo, &mi);\n  }\n  {\n    auto const& loops = loop.getLoopStmtsFor(CT);\n    te::For* n = loops[2];\n    te::For* no;\n    te::For* ni;\n    loop.splitWithMask(n, 16, &no, &ni);\n  }\n  // mo, mi, no, ni, k ->\n  // mo, no, mi, ni, k\n  {\n    auto const& loops = loop.getLoopStmtsFor(CT);\n    te::For* mi = loops[1];\n    te::For* no = loops[2];\n    loop.reorderAxis(mi, no);\n  }\n  // mo, no, mi, ni, k ->\n  // mo, no, mi, k, ni\n  {\n    auto const& loops = loop.getLoopStmtsFor(CT);\n    te::For* ni = loops[3];\n    te::For* k = loops[4];\n    loop.reorderAxis(ni, k);\n  }\n  // mo, no, mi, k, ni ->\n  // mo, no, k, mi, ni\n  {\n    auto const& loops = loop.getLoopStmtsFor(CT);\n    te::For* mi = loops[2];\n    te::For* k = loops[3];\n    loop.reorderAxis(mi, k);\n  }\n  {\n    auto const& loops = loop.getLoopStmtsFor(CT);\n    loop.cacheAccesses(CT->buf(), \"C_regs\", loops[2]);\n  }\n\n  loop.prepareForCodegen();\n  te::Stmt* s = loop.root_stmt();\n  s = te::IRSimplifier::simplify(s);\n  auto cg = CreateCodeGen(\"llvm_codegen\", s, {AP, BP, CT});\n\n  for (auto _ : state) {\n    cg->call({A.data_ptr<float>(), B.data_ptr<float>(), C.data_ptr<float>()});\n  }\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/cpp/tensorexpr/bench_ops.py",
        "functions": [
            "hardswish"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/cpp/tensorexpr/bench_reduce.cpp",
        "functions": [
            "{\n  for (auto _ : state) {\n    B = torch::sum(A, {0});\n  }\n}",
            "void",
            "{\n  VALIDATE(reduce1d_naive, A, B);\n  for (auto _ : state) {\n    reduce1d_naive(A, B);\n  }\n}",
            "void",
            "{\n  VALIDATE(reduce1d_native_rfactor, A, B);\n  for (auto _ : state) {\n    reduce1d_native_rfactor(A, B);\n  }\n}",
            "{\n  te::KernelScope ks;\n\n  int M = A.numel();\n\n  te::Placeholder AP(te::BufHandle(\"A\", {M}, te::kFloat));\n  te::Tensor* BT = te::Reduce(\n      \"reduce_full\",\n      {{1, \"N\"}},\n      te::Sum(),\n      [&](const te::ExprHandle& n, const te::ExprHandle& m) {\n        return AP.load(m);\n      },\n      {{M, \"M\"}});\n\n  te::LoopNest loop({BT});\n  loop.prepareForCodegen();\n  te::Stmt* s = loop.root_stmt();\n  s = te::IRSimplifier::simplify(s);\n  auto cg = CreateCodeGen(\"llvm_codegen\", s, {AP, BT});\n\n  auto func = [&](at::Tensor& A, at::Tensor& B) {\n    cg->call({A.data_ptr<float>(), B.data_ptr<float>()});\n  };\n\n  ValidateFunc(func, \"reduce1d_te_naive\", A, B);\n  for (auto _ : state) {\n    func(A, B);\n  }\n}",
            "{\n  te::KernelScope ks;\n\n  int M = A.numel();\n\n  te::Placeholder AP(te::BufHandle(\"A\", {M}, te::kFloat));\n  te::Tensor* BT = te::Reduce(\n      \"reduce_full\",\n      {{1, \"N\"}},\n      te::Sum(),\n      [&](const te::ExprHandle& n, const te::ExprHandle& m) {\n        return AP.load(m);\n      },\n      {{M, \"M\"}});\n\n  te::LoopNest loop({BT});\n  const int kChunkSize = 8;\n\n  {\n    auto const& loops = loop.getLoopStmtsFor(BT);\n    te::For* m = loops[1];\n    te::For* mo;\n    te::For* mi;\n    te::For* tail;\n    loop.splitWithTail(m, kChunkSize, &mo, &mi, &tail);\n  }\n  \n  loop.prepareForCodegen();\n  te::Stmt* s = loop.root_stmt();\n  s = te::IRSimplifier::simplify(s);\n  auto cg = CreateCodeGen(\"llvm_codegen\", s, {AP, BT});\n\n  auto func = [&](at::Tensor& A, at::Tensor& B) {\n    cg->call({A.data_ptr<float>(), B.data_ptr<float>()});\n  };\n\n  ValidateFunc(func, \"reduce1d_te_naive\", A, B);\n  for (auto _ : state) {\n    func(A, B);\n  }\n}",
            "{\n  te::KernelScope ks;\n\n  int M = A.numel();\n\n  te::Placeholder AP(te::BufHandle(\"A\", {M}, te::kFloat));\n  te::Tensor* BT = te::Reduce(\n      \"reduce_full\",\n      {{1, \"N\"}},\n      te::Sum(),\n      [&](const te::ExprHandle& n, const te::ExprHandle& m) {\n        return AP.load(m);\n      },\n      {{M, \"M\"}});\n\n  te::LoopNest loop({BT});\n  const int kChunkSize = 8;\n\n  {\n    auto const& loops = loop.getLoopStmtsFor(BT);\n    te::For* m = loops[1];\n    te::For* mo;\n    te::For* mi;\n    loop.splitWithMask(m, kChunkSize, &mo, &mi);\n  }\n  \n  loop.prepareForCodegen();\n  te::Stmt* s = loop.root_stmt();\n  s = te::IRSimplifier::simplify(s);\n  auto cg = CreateCodeGen(\"llvm_codegen\", s, {AP, BT});\n\n  auto func = [&](at::Tensor& A, at::Tensor& B) {\n    cg->call({A.data_ptr<float>(), B.data_ptr<float>()});\n  };\n\n  ValidateFunc(func, \"reduce1d_te_naive\", A, B);\n  for (auto _ : state) {\n    func(A, B);\n  }\n}",
            "{\n  te::KernelScope ks;\n\n  int M = A.numel();\n  const int kChunkSize = 8;\n  TORCH_CHECK(M % kChunkSize == 0);\n\n  te::Placeholder AP(te::BufHandle(\"A\", {M}, te::kFloat));\n  te::Tensor* BT = te::Reduce(\n      \"reduce_full\",\n      {},\n      te::Sum(),\n      [&](const te::ExprHandle& m) {\n        return AP.load(m);\n      },\n      {{M, \"M\"}});\n\n  te::LoopNest loop({BT});\n\n  {\n    auto const& loops = loop.getLoopStmtsFor(BT);\n    TORCH_CHECK(loops.size() == 1);\n    te::For* m = loops[0];\n    te::For* mo;\n    te::For* mi;\n    loop.splitWithMask(m, kChunkSize, &mo, &mi);\n  }\n\n  {\n    auto const& loops = loop.getLoopStmtsFor(BT);\n    TORCH_CHECK(loops.size() == 2);\n    te::For* mo = loops[0];\n    te::For* mi = loops[1];\n    // TODO: rfactor works on the untransformed var set. This is a problem since we need to\n    // look for the loop after Split to rfactor.\n    auto bt_body = te::NodeFinder<te::ReduceOp>::find(loop.root_stmt())[0];\n    loop.rfactor(bt_body, mi->var());\n  }\n  \n  loop.prepareForCodegen();\n  te::Stmt* s = loop.root_stmt();\n  s = te::IRSimplifier::simplify(s);\n  auto cg = CreateCodeGen(\"llvm_codegen\", s, {AP, BT});\n\n  auto func = [&](at::Tensor& A, at::Tensor& B) {\n    cg->call({A.data_ptr<float>(), B.data_ptr<float>()});\n  };\n\n  ValidateFunc(func, \"reduce1d_te_naive\", A, B);\n  for (auto _ : state) {\n    func(A, B);\n  }\n}",
            "{\n  te::KernelScope ks;\n\n  int M = A.numel();\n  const int kChunkSize = 8;\n  TORCH_CHECK(M % kChunkSize == 0);\n\n  te::Placeholder AP(te::BufHandle(\"A\", {M}, te::kFloat));\n  te::Tensor* BT = te::Reduce(\n      \"reduce_full\",\n      {},\n      te::Sum(),\n      [&](const te::ExprHandle& mo, const te::ExprHandle& mi) {\n        return AP.load(mo * kChunkSize + mi);\n      },\n      {{M / kChunkSize, \"mo\"}, {kChunkSize, \"mi\"}});\n\n  te::LoopNest loop({BT});\n\n  {\n    auto const& loops = loop.getLoopStmtsFor(BT);\n    TORCH_CHECK(loops.size() == 2);\n    te::For* mo = loops[0];\n    te::For* mi = loops[1];\n    auto bt_body = te::NodeFinder<te::ReduceOp>::find(loop.root_stmt())[0];\n    loop.rfactor(bt_body, mi->var());\n  }\n\n  {\n    // Look for the new For and vectorize, but rfactor didn't return the newly added \"For *\".\n    // Resort to a hack to find the lost \"For *\". \n    // TODO: make it easier to find the transformed loop after rfactor.\n    auto loops = te::NodeFinder<te::For>::find(loop.root_stmt());\n    TORCH_CHECK(loops.size() == 4);\n    auto mi = loops[2];\n    loop.vectorize(mi);\n  }\n\n  loop.prepareForCodegen();\n  te::Stmt* s = loop.root_stmt();\n  s = te::IRSimplifier::simplify(s);\n  auto cg = CreateCodeGen(\"llvm_codegen\", s, {AP, BT});\n\n  auto func = [&](at::Tensor& A, at::Tensor& B) {\n    cg->call({A.data_ptr<float>(), B.data_ptr<float>()});\n  };\n\n  ValidateFunc(func, \"reduce1d_te_naive\", A, B);\n  for (auto _ : state) {\n    func(A, B);\n  }\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/cpp/tensorexpr/main.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/distributed/ddp/benchmark.py",
        "functions": [
            "allgather_object",
            "allgather_run",
            "allequal",
            "benchmark_process_group",
            "run_benchmark",
            "sweep",
            "main"
        ],
        "classes": [
            "Benchmark",
            "TorchvisionBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/distributed/ddp/diff.py",
        "functions": [
            "load",
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/distributed/pipeline/benchmark_dataset.py",
        "functions": [
            "collate_sentences_lm"
        ],
        "classes": [
            "BenchmarkLMDataset"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/distributed/pipeline/pipe.py",
        "functions": [
            "sizeof_fmt",
            "init_random_seed",
            "make_model",
            "train",
            "generate_balance",
            "make_model_and_data",
            "bench_single_process"
        ],
        "classes": [
            "EmbeddingLayer",
            "PositionalEncodingLayer",
            "TransformerDecoderLayer",
            "LinearLayer",
            "TransformerLMSequential"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/distributed/rpc/rl/agent.py",
        "functions": [],
        "classes": [
            "Policy",
            "AgentBase"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/distributed/rpc/rl/coordinator.py",
        "functions": [],
        "classes": [
            "CoordinatorBase"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/distributed/rpc/rl/launcher.py",
        "functions": [
            "str2bool",
            "run_worker",
            "find_graph_variable",
            "append_spaces",
            "print_benchmark_results",
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/distributed/rpc/rl/observer.py",
        "functions": [],
        "classes": [
            "ObserverBase"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/fastrnns/bench.py",
        "functions": [
            "fit_str",
            "to_str",
            "print_header",
            "pretty_print",
            "trainbench",
            "print_stderr",
            "print_json_oss_format",
            "print_json_pep_format",
            "bench",
            "bench_group"
        ],
        "classes": [
            "Event"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/fastrnns/cells.py",
        "functions": [
            "milstm_cell",
            "lstm_cell",
            "flat_lstm_cell",
            "premul_lstm_cell",
            "premul_lstm_cell_no_bias",
            "gru_cell",
            "rnn_relu_cell",
            "rnn_tanh_cell"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/fastrnns/conftest.py",
        "functions": [
            "pytest_generate_tests",
            "pytest_addoption"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/fastrnns/custom_lstms.py",
        "functions": [
            "script_lstm",
            "script_lnlstm",
            "reverse",
            "init_stacked_lstm",
            "flatten_states",
            "double_flatten_states",
            "test_script_rnn_layer",
            "test_script_stacked_rnn",
            "test_script_stacked_bidir_rnn",
            "test_script_stacked_lstm_dropout",
            "test_script_stacked_lnlstm"
        ],
        "classes": [
            "LSTMCell",
            "LayerNorm",
            "LayerNormLSTMCell",
            "LSTMLayer",
            "ReverseLSTMLayer",
            "BidirLSTMLayer",
            "StackedLSTM",
            "StackedLSTM2",
            "StackedLSTMWithDropout"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/fastrnns/factory.py",
        "functions": [
            "flatten_list",
            "lstm_backward_setup",
            "simple_backward_setup",
            "simple_backward",
            "pytorch_lstm_creator",
            "lstm_creator",
            "lnlstm_creator",
            "dropoutlstm_creator",
            "lstm_premul_creator",
            "lstm_premul_bias_creator",
            "lstm_simple_creator",
            "lstm_multilayer_creator",
            "imagenet_cnn_creator",
            "varlen_lstm_inputs",
            "varlen_lstm_backward_setup",
            "varlen_pytorch_lstm_creator",
            "varlen_lstm_factory",
            "varlen_lstm_creator",
            "layernorm_pytorch_lstm_creator",
            "stack_weights",
            "lstm_inputs",
            "lstm_factory",
            "lstm_factory_premul",
            "lstm_factory_premul_bias",
            "lstm_factory_simple",
            "lstm_factory_multilayer"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/fastrnns/fuser.py",
        "functions": [
            "set_fuser"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/fastrnns/profile.py",
        "functions": [
            "run_rnn",
            "profile",
            "system",
            "describe_sizes",
            "nvprof_output_filename",
            "nvprof",
            "full_profile"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/fastrnns/runner.py",
        "functions": [
            "get_nn_runners"
        ],
        "classes": [
            "DisableCuDNN",
            "DummyContext",
            "AssertNoJIT"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/fastrnns/scratch.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/fastrnns/test.py",
        "functions": [
            "barf",
            "assertEqual",
            "filter_requires_grad",
            "test_rnns",
            "test_vl_py"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/fastrnns/test_bench.py",
        "functions": [
            "cuda_sync"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/fastrnns/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/framework_overhead_benchmark/C2Module.py",
        "functions": [
            "add_blob"
        ],
        "classes": [
            "C2SimpleNet"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/framework_overhead_benchmark/framework_overhead_benchmark.py",
        "functions": [
            "parse_op_args",
            "print_results",
            "benchmark_simple_fn",
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/framework_overhead_benchmark/pt_wrapper_module.py",
        "functions": [],
        "classes": [
            "WrapperModule"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/framework_overhead_benchmark/SimpleAddModule.py",
        "functions": [
            "add_tensors_loop"
        ],
        "classes": [
            "SimpleAddModule"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/framework_overhead_benchmark/utils.py",
        "functions": [
            "ms_to_us",
            "secs_to_us",
            "secs_to_ms",
            "benchmark_using_throughput_benchmark",
            "benchmark_module"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/functional_autograd_benchmark/audio_text_models.py",
        "functions": [
            "get_wav2letter",
            "get_deepspeech",
            "get_transformer",
            "get_multiheadattn"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/functional_autograd_benchmark/compare.py",
        "functions": [
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/functional_autograd_benchmark/functional_autograd_benchmark.py",
        "functions": [
            "get_v_for",
            "run_once",
            "run_model",
            "main"
        ],
        "classes": [
            "ModelDef"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/functional_autograd_benchmark/ppl_models.py",
        "functions": [
            "get_simple_regression",
            "get_robust_regression"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/functional_autograd_benchmark/torchaudio_models.py",
        "functions": [],
        "classes": [
            "Wav2Letter",
            "SequenceWise",
            "MaskConv",
            "InferenceBatchSoftmax",
            "BatchRNN",
            "Lookahead",
            "DeepSpeech",
            "PositionalEncoding",
            "TransformerModel",
            "MultiheadAttentionContainer",
            "ScaledDotProduct",
            "InProjContainer"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/functional_autograd_benchmark/torchvision_models.py",
        "functions": [
            "conv3x3",
            "conv1x1",
            "_resnet",
            "resnet18",
            "resnet50",
            "_segm_resnet",
            "_load_model",
            "fcn_resnet50",
            "generalized_box_iou",
            "box_cxcywh_to_xyxy",
            "box_area",
            "box_iou",
            "is_dist_avail_and_initialized",
            "get_world_size"
        ],
        "classes": [
            "BasicBlock",
            "Bottleneck",
            "ResNet",
            "IntermediateLayerGetter",
            "_SimpleSegmentationModel",
            "FCN",
            "FCNHead",
            "DETR",
            "SetCriterion",
            "HungarianMatcher"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/functional_autograd_benchmark/utils.py",
        "functions": [
            "_del_nested_attr",
            "_set_nested_attr",
            "extract_weights",
            "load_weights",
            "to_markdown_table",
            "from_markdown_table"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/functional_autograd_benchmark/vision_models.py",
        "functions": [
            "get_resnet18",
            "get_fcn_resnet",
            "get_detr"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/benchmark_all_other_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/benchmark_all_quantized_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/benchmark_all_test.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/benchmark_caffe2.py",
        "functions": [
            "create_caffe2_op_test_case",
            "generate_c2_test_from_ops",
            "generate_c2_test",
            "generate_c2_gradient_test"
        ],
        "classes": [
            "Caffe2BenchmarkBase",
            "Caffe2OperatorTestCase"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/benchmark_core.py",
        "functions": [
            "_register_test",
            "_create_test",
            "_build_test"
        ],
        "classes": [
            "BenchmarkRunner"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/benchmark_pytorch.py",
        "functions": [
            "create_pytorch_op_test_case"
        ],
        "classes": [
            "TorchBenchmarkBase",
            "PyTorchOperatorTestCase"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/benchmark_runner.py",
        "functions": [
            "parse_args",
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/benchmark_test_generator.py",
        "functions": [
            "generate_pt_test",
            "generate_pt_gradient_test",
            "generate_pt_tests_from_op_list",
            "generate_pt_gradient_tests_from_op_list"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/benchmark_utils.py",
        "functions": [
            "shape_to_string",
            "str2bool",
            "numpy_random",
            "set_omp_threads",
            "set_mkl_threads",
            "cross_product",
            "get_n_rand_nums",
            "generate_configs",
            "cross_product_configs",
            "_validate",
            "config_list",
            "attr_probs",
            "random_sample_configs",
            "op_list",
            "is_caffe2_enabled",
            "is_pytorch_enabled",
            "get_operator_range",
            "process_arg_list"
        ],
        "classes": [
            "RandomSample"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/operator_benchmark.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/c2/add_test.py",
        "functions": [],
        "classes": [
            "AddBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/c2/batch_box_cox_test.py",
        "functions": [],
        "classes": [
            "BatchBoxCoxBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/c2/batch_gather_test.py",
        "functions": [],
        "classes": [
            "BatchGatherBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/c2/clip_ranges_test.py",
        "functions": [],
        "classes": [
            "ClipRangesBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/c2/concat_test.py",
        "functions": [],
        "classes": [
            "ConcatBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/c2/matmul_test.py",
        "functions": [],
        "classes": [
            "MatMulBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/c2/quantile_op_test.py",
        "functions": [],
        "classes": [
            "QuantileOpBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/c2/replace_nan_test.py",
        "functions": [],
        "classes": [
            "ReplaceNaNBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/c2/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/common/repeat_benchmark.py",
        "functions": [
            "generate_data_for_repeat",
            "pt_repeat",
            "pt_repeat_n_times"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/common/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/common/tests/add_ops_list_test.py",
        "functions": [],
        "classes": [
            "UnaryOpBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/common/tests/c2_cpu_gpu_forward_backward_test.py",
        "functions": [],
        "classes": [
            "AddBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/common/tests/jit_forward_test.py",
        "functions": [],
        "classes": [
            "TorchSumBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/common/tests/pt_backward_test.py",
        "functions": [],
        "classes": [
            "AddBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/common/tests/pt_configs_list_test.py",
        "functions": [],
        "classes": [
            "AddBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/common/tests/pt_cpu_gpu_forward_backward_test.py",
        "functions": [],
        "classes": [
            "AddBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/common/tests/random_sample_test.py",
        "functions": [],
        "classes": [
            "AddBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/groupnorm_test.py",
        "functions": [],
        "classes": [
            "GroupNormBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/qbatchnorm_test.py",
        "functions": [],
        "classes": [
            "QBatchNormBenchmark",
            "QBatchNorm1dBenchmark",
            "QBatchNorm2dBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/add_test.py",
        "functions": [],
        "classes": [
            "AddBenchmark",
            "AddmmBenchmark",
            "AddrBenchmark",
            "AddbmmBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/as_strided_test.py",
        "functions": [],
        "classes": [
            "As_stridedBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/batchnorm_test.py",
        "functions": [],
        "classes": [
            "BatchNormBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/binary_test.py",
        "functions": [
            "copy"
        ],
        "classes": [
            "BinaryOpBcastBenchmark",
            "BinaryOpBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/cat_test.py",
        "functions": [],
        "classes": [
            "CatBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/channel_shuffle_test.py",
        "functions": [],
        "classes": [
            "ChannelSHuffleBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/chunk_test.py",
        "functions": [],
        "classes": [
            "ChunkBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/clip_ranges_test.py",
        "functions": [],
        "classes": [
            "ClipRangesBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/configs.py",
        "functions": [
            "remove_cuda"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/conv_test.py",
        "functions": [],
        "classes": [
            "Conv1dBenchmark",
            "ConvTranspose1dBenchmark",
            "Conv2dBenchmark",
            "ConvTranspose2dBenchmark",
            "Conv3dBenchmark",
            "ConvTranspose3dBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/diag_test.py",
        "functions": [],
        "classes": [
            "DiagBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/embeddingbag_test.py",
        "functions": [],
        "classes": [
            "EmbeddingBagBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/fill_test.py",
        "functions": [],
        "classes": [
            "Fill_Benchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/gather_test.py",
        "functions": [],
        "classes": [
            "GatherBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/hardsigmoid_test.py",
        "functions": [],
        "classes": [
            "HardsigmoidBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/hardswish_test.py",
        "functions": [],
        "classes": [
            "HardswishBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/index_select_test.py",
        "functions": [],
        "classes": [
            "IndexSelectBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/instancenorm_test.py",
        "functions": [],
        "classes": [
            "InstanceNormBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/layernorm_test.py",
        "functions": [],
        "classes": [
            "LayerNormBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/linear_test.py",
        "functions": [],
        "classes": [
            "LinearBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/matmul_test.py",
        "functions": [],
        "classes": [
            "MatMulBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/nan_to_num_test.py",
        "functions": [],
        "classes": [
            "ReplaceNaNBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/pool_test.py",
        "functions": [],
        "classes": [
            "Pool1dBenchmark",
            "Pool2dBenchmark",
            "Pool3dBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/qactivation_test.py",
        "functions": [],
        "classes": [
            "QActivationBenchmarkBase",
            "QActivationBenchmark",
            "QActivationScaleZeroPointBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/qarithmetic_test.py",
        "functions": [],
        "classes": [
            "_QFunctionalBinaryArithmeticBenchmarkBase",
            "QFunctionalBenchmark",
            "QFunctionalScalarBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/qcat_test.py",
        "functions": [],
        "classes": [
            "QCatBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/qcomparators_test.py",
        "functions": [],
        "classes": [
            "QComparatorBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/qconv_test.py",
        "functions": [],
        "classes": [
            "QConv1dBenchmark",
            "QConv2dBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/qembeddingbag_test.py",
        "functions": [],
        "classes": [
            "QEmbeddingBagBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/qembedding_bag_lookups_test.py",
        "functions": [
            "get_pruned_weights_and_mapping"
        ],
        "classes": [
            "EmbedddingBag4BitRowwiseOffsetsTest",
            "EmbedddingBagByteRowwiseOffsetsTest"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/qembedding_pack_test.py",
        "functions": [],
        "classes": [
            "EmbeddingBagFloatToFusedBase",
            "EmbeddingBagFusedToFloatBase"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/qgroupnorm_test.py",
        "functions": [],
        "classes": [
            "QGroupNormBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/qinstancenorm_test.py",
        "functions": [],
        "classes": [
            "QInstanceNormBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/qinterpolate_test.py",
        "functions": [],
        "classes": [
            "QInterpolateBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/qlayernorm_test.py",
        "functions": [],
        "classes": [
            "QLayerNormBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/qlinear_test.py",
        "functions": [],
        "classes": [
            "_QLinearBenchmarkBase",
            "QLinearBenchmark",
            "QDynamicLinearBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/qobserver_test.py",
        "functions": [],
        "classes": [
            "QObserverBenchmark",
            "QObserverBenchmarkCalculateQparams"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/qpool_test.py",
        "functions": [],
        "classes": [
            "_QPool2dBenchmarkBase",
            "QMaxPool2dBenchmark",
            "QAvgPool2dBenchmark",
            "QAdaptiveAvgPool2dBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/qrnn_test.py",
        "functions": [],
        "classes": [
            "LSTMBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/qtensor_method_test.py",
        "functions": [],
        "classes": [
            "_QMethodBenchmarkBase",
            "QMethodTensorInputCopyBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/quantization_test.py",
        "functions": [
            "fakeQuantizePerTensorPyModule",
            "fakeQuantizePerTensorLearnableKernel",
            "fakeQuantizePerTensorOriginalKernel",
            "fakeQuantizePerChannelPyModule",
            "fakeQuantizePerChannelLearnableKernel",
            "fakeQuantizePerChannelOriginalKernel"
        ],
        "classes": [
            "QuantizePerTensorBenchmark",
            "QuantizePerChannelBenchmark",
            "FakeQuantizeBenchmark",
            "FakeQuantizePerTensorBaseOpBenchmark",
            "FakeQuantizePerChannelOpBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/qunary_test.py",
        "functions": [],
        "classes": [
            "QUnaryOpBenchmark",
            "QTopkOpBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/remainder_test.py",
        "functions": [],
        "classes": [
            "RemainderOpBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/softmax_test.py",
        "functions": [],
        "classes": [
            "SoftmaxBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/split_test.py",
        "functions": [],
        "classes": [
            "SplitBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/stack_test.py",
        "functions": [],
        "classes": [
            "StackBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/sum_test.py",
        "functions": [],
        "classes": [
            "SumBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/tensor_to_test.py",
        "functions": [],
        "classes": [
            "FloatToHalfTensorConversionBenchmark",
            "HalfToFloatTensorConversionBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/unary_test.py",
        "functions": [
            "bernoulli_",
            "cauchy_",
            "digamma_",
            "exponential_",
            "normal_",
            "random_",
            "sign_",
            "uniform_",
            "half_",
            "long_"
        ],
        "classes": [
            "UnaryOpBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt_extension/cpp_extension_test.py",
        "functions": [],
        "classes": [
            "TestConsumeOp"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt_extension/extension.cpp",
        "functions": [
            "consume(Tensor a)",
            "consume_list(List<Tensor> a)",
            "{\n    m.def(\"_consume\", &consume);\n    m.def(\"_consume.list\", &consume_list);\n}",
            "{\n  m.def(\"_consume\", &consume, \"consume\");\n  m.def(\"_consume_list\", &consume_list, \"consume_list\");\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/operator_benchmark/pt_extension/setup.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/overrides_benchmark/bench.py",
        "functions": [
            "bench",
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/overrides_benchmark/common.py",
        "functions": [],
        "classes": [
            "SubTensor",
            "WithTorchFunction",
            "SubWithTorchFunction"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/overrides_benchmark/pyspybench.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/profiler_benchmark/profiler_bench.py",
        "functions": [
            "loop_workload",
            "parallel_workload"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/profiler_benchmark/resnet_memory_profiler.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/record_function_benchmark/record_function_bench.py",
        "functions": [
            "prepare_lstm_jit",
            "prepare_resnet50_jit",
            "run_bench"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/serialization/simple_measurement.py",
        "functions": [],
        "classes": [
            "Basic"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/sparse/matmul_dlmc_bench.py",
        "functions": [
            "read_matrix_params",
            "load_matrix",
            "scipy_coo_matmul",
            "to_coo_scipy",
            "torch_backward",
            "sparse_torch_backward",
            "load_dataset"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/tensorexpr/attention.py",
        "functions": [],
        "classes": [
            "BahdanauAttention"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/tensorexpr/benchmark.py",
        "functions": [
            "register_benchmark_class"
        ],
        "classes": [
            "Benchmark",
            "DynamicShape"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/tensorexpr/broadcast.py",
        "functions": [
            "register_broadcast_ops"
        ],
        "classes": [
            "BroadcastMulBench",
            "BroadcastRowBench",
            "BroadcastMidBench",
            "BroadcastColBench",
            "BroadcastThreeArgs",
            "BroadcastBench"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/tensorexpr/conv.py",
        "functions": [],
        "classes": [
            "ConvImplBench",
            "ConvBench",
            "DepthwiseConvBench"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/tensorexpr/elementwise.py",
        "functions": [
            "register_element_ops"
        ],
        "classes": [
            "ElementBench",
            "SimpleElementBench",
            "DynamicSimpleElementBench"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/tensorexpr/matmul.py",
        "functions": [],
        "classes": [
            "MatMulBench"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/tensorexpr/microbenchmarks.py",
        "functions": [
            "gen_unary_nnc_fun",
            "gen_unary_torch_fun",
            "gen_binary_nnc_fun",
            "gen_binary_torch_fun",
            "gen_int_comparison_tensors",
            "gen_float_comparison_tensors",
            "nnc_relu",
            "pt_relu",
            "gen_custom_torch_fun",
            "normalize_benchmarks",
            "run_benchmarks",
            "dump_plot"
        ],
        "classes": [
            "kernel_arena_scope"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/tensorexpr/normalization.py",
        "functions": [],
        "classes": [
            "NormalizationBench",
            "BatchNormBench",
            "InstanceNormBench",
            "LayerNormBench"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/tensorexpr/pooling.py",
        "functions": [],
        "classes": [
            "PoolingBench",
            "MaxPoolBench",
            "AvgPoolBench"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/tensorexpr/pt_engine.py",
        "functions": [],
        "classes": [
            "TorchTensorEngine"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/tensorexpr/reduction.py",
        "functions": [],
        "classes": [
            "ReduceBench",
            "ReduceRowBench",
            "ReduceMidBench",
            "ReduceColBench",
            "ReduceFullBench",
            "Reduce2DBench",
            "Reduce2DInnerBench",
            "Reduce2DOuterBench",
            "DynamicReduce2DBench",
            "DynamicReduce2DInnerBench",
            "DynamicReduce2DOuterBench"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/tensorexpr/rnn_eltwise.py",
        "functions": [],
        "classes": [
            "RNNEltwise",
            "DynamicLSTM"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/tensorexpr/softmax.py",
        "functions": [],
        "classes": [
            "SoftmaxBench"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/tensorexpr/swish.py",
        "functions": [],
        "classes": [
            "SwishBench"
        ]
    },
    {
        "file_path": "../pytorch/benchmarks/tensorexpr/tensor_engine.py",
        "functions": [
            "unsupported",
            "is_supported",
            "set_engine_mode",
            "get_engine"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/benchmarks/tensorexpr/__main__.py",
        "functions": [
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/binaries/bench_gen/bench_gen.py",
        "functions": [
            "parse_kwarg",
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/benchmark/intrusive_ptr_benchmark.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/core/UndefinedTensorImpl.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/core/Allocator.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/core/CopyBytes.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/core/CPUAllocator.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/core/DefaultDtype.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/core/Device.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/core/DeviceType.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/core/DispatchKey.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/core/DispatchKeySet.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/core/GeneratorImpl.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/core/Scalar.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/core/Storage.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/core/StorageImpl.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/core/Stream.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/core/TensorImpl.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/core/TensorOptions.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/core/thread_pool.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/core/impl/DeviceGuardImplInterface.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/core/impl/LocalDispatchKeySet.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/core/impl/SizesAndStrides.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/cuda/CUDACachingAllocator.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/cuda/CUDAFunctions.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/cuda/CUDAStream.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/cuda/impl/CUDAGuardImpl.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/cuda/impl/CUDATest.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/cuda/test/impl/CUDATest.cpp",
        "functions": [
            "{\n  c10_cuda_test();\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/mobile/CPUCachingAllocator.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/mobile/CPUProfilingAllocator.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/test/core/CompileTimeFunctionPointer_test.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/test/core/DeviceGuard_test.cpp",
        "functions": [
            "{\n  FakeGuardImpl<DeviceType::CUDA> cuda_impl;\n  FakeGuardImpl<DeviceType::HIP> hip_impl;\n  FakeGuardImpl<DeviceType::CUDA>::setDeviceIndex(0);\n  FakeGuardImpl<DeviceType::HIP>::setDeviceIndex(0);\n  DeviceGuard g(Device(DeviceType::CUDA, 1), &cuda_impl);\n  g.reset_device(Device(DeviceType::HIP, 2), &hip_impl);\n  ASSERT_EQ(FakeGuardImpl<DeviceType::CUDA>::getDeviceIndex(), 0);\n  ASSERT_EQ(FakeGuardImpl<DeviceType::HIP>::getDeviceIndex(), 2);\n  ASSERT_EQ(g.current_device(), Device(DeviceType::HIP, 2));\n  ASSERT_EQ(g.original_device(), Device(DeviceType::HIP, 0));\n}",
            "{\n  FakeGuardImpl<DeviceType::CUDA> cuda_impl;\n  FakeGuardImpl<DeviceType::HIP> hip_impl;\n  FakeGuardImpl<DeviceType::CUDA>::setDeviceIndex(0);\n  FakeGuardImpl<DeviceType::HIP>::setDeviceIndex(0);\n  OptionalDeviceGuard g;\n  g.reset_device(Device(DeviceType::CUDA, 1), &cuda_impl);\n  g.reset_device(Device(DeviceType::HIP, 2), &hip_impl);\n  ASSERT_EQ(FakeGuardImpl<DeviceType::CUDA>::getDeviceIndex(), 0);\n  ASSERT_EQ(FakeGuardImpl<DeviceType::HIP>::getDeviceIndex(), 2);\n  ASSERT_EQ(g.current_device(), make_optional(Device(DeviceType::HIP, 2)));\n  ASSERT_EQ(g.original_device(), make_optional(Device(DeviceType::HIP, 0)));\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/test/core/DispatchKeySet_test.cpp",
        "functions": [
            "{\n  DispatchKeySet empty_set;\n  for (uint8_t i = 1; i < static_cast<uint8_t>(DispatchKey::NumDispatchKeys); i++) {\n    auto tid = static_cast<DispatchKey>(i);\n    ASSERT_FALSE(empty_set.has(tid));\n  }\n  ASSERT_TRUE(empty_set.empty());\n  DispatchKeySet empty_set2;\n  ASSERT_TRUE(empty_set == empty_set2);\n  ASSERT_EQ(empty_set.highestPriorityTypeId(), DispatchKey::Undefined);\n}",
            "{\n  for (uint8_t i = 1; i < static_cast<uint8_t>(DispatchKey::NumDispatchKeys); i++) {\n    auto tid = static_cast<DispatchKey>(i);\n    DispatchKeySet sing(tid);\n    ASSERT_EQ(sing, sing);\n    ASSERT_EQ(sing, DispatchKeySet().add(tid));\n    ASSERT_EQ(sing, sing.add(tid));\n    ASSERT_EQ(sing, sing | sing);\n    ASSERT_FALSE(sing.empty());\n    ASSERT_TRUE(sing.has(tid));\n    ASSERT_EQ(sing.highestPriorityTypeId(), tid);\n    ASSERT_EQ(sing.remove(tid), DispatchKeySet());\n  }\n}",
            "{\n  for (uint8_t i = 1; i < static_cast<uint8_t>(DispatchKey::NumDispatchKeys); i++) {\n    for (uint8_t j = i + 1; j < static_cast<uint8_t>(DispatchKey::NumDispatchKeys); j++) {\n      ASSERT_LT(i, j);\n      auto tid1 = static_cast<DispatchKey>(i);\n      auto tid2 = static_cast<DispatchKey>(j);\n      auto doub = DispatchKeySet(tid1).add(tid2);\n      ASSERT_EQ(doub, DispatchKeySet(tid1) | DispatchKeySet(tid2));\n      ASSERT_TRUE(doub.has(tid1));\n      ASSERT_TRUE(doub.has(tid2));\n      ASSERT_EQ(doub.highestPriorityTypeId(), tid2);  // relies on i < j\n    }\n  }\n}",
            "{\n  DispatchKeySet full(DispatchKeySet::FULL);\n  for (uint8_t i = 1; i < static_cast<uint8_t>(DispatchKey::NumDispatchKeys); i++) {\n    auto tid = static_cast<DispatchKey>(i);\n    ASSERT_TRUE(full.has(tid));\n  }\n}",
            "{\n  DispatchKeySet empty_set;\n  DispatchKeySet full_set(DispatchKeySet::FULL);\n  DispatchKeySet mutated_set = empty_set.add(static_cast<DispatchKey>(1));\n\n  // Constructor + Comparison\n  ASSERT_EQ(*empty_set.begin(), DispatchKey::NumDispatchKeys);\n  ASSERT_EQ(*empty_set.end(), DispatchKey::NumDispatchKeys);\n  ASSERT_EQ(*mutated_set.begin(), static_cast<DispatchKey>(1));\n\n  ASSERT_TRUE(empty_set.begin() == empty_set.end());\n  ASSERT_TRUE(full_set.begin() != full_set.end());\n\n  // Increment Ops\n  ASSERT_TRUE(full_set.begin() == full_set.begin()++);\n  ASSERT_TRUE(full_set.begin() != ++full_set.begin());\n}",
            "{\n  DispatchKeySet empty_set;\n  uint8_t i = 0;\n\n  for (auto it = empty_set.begin(); it != empty_set.end(); ++it) {\n    i++;\n  }\n  ASSERT_EQ(i, 0);\n}",
            "{\n  DispatchKeySet full_set(DispatchKeySet::FULL);\n  uint8_t i = 0;\n\n  for (const auto& it : full_set) {\n    i++;\n    ASSERT_TRUE(it == static_cast<DispatchKey>(i));\n    ASSERT_TRUE(it != DispatchKey::NumDispatchKeys);\n  }\n  ASSERT_EQ(i, static_cast<uint8_t>(DispatchKey::NumDispatchKeys) - 1);\n}",
            "{\n  DispatchKeySet full_set(DispatchKeySet::FULL);\n  uint8_t i = 0;\n\n  for (DispatchKey dispatch_key: full_set) {\n    i++;\n    ASSERT_TRUE(dispatch_key == static_cast<DispatchKey>(i));\n  }\n\n  ASSERT_EQ(i, static_cast<uint8_t>(DispatchKey::NumDispatchKeys) - 1);\n}",
            "{\n  DispatchKeySet keyset({\n      static_cast<DispatchKey>(0), // Undefined should be ignored\n      static_cast<DispatchKey>(4),\n      static_cast<DispatchKey>(10),\n      static_cast<DispatchKey>(15),\n    });\n  std::unordered_set<DispatchKey> visited_keys;\n\n  for(DispatchKey key: keyset) {\n    visited_keys.insert(key);\n  }\n\n  ASSERT_EQ(visited_keys.size(), 3);\n  ASSERT_TRUE(visited_keys.find(static_cast<DispatchKey>(4)) != visited_keys.end());\n  ASSERT_TRUE(visited_keys.find(static_cast<DispatchKey>(10)) != visited_keys.end());\n  ASSERT_TRUE(visited_keys.find(static_cast<DispatchKey>(15)) != visited_keys.end());\n}",
            "{\n  DispatchKeySet full_set(DispatchKeySet::FULL);\n  uint64_t raw_repr = full_set.raw_repr();\n\n  EXPECT_THROW(DispatchKeySet::iterator(\n                   &raw_repr,\n                   static_cast<uint8_t>(DispatchKey::NumDispatchKeys) + 1\n               ),\n               c10::Error);\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/test/core/StreamGuard_test.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/test/core/impl/InlineDeviceGuard_test.cpp",
        "functions": [
            "Device",
            "{\n  for (DeviceIndex i : {-1, 0, 1}) {\n    DeviceIndex init_i = 0;\n    TestGuardImpl::setDeviceIndex(init_i);\n    auto test_body = [&](TestGuard& g) -> void {\n      ASSERT_EQ(g.original_device(), dev(init_i));\n      ASSERT_EQ(g.current_device(), dev(i == -1 ? init_i : i));\n      ASSERT_EQ(TestGuardImpl::getDeviceIndex(), i == -1 ? init_i : i);\n      // Test un-bracketed write to device index\n      TestGuardImpl::setDeviceIndex(4);\n    };\n    {\n      // Index constructor\n      TestGuard g(i);\n      test_body(g);\n    }\n    ASSERT_EQ(TestGuardImpl::getDeviceIndex(), init_i);\n    {\n      // Device constructor\n      TestGuard g(dev(i));\n      test_body(g);\n    }\n    ASSERT_EQ(TestGuardImpl::getDeviceIndex(), init_i);\n    /*\n    {\n      // Optional constructor\n      TestGuard g(make_optional(dev(i)));\n      test_body(g);\n    }\n    ASSERT_EQ(TestGuardImpl::getDeviceIndex(), init_i);\n    */\n  }\n}",
            "{\n  EXPECT_ANY_THROW(InlineDeviceGuard<FakeGuardImpl<DeviceType::CUDA>>\n                   g(Device(DeviceType::HIP, 1)));\n}",
            "{\n  DeviceIndex init_i = 0;\n  TestGuardImpl::setDeviceIndex(init_i);\n  DeviceIndex i = init_i + 1;\n  TestGuard g(i);\n  DeviceIndex i2 = init_i + 2;\n  g.set_device(dev(i2));\n  ASSERT_EQ(g.original_device(), dev(init_i));\n  ASSERT_EQ(g.current_device(), dev(i2));\n  ASSERT_EQ(TestGuardImpl::getDeviceIndex(), i2);\n  g.set_device(dev(i2));\n  ASSERT_EQ(g.original_device(), dev(init_i));\n  ASSERT_EQ(g.current_device(), dev(i2));\n  ASSERT_EQ(TestGuardImpl::getDeviceIndex(), i2);\n}",
            "{\n  DeviceIndex init_i = 0;\n  TestGuardImpl::setDeviceIndex(init_i);\n  DeviceIndex i = init_i + 1;\n  TestGuard g(i);\n  DeviceIndex i2 = init_i + 2;\n  g.reset_device(dev(i2));\n  ASSERT_EQ(g.original_device(), dev(init_i));\n  ASSERT_EQ(g.current_device(), dev(i2));\n  ASSERT_EQ(TestGuardImpl::getDeviceIndex(), i2);\n  g.reset_device(dev(i2));\n  ASSERT_EQ(g.original_device(), dev(init_i));\n  ASSERT_EQ(g.current_device(), dev(i2));\n  ASSERT_EQ(TestGuardImpl::getDeviceIndex(), i2);\n}",
            "{\n  DeviceIndex init_i = 0;\n  TestGuardImpl::setDeviceIndex(init_i);\n  DeviceIndex i = init_i + 1;\n  TestGuard g(i);\n  DeviceIndex i2 = init_i + 2;\n  g.set_index(i2);\n  ASSERT_EQ(g.original_device(), dev(init_i));\n  ASSERT_EQ(g.current_device(), dev(i2));\n  ASSERT_EQ(TestGuardImpl::getDeviceIndex(), i2);\n  g.set_index(i2);\n  ASSERT_EQ(g.original_device(), dev(init_i));\n  ASSERT_EQ(g.current_device(), dev(i2));\n  ASSERT_EQ(TestGuardImpl::getDeviceIndex(), i2);\n}",
            "{\n  for (DeviceIndex i : {-1, 0, 1}) {\n    DeviceIndex init_i = 0;\n    TestGuardImpl::setDeviceIndex(init_i);\n    auto test_body = [&](MaybeTestGuard& g) -> void {\n      ASSERT_EQ(g.original_device(), dev(init_i));\n      ASSERT_EQ(g.current_device(), dev(i == -1 ? init_i : i));\n      ASSERT_EQ(TestGuardImpl::getDeviceIndex(), i == -1 ? init_i : i);\n      // Test un-bracketed write to device index\n      TestGuardImpl::setDeviceIndex(4);\n    };\n    {\n      // Index constructor\n      MaybeTestGuard g(i);\n      test_body(g);\n    }\n    ASSERT_EQ(TestGuardImpl::getDeviceIndex(), init_i);\n    {\n      // Device constructor\n      MaybeTestGuard g(dev(i));\n      test_body(g);\n    }\n    ASSERT_EQ(TestGuardImpl::getDeviceIndex(), init_i);\n    {\n      // Optional constructor\n      MaybeTestGuard g(make_optional(dev(i)));\n      test_body(g);\n    }\n    ASSERT_EQ(TestGuardImpl::getDeviceIndex(), init_i);\n  }\n}",
            "{\n  DeviceIndex init_i = 0;\n  TestGuardImpl::setDeviceIndex(init_i);\n  auto test_body = [&](MaybeTestGuard& g) -> void {\n    ASSERT_EQ(g.original_device(), nullopt);\n    ASSERT_EQ(g.current_device(), nullopt);\n    ASSERT_EQ(TestGuardImpl::getDeviceIndex(), init_i);\n  };\n  {\n    MaybeTestGuard g;\n    test_body(g);\n  }\n  {\n    // If you want nullopt directly to work, define a nullopt_t\n    // overload.  But I don't really see why you'd want this lol.\n    optional<Device> dev_opt = nullopt;\n    MaybeTestGuard g(dev_opt);\n    test_body(g);\n  }\n}",
            "{\n  DeviceIndex init_i = 0;\n  TestGuardImpl::setDeviceIndex(init_i);\n  MaybeTestGuard g;\n  DeviceIndex i = init_i + 1;\n  g.set_device(dev(i));\n  ASSERT_EQ(g.original_device(), make_optional(dev(init_i)));\n  ASSERT_EQ(g.current_device(), make_optional(dev(i)));\n  ASSERT_EQ(TestGuardImpl::getDeviceIndex(), i);\n  g.set_device(dev(i));\n  ASSERT_EQ(g.original_device(), make_optional(dev(init_i)));\n  ASSERT_EQ(g.current_device(), make_optional(dev(i)));\n  ASSERT_EQ(TestGuardImpl::getDeviceIndex(), i);\n}",
            "{\n  DeviceIndex init_i = 0;\n  TestGuardImpl::setDeviceIndex(init_i);\n  DeviceIndex i = init_i + 1;\n  MaybeTestGuard g;\n  g.set_index(i);\n  ASSERT_EQ(g.original_device(), make_optional(dev(init_i)));\n  ASSERT_EQ(g.current_device(), make_optional(dev(i)));\n  ASSERT_EQ(TestGuardImpl::getDeviceIndex(), i);\n  g.set_index(i);\n  ASSERT_EQ(g.original_device(), make_optional(dev(init_i)));\n  ASSERT_EQ(g.current_device(), make_optional(dev(i)));\n  ASSERT_EQ(TestGuardImpl::getDeviceIndex(), i);\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/test/core/impl/InlineStreamGuard_test.cpp",
        "functions": [
            "Device",
            "Stream",
            "{\n  TestGuardImpl::setDeviceIndex(0);\n  TestGuardImpl::resetStreams();\n  {\n    TestGuard g(stream(1, 2));\n    ASSERT_EQ(TestGuardImpl::getDeviceIndex(), 1);\n    ASSERT_EQ(TestGuardImpl::getCurrentStreamIdFor(1), 2);\n    ASSERT_EQ(TestGuardImpl::getCurrentStreamIdFor(0), 0);\n    ASSERT_EQ(g.original_stream(), stream(0, 0));\n    ASSERT_EQ(g.current_stream(), stream(1, 2));\n    ASSERT_EQ(g.original_device(), dev(0));\n    ASSERT_EQ(g.current_device(), dev(1));\n  }\n  ASSERT_EQ(TestGuardImpl::getDeviceIndex(), 0);\n  ASSERT_EQ(TestGuardImpl::getCurrentStreamIdFor(1), 0);\n  ASSERT_EQ(TestGuardImpl::getCurrentStreamIdFor(0), 0);\n}",
            "{\n  TestGuardImpl::setDeviceIndex(0);\n  TestGuardImpl::resetStreams();\n  {\n    TestGuard g(stream(0, 2));\n    g.reset_stream(stream(0, 3));\n    ASSERT_EQ(TestGuardImpl::getDeviceIndex(), 0);\n    ASSERT_EQ(TestGuardImpl::getCurrentStreamIdFor(0), 3);\n    ASSERT_EQ(g.original_stream(), stream(0, 0));\n    ASSERT_EQ(g.current_stream(), stream(0, 3));\n    ASSERT_EQ(g.original_device(), dev(0));\n    ASSERT_EQ(g.current_device(), dev(0));\n  }\n  ASSERT_EQ(TestGuardImpl::getDeviceIndex(), 0);\n  ASSERT_EQ(TestGuardImpl::getCurrentStreamIdFor(0), 0);\n}",
            "{\n  TestGuardImpl::setDeviceIndex(0);\n  TestGuardImpl::resetStreams();\n  {\n    TestGuard g(stream(1, 2));\n    g.reset_stream(stream(1, 3));\n    ASSERT_EQ(TestGuardImpl::getDeviceIndex(), 1);\n    ASSERT_EQ(TestGuardImpl::getCurrentStreamIdFor(1), 3);\n    ASSERT_EQ(TestGuardImpl::getCurrentStreamIdFor(0), 0);\n    ASSERT_EQ(g.original_stream(), stream(0, 0));\n    ASSERT_EQ(g.current_stream(), stream(1, 3));\n    ASSERT_EQ(g.original_device(), dev(0));\n    ASSERT_EQ(g.current_device(), dev(1));\n  }\n  ASSERT_EQ(TestGuardImpl::getDeviceIndex(), 0);\n  ASSERT_EQ(TestGuardImpl::getCurrentStreamIdFor(1), 0);\n  ASSERT_EQ(TestGuardImpl::getCurrentStreamIdFor(0), 0);\n}",
            "{\n  TestGuardImpl::setDeviceIndex(0);\n  TestGuardImpl::resetStreams();\n  {\n    TestGuard g(stream(1, 2));\n    g.reset_stream(stream(2, 3));\n    ASSERT_EQ(TestGuardImpl::getDeviceIndex(), 2);\n    ASSERT_EQ(TestGuardImpl::getCurrentStreamIdFor(2), 3);\n    ASSERT_EQ(TestGuardImpl::getCurrentStreamIdFor(1), 0);\n    ASSERT_EQ(TestGuardImpl::getCurrentStreamIdFor(0), 0);\n    ASSERT_EQ(g.original_stream(), stream(0, 0));\n    ASSERT_EQ(g.current_stream(), stream(2, 3));\n    ASSERT_EQ(g.original_device(), dev(0));\n    ASSERT_EQ(g.current_device(), dev(2));\n  }\n  ASSERT_EQ(TestGuardImpl::getDeviceIndex(), 0);\n  ASSERT_EQ(TestGuardImpl::getCurrentStreamIdFor(2), 0);\n  ASSERT_EQ(TestGuardImpl::getCurrentStreamIdFor(1), 0);\n  ASSERT_EQ(TestGuardImpl::getCurrentStreamIdFor(0), 0);\n}",
            "{\n  TestGuardImpl::setDeviceIndex(0);\n  TestGuardImpl::resetStreams();\n  {\n    OptionalTestGuard g(stream(1, 2));\n    ASSERT_EQ(TestGuardImpl::getDeviceIndex(), 1);\n    ASSERT_EQ(TestGuardImpl::getCurrentStreamIdFor(1), 2);\n    ASSERT_EQ(TestGuardImpl::getCurrentStreamIdFor(0), 0);\n    ASSERT_EQ(g.original_stream(), make_optional(stream(0, 0)));\n    ASSERT_EQ(g.current_stream(), make_optional(stream(1, 2)));\n  }\n  ASSERT_EQ(TestGuardImpl::getDeviceIndex(), 0);\n  ASSERT_EQ(TestGuardImpl::getCurrentStreamIdFor(1), 0);\n  ASSERT_EQ(TestGuardImpl::getCurrentStreamIdFor(0), 0);\n  {\n    OptionalTestGuard g(make_optional(stream(1, 2)));\n    ASSERT_EQ(TestGuardImpl::getDeviceIndex(), 1);\n    ASSERT_EQ(TestGuardImpl::getCurrentStreamIdFor(1), 2);\n    ASSERT_EQ(TestGuardImpl::getCurrentStreamIdFor(0), 0);\n    ASSERT_EQ(g.original_stream(), make_optional(stream(0, 0)));\n    ASSERT_EQ(g.current_stream(), make_optional(stream(1, 2)));\n  }\n  ASSERT_EQ(TestGuardImpl::getDeviceIndex(), 0);\n  ASSERT_EQ(TestGuardImpl::getCurrentStreamIdFor(1), 0);\n  ASSERT_EQ(TestGuardImpl::getCurrentStreamIdFor(0), 0);\n  {\n    OptionalTestGuard g;\n    ASSERT_EQ(TestGuardImpl::getDeviceIndex(), 0);\n    ASSERT_EQ(TestGuardImpl::getCurrentStreamIdFor(1), 0);\n    ASSERT_EQ(TestGuardImpl::getCurrentStreamIdFor(0), 0);\n  }\n  ASSERT_EQ(TestGuardImpl::getDeviceIndex(), 0);\n  ASSERT_EQ(TestGuardImpl::getCurrentStreamIdFor(1), 0);\n  ASSERT_EQ(TestGuardImpl::getCurrentStreamIdFor(0), 0);\n}",
            "{\n  TestGuardImpl::setDeviceIndex(0);\n  TestGuardImpl::resetStreams();\n  {\n    OptionalTestGuard g;\n    g.reset_stream(stream(1, 3));\n    ASSERT_EQ(TestGuardImpl::getDeviceIndex(), 1);\n    ASSERT_EQ(TestGuardImpl::getCurrentStreamIdFor(1), 3);\n    ASSERT_EQ(TestGuardImpl::getCurrentStreamIdFor(0), 0);\n    ASSERT_EQ(g.original_stream(), make_optional(stream(0, 0)));\n    ASSERT_EQ(g.current_stream(), make_optional(stream(1, 3)));\n  }\n  ASSERT_EQ(TestGuardImpl::getDeviceIndex(), 0);\n  ASSERT_EQ(TestGuardImpl::getCurrentStreamIdFor(1), 0);\n  ASSERT_EQ(TestGuardImpl::getCurrentStreamIdFor(0), 0);\n}",
            "{\n  TestGuardImpl::setDeviceIndex(0);\n  TestGuardImpl::resetStreams();\n  {\n    OptionalTestGuard g;\n    g.reset_stream(stream(2, 3));\n    ASSERT_EQ(TestGuardImpl::getDeviceIndex(), 2);\n    ASSERT_EQ(TestGuardImpl::getCurrentStreamIdFor(2), 3);\n    ASSERT_EQ(TestGuardImpl::getCurrentStreamIdFor(1), 0);\n    ASSERT_EQ(TestGuardImpl::getCurrentStreamIdFor(0), 0);\n    ASSERT_EQ(g.original_stream(), make_optional(stream(0, 0)));\n    ASSERT_EQ(g.current_stream(), make_optional(stream(2, 3)));\n  }\n  ASSERT_EQ(TestGuardImpl::getDeviceIndex(), 0);\n  ASSERT_EQ(TestGuardImpl::getCurrentStreamIdFor(2), 0);\n  ASSERT_EQ(TestGuardImpl::getCurrentStreamIdFor(1), 0);\n  ASSERT_EQ(TestGuardImpl::getCurrentStreamIdFor(0), 0);\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/test/core/impl/SizesAndStrides_test.cpp",
        "functions": [
            "void",
            "{\n  SizesAndStrides sz;\n  checkData(sz, {0}, {1});\n  // Can't test size_at() out of bounds because it just asserts for now.\n}",
            "{\n  SizesAndStrides sz;\n  sz.set_sizes({5, 6, 7, 8});\n  checkData(sz, {5, 6, 7, 8}, {1, 0, 0, 0});\n}",
            "{\n  SizesAndStrides sz;\n\n  sz.resize(2);\n\n  // Small to small growing.\n  checkData(sz, {0, 0}, {1, 0});\n\n  // Small to small growing, again.\n  sz.resize(5);\n  checkData(sz, {0, 0, 0, 0, 0}, {1, 0, 0, 0, 0});\n\n  for (int ii = 0; ii < sz.size(); ++ii) {\n    sz.size_at_unchecked(ii) = ii + 1;\n    sz.stride_at_unchecked(ii) = 2 * (ii + 1);\n  }\n\n  checkData(sz, {1, 2, 3, 4, 5}, {2, 4, 6, 8, 10});\n\n  // Small to small, shrinking.\n  sz.resize(4);\n  checkData(sz, {1, 2, 3, 4}, {2, 4, 6, 8});\n\n  // Small to small with no size change.\n  sz.resize(4);\n  checkData(sz, {1, 2, 3, 4}, {2, 4, 6, 8});\n\n  // Small to small, growing back so that we can confirm that our \"new\"\n  // data really does get zeroed.\n  sz.resize(5);\n  checkData(sz, {1, 2, 3, 4, 0}, {2, 4, 6, 8, 0});\n\n  // Small to big.\n  sz.resize(6);\n\n  checkData(sz, {1, 2, 3, 4, 0, 0}, {2, 4, 6, 8, 0, 0});\n\n  sz.size_at_unchecked(5) = 6;\n  sz.stride_at_unchecked(5) = 12;\n\n  checkData(sz, {1, 2, 3, 4, 0, 6}, {2, 4, 6, 8, 0, 12});\n\n  // Big to big, growing.\n  sz.resize(7);\n\n  checkData(sz, {1, 2, 3, 4, 0, 6, 0}, {2, 4, 6, 8, 0, 12, 0});\n\n  // Big to big with no size change.\n  sz.resize(7);\n\n  checkData(sz, {1, 2, 3, 4, 0, 6, 0}, {2, 4, 6, 8, 0, 12, 0});\n\n  sz.size_at_unchecked(6) = 11;\n  sz.stride_at_unchecked(6) = 22;\n\n  checkData(sz, {1, 2, 3, 4, 0, 6, 11}, {2, 4, 6, 8, 0, 12, 22});\n\n  // Big to big, shrinking.\n  sz.resize(6);\n  checkData(sz, {1, 2, 3, 4, 0, 6}, {2, 4, 6, 8, 0, 12});\n\n  // Grow back to make sure \"new\" elements get zeroed in big mode too.\n  sz.resize(7);\n  checkData(sz, {1, 2, 3, 4, 0, 6, 0}, {2, 4, 6, 8, 0, 12, 0});\n\n  // Finally, big to small.\n\n  // Give it different data than it had when it was small to avoid\n  // getting it right by accident (i.e., because of leftover inline\n  // storage when going small to big).\n  for (int ii = 0; ii < sz.size(); ++ii) {\n    sz.size_at_unchecked(ii) = ii - 1;\n    sz.stride_at_unchecked(ii) = 2 * (ii - 1);\n  }\n\n  checkData(sz, {-1, 0, 1, 2, 3, 4, 5}, {-2, 0, 2, 4, 6, 8, 10});\n\n  sz.resize(5);\n  checkData(sz, {-1, 0, 1, 2, 3}, {-2, 0, 2, 4, 6});\n}",
            "{\n  SizesAndStrides sz;\n\n  sz.resize(5);\n  sz.size_at(4) = 42;\n  sz.stride_at(4) = 23;\n\n  checkData(sz, {0, 0, 0, 0, 42}, {1, 0, 0, 0, 23});\n\n  sz.resize(6);\n  sz.size_at(5) = 43;\n  sz.stride_at(5) = 24;\n\n  checkData(sz, {0, 0, 0, 0, 42, 43}, {1, 0, 0, 0, 23, 24});\n}",
            "{\n  SizesAndStrides sz;\n\n  sz.resize(5);\n  *(sz.sizes_begin() + 4) = 42;\n  *(sz.strides_begin() + 4) = 23;\n\n  checkData(sz, {0, 0, 0, 0, 42}, {1, 0, 0, 0, 23});\n\n  sz.resize(6);\n  *(sz.sizes_begin() + 5) = 43;\n  *(sz.strides_begin() + 5) = 24;\n\n  checkData(sz, {0, 0, 0, 0, 42, 43}, {1, 0, 0, 0, 23, 24});\n}",
            "{\n  SizesAndStrides sz;\n\n  sz.resize(5);\n  *(sz.sizes_data() + 4) = 42;\n  *(sz.strides_data() + 4) = 23;\n\n  checkData(sz, {0, 0, 0, 0, 42}, {1, 0, 0, 0, 23});\n\n  sz.resize(6);\n  *(sz.sizes_data() + 5) = 43;\n  *(sz.strides_data() + 5) = 24;\n\n  checkData(sz, {0, 0, 0, 0, 42, 43}, {1, 0, 0, 0, 23, 24});\n}",
            "SizesAndStrides",
            "SizesAndStrides",
            "void",
            "void",
            "{\n  SizesAndStrides empty;\n\n  SizesAndStrides movedEmpty(std::move(empty));\n\n  EXPECT_EQ(empty.size(), 0);\n  EXPECT_EQ(movedEmpty.size(), 1);\n  checkData(movedEmpty, {0}, {1});\n\n  SizesAndStrides small = makeSmall();\n  checkSmall(small);\n\n  SizesAndStrides movedSmall(std::move(small));\n  checkSmall(movedSmall);\n  EXPECT_EQ(small.size(), 0);\n\n  SizesAndStrides big = makeBig();\n  checkBig(big);\n\n  SizesAndStrides movedBig(std::move(big));\n  checkBig(movedBig);\n  EXPECT_EQ(big.size(), 0);\n}",
            "{\n  SizesAndStrides empty;\n\n  SizesAndStrides copiedEmpty(empty);\n\n  EXPECT_EQ(empty.size(), 1);\n  EXPECT_EQ(copiedEmpty.size(), 1);\n  checkData(empty, {0}, {1});\n  checkData(copiedEmpty, {0}, {1});\n\n  SizesAndStrides small = makeSmall();\n  checkSmall(small);\n\n  SizesAndStrides copiedSmall(small);\n  checkSmall(copiedSmall);\n  checkSmall(small);\n\n  SizesAndStrides big = makeBig();\n  checkBig(big);\n\n  SizesAndStrides copiedBig(big);\n  checkBig(big);\n  checkBig(copiedBig);\n}",
            "{\n  SizesAndStrides smallTarget = makeSmall();\n  SizesAndStrides smallCopyFrom = makeSmall(1);\n\n  checkSmall(smallTarget);\n  checkSmall(smallCopyFrom, 1);\n\n  smallTarget = smallCopyFrom;\n\n  checkSmall(smallTarget, 1);\n  checkSmall(smallCopyFrom, 1);\n}",
            "{\n  SizesAndStrides smallTarget = makeSmall();\n  SizesAndStrides smallMoveFrom = makeSmall(1);\n\n  checkSmall(smallTarget);\n  checkSmall(smallMoveFrom, 1);\n\n  smallTarget = std::move(smallMoveFrom);\n\n  checkSmall(smallTarget, 1);\n  EXPECT_EQ(smallMoveFrom.size(), 0);\n}",
            "{\n  SizesAndStrides bigTarget = makeBig();\n  SizesAndStrides smallCopyFrom = makeSmall();\n\n  checkBig(bigTarget);\n  checkSmall(smallCopyFrom);\n\n  bigTarget = smallCopyFrom;\n\n  checkSmall(bigTarget);\n  checkSmall(smallCopyFrom);\n}",
            "{\n  SizesAndStrides bigTarget = makeBig();\n  SizesAndStrides smallMoveFrom = makeSmall();\n\n  checkBig(bigTarget);\n  checkSmall(smallMoveFrom);\n\n  bigTarget = std::move(smallMoveFrom);\n\n  checkSmall(bigTarget);\n  EXPECT_EQ(smallMoveFrom.size(), 0);\n}",
            "{\n  SizesAndStrides bigTarget = makeBig();\n  SizesAndStrides bigCopyFrom = makeBig(1);\n\n  checkBig(bigTarget);\n  checkBig(bigCopyFrom, 1);\n\n  bigTarget = bigCopyFrom;\n\n  checkBig(bigTarget, 1);\n  checkBig(bigCopyFrom, 1);\n}",
            "{\n  SizesAndStrides bigTarget = makeBig();\n  SizesAndStrides bigMoveFrom = makeBig(1);\n\n  checkBig(bigTarget);\n  checkBig(bigMoveFrom, 1);\n\n  bigTarget = std::move(bigMoveFrom);\n\n  checkBig(bigTarget, 1);\n  EXPECT_EQ(bigMoveFrom.size(), 0);\n}",
            "{\n  SizesAndStrides smallTarget = makeSmall();\n  SizesAndStrides bigCopyFrom = makeBig();\n\n  checkSmall(smallTarget);\n  checkBig(bigCopyFrom);\n\n  smallTarget = bigCopyFrom;\n\n  checkBig(smallTarget);\n  checkBig(bigCopyFrom);\n}",
            "{\n  SizesAndStrides smallTarget = makeSmall();\n  SizesAndStrides bigMoveFrom = makeBig();\n\n  checkSmall(smallTarget);\n  checkBig(bigMoveFrom);\n\n  smallTarget = std::move(bigMoveFrom);\n\n  checkBig(smallTarget);\n  EXPECT_EQ(bigMoveFrom.size(), 0);\n}",
            "{\n  SizesAndStrides small = makeSmall();\n  SizesAndStrides big = makeBig();\n\n  checkSmall(small);\n  checkBig(big);\n\n  small = small;\n  checkSmall(small);\n\n  big = big;\n  checkBig(big);\n}",
            "void",
            "{\n  SizesAndStrides small = makeSmall();\n  SizesAndStrides big = makeBig();\n\n  checkSmall(small);\n  checkBig(big);\n\n  selfMove(small, small);\n  checkSmall(small);\n\n  selfMove(big, big);\n  checkBig(big);\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/test/util/accumulate_test.cpp",
        "functions": [
            "{\n    std::vector<int> ints = {1, 2, 3, 4, 5};\n\n    EXPECT_EQ(c10::sum_integers(ints), 1+2+3+4+5);\n    EXPECT_EQ(c10::multiply_integers(ints), 1*2*3*4*5);\n\n    EXPECT_EQ(c10::sum_integers(ints.begin(), ints.end()), 1+2+3+4+5);\n    EXPECT_EQ(c10::multiply_integers(ints.begin(), ints.end()), 1*2*3*4*5);\n\n    EXPECT_EQ(c10::sum_integers(ints.begin()+1, ints.end()-1), 2+3+4);\n    EXPECT_EQ(c10::multiply_integers(ints.begin()+1, ints.end()-1), 2*3*4);\n\n    EXPECT_EQ(c10::numelements_from_dim(2, ints), 3*4*5);\n    EXPECT_EQ(c10::numelements_to_dim(3, ints), 1*2*3);\n    EXPECT_EQ(c10::numelements_between_dim(2, 4, ints), 3*4);\n    EXPECT_EQ(c10::numelements_between_dim(4, 2, ints), 3*4);\n}",
            "{\n    std::list<int> ints = {1, 2, 3, 4, 5};\n\n    EXPECT_EQ(c10::sum_integers(ints), 1+2+3+4+5);\n    EXPECT_EQ(c10::multiply_integers(ints), 1*2*3*4*5);\n\n    EXPECT_EQ(c10::sum_integers(ints.begin(), ints.end()), 1+2+3+4+5);\n    EXPECT_EQ(c10::multiply_integers(ints.begin(), ints.end()), 1*2*3*4*5);\n\n    EXPECT_EQ(c10::numelements_from_dim(2, ints), 3*4*5);\n    EXPECT_EQ(c10::numelements_to_dim(3, ints), 1*2*3);\n    EXPECT_EQ(c10::numelements_between_dim(2, 4, ints), 3*4);\n    EXPECT_EQ(c10::numelements_between_dim(4, 2, ints), 3*4);\n}",
            "{\n    std::vector<int> ints = {};\n\n    EXPECT_EQ(c10::sum_integers(ints), 0);\n    EXPECT_EQ(c10::multiply_integers(ints), 1);\n}",
            "{\n    std::vector<int> ints = {1,2,3,4,5};\n\n    #ifndef NDEBUG\n    EXPECT_THROW(c10::numelements_from_dim(-1, ints), c10::Error);\n    #endif\n\n    EXPECT_THROW(c10::numelements_to_dim(-1, ints), c10::Error);\n    EXPECT_THROW(c10::numelements_between_dim(-1, 10, ints), c10::Error);\n    EXPECT_THROW(c10::numelements_between_dim(10, -1, ints), c10::Error);\n\n    EXPECT_EQ(c10::numelements_from_dim(10, ints),1);\n    EXPECT_THROW(c10::numelements_to_dim(10, ints), c10::Error);\n    EXPECT_THROW(c10::numelements_between_dim(10, 4, ints), c10::Error);\n    EXPECT_THROW(c10::numelements_between_dim(4, 10, ints), c10::Error);\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/test/util/Array_test.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/test/util/bfloat16_test.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/test/util/Bitset_test.cpp",
        "functions": [
            "{\n  bitset b;\n  for (size_t i = 0; i < bitset::NUM_BITS(); ++i) {\n    EXPECT_FALSE(b.get(i));\n  }\n}",
            "{\n  bitset b;\n  b.unset(4);\n  for (size_t i = 0; i < bitset::NUM_BITS(); ++i) {\n    EXPECT_FALSE(b.get(i));\n  }\n}",
            "{\n  bitset b;\n  b.set(4);\n  b.unset(4);\n  for (size_t i = 0; i < bitset::NUM_BITS(); ++i) {\n    EXPECT_FALSE(b.get(i));\n  }\n}",
            "{\n  bitset b;\n  b.set(6);\n  EXPECT_TRUE(b.get(6));\n}",
            "{\n  bitset b;\n  b.set(6);\n  for (size_t i = 0; i < 6; ++i) {\n    EXPECT_FALSE(b.get(i));\n  }\n  for (size_t i = 7; i < bitset::NUM_BITS(); ++i) {\n    EXPECT_FALSE(b.get(i));\n  }\n}",
            "{\n  bitset b;\n  b.set(6);\n  b.set(30);\n  EXPECT_TRUE(b.get(30));\n}",
            "{\n  bitset b;\n  b.set(6);\n  b.set(30);\n  for (size_t i = 0; i < 6; ++i) {\n    EXPECT_FALSE(b.get(i));\n  }\n  for (size_t i = 7; i < 30; ++i) {\n    EXPECT_FALSE(b.get(i));\n  }\n  for (size_t i = 31; i < bitset::NUM_BITS(); ++i) {\n    EXPECT_FALSE(b.get(i));\n  }\n}",
            "{\n  bitset b;\n  b.set(6);\n  b.set(30);\n  b.unset(6);\n  EXPECT_FALSE(b.get(6));\n}",
            "{\n  bitset b;\n  b.set(6);\n  b.set(30);\n  b.unset(6);\n  for (size_t i = 0; i < 30; ++i) {\n    EXPECT_FALSE(b.get(i));\n  }\n  EXPECT_TRUE(b.get(30));\n  for (size_t i = 31; i < bitset::NUM_BITS(); ++i) {\n    EXPECT_FALSE(b.get(i));\n  }\n}",
            "{\n  IndexCallbackMock callback;\n  bitset b;\n  b.for_each_set_bit(callback);\n  callback.expect_was_called_for_indices({});\n}",
            "{\n  IndexCallbackMock callback;\n  bitset b;\n  b.set(5);\n  b.for_each_set_bit(callback);\n  callback.expect_was_called_for_indices({5});\n}",
            "{\n  IndexCallbackMock callback;\n  bitset b;\n  b.set(5);\n  b.set(2);\n  b.set(25);\n  b.set(32);\n  b.set(50);\n  b.set(0);\n  b.unset(25);\n  b.set(10);\n  b.for_each_set_bit(callback);\n  callback.expect_was_called_for_indices({0, 2, 5, 10, 32, 50});\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/test/util/C++17_test.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/test/util/complex_math_test.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/test/util/complex_test.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/test/util/ConstexprCrc_test.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/test/util/either_test.cpp",
        "functions": [
            "{\n    TestSpaceUsage<char, int>();\n    TestSpaceUsage<int, short>();\n    TestSpaceUsage<char, short>();\n    TestSpaceUsage<int, string>();\n    TestSpaceUsage<string, vector<string>>();\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<int, string>&)> test) {\n        either<int, string> a(4);\n        test(a);\n      }, [] (std::function<void(either<int, string>&)> test) {\n        either<int, string> a = 4;\n        test(a);\n      },\n    },\n    EXPECT_IS_LEFT<int, string>(4)\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<int, string>&)> test) {\n        either<int, string> a(\"4\");\n        test(a);\n      }, [] (std::function<void(either<int, string>&)> test) {\n        either<int, string> a = string(\"4\");\n        test(a);\n      }\n    },\n    EXPECT_IS_RIGHT<int, string>(\"4\")\n  );\n}",
            "{\n    test_with_matrix({\n      [] (std::function<void(either<int, string>&)> test) {\n        either<int, string> a = make_left<int, string>(4);\n        test(a);\n      }, [] (std::function<void(either<int, string>&)> test) {\n        auto a = make_left<int, string>(4);\n        test(a);\n      },\n    },\n    EXPECT_IS_LEFT<int, string>(4)\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<int, int>&)> test) {\n        either<int, int> a = make_left<int, int>(4);\n        test(a);\n      }, [] (std::function<void(either<int, int>&)> test) {\n        auto a = make_left<int, int>(4);\n        test(a);\n      },\n    },\n    EXPECT_IS_LEFT<int, int>(4)\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<int, string>&)> test) {\n        either<int, string> a = make_right<int, string>(\"4\");\n        test(a);\n      }, [] (std::function<void(either<int, string>&)> test) {\n        auto a = make_right<int, string>(\"4\");\n        test(a);\n      }\n    },\n    EXPECT_IS_RIGHT<int, string>(\"4\")\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<string, string>&)> test) {\n        either<string, string> a = make_right<string, string>(\"4\");\n        test(a);\n      }, [] (std::function<void(either<string, string>&)> test) {\n        auto a = make_right<string, string>(\"4\");\n        test(a);\n      }\n    },\n    EXPECT_IS_RIGHT<string, string>(\"4\")\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<MovableOnly, string>&)> test) {\n        either<MovableOnly, string> a = make_left<MovableOnly, string>(3);\n        test(a);\n      }, [] (std::function<void(either<MovableOnly, string>&)> test) {\n        auto a = make_left<MovableOnly, string>(3);\n        test(a);\n      },\n    },\n    EXPECT_IS_LEFT<MovableOnly, string>(MovableOnly(3))\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<int, MovableOnly>&)> test) {\n        either<int, MovableOnly> a = make_right<int, MovableOnly>(3);\n        test(a);\n      }, [] (std::function<void(either<int, MovableOnly>&)> test) {\n        auto a = make_right<int, MovableOnly>(3);\n        test(a);\n      }\n    },\n    EXPECT_IS_RIGHT<int, MovableOnly>(MovableOnly(3))\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<pair<int, int>, string>&)> test) {\n        either<pair<int, int>, string> a = make_left<pair<int, int>, string>(5, 6);\n        test(a);\n      }, [] (std::function<void(either<pair<int, int>, string>&)> test) {\n        auto a = make_left<pair<int, int>, string>(5, 6);\n        test(a);\n      },\n    },\n    EXPECT_IS_LEFT<pair<int, int>, string>(pair<int, int>(5, 6))\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<int, pair<int, int>>&)> test) {\n        either<int, pair<int, int>> a = make_right<int, pair<int, int>>(5, 6);\n        test(a);\n      }, [] (std::function<void(either<int, pair<int, int>>&)> test) {\n        auto a = make_right<int, pair<int, int>>(5, 6);\n        test(a);\n      }\n    },\n    EXPECT_IS_RIGHT<int, pair<int, int>>(pair<int, int>(5, 6))\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<string, int>&)> test) {\n        string a = \"4\";\n        either<string, int> b(a);\n        test(b);\n      }\n    },\n    EXPECT_IS_LEFT<string, int>(\"4\")\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(string&)> test) {\n        string a = \"4\";\n        either<string, int> b(a);\n        test(a);\n      }\n    },\n    EXPECT_IS<string>(\"4\")\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<int, string>&)> test) {\n        string a = \"4\";\n        either<int, string> b(a);\n        test(b);\n      }\n    },\n    EXPECT_IS_RIGHT<int, string>(\"4\")\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(string&)> test) {\n        string a = \"4\";\n        either<int, string> b(a);\n        test(a);\n      }\n    },\n    EXPECT_IS<string>(\"4\")\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<MovableOnly, int>&)> test) {\n        MovableOnly a(3);\n        either<MovableOnly, int> b(std::move(a));\n        test(b);\n      }\n    },\n    EXPECT_IS_LEFT<MovableOnly, int>(MovableOnly(3))\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(MovableOnly&)> test) {\n        MovableOnly a(3);\n        either<MovableOnly, int> b(std::move(a));\n        test(a);  // NOLINT(bugprone-use-after-move)\n      }\n    },\n    EXPECT_IS<MovableOnly>(MovableOnly(0))  // 0 is moved-from value\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<int, MovableOnly>&)> test) {\n        MovableOnly a(3);\n        either<int, MovableOnly> b(std::move(a));\n        test(b);\n      }\n    },\n    EXPECT_IS_RIGHT<int, MovableOnly>(MovableOnly(3))\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(MovableOnly&)> test) {\n        MovableOnly a(3);\n        either<int, MovableOnly> b(std::move(a));\n        test(a);  // NOLINT(bugprone-use-after-move)\n      }\n    },\n    EXPECT_IS<MovableOnly>(MovableOnly(0))  // 0 is moved-from value\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<string, int>&)> test) {\n        string a = \"4\";\n        either<string, int> b(2);\n        b = a;\n        test(b);\n      }, [] (std::function<void(either<string, int>&)> test) {\n        string a = \"4\";\n        either<string, int> b(\"2\");\n        b = a;\n        test(b);\n      }\n    },\n    EXPECT_IS_LEFT<string, int>(\"4\")\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(string&)> test) {\n        string a = \"4\";\n        either<string, int> b(2);\n        b = a;\n        test(a);\n      }, [] (std::function<void(string&)> test) {\n        string a = \"4\";\n        either<string, int> b(\"2\");\n        b = a;\n        test(a);\n      }\n    },\n    EXPECT_IS<string>(\"4\")\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<int, string>&)> test) {\n        string a = \"4\";\n        either<int, string> b(2);\n        b = a;\n        test(b);\n      }, [] (std::function<void(either<int, string>&)> test) {\n        string a = \"4\";\n        either<int, string> b(\"2\");\n        b = a;\n        test(b);\n      }\n    },\n    EXPECT_IS_RIGHT<int, string>(\"4\")\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(string&)> test) {\n        string a = \"4\";\n        either<int, string> b(2);\n        b = a;\n        test(a);\n      }, [] (std::function<void(string&)> test) {\n        string a = \"4\";\n        either<int, string> b(\"2\");\n        b = a;\n        test(a);\n      }\n    },\n    EXPECT_IS<string>(\"4\")\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<MovableOnly, string>&)> test) {\n        MovableOnly a(3);\n        either<MovableOnly, string> b(2);\n        b = std::move(a);\n        test(b);\n      }, [] (std::function<void(either<MovableOnly, string>&)> test) {\n        MovableOnly a(3);\n        either<MovableOnly, string> b(MovableOnly(2));\n        b = std::move(a);\n        test(b);\n      }\n    },\n    EXPECT_IS_LEFT<MovableOnly, string>(MovableOnly(3))\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(MovableOnly&)> test) {\n        MovableOnly a(3);\n        either<MovableOnly, string> b(\"2\");\n        b = std::move(a);\n        test(a);  // NOLINT(bugprone-use-after-move)\n      }, [] (std::function<void(MovableOnly&)> test) {\n        MovableOnly a(3);\n        either<MovableOnly, string> b(MovableOnly(0));\n        b = std::move(a);\n        test(a);  // NOLINT(bugprone-use-after-move)\n      }\n    },\n    EXPECT_IS<MovableOnly>(MovableOnly(0))\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<string, MovableOnly>&)> test) {\n        MovableOnly a(3);\n        either<string, MovableOnly> b(\"2\");\n        b = std::move(a);\n        test(b);\n      }, [] (std::function<void(either<string, MovableOnly>&)> test) {\n        MovableOnly a(3);\n        either<string, MovableOnly> b(MovableOnly(2));\n        b = std::move(a);\n        test(b);\n      }\n    },\n    EXPECT_IS_RIGHT<string, MovableOnly>(MovableOnly(3))\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(MovableOnly&)> test) {\n        MovableOnly a(3);\n        either<string, MovableOnly> b(\"2\");\n        b = std::move(a);\n        test(a);  // NOLINT(bugprone-use-after-move)\n      }, [] (std::function<void(MovableOnly&)> test) {\n        MovableOnly a(3);\n        either<string, MovableOnly> b(MovableOnly(2));\n        b = std::move(a);\n        test(a);  // NOLINT(bugprone-use-after-move)\n      }\n    },\n    EXPECT_IS<MovableOnly>(MovableOnly(0))  // 0 is moved-from value\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<string, int>&)> test) {\n        either<string, int> a(\"4\");\n        either<string, int> b(a);\n        test(b);\n      }\n    },\n    EXPECT_IS_LEFT<string, int>(\"4\")\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<string, int>&)> test) {\n        either<string, int> a(\"4\");\n        either<string, int> b(a);\n        test(a);\n      }\n    },\n    EXPECT_IS_LEFT<string, int>(\"4\")\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<string, string>&)> test) {\n        either<string, string> a = make_left<string, string>(\"4\");\n        either<string, string> b(a);\n        test(b);\n      }\n    },\n    EXPECT_IS_LEFT<string, string>(\"4\")\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<string, string>&)> test) {\n        either<string, string> a = make_left<string, string>(\"4\");\n        either<string, string> b(a);\n        test(a);\n      }\n    },\n    EXPECT_IS_LEFT<string, string>(\"4\")\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<int, string>&)> test) {\n        either<int, string> a(\"4\");\n        either<int, string> b(a);\n        test(b);\n      }\n    },\n    EXPECT_IS_RIGHT<int, string>(\"4\")\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<int, string>&)> test) {\n        either<int, string> a(\"4\");\n        either<int, string> b(a);\n        test(a);\n      }\n    },\n    EXPECT_IS_RIGHT<int, string>(\"4\")\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<string, string>&)> test) {\n        either<string, string> a = make_right<string, string>(\"4\");\n        either<string, string> b(a);\n        test(b);\n      }\n    },\n    EXPECT_IS_RIGHT<string, string>(\"4\")\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<string, string>&)> test) {\n        either<string, string> a = make_right<string, string>(\"4\");\n        either<string, string> b(a);\n        test(a);\n      }\n    },\n    EXPECT_IS_RIGHT<string, string>(\"4\")\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<MovableOnly, int>&)> test) {\n        either<MovableOnly, int> a(MovableOnly(3));\n        either<MovableOnly, int> b(std::move(a));\n        test(b);\n      }\n    },\n    EXPECT_IS_LEFT<MovableOnly, int>(MovableOnly(3))\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<MovableOnly, int>&)> test) {\n        either<MovableOnly, int> a(MovableOnly(3));\n        either<MovableOnly, int> b(std::move(a));\n        test(a);  // NOLINT(bugprone-use-after-move)\n      }\n    },\n    EXPECT_IS_LEFT<MovableOnly, int>(MovableOnly(0))  // 0 is moved-from value\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<MovableOnly, MovableOnly>&)> test) {\n        either<MovableOnly, MovableOnly> a = make_left<MovableOnly, MovableOnly>(MovableOnly(3));\n        either<MovableOnly, MovableOnly> b(std::move(a));\n        test(b);\n      }\n    },\n    EXPECT_IS_LEFT<MovableOnly, MovableOnly>(MovableOnly(3))\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<MovableOnly, MovableOnly>&)> test) {\n        either<MovableOnly, MovableOnly> a = make_left<MovableOnly, MovableOnly>(MovableOnly(3));\n        either<MovableOnly, MovableOnly> b(std::move(a));\n        test(a);  // NOLINT(bugprone-use-after-move)\n      }\n    },\n    EXPECT_IS_LEFT<MovableOnly, MovableOnly>(MovableOnly(0))  // 0 is moved-from value\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<int, MovableOnly>&)> test) {\n        either<int, MovableOnly> a(MovableOnly(3));\n        either<int, MovableOnly> b(std::move(a));\n        test(b);\n      }\n    },\n    EXPECT_IS_RIGHT<int, MovableOnly>(MovableOnly(3))\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<int, MovableOnly>&)> test) {\n        either<int, MovableOnly> a(MovableOnly(3));\n        either<int, MovableOnly> b(std::move(a));\n        test(a);  // NOLINT(bugprone-use-after-move)\n      }\n    },\n    EXPECT_IS_RIGHT<int, MovableOnly>(MovableOnly(0))  // 0 is moved-from value\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<MovableOnly, MovableOnly>&)> test) {\n        either<MovableOnly, MovableOnly> a = make_right<MovableOnly, MovableOnly>(MovableOnly(3));\n        either<MovableOnly, MovableOnly> b(std::move(a));\n        test(b);\n      }\n    },\n    EXPECT_IS_RIGHT<MovableOnly, MovableOnly>(MovableOnly(3))\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<MovableOnly, MovableOnly>&)> test) {\n        either<MovableOnly, MovableOnly> a = make_right<MovableOnly, MovableOnly>(MovableOnly(3));\n        either<MovableOnly, MovableOnly> b(std::move(a));\n        test(a);  // NOLINT(bugprone-use-after-move)\n      }\n    },\n    EXPECT_IS_RIGHT<MovableOnly, MovableOnly>(MovableOnly(0))  // 0 is moved-from value\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<string, int>&)> test) {\n        either<string, int> a(\"4\");\n        either<string, int> b(2);\n        b = a;\n        test(b);\n      }, [] (std::function<void(either<string, int>&)> test) {\n        either<string, int> a(\"4\");\n        either<string, int> b(\"2\");\n        b = a;\n        test(b);\n      }\n    },\n    EXPECT_IS_LEFT<string, int>(\"4\")\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<string, int>&)> test) {\n        either<string, int> a(\"4\");\n        either<string, int> b(2);\n        b = a;\n        test(a);\n      }, [] (std::function<void(either<string, int>&)> test) {\n        either<string, int> a(\"4\");\n        either<string, int> b(\"2\");\n        b = a;\n        test(a);\n      }\n    },\n    EXPECT_IS_LEFT<string, int>(\"4\")\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<string, string>&)> test) {\n        either<string, string> a = make_left<string, string>(\"4\");\n        either<string, string> b = make_right<string, string>(\"2\");\n        b = a;\n        test(b);\n      }, [] (std::function<void(either<string, string>&)> test) {\n        either<string, string> a = make_left<string, string>(\"4\");\n        either<string, string> b = make_left<string, string>(\"2\");\n        b = a;\n        test(b);\n      }\n    },\n    EXPECT_IS_LEFT<string, string>(\"4\")\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<string, string>&)> test) {\n        either<string, string> a = make_left<string, string>(\"4\");\n        either<string, string> b = make_right<string, string>(\"2\");\n        b = a;\n        test(a);\n      }, [] (std::function<void(either<string, string>&)> test) {\n        either<string, string> a = make_left<string, string>(\"4\");\n        either<string, string> b = make_left<string, string>(\"2\");\n        b = a;\n        test(a);\n      }\n    },\n    EXPECT_IS_LEFT<string, string>(\"4\")\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<int, string>&)> test) {\n        either<int, string> a(\"4\");\n        either<int, string> b(2);\n        b = a;\n        test(b);\n      }, [] (std::function<void(either<int, string>&)> test) {\n        either<int, string> a(\"4\");\n        either<int, string> b(\"2\");\n        b = a;\n        test(b);\n      }\n    },\n    EXPECT_IS_RIGHT<int, string>(\"4\")\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<int, string>&)> test) {\n        either<int, string> a(\"4\");\n        either<int, string> b(2);\n        b = a;\n        test(a);\n      }, [] (std::function<void(either<int, string>&)> test) {\n        either<int, string> a(\"4\");\n        either<int, string> b(\"2\");\n        b = a;\n        test(a);\n      }\n    },\n    EXPECT_IS_RIGHT<int, string>(\"4\")\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<string, string>&)> test) {\n        either<string, string> a = make_right<string, string>(\"4\");\n        either<string, string> b = make_left<string, string>(\"2\");\n        b = a;\n        test(b);\n      }, [] (std::function<void(either<string, string>&)> test) {\n        either<string, string> a = make_right<string, string>(\"4\");\n        either<string, string> b = make_right<string, string>(\"2\");\n        b = a;\n        test(b);\n      }\n    },\n    EXPECT_IS_RIGHT<string, string>(\"4\")\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<string, string>&)> test) {\n        either<string, string> a = make_right<string, string>(\"4\");\n        either<string, string> b = make_left<string, string>(\"2\");\n        b = a;\n        test(a);\n      }, [] (std::function<void(either<string, string>&)> test) {\n        either<string, string> a = make_right<string, string>(\"4\");\n        either<string, string> b = make_right<string, string>(\"2\");\n        b = a;\n        test(a);\n      }\n    },\n    EXPECT_IS_RIGHT<string, string>(\"4\")\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<MovableOnly, string>&)> test) {\n        either<MovableOnly, string> a(MovableOnly(3));\n        either<MovableOnly, string> b(2);\n        b = std::move(a);\n        test(b);\n      }, [] (std::function<void(either<MovableOnly, string>&)> test) {\n        either<MovableOnly, string> a(MovableOnly(3));\n        either<MovableOnly, string> b(MovableOnly(2));\n        b = std::move(a);\n        test(b);\n      }\n    },\n    EXPECT_IS_LEFT<MovableOnly, string>(MovableOnly(3))\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<MovableOnly, string>&)> test) {\n        either<MovableOnly, string> a(MovableOnly(3));\n        either<MovableOnly, string> b(2);\n        b = std::move(a);\n        test(a);  // NOLINT(bugprone-use-after-move)\n      }, [] (std::function<void(either<MovableOnly, string>&)> test) {\n        either<MovableOnly, string> a(MovableOnly(3));\n        either<MovableOnly, string> b(MovableOnly(2));\n        b = std::move(a);\n        test(a);  // NOLINT(bugprone-use-after-move)\n      }\n    },\n    EXPECT_IS_LEFT<MovableOnly, string>(MovableOnly(0)) // 0 is moved-from value\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<MovableOnly, MovableOnly>&)> test) {\n        either<MovableOnly, MovableOnly> a = make_left<MovableOnly, MovableOnly>(3);\n        either<MovableOnly, MovableOnly> b = make_right<MovableOnly, MovableOnly>(2);\n        b = std::move(a);\n        test(b);\n      }, [] (std::function<void(either<MovableOnly, MovableOnly>&)> test) {\n        either<MovableOnly, MovableOnly> a = make_left<MovableOnly, MovableOnly>(3);\n        either<MovableOnly, MovableOnly> b = make_left<MovableOnly, MovableOnly>(2);\n        b = std::move(a);\n        test(b);\n      }\n    },\n    EXPECT_IS_LEFT<MovableOnly, MovableOnly>(MovableOnly(3))\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<MovableOnly, MovableOnly>&)> test) {\n        either<MovableOnly, MovableOnly> a = make_left<MovableOnly, MovableOnly>(3);\n        either<MovableOnly, MovableOnly> b = make_right<MovableOnly, MovableOnly>(2);\n        b = std::move(a);\n        test(a);  // NOLINT(bugprone-use-after-move)\n      }, [] (std::function<void(either<MovableOnly, MovableOnly>&)> test) {\n        either<MovableOnly, MovableOnly> a = make_left<MovableOnly, MovableOnly>(3);\n        either<MovableOnly, MovableOnly> b = make_left<MovableOnly, MovableOnly>(2);\n        b = std::move(a);\n        test(a);  // NOLINT(bugprone-use-after-move)\n      }\n    },\n    EXPECT_IS_LEFT<MovableOnly, MovableOnly>(MovableOnly(0)) // 0 is moved-from value\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<string, MovableOnly>&)> test) {\n        either<string, MovableOnly> a(MovableOnly(3));\n        either<string, MovableOnly> b(\"2\");\n        b = std::move(a);\n        test(b);\n      }, [] (std::function<void(either<string, MovableOnly>&)> test) {\n        either<string, MovableOnly> a(MovableOnly(3));\n        either<string, MovableOnly> b(MovableOnly(2));\n        b = std::move(a);\n        test(b);\n      }\n    },\n    EXPECT_IS_RIGHT<string, MovableOnly>(MovableOnly(3))\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<string, MovableOnly>&)> test) {\n        either<string, MovableOnly> a(MovableOnly(3));\n        either<string, MovableOnly> b(\"2\");\n        b = std::move(a);\n        test(a);  // NOLINT(bugprone-use-after-move)\n      }, [] (std::function<void(either<string, MovableOnly>&)> test) {\n        either<string, MovableOnly> a(MovableOnly(3));\n        either<string, MovableOnly> b(MovableOnly(2));\n        b = std::move(a);\n        test(a);  // NOLINT(bugprone-use-after-move)\n      }\n    },\n    EXPECT_IS_RIGHT<string, MovableOnly>(MovableOnly(0)) // 0 is moved-from value\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<MovableOnly, MovableOnly>&)> test) {\n        either<MovableOnly, MovableOnly> a = make_right<MovableOnly, MovableOnly>(3);\n        either<MovableOnly, MovableOnly> b = make_left<MovableOnly, MovableOnly>(2);\n        b = std::move(a);\n        test(b);\n      }, [] (std::function<void(either<MovableOnly, MovableOnly>&)> test) {\n        either<MovableOnly, MovableOnly> a = make_right<MovableOnly, MovableOnly>(3);\n        either<MovableOnly, MovableOnly> b = make_right<MovableOnly, MovableOnly>(2);\n        b = std::move(a);\n        test(b);\n      }\n    },\n    EXPECT_IS_RIGHT<MovableOnly, MovableOnly>(MovableOnly(3))\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<MovableOnly, MovableOnly>&)> test) {\n        either<MovableOnly, MovableOnly> a = make_right<MovableOnly, MovableOnly>(3);\n        either<MovableOnly, MovableOnly> b = make_left<MovableOnly, MovableOnly>(2);\n        b = std::move(a);\n        test(a);  // NOLINT(bugprone-use-after-move)\n      }, [] (std::function<void(either<MovableOnly, MovableOnly>&)> test) {\n        either<MovableOnly, MovableOnly> a = make_right<MovableOnly, MovableOnly>(3);\n        either<MovableOnly, MovableOnly> b = make_right<MovableOnly, MovableOnly>(2);\n        b = std::move(a);\n        test(a);  // NOLINT(bugprone-use-after-move)\n      }\n    },\n    EXPECT_IS_RIGHT<MovableOnly, MovableOnly>(MovableOnly(0)) // 0 is moved-from value\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<int, string>&)> test) {\n        either<int, string> a(4);\n        a.left() = 5;\n        test(a);\n      }, [] (std::function<void(either<int, string>&)> test) {\n        either<int, string> a(4);\n        a.left() = 5;\n        test(a);\n      }\n    },\n    EXPECT_IS_LEFT<int, string>(5)\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<int, string>&)> test) {\n        either<int, string> a(\"4\");\n        a.right() = \"5\";\n        test(a);\n      }, [] (std::function<void(either<int, string>&)> test) {\n        either<int, string> a(\"4\");\n        a.right() = \"5\";\n        test(a);\n      }\n    },\n    EXPECT_IS_RIGHT<int, string>(\"5\")\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<tuple<int, int>, tuple<int, string, int>>&)> test) {\n        either<tuple<int, int>, tuple<int, string, int>> a(2, 3);\n        test(a);\n      }\n    },\n    EXPECT_IS_LEFT<tuple<int, int>, tuple<int, string, int>>(tuple<int, int>(2, 3))\n  );\n}",
            "{\n  test_with_matrix({\n      [] (std::function<void(either<tuple<int, int>, tuple<int, string, int>>&)> test) {\n        either<tuple<int, int>, tuple<int, string, int>> a(2, \"3\", 4);\n        test(a);\n      }\n    },\n    EXPECT_IS_RIGHT<tuple<int, int>, tuple<int, string, int>>(tuple<int, string, int>(2, \"3\", 4))\n  );\n}",
            "{\n  either<string, int> a(\"3\");\n  either<string, int> b(\"3\");\n  EXPECT_TRUE(a == b);\n}",
            "{\n  either<string, int> a(\"3\");\n  either<string, int> b(\"3\");\n  EXPECT_FALSE(a != b);\n}",
            "{\n  either<string, int> a(3);\n  either<string, int> b(3);\n  EXPECT_TRUE(a == b);\n}",
            "{\n  either<string, int> a(3);\n  either<string, int> b(3);\n  EXPECT_FALSE(a != b);\n}",
            "{\n  either<string, int> a(\"3\");\n  either<string, int> b(3);\n  EXPECT_FALSE(a == b);\n  EXPECT_FALSE(b == a);\n}",
            "{\n  either<string, int> a(\"3\");\n  either<string, int> b(3);\n  EXPECT_TRUE(a != b);\n  EXPECT_TRUE(b != a);\n}",
            "{\n  ostringstream str;\n  str << either<string, int>(\"mystring\");\n  EXPECT_EQ(\"Left(mystring)\", str.str());\n}",
            "{\n  ostringstream str;\n  str << either<int, string>(\"mystring\");\n  EXPECT_EQ(\"Right(mystring)\", str.str());\n}",
            "{\n  either<string, string> a = make_left<string, string>(\"3\");\n  either<string, string> b = make_right<string, string>(\"3\");\n  EXPECT_FALSE(a == b);\n  EXPECT_FALSE(b == a);\n}",
            "{\n  either<string, string> a = make_left<string, string>(\"3\");\n  either<string, string> b = make_right<string, string>(\"3\");\n  EXPECT_TRUE(a != b);\n  EXPECT_TRUE(b != a);\n}",
            "{\n    DestructorCallback destructorCallback;\n    destructorCallback.EXPECT_CALLED(2);  //Once for the temp object, once when the either class destructs\n\n    ClassWithDestructorCallback temp(&destructorCallback);\n    either<ClassWithDestructorCallback, string> var = temp;\n}",
            "{\n    DestructorCallback destructorCallback;\n    destructorCallback.EXPECT_CALLED(2);  //Once for the temp object, once when the either class destructs\n\n    ClassWithDestructorCallback temp(&destructorCallback);\n    either<string, ClassWithDestructorCallback> var = temp;\n}",
            "{\n    DestructorCallback destructorCallback;\n    destructorCallback.EXPECT_CALLED(3);  //Once for the temp object, once for var1 and once for var2\n\n    ClassWithDestructorCallback temp(&destructorCallback);\n    either<ClassWithDestructorCallback, string> var1 = temp;\n    either<ClassWithDestructorCallback, string> var2 = var1;\n}",
            "{\n    DestructorCallback destructorCallback;\n    destructorCallback.EXPECT_CALLED(3);  //Once for the temp object, once for var1 and once for var2\n\n    ClassWithDestructorCallback temp(&destructorCallback);\n    either<string, ClassWithDestructorCallback> var1 = temp;\n    either<string, ClassWithDestructorCallback> var2 = var1;\n}",
            "{\n    DestructorCallback destructorCallback;\n    destructorCallback.EXPECT_CALLED(3);  //Once for the temp object, once for var1 and once for var2\n\n    OnlyMoveableClassWithDestructorCallback temp(&destructorCallback);\n    either<OnlyMoveableClassWithDestructorCallback, string> var1 = std::move(temp);\n    either<OnlyMoveableClassWithDestructorCallback, string> var2 = std::move(var1);\n}",
            "{\n    DestructorCallback destructorCallback;\n    destructorCallback.EXPECT_CALLED(3);  //Once for the temp object, once for var1 and once for var2\n\n    OnlyMoveableClassWithDestructorCallback temp(&destructorCallback);\n    either<string, OnlyMoveableClassWithDestructorCallback> var1 = std::move(temp);\n    either<string, OnlyMoveableClassWithDestructorCallback> var2 = std::move(var1);\n}",
            "{\n    DestructorCallback destructorCallback1;\n    DestructorCallback destructorCallback2;\n    destructorCallback1.EXPECT_CALLED(2); //Once for the temp1 object, once at the assignment\n    destructorCallback2.EXPECT_CALLED(3); //Once for the temp2 object, once in destructor of var2, once in destructor of var1\n\n    ClassWithDestructorCallback temp1(&destructorCallback1);\n    either<ClassWithDestructorCallback, string> var1 = temp1;\n    ClassWithDestructorCallback temp2(&destructorCallback2);\n    either<ClassWithDestructorCallback, string> var2 = temp2;\n    var1 = var2;\n}",
            "{\n    DestructorCallback destructorCallback1;\n    DestructorCallback destructorCallback2;\n    destructorCallback1.EXPECT_CALLED(2); //Once for the temp1 object, once at the assignment\n    destructorCallback2.EXPECT_CALLED(3); //Once for the temp2 object, once in destructor of var2, once in destructor of var1\n\n    ClassWithDestructorCallback temp1(&destructorCallback1);\n    either<string, ClassWithDestructorCallback> var1 = temp1;\n    ClassWithDestructorCallback temp2(&destructorCallback2);\n    either<string, ClassWithDestructorCallback> var2 = temp2;\n    var1 = var2;\n}",
            "{\n    DestructorCallback destructorCallback1;\n    DestructorCallback destructorCallback2;\n    destructorCallback1.EXPECT_CALLED(2); //Once for the temp1 object, once at the assignment\n    destructorCallback2.EXPECT_CALLED(3); //Once for the temp2 object, once in destructor of var2, once in destructor of var1\n\n    OnlyMoveableClassWithDestructorCallback temp1(&destructorCallback1);\n    either<OnlyMoveableClassWithDestructorCallback, string> var1 = std::move(temp1);\n    OnlyMoveableClassWithDestructorCallback temp2(&destructorCallback2);\n    either<OnlyMoveableClassWithDestructorCallback, string> var2 = std::move(temp2);\n    var1 = std::move(var2);\n}",
            "{\n    DestructorCallback destructorCallback1;\n    DestructorCallback destructorCallback2;\n    destructorCallback1.EXPECT_CALLED(2); //Once for the temp1 object, once at the assignment\n    destructorCallback2.EXPECT_CALLED(3); //Once for the temp2 object, once in destructor of var2, once in destructor of var1\n\n    OnlyMoveableClassWithDestructorCallback temp1(&destructorCallback1);\n    either<string, OnlyMoveableClassWithDestructorCallback> var1 = std::move(temp1);\n    OnlyMoveableClassWithDestructorCallback temp2(&destructorCallback2);\n    either<string, OnlyMoveableClassWithDestructorCallback> var2 = std::move(temp2);\n    var1 = std::move(var2);\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/test/util/exception_test.cpp",
        "functions": [
            "{\n#ifdef NDEBUG\n  ASSERT_NO_THROW(TORCH_INTERNAL_ASSERT_DEBUG_ONLY(false));\n  // Does nothing - `throw_func()` should not be evaluated\n  ASSERT_NO_THROW(TORCH_INTERNAL_ASSERT_DEBUG_ONLY(throw_func()));\n#else\n  ASSERT_THROW(TORCH_INTERNAL_ASSERT_DEBUG_ONLY(false), c10::Error);\n  ASSERT_NO_THROW(TORCH_INTERNAL_ASSERT_DEBUG_ONLY(true));\n#endif\n}",
            "{\n  TORCH_WARN(\"I'm a warning\");\n}",
            "{\n  expectThrowsEq([]() {\n    TORCH_CHECK(false, \"This is invalid\");\n  }, \"This is invalid\");\n\n  expectThrowsEq([]() {\n    try {\n      TORCH_CHECK(false, \"This is invalid\");\n    } catch (Error& e) {\n      TORCH_RETHROW(e, \"While checking X\");\n    }\n  }, \"This is invalid (While checking X)\");\n\n  expectThrowsEq([]() {\n    try {\n      try {\n        TORCH_CHECK(false, \"This is invalid\");\n      } catch (Error& e) {\n        TORCH_RETHROW(e, \"While checking X\");\n      }\n    } catch (Error& e) {\n      TORCH_RETHROW(e, \"While checking Y\");\n    }\n  },\nR\"msg(This is invalid\n  While checking X\n  While checking Y)msg\");\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/test/util/flags_test.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/test/util/Half_test.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/test/util/intrusive_ptr_test.cpp",
        "functions": [
            "{\n  intrusive_ptr<SomeClass0Parameters> var =\n      make_intrusive<SomeClass0Parameters>();\n  // Check that the type is correct\n  EXPECT_EQ(var.get(), dynamic_cast<SomeClass0Parameters*>(var.get()));\n}",
            "{\n  intrusive_ptr<SomeClass1Parameter> var =\n      make_intrusive<SomeClass1Parameter>(5);\n  EXPECT_EQ(5, var->param);\n}",
            "{\n  intrusive_ptr<SomeClass2Parameters> var =\n      make_intrusive<SomeClass2Parameters>(7, 2);\n  EXPECT_EQ(7, var->param1);\n  EXPECT_EQ(2, var->param2);\n}",
            "{\n  auto var2 = make_intrusive<SomeClass0Parameters>();\n  auto var3 = make_intrusive<SomeClass1Parameter>(2);\n  auto var4 = make_intrusive<SomeClass2Parameters>(2, 3);\n}",
            "{\n  intrusive_ptr<SomeBaseClass> var = make_intrusive<SomeChildClass>(3);\n  EXPECT_EQ(3, var->v);\n}",
            "{\n  SomeClass myClass;\n}",
            "{\n  intrusive_ptr<SomeClass1Parameter> obj =\n      make_intrusive<SomeClass1Parameter>(5);\n  EXPECT_EQ(5, obj.get()->param);\n}",
            "{\n  const intrusive_ptr<SomeClass1Parameter> obj =\n      make_intrusive<SomeClass1Parameter>(5);\n  EXPECT_EQ(5, obj.get()->param);\n}",
            "{\n  intrusive_ptr<SomeClass1Parameter> obj;\n  EXPECT_EQ(nullptr, obj.get());\n}",
            "{\n  intrusive_ptr<SomeClass1Parameter> obj =\n      make_intrusive<SomeClass1Parameter>(5);\n  EXPECT_EQ(5, (*obj).param);\n}",
            "{\n  const intrusive_ptr<SomeClass1Parameter> obj =\n      make_intrusive<SomeClass1Parameter>(5);\n  EXPECT_EQ(5, (*obj).param);\n}",
            "{\n  intrusive_ptr<SomeClass1Parameter> obj =\n      make_intrusive<SomeClass1Parameter>(3);\n  EXPECT_EQ(3, obj->param);\n}",
            "{\n  const intrusive_ptr<SomeClass1Parameter> obj =\n      make_intrusive<SomeClass1Parameter>(3);\n  EXPECT_EQ(3, obj->param);\n}",
            "{\n  intrusive_ptr<SomeClass> obj1 = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> obj2 = make_intrusive<SomeClass>();\n  SomeClass* obj1ptr = obj1.get();\n  obj2 = std::move(obj1);\n  EXPECT_EQ(obj1ptr, obj2.get());\n}",
            "{\n  intrusive_ptr<SomeClass> obj1 = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> obj2 = make_intrusive<SomeClass>();\n  obj2 = std::move(obj1);\n  EXPECT_FALSE(obj1.defined());\n}",
            "{\n  intrusive_ptr<SomeClass> obj1 = make_intrusive<SomeClass>();\n  SomeClass* obj1ptr = obj1.get();\n  obj1 = std::move(obj1);\n  EXPECT_EQ(obj1ptr, obj1.get());\n}",
            "{\n  intrusive_ptr<SomeClass> obj1 = make_intrusive<SomeClass>();\n  obj1 = std::move(obj1);\n  EXPECT_TRUE(obj1.defined());\n}",
            "{\n  intrusive_ptr<SomeClass> obj1;\n  obj1 = std::move(obj1);\n  EXPECT_FALSE(obj1.defined());\n}",
            "{\n  intrusive_ptr<SomeClass> obj1 = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> obj2;\n  SomeClass* obj1ptr = obj1.get();\n  obj2 = std::move(obj1);\n  EXPECT_TRUE(obj2.defined());\n}",
            "{\n  intrusive_ptr<SomeClass> obj1 = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> obj2;\n  SomeClass* obj1ptr = obj1.get();\n  obj2 = std::move(obj1);\n  EXPECT_EQ(obj1ptr, obj2.get());\n}",
            "{\n  intrusive_ptr<SomeClass> obj1;\n  intrusive_ptr<SomeClass> obj2 = make_intrusive<SomeClass>();\n  EXPECT_TRUE(obj2.defined());\n  obj2 = std::move(obj1);\n  EXPECT_FALSE(obj2.defined());\n}",
            "{\n  intrusive_ptr<SomeChildClass> obj1 = make_intrusive<SomeChildClass>(1);\n  intrusive_ptr<SomeBaseClass> obj2 = make_intrusive<SomeBaseClass>(2);\n  SomeBaseClass* obj1ptr = obj1.get();\n  obj2 = std::move(obj1);\n  EXPECT_EQ(obj1ptr, obj2.get());\n  EXPECT_EQ(1, obj2->v);\n}",
            "{\n  intrusive_ptr<SomeChildClass> obj1 = make_intrusive<SomeChildClass>(1);\n  intrusive_ptr<SomeBaseClass> obj2 = make_intrusive<SomeBaseClass>(2);\n  obj2 = std::move(obj1);\n  EXPECT_FALSE(obj1.defined());\n}",
            "{\n  intrusive_ptr<SomeChildClass> obj1 = make_intrusive<SomeChildClass>(5);\n  intrusive_ptr<SomeBaseClass> obj2;\n  SomeBaseClass* obj1ptr = obj1.get();\n  obj2 = std::move(obj1);\n  EXPECT_TRUE(obj2.defined());\n}",
            "{\n  intrusive_ptr<SomeChildClass> obj1 = make_intrusive<SomeChildClass>(5);\n  intrusive_ptr<SomeBaseClass> obj2;\n  SomeBaseClass* obj1ptr = obj1.get();\n  obj2 = std::move(obj1);\n  EXPECT_EQ(obj1ptr, obj2.get());\n  EXPECT_EQ(5, obj2->v);\n}",
            "{\n  intrusive_ptr<SomeChildClass> obj1;\n  intrusive_ptr<SomeBaseClass> obj2 = make_intrusive<SomeBaseClass>(2);\n  EXPECT_TRUE(obj2.defined());\n  obj2 = std::move(obj1);\n  EXPECT_FALSE(obj2.defined());\n}",
            "{\n  intrusive_ptr<SomeClass, NullType1> obj1;\n  intrusive_ptr<SomeClass, NullType2> obj2;\n  obj2 = std::move(obj1);\n  EXPECT_NE(NullType1::singleton(), NullType2::singleton());\n  EXPECT_EQ(NullType1::singleton(), obj1.get());\n  EXPECT_EQ(NullType2::singleton(), obj2.get());\n  EXPECT_FALSE(obj1.defined());\n  EXPECT_FALSE(obj2.defined());\n}",
            "{\n  intrusive_ptr<SomeClass> obj1 = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> obj2 = make_intrusive<SomeClass>();\n  SomeClass* obj1ptr = obj1.get();\n  obj2 = obj1;\n  EXPECT_EQ(obj1ptr, obj2.get());\n}",
            "{\n  intrusive_ptr<SomeClass> obj1 = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> obj2 = make_intrusive<SomeClass>();\n  obj2 = obj1;\n  EXPECT_TRUE(obj1.defined());\n}",
            "{\n  intrusive_ptr<SomeClass> obj1 = make_intrusive<SomeClass>();\n  SomeClass* obj1ptr = obj1.get();\n  obj1 = obj1;\n  EXPECT_EQ(obj1ptr, obj1.get());\n}",
            "{\n  intrusive_ptr<SomeClass> obj1 = make_intrusive<SomeClass>();\n  obj1 = obj1;\n  EXPECT_TRUE(obj1.defined());\n}",
            "{\n  intrusive_ptr<SomeClass> obj1;\n  obj1 = obj1;\n  EXPECT_FALSE(obj1.defined());\n}",
            "{\n  intrusive_ptr<SomeClass> obj1 = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> obj2;\n  SomeClass* obj1ptr = obj1.get();\n  obj2 = obj1;\n  EXPECT_TRUE(obj2.defined());\n}",
            "{\n  intrusive_ptr<SomeChildClass> child = make_intrusive<SomeChildClass>(3);\n  intrusive_ptr<SomeBaseClass> base = make_intrusive<SomeBaseClass>(10);\n  base = child;\n  EXPECT_EQ(3, base->v);\n}",
            "{\n  intrusive_ptr<SomeChildClass> obj1 = make_intrusive<SomeChildClass>(3);\n  intrusive_ptr<SomeBaseClass> obj2 = make_intrusive<SomeBaseClass>(10);\n  obj2 = obj1;\n  EXPECT_TRUE(obj1.defined());\n}",
            "{\n  intrusive_ptr<SomeChildClass> obj1 = make_intrusive<SomeChildClass>(5);\n  intrusive_ptr<SomeBaseClass> obj2;\n  SomeBaseClass* obj1ptr = obj1.get();\n  obj2 = obj1;\n  EXPECT_TRUE(obj2.defined());\n}",
            "{\n  intrusive_ptr<SomeChildClass> obj1 = make_intrusive<SomeChildClass>(5);\n  intrusive_ptr<SomeBaseClass> obj2;\n  SomeBaseClass* obj1ptr = obj1.get();\n  obj2 = obj1;\n  EXPECT_EQ(obj1ptr, obj2.get());\n  EXPECT_EQ(5, obj2->v);\n}",
            "{\n  intrusive_ptr<SomeChildClass> obj1;\n  intrusive_ptr<SomeBaseClass> obj2 = make_intrusive<SomeBaseClass>(2);\n  EXPECT_TRUE(obj2.defined());\n  obj2 = obj1;\n  EXPECT_FALSE(obj2.defined());\n}",
            "{\n  intrusive_ptr<SomeClass, NullType1> obj1;\n  intrusive_ptr<SomeClass, NullType2> obj2;\n  obj2 = obj1;\n  EXPECT_NE(NullType1::singleton(), NullType2::singleton());\n  EXPECT_EQ(NullType1::singleton(), obj1.get());\n  EXPECT_EQ(NullType2::singleton(), obj2.get());\n  EXPECT_FALSE(obj1.defined());\n  EXPECT_FALSE(obj2.defined());\n}",
            "{\n  intrusive_ptr<SomeClass> obj1 = make_intrusive<SomeClass>();\n  SomeClass* obj1ptr = obj1.get();\n  intrusive_ptr<SomeClass> obj2 = std::move(obj1);\n  EXPECT_EQ(obj1ptr, obj2.get());\n}",
            "{\n  intrusive_ptr<SomeClass> obj1 = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> obj2 = std::move(obj1);\n  EXPECT_FALSE(obj1.defined());\n}",
            "{\n  intrusive_ptr<SomeClass> obj1 = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> obj2 = std::move(obj1);\n  EXPECT_TRUE(obj2.defined());\n}",
            "{\n  intrusive_ptr<SomeClass> obj1;\n  intrusive_ptr<SomeClass> obj2 = std::move(obj1);\n  EXPECT_FALSE(obj2.defined());\n}",
            "{\n  intrusive_ptr<SomeChildClass> child = make_intrusive<SomeChildClass>(3);\n  SomeBaseClass* objptr = child.get();\n  intrusive_ptr<SomeBaseClass> base = std::move(child);\n  EXPECT_EQ(3, base->v);\n  EXPECT_EQ(objptr, base.get());\n}",
            "{\n  intrusive_ptr<SomeChildClass> child = make_intrusive<SomeChildClass>(3);\n  intrusive_ptr<SomeBaseClass> base = std::move(child);\n  EXPECT_FALSE(child.defined());\n}",
            "{\n  intrusive_ptr<SomeChildClass> obj1 = make_intrusive<SomeChildClass>(2);\n  intrusive_ptr<SomeBaseClass> obj2 = std::move(obj1);\n  EXPECT_TRUE(obj2.defined());\n}",
            "{\n  intrusive_ptr<SomeChildClass> obj1;\n  intrusive_ptr<SomeBaseClass> obj2 = std::move(obj1);\n  EXPECT_FALSE(obj2.defined());\n}",
            "{\n  intrusive_ptr<SomeClass, NullType1> obj1;\n  intrusive_ptr<SomeClass, NullType2> obj2 = std::move(obj1);\n  EXPECT_NE(NullType1::singleton(), NullType2::singleton());\n  EXPECT_EQ(NullType1::singleton(), obj1.get());\n  EXPECT_EQ(NullType2::singleton(), obj2.get());\n  EXPECT_FALSE(obj1.defined());\n  EXPECT_FALSE(obj2.defined());\n}",
            "{\n  intrusive_ptr<SomeClass> obj1 = make_intrusive<SomeClass>();\n  SomeClass* obj1ptr = obj1.get();\n  intrusive_ptr<SomeClass> obj2 = obj1;\n  EXPECT_EQ(obj1ptr, obj2.get());\n  EXPECT_TRUE(obj1.defined());\n}",
            "{\n  intrusive_ptr<SomeClass> obj1 = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> obj2 = obj1;\n  EXPECT_TRUE(obj1.defined());\n}",
            "{\n  intrusive_ptr<SomeClass> obj1 = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> obj2 = obj1;\n  EXPECT_TRUE(obj2.defined());\n}",
            "{\n  intrusive_ptr<SomeClass> obj1;\n  intrusive_ptr<SomeClass> obj2 = obj1;\n  EXPECT_FALSE(obj2.defined());\n}",
            "{\n  intrusive_ptr<SomeChildClass> child = make_intrusive<SomeChildClass>(3);\n  SomeBaseClass* objptr = child.get();\n  intrusive_ptr<SomeBaseClass> base = child;\n  EXPECT_EQ(3, base->v);\n  EXPECT_EQ(objptr, base.get());\n}",
            "{\n  intrusive_ptr<SomeChildClass> child = make_intrusive<SomeChildClass>(3);\n  intrusive_ptr<SomeBaseClass> base = child;\n  EXPECT_TRUE(child.defined());\n}",
            "{\n  intrusive_ptr<SomeChildClass> child = make_intrusive<SomeChildClass>(3);\n  intrusive_ptr<SomeBaseClass> base = child;\n  EXPECT_TRUE(base.defined());\n}",
            "{\n  intrusive_ptr<SomeChildClass> obj1;\n  intrusive_ptr<SomeBaseClass> obj2 = obj1;\n  EXPECT_FALSE(obj2.defined());\n}",
            "{\n  intrusive_ptr<SomeClass, NullType1> obj1;\n  intrusive_ptr<SomeClass, NullType2> obj2 = obj1;\n  EXPECT_NE(NullType1::singleton(), NullType2::singleton());\n  EXPECT_EQ(NullType1::singleton(), obj1.get());\n  EXPECT_EQ(NullType2::singleton(), obj2.get());\n  EXPECT_FALSE(obj1.defined());\n  EXPECT_FALSE(obj2.defined());\n}",
            "{\n  intrusive_ptr<SomeClass> obj1 = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> obj2 = make_intrusive<SomeClass>();\n  SomeClass* obj1ptr = obj1.get();\n  SomeClass* obj2ptr = obj2.get();\n  swap(obj1, obj2);\n  EXPECT_EQ(obj2ptr, obj1.get());\n  EXPECT_EQ(obj1ptr, obj2.get());\n}",
            "{\n  intrusive_ptr<SomeClass> obj1 = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> obj2 = make_intrusive<SomeClass>();\n  SomeClass* obj1ptr = obj1.get();\n  SomeClass* obj2ptr = obj2.get();\n  obj1.swap(obj2);\n  EXPECT_EQ(obj2ptr, obj1.get());\n  EXPECT_EQ(obj1ptr, obj2.get());\n}",
            "{\n  intrusive_ptr<SomeClass> obj1;\n  intrusive_ptr<SomeClass> obj2 = make_intrusive<SomeClass>();\n  SomeClass* obj2ptr = obj2.get();\n  swap(obj1, obj2);\n  EXPECT_EQ(obj2ptr, obj1.get());\n  EXPECT_TRUE(obj1.defined());\n  EXPECT_FALSE(obj2.defined());\n}",
            "{\n  intrusive_ptr<SomeClass> obj1;\n  intrusive_ptr<SomeClass> obj2 = make_intrusive<SomeClass>();\n  SomeClass* obj2ptr = obj2.get();\n  obj1.swap(obj2);\n  EXPECT_EQ(obj2ptr, obj1.get());\n  EXPECT_TRUE(obj1.defined());\n  EXPECT_FALSE(obj2.defined());\n}",
            "{\n  intrusive_ptr<SomeClass> obj1 = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> obj2;\n  SomeClass* obj1ptr = obj1.get();\n  swap(obj1, obj2);\n  EXPECT_FALSE(obj1.defined());\n  EXPECT_TRUE(obj2.defined());\n  EXPECT_EQ(obj1ptr, obj2.get());\n}",
            "{\n  intrusive_ptr<SomeClass> obj1 = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> obj2;\n  SomeClass* obj1ptr = obj1.get();\n  obj1.swap(obj2);\n  EXPECT_FALSE(obj1.defined());\n  EXPECT_TRUE(obj2.defined());\n  EXPECT_EQ(obj1ptr, obj2.get());\n}",
            "{\n  intrusive_ptr<SomeClass> obj1;\n  intrusive_ptr<SomeClass> obj2;\n  swap(obj1, obj2);\n  EXPECT_FALSE(obj1.defined());\n  EXPECT_FALSE(obj2.defined());\n}",
            "{\n  intrusive_ptr<SomeClass> obj1;\n  intrusive_ptr<SomeClass> obj2;\n  obj1.swap(obj2);\n  EXPECT_FALSE(obj1.defined());\n  EXPECT_FALSE(obj2.defined());\n}",
            "{\n  std::vector<intrusive_ptr<SomeClass1Parameter>> vec;\n  vec.push_back(make_intrusive<SomeClass1Parameter>(5));\n  EXPECT_EQ(5, vec[0]->param);\n}",
            "{\n  std::set<intrusive_ptr<SomeClass1Parameter>> set;\n  set.insert(make_intrusive<SomeClass1Parameter>(5));\n  EXPECT_EQ(5, (*set.begin())->param);\n}",
            "{\n  std::unordered_set<intrusive_ptr<SomeClass1Parameter>> set;\n  set.insert(make_intrusive<SomeClass1Parameter>(5));\n  EXPECT_EQ(5, (*set.begin())->param);\n}",
            "{\n  std::map<\n      intrusive_ptr<SomeClass1Parameter>,\n      intrusive_ptr<SomeClass1Parameter>>\n      map;\n  map.insert(std::make_pair(\n      make_intrusive<SomeClass1Parameter>(5),\n      make_intrusive<SomeClass1Parameter>(3)));\n  EXPECT_EQ(5, map.begin()->first->param);\n  EXPECT_EQ(3, map.begin()->second->param);\n}",
            "{\n  std::unordered_map<\n      intrusive_ptr<SomeClass1Parameter>,\n      intrusive_ptr<SomeClass1Parameter>>\n      map;\n  map.insert(std::make_pair(\n      make_intrusive<SomeClass1Parameter>(3),\n      make_intrusive<SomeClass1Parameter>(5)));\n  EXPECT_EQ(3, map.begin()->first->param);\n  EXPECT_EQ(5, map.begin()->second->param);\n}",
            "{\n  intrusive_ptr<SomeClass> var1 = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> var2 = var1;\n  EXPECT_TRUE(var1 == var2);\n  EXPECT_FALSE(var1 != var2);\n}",
            "{\n  intrusive_ptr<SomeClass> var1 = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> var2 = make_intrusive<SomeClass>();\n  var2 = var1;\n  EXPECT_TRUE(var1 == var2);\n  EXPECT_FALSE(var1 != var2);\n}",
            "{\n  intrusive_ptr<SomeClass> var1;\n  intrusive_ptr<SomeClass> var2;\n  EXPECT_TRUE(var1 == var2);\n  EXPECT_FALSE(var1 != var2);\n}",
            "{\n  intrusive_ptr<SomeClass> var1 = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> var2 = make_intrusive<SomeClass>();\n  EXPECT_TRUE(var1 != var2);\n  EXPECT_FALSE(var1 == var2);\n}",
            "{\n  intrusive_ptr<SomeClass> var1;\n  intrusive_ptr<SomeClass> var2 = make_intrusive<SomeClass>();\n  EXPECT_TRUE(var1 != var2);\n  EXPECT_FALSE(var1 == var2);\n}",
            "{\n  intrusive_ptr<SomeClass> var1 = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> var2;\n  EXPECT_TRUE(var1 != var2);\n  EXPECT_FALSE(var1 == var2);\n}",
            "{\n  intrusive_ptr<SomeClass> var1 = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> var2 = make_intrusive<SomeClass>();\n  EXPECT_NE(\n      std::hash<intrusive_ptr<SomeClass>>()(var1),\n      std::hash<intrusive_ptr<SomeClass>>()(var2));\n}",
            "{\n  intrusive_ptr<SomeClass> var1;\n  intrusive_ptr<SomeClass> var2 = make_intrusive<SomeClass>();\n  EXPECT_NE(\n      std::hash<intrusive_ptr<SomeClass>>()(var1),\n      std::hash<intrusive_ptr<SomeClass>>()(var2));\n}",
            "{\n  intrusive_ptr<SomeClass> var1 = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> var2 = var1;\n  EXPECT_EQ(\n      std::hash<intrusive_ptr<SomeClass>>()(var1),\n      std::hash<intrusive_ptr<SomeClass>>()(var2));\n}",
            "{\n  intrusive_ptr<SomeClass> var1 = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> var2 = make_intrusive<SomeClass>();\n  var2 = var1;\n  EXPECT_EQ(\n      std::hash<intrusive_ptr<SomeClass>>()(var1),\n      std::hash<intrusive_ptr<SomeClass>>()(var2));\n}",
            "{\n  intrusive_ptr<SomeClass> var1;\n  intrusive_ptr<SomeClass> var2;\n  EXPECT_EQ(\n      std::hash<intrusive_ptr<SomeClass>>()(var1),\n      std::hash<intrusive_ptr<SomeClass>>()(var2));\n}",
            "{\n  intrusive_ptr<SomeClass> var1 = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> var2 = make_intrusive<SomeClass>();\n  EXPECT_TRUE(\n      std::less<intrusive_ptr<SomeClass>>()(var1, var2) !=\n      std::less<intrusive_ptr<SomeClass>>()(var2, var1));\n}",
            "{\n  intrusive_ptr<SomeClass> var1;\n  intrusive_ptr<SomeClass> var2 = make_intrusive<SomeClass>();\n  EXPECT_TRUE(std::less<intrusive_ptr<SomeClass>>()(var1, var2));\n}",
            "{\n  intrusive_ptr<SomeClass> var1 = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> var2;\n  EXPECT_FALSE(std::less<intrusive_ptr<SomeClass>>()(var1, var2));\n}",
            "{\n  intrusive_ptr<SomeClass> var1;\n  intrusive_ptr<SomeClass> var2;\n  EXPECT_FALSE(std::less<intrusive_ptr<SomeClass>>()(var1, var2));\n}",
            "{\n  auto obj = make_intrusive<SomeClass>();\n  EXPECT_TRUE(obj.defined());\n  obj.reset();\n  EXPECT_FALSE(obj.defined());\n}",
            "{\n  auto obj = make_intrusive<SomeClass>();\n  EXPECT_NE(nullptr, obj.get());\n  obj.reset();\n  EXPECT_EQ(nullptr, obj.get());\n}",
            "{\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  {\n    auto obj = make_intrusive<DestructableMock>(&resourcesReleased, &wasDestructed);\n    EXPECT_FALSE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n  }\n  EXPECT_TRUE(resourcesReleased);\n  EXPECT_TRUE(wasDestructed);\n}",
            "{\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  auto obj = make_intrusive<DestructableMock>(&resourcesReleased, &wasDestructed);\n  {\n    auto obj2 = std::move(obj);\n    EXPECT_FALSE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n  }\n  EXPECT_TRUE(resourcesReleased);\n  EXPECT_TRUE(wasDestructed);\n}",
            "{\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  auto obj = make_intrusive<ChildDestructableMock>(&resourcesReleased, &wasDestructed);\n  {\n    intrusive_ptr<DestructableMock> obj2 = std::move(obj);\n    EXPECT_FALSE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n  }\n  EXPECT_TRUE(resourcesReleased);\n  EXPECT_TRUE(wasDestructed);\n}",
            "{\n  bool dummy = false;\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  auto obj = make_intrusive<DestructableMock>(&dummy, &dummy);\n  {\n    auto obj2 = make_intrusive<DestructableMock>(&resourcesReleased, &wasDestructed);\n    EXPECT_FALSE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n    obj2 = std::move(obj);\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_TRUE(wasDestructed);\n  }\n}",
            "{\n  bool dummy = false;\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  auto obj = make_intrusive<ChildDestructableMock>(&dummy, &dummy);\n  {\n    auto obj2 = make_intrusive<DestructableMock>(&resourcesReleased, &wasDestructed);\n    EXPECT_FALSE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n    obj2 = std::move(obj);\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_TRUE(wasDestructed);\n  }\n}",
            "{\n  bool dummy = false;\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  auto obj = make_intrusive<DestructableMock>(&dummy, &dummy);\n  {\n    auto obj2 = make_intrusive<DestructableMock>(&resourcesReleased, &wasDestructed);\n    {\n      auto copy = obj2;\n      EXPECT_FALSE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n      obj2 = std::move(obj);\n      EXPECT_FALSE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n    }\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_TRUE(wasDestructed);\n  }\n}",
            "{\n  bool dummy = false;\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  auto obj = make_intrusive<ChildDestructableMock>(&dummy, &dummy);\n  {\n    auto obj2 =\n        make_intrusive<ChildDestructableMock>(&resourcesReleased, &wasDestructed);\n    {\n      intrusive_ptr<DestructableMock> copy = obj2;\n      EXPECT_FALSE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n      obj2 = std::move(obj);\n      EXPECT_FALSE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n    }\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_TRUE(wasDestructed);\n  }\n}",
            "{\n  bool dummy = false;\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  auto obj = make_intrusive<ChildDestructableMock>(&dummy, &dummy);\n  {\n    auto obj2 = make_intrusive<DestructableMock>(&resourcesReleased, &wasDestructed);\n    {\n      intrusive_ptr<DestructableMock> copy = obj2;\n      EXPECT_FALSE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n      obj2 = std::move(obj);\n      EXPECT_FALSE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n    }\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_TRUE(wasDestructed);\n  }\n}",
            "{\n  bool dummy = false;\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  auto obj = make_intrusive<DestructableMock>(&resourcesReleased, &wasDestructed);\n  {\n    auto obj2 = make_intrusive<DestructableMock>(&dummy, &dummy);\n    obj2 = std::move(obj);\n    EXPECT_FALSE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n  }\n  EXPECT_TRUE(resourcesReleased);\n  EXPECT_TRUE(wasDestructed);\n}",
            "{\n  bool dummy = false;\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  auto obj = make_intrusive<ChildDestructableMock>(&resourcesReleased, &wasDestructed);\n  {\n    auto obj2 = make_intrusive<DestructableMock>(&dummy, &dummy);\n    obj2 = std::move(obj);\n    EXPECT_FALSE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n  }\n  EXPECT_TRUE(resourcesReleased);\n  EXPECT_TRUE(wasDestructed);\n}",
            "{\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  {\n    auto obj = make_intrusive<DestructableMock>(&resourcesReleased, &wasDestructed);\n    {\n      intrusive_ptr<DestructableMock> copy = obj;\n      EXPECT_FALSE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n    }\n    EXPECT_FALSE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n  }\n  EXPECT_TRUE(resourcesReleased);\n  EXPECT_TRUE(wasDestructed);\n}",
            "{\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  {\n    auto obj = make_intrusive<ChildDestructableMock>(&resourcesReleased, &wasDestructed);\n    {\n      intrusive_ptr<DestructableMock> copy = obj;\n      EXPECT_FALSE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n    }\n    EXPECT_FALSE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n  }\n  EXPECT_TRUE(resourcesReleased);\n  EXPECT_TRUE(wasDestructed);\n}",
            "{\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  {\n    auto obj = make_intrusive<DestructableMock>(&resourcesReleased, &wasDestructed);\n    intrusive_ptr<DestructableMock> copy = obj;\n    obj.reset();\n    EXPECT_FALSE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n  }\n  EXPECT_TRUE(resourcesReleased);\n  EXPECT_TRUE(wasDestructed);\n}",
            "{\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  {\n    auto obj = make_intrusive<ChildDestructableMock>(&resourcesReleased, &wasDestructed);\n    intrusive_ptr<DestructableMock> copy = obj;\n    obj.reset();\n    EXPECT_FALSE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n  }\n  EXPECT_TRUE(resourcesReleased);\n  EXPECT_TRUE(wasDestructed);\n}",
            "{\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  bool dummy = false;\n  {\n    auto obj = make_intrusive<DestructableMock>(&resourcesReleased, &wasDestructed);\n    {\n      intrusive_ptr<DestructableMock> copy =\n          make_intrusive<DestructableMock>(&dummy, &dummy);\n      copy = obj;\n      EXPECT_FALSE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n    }\n    EXPECT_FALSE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n  }\n  EXPECT_TRUE(resourcesReleased);\n  EXPECT_TRUE(wasDestructed);\n}",
            "{\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  bool dummy = false;\n  {\n    auto obj = make_intrusive<ChildDestructableMock>(&resourcesReleased, &wasDestructed);\n    {\n      intrusive_ptr<DestructableMock> copy =\n          make_intrusive<DestructableMock>(&dummy, &dummy);\n      copy = obj;\n      EXPECT_FALSE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n    }\n    EXPECT_FALSE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n  }\n  EXPECT_TRUE(resourcesReleased);\n  EXPECT_TRUE(wasDestructed);\n}",
            "{\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  bool dummy = false;\n  {\n    auto copy = make_intrusive<DestructableMock>(&dummy, &dummy);\n    {\n      auto obj = make_intrusive<DestructableMock>(&resourcesReleased, &wasDestructed);\n      copy = obj;\n      EXPECT_FALSE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n    }\n    EXPECT_FALSE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n  }\n  EXPECT_TRUE(resourcesReleased);\n  EXPECT_TRUE(wasDestructed);\n}",
            "{\n  bool wasDestructed = false;\n  bool resourcesReleased = false;\n  bool dummy = false;\n  {\n    auto copy = make_intrusive<DestructableMock>(&dummy, &dummy);\n    {\n      auto obj =\n          make_intrusive<ChildDestructableMock>(&resourcesReleased, &wasDestructed);\n      copy = obj;\n      EXPECT_FALSE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n    }\n    EXPECT_FALSE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n  }\n  EXPECT_TRUE(resourcesReleased);\n  EXPECT_TRUE(wasDestructed);\n}",
            "{\n  bool dummy = false;\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  auto obj = make_intrusive<DestructableMock>(&dummy, &dummy);\n  {\n    auto obj2 = make_intrusive<DestructableMock>(&resourcesReleased, &wasDestructed);\n    EXPECT_FALSE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n    obj2 = obj;\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_TRUE(wasDestructed);\n  }\n}",
            "{\n  bool dummy = false;\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  auto obj = make_intrusive<ChildDestructableMock>(&dummy, &dummy);\n  {\n    auto obj2 = make_intrusive<DestructableMock>(&resourcesReleased, &wasDestructed);\n    EXPECT_FALSE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n    obj2 = obj;\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_TRUE(wasDestructed);\n  }\n}",
            "{\n  bool dummy = false;\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  auto obj = make_intrusive<DestructableMock>(&dummy, &dummy);\n  {\n    auto obj2 = make_intrusive<DestructableMock>(&resourcesReleased, &wasDestructed);\n    {\n      auto copy = obj2;\n      EXPECT_FALSE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n      obj2 = obj;\n      EXPECT_FALSE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n    }\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_TRUE(wasDestructed);\n  }\n}",
            "{\n  bool dummy = false;\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  auto obj = make_intrusive<ChildDestructableMock>(&dummy, &dummy);\n  {\n    auto obj2 =\n        make_intrusive<ChildDestructableMock>(&resourcesReleased, &wasDestructed);\n    {\n      intrusive_ptr<DestructableMock> copy = obj2;\n      EXPECT_FALSE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n      obj2 = obj;\n      EXPECT_FALSE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n    }\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_TRUE(wasDestructed);\n  }\n}",
            "{\n  bool dummy = false;\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  auto obj = make_intrusive<ChildDestructableMock>(&dummy, &dummy);\n  {\n    auto obj2 = make_intrusive<DestructableMock>(&resourcesReleased, &wasDestructed);\n    {\n      intrusive_ptr<DestructableMock> copy = obj2;\n      EXPECT_FALSE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n      obj2 = obj;\n      EXPECT_FALSE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n    }\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_TRUE(wasDestructed);\n  }\n}",
            "{\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  auto obj = make_intrusive<DestructableMock>(&resourcesReleased, &wasDestructed);\n  EXPECT_FALSE(resourcesReleased);\n  EXPECT_FALSE(wasDestructed);\n  obj.reset();\n  EXPECT_TRUE(resourcesReleased);\n  EXPECT_TRUE(wasDestructed);\n}",
            "{\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  auto obj = make_intrusive<DestructableMock>(&resourcesReleased, &wasDestructed);\n  {\n    auto copy = obj;\n    obj.reset();\n    EXPECT_FALSE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n    copy.reset();\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_TRUE(wasDestructed);\n  }\n}",
            "{\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  auto obj = make_intrusive<DestructableMock>(&resourcesReleased, &wasDestructed);\n  {\n    auto copy = obj;\n    copy.reset();\n    EXPECT_FALSE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n    obj.reset();\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_TRUE(wasDestructed);\n  }\n}",
            "{\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  auto obj = make_intrusive<DestructableMock>(&resourcesReleased, &wasDestructed);\n  {\n    auto moved = std::move(obj);\n    obj.reset();\n    EXPECT_FALSE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n    moved.reset();\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_TRUE(wasDestructed);\n  }\n}",
            "{\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  auto obj = make_intrusive<DestructableMock>(&resourcesReleased, &wasDestructed);\n  {\n    auto moved = std::move(obj);\n    moved.reset();\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_TRUE(wasDestructed);\n  }\n}",
            "{\n  intrusive_ptr<SomeClass> a = make_intrusive<SomeClass>();\n  intrusive_ptr<const SomeClass> b = std::move(a);\n}",
            "{\n  intrusive_ptr<SomeClass> a = make_intrusive<SomeClass>();\n  intrusive_ptr<const SomeClass> b = a;\n}",
            "{\n  intrusive_ptr<SomeClass> a = make_intrusive<SomeClass>();\n  intrusive_ptr<const SomeClass> b = make_intrusive<SomeClass>();\n  b = std::move(a);\n}",
            "{\n  intrusive_ptr<SomeClass> a = make_intrusive<SomeClass>();\n  intrusive_ptr<const SomeClass> b = make_intrusive<const SomeClass>();\n  b = a;\n}",
            "{\n  intrusive_ptr<SomeClass> obj = make_intrusive<SomeClass>();\n  EXPECT_EQ(1, obj.use_count());\n}",
            "{\n  intrusive_ptr<SomeClass> obj = make_intrusive<SomeClass>();\n  EXPECT_TRUE(obj.unique());\n}",
            "{\n  intrusive_ptr<SomeClass> obj;\n  EXPECT_EQ(0, obj.use_count());\n}",
            "{\n  intrusive_ptr<SomeClass> obj;\n  EXPECT_FALSE(obj.unique());\n}",
            "{\n  intrusive_ptr<SomeClass> obj = make_intrusive<SomeClass>();\n  obj.reset();\n  EXPECT_EQ(0, obj.use_count());\n}",
            "{\n  intrusive_ptr<SomeClass> obj = make_intrusive<SomeClass>();\n  obj.reset();\n  EXPECT_FALSE(obj.unique());\n}",
            "{\n  intrusive_ptr<SomeClass> obj = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> obj2 = std::move(obj);\n  EXPECT_EQ(1, obj2.use_count());\n}",
            "{\n  intrusive_ptr<SomeClass> obj = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> obj2 = std::move(obj);\n  EXPECT_TRUE(obj2.unique());\n}",
            "{\n  intrusive_ptr<SomeClass> obj = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> obj2 = std::move(obj);\n  EXPECT_EQ(0, obj.use_count());\n}",
            "{\n  intrusive_ptr<SomeClass> obj = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> obj2 = std::move(obj);\n  EXPECT_FALSE(obj.unique());\n}",
            "{\n  intrusive_ptr<SomeClass> obj = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> obj2 = make_intrusive<SomeClass>();\n  obj2 = std::move(obj);\n  EXPECT_EQ(1, obj2.use_count());\n}",
            "{\n  intrusive_ptr<SomeClass> obj = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> obj2 = make_intrusive<SomeClass>();\n  obj2 = std::move(obj);\n  EXPECT_TRUE(obj2.unique());\n}",
            "{\n  intrusive_ptr<SomeClass> obj = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> obj2 = make_intrusive<SomeClass>();\n  obj2 = std::move(obj);\n  EXPECT_EQ(0, obj.use_count());\n}",
            "{\n  intrusive_ptr<SomeClass> obj = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> obj2 = make_intrusive<SomeClass>();\n  obj2 = std::move(obj);\n  EXPECT_FALSE(obj.unique());\n}",
            "{\n  intrusive_ptr<SomeClass> obj = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> obj2 = obj;\n  EXPECT_EQ(2, obj2.use_count());\n}",
            "{\n  intrusive_ptr<SomeClass> obj = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> obj2 = obj;\n  EXPECT_FALSE(obj2.unique());\n}",
            "{\n  intrusive_ptr<SomeClass> obj = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> obj2 = obj;\n  EXPECT_EQ(2, obj.use_count());\n}",
            "{\n  intrusive_ptr<SomeClass> obj = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> obj2 = obj;\n  EXPECT_FALSE(obj.unique());\n}",
            "{\n  intrusive_ptr<SomeClass> obj = make_intrusive<SomeClass>();\n  {\n    intrusive_ptr<SomeClass> obj2 = obj;\n    EXPECT_EQ(2, obj.use_count());\n  }\n  EXPECT_EQ(1, obj.use_count());\n}",
            "{\n  intrusive_ptr<SomeClass> obj = make_intrusive<SomeClass>();\n  {\n    intrusive_ptr<SomeClass> obj2 = obj;\n    EXPECT_FALSE(obj.unique());\n  }\n  EXPECT_TRUE(obj.unique());\n}",
            "{\n  intrusive_ptr<SomeClass> obj = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> obj2 = obj;\n  EXPECT_EQ(2, obj.use_count());\n  obj2 = make_intrusive<SomeClass>();\n  EXPECT_EQ(1, obj.use_count());\n  EXPECT_EQ(1, obj2.use_count());\n}",
            "{\n  intrusive_ptr<SomeClass> obj = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> obj2 = obj;\n  EXPECT_FALSE(obj.unique());\n  obj2 = make_intrusive<SomeClass>();\n  EXPECT_TRUE(obj.unique());\n  EXPECT_TRUE(obj2.unique());\n}",
            "{\n  intrusive_ptr<SomeClass> obj = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> obj2 = make_intrusive<SomeClass>();\n  obj2 = obj;\n  EXPECT_EQ(2, obj.use_count());\n  EXPECT_EQ(2, obj2.use_count());\n}",
            "{\n  intrusive_ptr<SomeClass> obj = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> obj2 = make_intrusive<SomeClass>();\n  obj2 = obj;\n  EXPECT_FALSE(obj.unique());\n  EXPECT_FALSE(obj2.unique());\n}",
            "{\n  intrusive_ptr<SomeClass> obj = make_intrusive<SomeClass>();\n  {\n    intrusive_ptr<SomeClass> obj2 = make_intrusive<SomeClass>();\n    obj2 = obj;\n    EXPECT_EQ(2, obj.use_count());\n  }\n  EXPECT_EQ(1, obj.use_count());\n}",
            "{\n  intrusive_ptr<SomeClass> obj = make_intrusive<SomeClass>();\n  {\n    intrusive_ptr<SomeClass> obj2 = make_intrusive<SomeClass>();\n    obj2 = obj;\n    EXPECT_FALSE(obj.unique());\n  }\n  EXPECT_TRUE(obj.unique());\n}",
            "{\n  intrusive_ptr<SomeClass> obj = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> obj2 = make_intrusive<SomeClass>();\n  obj2 = obj;\n  EXPECT_EQ(2, obj.use_count());\n  obj2 = make_intrusive<SomeClass>();\n  EXPECT_EQ(1, obj.use_count());\n  EXPECT_EQ(1, obj2.use_count());\n}",
            "{\n  intrusive_ptr<SomeClass> obj = make_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> obj2 = make_intrusive<SomeClass>();\n  obj2 = obj;\n  EXPECT_FALSE(obj.unique());\n  obj2 = make_intrusive<SomeClass>();\n  EXPECT_TRUE(obj.unique());\n  EXPECT_TRUE(obj2.unique());\n}",
            "{\n  intrusive_ptr<SomeClass> obj = make_intrusive<SomeClass>();\n  SomeClass* ptr = obj.release();\n  EXPECT_FALSE(obj.defined());\n  intrusive_ptr<SomeClass> reclaimed = intrusive_ptr<SomeClass>::reclaim(ptr);\n}",
            "{\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  {\n    intrusive_ptr<DestructableMock> outer;\n    {\n      intrusive_ptr<DestructableMock> inner =\n          make_intrusive<DestructableMock>(&resourcesReleased, &wasDestructed);\n      DestructableMock* ptr = inner.release();\n      EXPECT_FALSE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n      outer = intrusive_ptr<DestructableMock>::reclaim(ptr);\n    }\n    // inner is destructed\n    EXPECT_FALSE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n  }\n  // outer is destructed\n  EXPECT_TRUE(resourcesReleased);\n  EXPECT_TRUE(wasDestructed);\n}",
            "{\n  intrusive_ptr<SomeClass> obj = make_intrusive<SomeClass>();\n  SomeClass* raw_ptr = obj.get();\n  EXPECT_TRUE(obj.defined());\n  intrusive_ptr<SomeClass> reclaimed =\n      intrusive_ptr<SomeClass>::unsafe_reclaim_from_nonowning(raw_ptr);\n  EXPECT_TRUE(reclaimed.defined());\n  EXPECT_EQ(reclaimed.get(), obj.get());\n}",
            "{\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  {\n    intrusive_ptr<DestructableMock> outer;\n    {\n      intrusive_ptr<DestructableMock> inner =\n          make_intrusive<DestructableMock>(&resourcesReleased, &wasDestructed);\n      DestructableMock* raw_ptr = inner.get();\n      outer = intrusive_ptr<DestructableMock>::unsafe_reclaim_from_nonowning(\n          raw_ptr);\n    }\n    // inner is destructed\n    EXPECT_FALSE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n  }\n  // outer is destructed\n  EXPECT_TRUE(resourcesReleased);\n  EXPECT_TRUE(wasDestructed);\n}",
            "{\n  IntrusiveAndWeak<SomeClass> var = make_weak_intrusive<SomeClass>();\n}",
            "{\n  IntrusiveAndWeak<SomeClass> var = make_weak_intrusive<SomeClass>();\n  intrusive_ptr<SomeClass> locked = var.weak.lock();\n  EXPECT_EQ(var.ptr.get(), locked.get());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> var = make_weak_intrusive<SomeClass>();\n  // reset the intrusive_ptr to test if weak pointer still valid\n  var.ptr.reset();\n  EXPECT_TRUE(var.weak.expired());\n  intrusive_ptr<SomeClass> locked = var.weak.lock();\n  EXPECT_FALSE(locked.defined());\n}",
            "{\n  auto weak_ptr = make_invalid_weak<SomeClass>();\n  intrusive_ptr<SomeClass> locked = weak_ptr.lock();\n  EXPECT_FALSE(locked.defined());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj1 = make_weak_intrusive<SomeClass>();\n  IntrusiveAndWeak<SomeClass> obj2 = make_weak_intrusive<SomeClass>();\n  SomeClass* obj1ptr = obj1.weak.lock().get();\n  obj2.weak = std::move(obj1.weak);\n  EXPECT_EQ(obj1ptr, obj2.weak.lock().get());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj1 = make_weak_intrusive<SomeClass>();\n  IntrusiveAndWeak<SomeClass> obj2 = make_weak_intrusive<SomeClass>();\n  obj2.weak = std::move(obj1.weak);\n  EXPECT_TRUE(obj1.weak.expired());\n}",
            "{\n  std::vector<weak_intrusive_ptr<SomeClass>> priorWorks;\n  std::vector<intrusive_ptr<SomeClass>> wips;\n  wips.push_back(make_intrusive<SomeClass>());\n  priorWorks.insert(priorWorks.end(), wips.begin(), wips.end());\n  EXPECT_EQ(priorWorks.size(), 1);\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj1 = make_weak_intrusive<SomeClass>();\n  weak_intrusive_ptr<SomeClass> obj2 = make_invalid_weak<SomeClass>();\n  SomeClass* obj1ptr = obj1.weak.lock().get();\n  obj2 = std::move(obj1.weak);\n  EXPECT_FALSE(obj2.expired());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj1 = make_weak_intrusive<SomeClass>();\n  SomeClass* obj1ptr = obj1.weak.lock().get();\n  obj1.weak = std::move(obj1.weak);\n  EXPECT_EQ(obj1ptr, obj1.weak.lock().get());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj1 = make_weak_intrusive<SomeClass>();\n  obj1.weak = std::move(obj1.weak);\n  EXPECT_FALSE(obj1.weak.expired());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj1 = make_weak_intrusive<SomeClass>();\n  weak_intrusive_ptr<SomeClass> obj2 = make_invalid_weak<SomeClass>();\n  SomeClass* obj1ptr = obj1.weak.lock().get();\n  obj2 = std::move(obj1.weak);\n  EXPECT_EQ(obj1ptr, obj2.lock().get());\n}",
            "{\n  weak_intrusive_ptr<SomeClass> obj1 = make_invalid_weak<SomeClass>();\n  obj1 = std::move(obj1);\n  EXPECT_TRUE(obj1.expired());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj1 = make_weak_intrusive<SomeClass>();\n  weak_intrusive_ptr<SomeClass> obj2 = make_weak_only<SomeClass>();\n  SomeClass* obj1ptr = obj1.weak.lock().get();\n  obj2 = std::move(obj1.weak);\n  EXPECT_FALSE(obj2.expired());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj1 = make_weak_intrusive<SomeClass>();\n  weak_intrusive_ptr<SomeClass> obj2 = make_weak_only<SomeClass>();\n  SomeClass* obj1ptr = obj1.weak.lock().get();\n  obj2 = std::move(obj1.weak);\n  EXPECT_EQ(obj1ptr, obj2.lock().get());\n}",
            "{\n  weak_intrusive_ptr<SomeClass> obj1 = make_weak_only<SomeClass>();\n  SomeClass* obj1ptr = obj1.lock().get();\n  obj1 = std::move(obj1);\n  EXPECT_TRUE(obj1.expired());\n}",
            "{\n  weak_intrusive_ptr<SomeClass> obj1 = make_weak_only<SomeClass>();\n  SomeClass* obj1ptr = obj1.lock().get();\n  obj1 = std::move(obj1);\n  EXPECT_EQ(obj1ptr, obj1.lock().get());\n}",
            "{\n  weak_intrusive_ptr<SomeClass> obj1 = make_invalid_weak<SomeClass>();\n  IntrusiveAndWeak<SomeClass> obj2 = make_weak_intrusive<SomeClass>();\n  EXPECT_FALSE(obj2.weak.expired());\n  obj2.weak = std::move(obj1);\n  EXPECT_TRUE(obj2.weak.expired());\n}",
            "{\n  weak_intrusive_ptr<SomeClass> obj1 = make_weak_only<SomeClass>();\n  IntrusiveAndWeak<SomeClass> obj2 = make_weak_intrusive<SomeClass>();\n  EXPECT_FALSE(obj2.weak.expired());\n  obj2.weak = std::move(obj1);\n  EXPECT_TRUE(obj2.weak.expired());\n}",
            "{\n  IntrusiveAndWeak<SomeChildClass> obj1 =\n      make_weak_intrusive<SomeChildClass>(1);\n  IntrusiveAndWeak<SomeBaseClass> obj2 = make_weak_intrusive<SomeBaseClass>(2);\n  SomeBaseClass* obj1ptr = obj1.weak.lock().get();\n  obj2.weak = std::move(obj1.weak);\n  EXPECT_EQ(obj1ptr, obj2.weak.lock().get());\n  EXPECT_EQ(1, obj2.weak.lock()->v);\n}",
            "{\n  IntrusiveAndWeak<SomeChildClass> obj1 =\n      make_weak_intrusive<SomeChildClass>(1);\n  IntrusiveAndWeak<SomeBaseClass> obj2 = make_weak_intrusive<SomeBaseClass>(2);\n  obj2.weak = std::move(obj1.weak);\n  EXPECT_TRUE(obj1.weak.expired());\n}",
            "{\n  IntrusiveAndWeak<SomeChildClass> obj1 =\n      make_weak_intrusive<SomeChildClass>(5);\n  weak_intrusive_ptr<SomeBaseClass> obj2 = make_invalid_weak<SomeBaseClass>();\n  SomeBaseClass* obj1ptr = obj1.weak.lock().get();\n  obj2 = std::move(obj1.weak);\n  EXPECT_FALSE(obj2.expired());\n}",
            "{\n  IntrusiveAndWeak<SomeChildClass> obj1 =\n      make_weak_intrusive<SomeChildClass>(5);\n  weak_intrusive_ptr<SomeBaseClass> obj2 = make_invalid_weak<SomeBaseClass>();\n  SomeBaseClass* obj1ptr = obj1.weak.lock().get();\n  obj2 = std::move(obj1.weak);\n  EXPECT_EQ(obj1ptr, obj2.lock().get());\n  EXPECT_EQ(5, obj2.lock()->v);\n}",
            "{\n  weak_intrusive_ptr<SomeChildClass> obj1 = make_invalid_weak<SomeChildClass>();\n  IntrusiveAndWeak<SomeBaseClass> obj2 = make_weak_intrusive<SomeBaseClass>(2);\n  EXPECT_FALSE(obj2.weak.expired());\n  obj2.weak = std::move(obj1);\n  EXPECT_TRUE(obj2.weak.expired());\n}",
            "{\n  IntrusiveAndWeak<SomeChildClass> obj1 =\n      make_weak_intrusive<SomeChildClass>(5);\n  weak_intrusive_ptr<SomeBaseClass> obj2 = make_weak_only<SomeBaseClass>(2);\n  SomeBaseClass* obj1ptr = obj1.weak.lock().get();\n  obj2 = std::move(obj1.weak);\n  EXPECT_FALSE(obj2.expired());\n}",
            "{\n  IntrusiveAndWeak<SomeChildClass> obj1 =\n      make_weak_intrusive<SomeChildClass>(5);\n  weak_intrusive_ptr<SomeBaseClass> obj2 = make_weak_only<SomeBaseClass>(2);\n  SomeBaseClass* obj1ptr = obj1.weak.lock().get();\n  obj2 = std::move(obj1.weak);\n  EXPECT_EQ(obj1ptr, obj2.lock().get());\n  EXPECT_EQ(5, obj2.lock()->v);\n}",
            "{\n  weak_intrusive_ptr<SomeChildClass> obj1 = make_weak_only<SomeChildClass>(5);\n  IntrusiveAndWeak<SomeBaseClass> obj2 = make_weak_intrusive<SomeBaseClass>(2);\n  EXPECT_FALSE(obj2.weak.expired());\n  obj2.weak = std::move(obj1);\n  EXPECT_TRUE(obj2.weak.expired());\n}",
            "{\n  weak_intrusive_ptr<SomeClass, NullType1> obj1 = make_invalid_weak<SomeClass, NullType1>();\n  weak_intrusive_ptr<SomeClass, NullType2> obj2 = make_invalid_weak<SomeClass, NullType2>();\n  obj2 = std::move(obj1);\n  EXPECT_NE(NullType1::singleton(), NullType2::singleton());\n  EXPECT_TRUE(obj1.expired());\n  EXPECT_TRUE(obj2.expired());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj1 = make_weak_intrusive<SomeClass>();\n  IntrusiveAndWeak<SomeClass> obj2 = make_weak_intrusive<SomeClass>();\n  SomeClass* obj1ptr = obj1.weak.lock().get();\n  obj2.weak = obj1.weak;\n  EXPECT_EQ(obj1ptr, obj2.weak.lock().get());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj1 = make_weak_intrusive<SomeClass>();\n  IntrusiveAndWeak<SomeClass> obj2 = make_weak_intrusive<SomeClass>();\n  obj2.weak = obj1.weak;\n  EXPECT_FALSE(obj1.weak.expired());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj1 = make_weak_intrusive<SomeClass>();\n  SomeClass* obj1ptr = obj1.weak.lock().get();\n  obj1.weak = obj1.weak;\n  EXPECT_EQ(obj1ptr, obj1.weak.lock().get());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj1 = make_weak_intrusive<SomeClass>();\n  obj1.weak = obj1.weak;\n  EXPECT_FALSE(obj1.weak.expired());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj1 = make_weak_intrusive<SomeClass>();\n  weak_intrusive_ptr<SomeClass> obj2 = make_invalid_weak<SomeClass>();\n  SomeClass* obj1ptr = obj1.weak.lock().get();\n  obj2 = obj1.weak;\n  EXPECT_FALSE(obj2.expired());\n}",
            "{\n  weak_intrusive_ptr<SomeClass> obj1 = make_invalid_weak<SomeClass>();\n  obj1 = obj1;\n  EXPECT_TRUE(obj1.expired());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj1 = make_weak_intrusive<SomeClass>();\n  weak_intrusive_ptr<SomeClass> obj2 = make_weak_only<SomeClass>();\n  SomeClass* obj1ptr = obj1.weak.lock().get();\n  obj2 = obj1.weak;\n  EXPECT_FALSE(obj2.expired());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj1 = make_weak_intrusive<SomeClass>();\n  weak_intrusive_ptr<SomeClass> obj2 = make_weak_only<SomeClass>();\n  SomeClass* obj1ptr = obj1.weak.lock().get();\n  obj2 = obj1.weak;\n  EXPECT_EQ(obj1ptr, obj2.lock().get());\n}",
            "{\n  weak_intrusive_ptr<SomeClass> obj1 = make_weak_only<SomeClass>();\n  SomeClass* obj1ptr = obj1.lock().get();\n  obj1 = obj1;\n  EXPECT_TRUE(obj1.expired());\n}",
            "{\n  weak_intrusive_ptr<SomeClass> obj1 = make_weak_only<SomeClass>();\n  SomeClass* obj1ptr = obj1.lock().get();\n  obj1 = obj1;\n  EXPECT_EQ(obj1ptr, obj1.lock().get());\n}",
            "{\n  IntrusiveAndWeak<SomeChildClass> child =\n      make_weak_intrusive<SomeChildClass>(3);\n  IntrusiveAndWeak<SomeBaseClass> base = make_weak_intrusive<SomeBaseClass>(10);\n  base.weak = child.weak;\n  EXPECT_EQ(3, base.weak.lock()->v);\n}",
            "{\n  IntrusiveAndWeak<SomeChildClass> obj1 =\n      make_weak_intrusive<SomeChildClass>(3);\n  IntrusiveAndWeak<SomeBaseClass> obj2 = make_weak_intrusive<SomeBaseClass>(10);\n  obj2.weak = obj1.weak;\n  EXPECT_FALSE(obj1.weak.expired());\n}",
            "{\n  IntrusiveAndWeak<SomeChildClass> obj1 =\n      make_weak_intrusive<SomeChildClass>(5);\n  weak_intrusive_ptr<SomeBaseClass> obj2 = make_invalid_weak<SomeBaseClass>();\n  SomeBaseClass* obj1ptr = obj1.weak.lock().get();\n  obj2 = obj1.weak;\n  EXPECT_FALSE(obj2.expired());\n}",
            "{\n  IntrusiveAndWeak<SomeChildClass> obj1 =\n      make_weak_intrusive<SomeChildClass>(5);\n  weak_intrusive_ptr<SomeBaseClass> obj2 = make_invalid_weak<SomeBaseClass>();\n  SomeBaseClass* obj1ptr = obj1.weak.lock().get();\n  obj2 = obj1.weak;\n  EXPECT_EQ(obj1ptr, obj2.lock().get());\n  EXPECT_EQ(5, obj2.lock()->v);\n}",
            "{\n  weak_intrusive_ptr<SomeChildClass> obj1 = make_invalid_weak<SomeChildClass>();\n  IntrusiveAndWeak<SomeBaseClass> obj2 = make_weak_intrusive<SomeBaseClass>(2);\n  EXPECT_FALSE(obj2.weak.expired());\n  obj2.weak = obj1;\n  EXPECT_TRUE(obj2.weak.expired());\n}",
            "{\n  IntrusiveAndWeak<SomeChildClass> obj1 =\n      make_weak_intrusive<SomeChildClass>(5);\n  weak_intrusive_ptr<SomeBaseClass> obj2 = make_weak_only<SomeBaseClass>(2);\n  SomeBaseClass* obj1ptr = obj1.weak.lock().get();\n  obj2 = obj1.weak;\n  EXPECT_FALSE(obj2.expired());\n}",
            "{\n  IntrusiveAndWeak<SomeChildClass> obj1 =\n      make_weak_intrusive<SomeChildClass>(5);\n  weak_intrusive_ptr<SomeBaseClass> obj2 = make_weak_only<SomeBaseClass>(2);\n  SomeBaseClass* obj1ptr = obj1.weak.lock().get();\n  obj2 = obj1.weak;\n  EXPECT_EQ(obj1ptr, obj2.lock().get());\n  EXPECT_EQ(5, obj2.lock()->v);\n}",
            "{\n  weak_intrusive_ptr<SomeChildClass> obj1 = make_weak_only<SomeChildClass>(2);\n  IntrusiveAndWeak<SomeBaseClass> obj2 = make_weak_intrusive<SomeBaseClass>(2);\n  EXPECT_FALSE(obj2.weak.expired());\n  obj2.weak = obj1;\n  EXPECT_TRUE(obj2.weak.expired());\n}",
            "{\n  weak_intrusive_ptr<SomeClass, NullType1> obj1 = make_invalid_weak<SomeClass, NullType1>();\n  weak_intrusive_ptr<SomeClass, NullType2> obj2 = make_invalid_weak<SomeClass, NullType2>();\n  obj2 = obj1;\n  EXPECT_NE(NullType1::singleton(), NullType2::singleton());\n  EXPECT_TRUE(obj1.expired());\n  EXPECT_TRUE(obj2.expired());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj1 = make_weak_intrusive<SomeClass>();\n  SomeClass* obj1ptr = obj1.weak.lock().get();\n  weak_intrusive_ptr<SomeClass> obj2 = std::move(obj1.weak);\n  EXPECT_EQ(obj1ptr, obj2.lock().get());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj1 = make_weak_intrusive<SomeClass>();\n  weak_intrusive_ptr<SomeClass> obj2 = std::move(obj1.weak);\n  EXPECT_TRUE(obj1.weak.expired());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj1 = make_weak_intrusive<SomeClass>();\n  weak_intrusive_ptr<SomeClass> obj2 = std::move(obj1.weak);\n  EXPECT_FALSE(obj2.expired());\n}",
            "{\n  weak_intrusive_ptr<SomeClass> obj1 = make_invalid_weak<SomeClass>();\n  weak_intrusive_ptr<SomeClass> obj2 = std::move(obj1);\n  EXPECT_TRUE(obj2.expired());\n}",
            "{\n  weak_intrusive_ptr<SomeClass> obj1 = make_weak_only<SomeClass>();\n  weak_intrusive_ptr<SomeClass> obj2 = std::move(obj1);\n  EXPECT_TRUE(obj2.expired());\n}",
            "{\n  IntrusiveAndWeak<SomeChildClass> child =\n      make_weak_intrusive<SomeChildClass>(3);\n  SomeBaseClass* objptr = child.weak.lock().get();\n  weak_intrusive_ptr<SomeBaseClass> base = std::move(child.weak);\n  EXPECT_EQ(3, base.lock()->v);\n  EXPECT_EQ(objptr, base.lock().get());\n}",
            "{\n  IntrusiveAndWeak<SomeChildClass> child =\n      make_weak_intrusive<SomeChildClass>(3);\n  weak_intrusive_ptr<SomeBaseClass> base = std::move(child.weak);\n  EXPECT_TRUE(child.weak.expired());\n}",
            "{\n  IntrusiveAndWeak<SomeChildClass> obj1 =\n      make_weak_intrusive<SomeChildClass>(2);\n  weak_intrusive_ptr<SomeBaseClass> obj2 = std::move(obj1.weak);\n  EXPECT_FALSE(obj2.expired());\n}",
            "{\n  weak_intrusive_ptr<SomeChildClass> obj1 = make_invalid_weak<SomeChildClass>();\n  weak_intrusive_ptr<SomeBaseClass> obj2 = std::move(obj1);\n  EXPECT_TRUE(obj2.expired());\n}",
            "{\n  weak_intrusive_ptr<SomeChildClass> obj1 = make_weak_only<SomeChildClass>(2);\n  weak_intrusive_ptr<SomeBaseClass> obj2 = std::move(obj1);\n  EXPECT_TRUE(obj2.expired());\n}",
            "{\n  weak_intrusive_ptr<SomeClass, NullType1> obj1 = make_invalid_weak<SomeClass, NullType1>();\n  weak_intrusive_ptr<SomeClass, NullType2> obj2 = std::move(obj1);\n  EXPECT_NE(NullType1::singleton(), NullType2::singleton());\n  EXPECT_TRUE(obj1.expired());\n  EXPECT_TRUE(obj2.expired());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj1 = make_weak_intrusive<SomeClass>();\n  SomeClass* obj1ptr = obj1.weak.lock().get();\n  weak_intrusive_ptr<SomeClass> obj2 = obj1.weak;\n  EXPECT_EQ(obj1ptr, obj2.lock().get());\n  EXPECT_FALSE(obj1.weak.expired());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj1 = make_weak_intrusive<SomeClass>();\n  weak_intrusive_ptr<SomeClass> obj2 = obj1.weak;\n  EXPECT_FALSE(obj1.weak.expired());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj1 = make_weak_intrusive<SomeClass>();\n  weak_intrusive_ptr<SomeClass> obj2 = obj1.weak;\n  EXPECT_FALSE(obj2.expired());\n}",
            "{\n  weak_intrusive_ptr<SomeClass> obj1 = make_invalid_weak<SomeClass>();\n  weak_intrusive_ptr<SomeClass> obj2 = obj1;\n  EXPECT_TRUE(obj2.expired());\n}",
            "{\n  weak_intrusive_ptr<SomeClass> obj1 = make_weak_only<SomeClass>();\n  weak_intrusive_ptr<SomeClass> obj2 = obj1;\n  EXPECT_TRUE(obj2.expired());\n}",
            "{\n  IntrusiveAndWeak<SomeChildClass> child =\n      make_weak_intrusive<SomeChildClass>(3);\n  SomeBaseClass* objptr = child.weak.lock().get();\n  weak_intrusive_ptr<SomeBaseClass> base = child.weak;\n  EXPECT_EQ(3, base.lock()->v);\n  EXPECT_EQ(objptr, base.lock().get());\n}",
            "{\n  IntrusiveAndWeak<SomeChildClass> child =\n      make_weak_intrusive<SomeChildClass>(3);\n  weak_intrusive_ptr<SomeBaseClass> base = child.weak;\n  EXPECT_FALSE(child.weak.expired());\n}",
            "{\n  IntrusiveAndWeak<SomeChildClass> child =\n      make_weak_intrusive<SomeChildClass>(3);\n  weak_intrusive_ptr<SomeBaseClass> base = child.weak;\n  EXPECT_FALSE(base.expired());\n}",
            "{\n  weak_intrusive_ptr<SomeChildClass> obj1 = make_invalid_weak<SomeChildClass>();\n  weak_intrusive_ptr<SomeBaseClass> obj2 = obj1;\n  EXPECT_TRUE(obj2.expired());\n}",
            "{\n  weak_intrusive_ptr<SomeChildClass> obj1 = make_weak_only<SomeChildClass>(2);\n  weak_intrusive_ptr<SomeBaseClass> obj2 = obj1;\n  EXPECT_TRUE(obj2.expired());\n}",
            "{\n  weak_intrusive_ptr<SomeClass, NullType1> obj1 = make_invalid_weak<SomeClass, NullType1>();\n  weak_intrusive_ptr<SomeClass, NullType2> obj2 = obj1;\n  EXPECT_NE(NullType1::singleton(), NullType2::singleton());\n  EXPECT_TRUE(obj1.expired());\n  EXPECT_TRUE(obj2.expired());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj1 = make_weak_intrusive<SomeClass>();\n  IntrusiveAndWeak<SomeClass> obj2 = make_weak_intrusive<SomeClass>();\n  SomeClass* obj1ptr = obj1.weak.lock().get();\n  SomeClass* obj2ptr = obj2.weak.lock().get();\n  swap(obj1.weak, obj2.weak);\n  EXPECT_EQ(obj2ptr, obj1.weak.lock().get());\n  EXPECT_EQ(obj1ptr, obj2.weak.lock().get());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj1 = make_weak_intrusive<SomeClass>();\n  IntrusiveAndWeak<SomeClass> obj2 = make_weak_intrusive<SomeClass>();\n  SomeClass* obj1ptr = obj1.weak.lock().get();\n  SomeClass* obj2ptr = obj2.weak.lock().get();\n  obj1.weak.swap(obj2.weak);\n  EXPECT_EQ(obj2ptr, obj1.weak.lock().get());\n  EXPECT_EQ(obj1ptr, obj2.weak.lock().get());\n}",
            "{\n  weak_intrusive_ptr<SomeClass> obj1 = make_invalid_weak<SomeClass>();\n  IntrusiveAndWeak<SomeClass> obj2 = make_weak_intrusive<SomeClass>();\n  SomeClass* obj2ptr = obj2.weak.lock().get();\n  swap(obj1, obj2.weak);\n  EXPECT_EQ(obj2ptr, obj1.lock().get());\n  EXPECT_FALSE(obj1.expired());\n  EXPECT_TRUE(obj2.weak.expired());\n}",
            "{\n  weak_intrusive_ptr<SomeClass> obj1 = make_invalid_weak<SomeClass>();\n  IntrusiveAndWeak<SomeClass> obj2 = make_weak_intrusive<SomeClass>();\n  SomeClass* obj2ptr = obj2.weak.lock().get();\n  obj1.swap(obj2.weak);\n  EXPECT_EQ(obj2ptr, obj1.lock().get());\n  EXPECT_FALSE(obj1.expired());\n  EXPECT_TRUE(obj2.weak.expired());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj1 = make_weak_intrusive<SomeClass>();\n  weak_intrusive_ptr<SomeClass> obj2 = make_invalid_weak<SomeClass>();\n  SomeClass* obj1ptr = obj1.weak.lock().get();\n  swap(obj1.weak, obj2);\n  EXPECT_TRUE(obj1.weak.expired());\n  EXPECT_FALSE(obj2.expired());\n  EXPECT_EQ(obj1ptr, obj2.lock().get());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj1 = make_weak_intrusive<SomeClass>();\n  weak_intrusive_ptr<SomeClass> obj2 = make_invalid_weak<SomeClass>();\n  SomeClass* obj1ptr = obj1.weak.lock().get();\n  obj1.weak.swap(obj2);\n  EXPECT_TRUE(obj1.weak.expired());\n  EXPECT_FALSE(obj2.expired());\n  EXPECT_EQ(obj1ptr, obj2.lock().get());\n}",
            "{\n  weak_intrusive_ptr<SomeClass> obj1 = make_invalid_weak<SomeClass>();\n  weak_intrusive_ptr<SomeClass> obj2 = make_invalid_weak<SomeClass>();\n  swap(obj1, obj2);\n  EXPECT_TRUE(obj1.expired());\n  EXPECT_TRUE(obj2.expired());\n}",
            "{\n  weak_intrusive_ptr<SomeClass> obj1 = make_invalid_weak<SomeClass>();\n  weak_intrusive_ptr<SomeClass> obj2 = make_invalid_weak<SomeClass>();\n  obj1.swap(obj2);\n  EXPECT_TRUE(obj1.expired());\n  EXPECT_TRUE(obj2.expired());\n}",
            "{\n  weak_intrusive_ptr<SomeClass> obj1 = make_weak_only<SomeClass>();\n  IntrusiveAndWeak<SomeClass> obj2 = make_weak_intrusive<SomeClass>();\n  SomeClass* obj2ptr = obj2.weak.lock().get();\n  swap(obj1, obj2.weak);\n  EXPECT_EQ(obj2ptr, obj1.lock().get());\n  EXPECT_FALSE(obj1.expired());\n  EXPECT_TRUE(obj2.weak.expired());\n}",
            "{\n  weak_intrusive_ptr<SomeClass> obj1 = make_weak_only<SomeClass>();\n  IntrusiveAndWeak<SomeClass> obj2 = make_weak_intrusive<SomeClass>();\n  SomeClass* obj2ptr = obj2.weak.lock().get();\n  obj1.swap(obj2.weak);\n  EXPECT_EQ(obj2ptr, obj1.lock().get());\n  EXPECT_FALSE(obj1.expired());\n  EXPECT_TRUE(obj2.weak.expired());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj1 = make_weak_intrusive<SomeClass>();\n  weak_intrusive_ptr<SomeClass> obj2 = make_weak_only<SomeClass>();\n  SomeClass* obj1ptr = obj1.weak.lock().get();\n  swap(obj1.weak, obj2);\n  EXPECT_TRUE(obj1.weak.expired());\n  EXPECT_FALSE(obj2.expired());\n  EXPECT_EQ(obj1ptr, obj2.lock().get());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj1 = make_weak_intrusive<SomeClass>();\n  weak_intrusive_ptr<SomeClass> obj2 = make_weak_only<SomeClass>();\n  SomeClass* obj1ptr = obj1.weak.lock().get();\n  obj1.weak.swap(obj2);\n  EXPECT_TRUE(obj1.weak.expired());\n  EXPECT_FALSE(obj2.expired());\n  EXPECT_EQ(obj1ptr, obj2.lock().get());\n}",
            "{\n  weak_intrusive_ptr<SomeClass> obj1 = make_weak_only<SomeClass>();\n  weak_intrusive_ptr<SomeClass> obj2 = make_weak_only<SomeClass>();\n  swap(obj1, obj2);\n  EXPECT_TRUE(obj1.expired());\n  EXPECT_TRUE(obj2.expired());\n}",
            "{\n  weak_intrusive_ptr<SomeClass> obj1 = make_weak_only<SomeClass>();\n  weak_intrusive_ptr<SomeClass> obj2 = make_weak_only<SomeClass>();\n  obj1.swap(obj2);\n  EXPECT_TRUE(obj1.expired());\n  EXPECT_TRUE(obj2.expired());\n}",
            "{\n  std::vector<weak_intrusive_ptr<SomeClass1Parameter>> vec;\n  IntrusiveAndWeak<SomeClass1Parameter> obj =\n      make_weak_intrusive<SomeClass1Parameter>(5);\n  vec.push_back(obj.weak);\n  EXPECT_EQ(5, vec[0].lock()->param);\n}",
            "{\n  std::set<weak_intrusive_ptr<SomeClass1Parameter>> set;\n  IntrusiveAndWeak<SomeClass1Parameter> obj =\n      make_weak_intrusive<SomeClass1Parameter>(5);\n  set.insert(obj.weak);\n  EXPECT_EQ(5, set.begin()->lock()->param);\n}",
            "{\n  std::unordered_set<weak_intrusive_ptr<SomeClass1Parameter>> set;\n  IntrusiveAndWeak<SomeClass1Parameter> obj =\n      make_weak_intrusive<SomeClass1Parameter>(5);\n  set.insert(obj.weak);\n  EXPECT_EQ(5, set.begin()->lock()->param);\n}",
            "{\n  std::map<\n      weak_intrusive_ptr<SomeClass1Parameter>,\n      weak_intrusive_ptr<SomeClass1Parameter>>\n      map;\n  IntrusiveAndWeak<SomeClass1Parameter> obj1 =\n      make_weak_intrusive<SomeClass1Parameter>(5);\n  IntrusiveAndWeak<SomeClass1Parameter> obj2 =\n      make_weak_intrusive<SomeClass1Parameter>(3);\n  map.insert(std::make_pair(obj1.weak, obj2.weak));\n  EXPECT_EQ(5, map.begin()->first.lock()->param);\n  EXPECT_EQ(3, map.begin()->second.lock()->param);\n}",
            "{\n  std::unordered_map<\n      weak_intrusive_ptr<SomeClass1Parameter>,\n      weak_intrusive_ptr<SomeClass1Parameter>>\n      map;\n  IntrusiveAndWeak<SomeClass1Parameter> obj1 =\n      make_weak_intrusive<SomeClass1Parameter>(5);\n  IntrusiveAndWeak<SomeClass1Parameter> obj2 =\n      make_weak_intrusive<SomeClass1Parameter>(3);\n  map.insert(std::make_pair(obj1.weak, obj2.weak));\n  EXPECT_EQ(5, map.begin()->first.lock()->param);\n  EXPECT_EQ(3, map.begin()->second.lock()->param);\n}",
            "{\n  IntrusiveAndWeak<SomeClass> var1 = make_weak_intrusive<SomeClass>();\n  weak_intrusive_ptr<SomeClass> var2 = var1.weak;\n  EXPECT_TRUE(var1.weak == var2);\n  EXPECT_FALSE(var1.weak != var2);\n}",
            "{\n  IntrusiveAndWeak<SomeClass> var1 = make_weak_intrusive<SomeClass>();\n  IntrusiveAndWeak<SomeClass> var2 = make_weak_intrusive<SomeClass>();\n  var2.weak = var1.weak;\n  EXPECT_TRUE(var1.weak == var2.weak);\n  EXPECT_FALSE(var1.weak != var2.weak);\n}",
            "{\n  weak_intrusive_ptr<SomeClass> var1 = make_weak_only<SomeClass>();\n  weak_intrusive_ptr<SomeClass> var2 = var1;\n  EXPECT_TRUE(var1 == var2);\n  EXPECT_FALSE(var1 != var2);\n}",
            "{\n  weak_intrusive_ptr<SomeClass> var1 = make_invalid_weak<SomeClass>();\n  weak_intrusive_ptr<SomeClass> var2 = make_invalid_weak<SomeClass>();\n  EXPECT_TRUE(var1 == var2);\n  EXPECT_FALSE(var1 != var2);\n}",
            "{\n  IntrusiveAndWeak<SomeClass> var1 = make_intrusive<SomeClass>();\n  IntrusiveAndWeak<SomeClass> var2 = make_intrusive<SomeClass>();\n  EXPECT_TRUE(var1.weak != var2.weak);\n  EXPECT_FALSE(var1.weak == var2.weak);\n}",
            "{\n  weak_intrusive_ptr<SomeClass> var1 = make_invalid_weak<SomeClass>();\n  IntrusiveAndWeak<SomeClass> var2 = make_intrusive<SomeClass>();\n  EXPECT_TRUE(var1 != var2.weak);\n  EXPECT_FALSE(var1 == var2.weak);\n}",
            "{\n  IntrusiveAndWeak<SomeClass> var1 = make_intrusive<SomeClass>();\n  weak_intrusive_ptr<SomeClass> var2 = make_invalid_weak<SomeClass>();\n  EXPECT_TRUE(var1.weak != var2);\n  EXPECT_FALSE(var1.weak == var2);\n}",
            "{\n  weak_intrusive_ptr<SomeClass> var1 = make_weak_only<SomeClass>();\n  weak_intrusive_ptr<SomeClass> var2 = make_weak_only<SomeClass>();\n  EXPECT_TRUE(var1 != var2);\n  EXPECT_FALSE(var1 == var2);\n}",
            "{\n  IntrusiveAndWeak<SomeClass> var1 = make_weak_intrusive<SomeClass>();\n  IntrusiveAndWeak<SomeClass> var2 = make_weak_intrusive<SomeClass>();\n  EXPECT_NE(\n      std::hash<weak_intrusive_ptr<SomeClass>>()(var1.weak),\n      std::hash<weak_intrusive_ptr<SomeClass>>()(var2.weak));\n}",
            "{\n  weak_intrusive_ptr<SomeClass> var1 = make_invalid_weak<SomeClass>();\n  IntrusiveAndWeak<SomeClass> var2 = make_weak_intrusive<SomeClass>();\n  EXPECT_NE(\n      std::hash<weak_intrusive_ptr<SomeClass>>()(var1),\n      std::hash<weak_intrusive_ptr<SomeClass>>()(var2.weak));\n}",
            "{\n  weak_intrusive_ptr<SomeClass> var1 = make_weak_only<SomeClass>();\n  IntrusiveAndWeak<SomeClass> var2 = make_weak_intrusive<SomeClass>();\n  EXPECT_NE(\n      std::hash<weak_intrusive_ptr<SomeClass>>()(var1),\n      std::hash<weak_intrusive_ptr<SomeClass>>()(var2.weak));\n}",
            "{\n  weak_intrusive_ptr<SomeClass> var1 = make_weak_only<SomeClass>();\n  weak_intrusive_ptr<SomeClass> var2 = make_weak_only<SomeClass>();\n  EXPECT_NE(\n      std::hash<weak_intrusive_ptr<SomeClass>>()(var1),\n      std::hash<weak_intrusive_ptr<SomeClass>>()(var2));\n}",
            "{\n  IntrusiveAndWeak<SomeClass> var1 = make_weak_intrusive<SomeClass>();\n  weak_intrusive_ptr<SomeClass> var2 = var1.weak;\n  EXPECT_EQ(\n      std::hash<weak_intrusive_ptr<SomeClass>>()(var1.weak),\n      std::hash<weak_intrusive_ptr<SomeClass>>()(var2));\n}",
            "{\n  weak_intrusive_ptr<SomeClass> var1 = make_weak_only<SomeClass>();\n  weak_intrusive_ptr<SomeClass> var2 = var1;\n  EXPECT_EQ(\n      std::hash<weak_intrusive_ptr<SomeClass>>()(var1),\n      std::hash<weak_intrusive_ptr<SomeClass>>()(var2));\n}",
            "{\n  IntrusiveAndWeak<SomeClass> var1 = make_weak_intrusive<SomeClass>();\n  IntrusiveAndWeak<SomeClass> var2 = make_weak_intrusive<SomeClass>();\n  var2.weak = var1.weak;\n  EXPECT_EQ(\n      std::hash<weak_intrusive_ptr<SomeClass>>()(var1.weak),\n      std::hash<weak_intrusive_ptr<SomeClass>>()(var2.weak));\n}",
            "{\n  weak_intrusive_ptr<SomeClass> var1 = make_weak_only<SomeClass>();\n  weak_intrusive_ptr<SomeClass> var2 = make_invalid_weak<SomeClass>();\n  var2 = var1;\n  EXPECT_EQ(\n      std::hash<weak_intrusive_ptr<SomeClass>>()(var1),\n      std::hash<weak_intrusive_ptr<SomeClass>>()(var2));\n}",
            "{\n  weak_intrusive_ptr<SomeClass> var1 = make_invalid_weak<SomeClass>();\n  weak_intrusive_ptr<SomeClass> var2 = make_invalid_weak<SomeClass>();\n  EXPECT_EQ(\n      std::hash<weak_intrusive_ptr<SomeClass>>()(var1),\n      std::hash<weak_intrusive_ptr<SomeClass>>()(var2));\n}",
            "{\n  IntrusiveAndWeak<SomeClass> var1 = make_weak_intrusive<SomeClass>();\n  IntrusiveAndWeak<SomeClass> var2 = make_weak_intrusive<SomeClass>();\n  EXPECT_TRUE(\n      std::less<weak_intrusive_ptr<SomeClass>>()(var1.weak, var2.weak) !=\n      std::less<weak_intrusive_ptr<SomeClass>>()(var2.weak, var1.weak));\n}",
            "{\n  weak_intrusive_ptr<SomeClass> var1 = make_invalid_weak<SomeClass>();\n  IntrusiveAndWeak<SomeClass> var2 = make_weak_intrusive<SomeClass>();\n  EXPECT_TRUE(std::less<weak_intrusive_ptr<SomeClass>>()(var1, var2.weak));\n}",
            "{\n  IntrusiveAndWeak<SomeClass> var1 = make_weak_intrusive<SomeClass>();\n  weak_intrusive_ptr<SomeClass> var2 = make_invalid_weak<SomeClass>();\n  EXPECT_FALSE(std::less<weak_intrusive_ptr<SomeClass>>()(var1.weak, var2));\n}",
            "{\n  weak_intrusive_ptr<SomeClass> var1 = make_invalid_weak<SomeClass>();\n  weak_intrusive_ptr<SomeClass> var2 = make_invalid_weak<SomeClass>();\n  EXPECT_FALSE(std::less<weak_intrusive_ptr<SomeClass>>()(var1, var2));\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj = make_weak_intrusive<SomeClass>();\n  EXPECT_FALSE(obj.weak.expired());\n  obj.weak.reset();\n  EXPECT_TRUE(obj.weak.expired());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj = make_weak_intrusive<SomeClass>();\n  EXPECT_FALSE(obj.weak.expired());\n  obj.ptr.reset();\n  EXPECT_TRUE(obj.weak.expired());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> a = make_weak_intrusive<SomeClass>();\n  weak_intrusive_ptr<const SomeClass> b = std::move(a.weak);\n}",
            "{\n  IntrusiveAndWeak<SomeClass> a = make_weak_intrusive<SomeClass>();\n  weak_intrusive_ptr<const SomeClass> b = a.weak;\n}",
            "{\n  IntrusiveAndWeak<SomeClass> a = make_weak_intrusive<SomeClass>();\n  IntrusiveAndWeak<const SomeClass> b = make_weak_intrusive<const SomeClass>();\n  b.weak = std::move(a.weak);\n}",
            "{\n  IntrusiveAndWeak<SomeClass> a = make_weak_intrusive<SomeClass>();\n  IntrusiveAndWeak<const SomeClass> b = make_weak_intrusive<const SomeClass>();\n  b.weak = a.weak;\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj = make_weak_intrusive<SomeClass>();\n  EXPECT_EQ(1, obj.weak.use_count());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj = make_weak_intrusive<SomeClass>();\n  EXPECT_FALSE(obj.weak.expired());\n}",
            "{\n  weak_intrusive_ptr<SomeClass> obj = make_invalid_weak<SomeClass>();\n  EXPECT_EQ(0, obj.use_count());\n}",
            "{\n  weak_intrusive_ptr<SomeClass> obj = make_invalid_weak<SomeClass>();\n  EXPECT_TRUE(obj.expired());\n}",
            "{\n  weak_intrusive_ptr<SomeClass> obj = make_weak_only<SomeClass>();\n  EXPECT_EQ(0, obj.use_count());\n}",
            "{\n  weak_intrusive_ptr<SomeClass> obj = make_weak_only<SomeClass>();\n  EXPECT_TRUE(obj.expired());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj = make_weak_intrusive<SomeClass>();\n  obj.weak.reset();\n  EXPECT_EQ(0, obj.weak.use_count());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj = make_weak_intrusive<SomeClass>();\n  obj.weak.reset();\n  EXPECT_TRUE(obj.weak.expired());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj = make_weak_intrusive<SomeClass>();\n  obj.ptr.reset();\n  EXPECT_EQ(0, obj.weak.use_count());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj = make_weak_intrusive<SomeClass>();\n  obj.ptr.reset();\n  EXPECT_TRUE(obj.weak.expired());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj = make_weak_intrusive<SomeClass>();\n  weak_intrusive_ptr<SomeClass> obj2 = std::move(obj.weak);\n  EXPECT_EQ(1, obj2.use_count());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj = make_weak_intrusive<SomeClass>();\n  weak_intrusive_ptr<SomeClass> obj2 = std::move(obj.weak);\n  EXPECT_FALSE(obj2.expired());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj = make_weak_intrusive<SomeClass>();\n  weak_intrusive_ptr<SomeClass> obj2 = std::move(obj.weak);\n  EXPECT_EQ(0, obj.weak.use_count());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj = make_weak_intrusive<SomeClass>();\n  weak_intrusive_ptr<SomeClass> obj2 = std::move(obj.weak);\n  EXPECT_TRUE(obj.weak.expired());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj = make_weak_intrusive<SomeClass>();\n  IntrusiveAndWeak<SomeClass> obj2 = make_weak_intrusive<SomeClass>();\n  obj2.weak = std::move(obj.weak);\n  EXPECT_EQ(1, obj2.weak.use_count());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj = make_weak_intrusive<SomeClass>();\n  IntrusiveAndWeak<SomeClass> obj2 = make_weak_intrusive<SomeClass>();\n  obj2.weak = std::move(obj.weak);\n  EXPECT_FALSE(obj2.weak.expired());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj = make_weak_intrusive<SomeClass>();\n  IntrusiveAndWeak<SomeClass> obj2 = make_weak_intrusive<SomeClass>();\n  obj2.weak = std::move(obj.weak);\n  EXPECT_EQ(0, obj.weak.use_count());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj = make_weak_intrusive<SomeClass>();\n  IntrusiveAndWeak<SomeClass> obj2 = make_weak_intrusive<SomeClass>();\n  obj2.weak = std::move(obj.weak);\n  EXPECT_TRUE(obj.weak.expired());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj = make_weak_intrusive<SomeClass>();\n  weak_intrusive_ptr<SomeClass> obj2 = obj.weak;\n  EXPECT_EQ(1, obj2.use_count());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj = make_weak_intrusive<SomeClass>();\n  weak_intrusive_ptr<SomeClass> obj2 = obj.weak;\n  EXPECT_FALSE(obj2.expired());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj = make_weak_intrusive<SomeClass>();\n  weak_intrusive_ptr<SomeClass> obj2 = obj.weak;\n  EXPECT_EQ(1, obj.weak.use_count());\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj = make_weak_intrusive<SomeClass>();\n  weak_intrusive_ptr<SomeClass> obj2 = obj.weak;\n  EXPECT_FALSE(obj.weak.expired());\n}",
            "{\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  auto obj = make_weak_intrusive<DestructableMock>(&resourcesReleased, &wasDestructed);\n  EXPECT_FALSE(resourcesReleased);\n  EXPECT_FALSE(wasDestructed);\n  obj.ptr.reset();\n  EXPECT_TRUE(resourcesReleased);\n  EXPECT_FALSE(wasDestructed);\n  obj.weak.reset();\n  EXPECT_TRUE(resourcesReleased);\n  EXPECT_TRUE(wasDestructed);\n}",
            "{\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  auto obj = make_weak_intrusive<DestructableMock>(&resourcesReleased, &wasDestructed);\n  EXPECT_FALSE(resourcesReleased);\n  EXPECT_FALSE(wasDestructed);\n  obj.weak.reset();\n  EXPECT_FALSE(resourcesReleased);\n  EXPECT_FALSE(wasDestructed);\n  obj.ptr.reset();\n  EXPECT_TRUE(resourcesReleased);\n  EXPECT_TRUE(wasDestructed);\n}",
            "{\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  {\n    auto obj = make_weak_only<DestructableMock>(&resourcesReleased, &wasDestructed);\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n  }\n  EXPECT_TRUE(resourcesReleased);\n  EXPECT_TRUE(wasDestructed);\n}",
            "{\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  auto obj = make_weak_only<DestructableMock>(&resourcesReleased, &wasDestructed);\n  {\n    auto obj2 = std::move(obj);\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n  }\n  EXPECT_TRUE(resourcesReleased);\n  EXPECT_TRUE(wasDestructed);\n}",
            "{\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  auto obj = make_weak_only<ChildDestructableMock>(&resourcesReleased, &wasDestructed);\n  {\n    weak_intrusive_ptr<DestructableMock> obj2 = std::move(obj);\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n  }\n  EXPECT_TRUE(resourcesReleased);\n  EXPECT_TRUE(wasDestructed);\n}",
            "{\n  bool dummy = false;\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  auto obj = make_weak_only<DestructableMock>(&dummy, &dummy);\n  {\n    auto obj2 = make_weak_only<DestructableMock>(&resourcesReleased, &wasDestructed);\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n    obj2 = std::move(obj);\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_TRUE(wasDestructed);\n  }\n}",
            "{\n  bool dummy = false;\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  auto obj = make_weak_only<ChildDestructableMock>(&dummy, &dummy);\n  {\n    auto obj2 = make_weak_only<DestructableMock>(&resourcesReleased, &wasDestructed);\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n    obj2 = std::move(obj);\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_TRUE(wasDestructed);\n  }\n}",
            "{\n  bool dummy = false;\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  auto obj = make_weak_only<DestructableMock>(&dummy, &dummy);\n  {\n    auto obj2 = make_weak_only<DestructableMock>(&resourcesReleased, &wasDestructed);\n    {\n      auto copy = obj2;\n      EXPECT_TRUE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n      obj2 = std::move(obj);\n      EXPECT_TRUE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n    }\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_TRUE(wasDestructed);\n  }\n}",
            "{\n  bool dummy = false;\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  auto obj = make_weak_only<ChildDestructableMock>(&dummy, &dummy);\n  {\n    auto obj2 =\n        make_weak_only<ChildDestructableMock>(&resourcesReleased, &wasDestructed);\n    {\n      weak_intrusive_ptr<DestructableMock> copy = obj2;\n      EXPECT_TRUE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n      obj2 = std::move(obj);\n      EXPECT_TRUE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n    }\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_TRUE(wasDestructed);\n  }\n}",
            "{\n  bool dummy = false;\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  auto obj = make_weak_only<ChildDestructableMock>(&dummy, &dummy);\n  {\n    auto obj2 = make_weak_only<DestructableMock>(&resourcesReleased, &wasDestructed);\n    {\n      weak_intrusive_ptr<DestructableMock> copy = obj2;\n      EXPECT_TRUE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n      obj2 = std::move(obj);\n      EXPECT_TRUE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n    }\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_TRUE(wasDestructed);\n  }\n}",
            "{\n  bool dummy = false;\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  auto obj = make_weak_only<DestructableMock>(&resourcesReleased, &wasDestructed);\n  {\n    auto obj2 = make_weak_only<DestructableMock>(&dummy, &dummy);\n    obj2 = std::move(obj);\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n  }\n  EXPECT_TRUE(resourcesReleased);\n  EXPECT_TRUE(wasDestructed);\n}",
            "{\n  bool dummy = false;\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  auto obj = make_weak_only<ChildDestructableMock>(&resourcesReleased, &wasDestructed);\n  {\n    auto obj2 = make_weak_only<DestructableMock>(&dummy, &dummy);\n    obj2 = std::move(obj);\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n  }\n  EXPECT_TRUE(resourcesReleased);\n  EXPECT_TRUE(wasDestructed);\n}",
            "{\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  {\n    auto obj = make_weak_only<DestructableMock>(&resourcesReleased, &wasDestructed);\n    {\n      weak_intrusive_ptr<DestructableMock> copy = obj;\n      EXPECT_TRUE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n    }\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n  }\n  EXPECT_TRUE(resourcesReleased);\n  EXPECT_TRUE(wasDestructed);\n}",
            "{\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  {\n    auto obj = make_weak_only<ChildDestructableMock>(&resourcesReleased, &wasDestructed);\n    {\n      weak_intrusive_ptr<DestructableMock> copy = obj;\n      EXPECT_TRUE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n    }\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n  }\n  EXPECT_TRUE(resourcesReleased);\n  EXPECT_TRUE(wasDestructed);\n}",
            "{\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  {\n    auto obj = make_weak_only<DestructableMock>(&resourcesReleased, &wasDestructed);\n    weak_intrusive_ptr<DestructableMock> copy = obj;\n    obj.reset();\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n  }\n  EXPECT_TRUE(resourcesReleased);\n  EXPECT_TRUE(wasDestructed);\n}",
            "{\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  {\n    auto obj = make_weak_only<ChildDestructableMock>(&resourcesReleased, &wasDestructed);\n    weak_intrusive_ptr<DestructableMock> copy = obj;\n    obj.reset();\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n  }\n  EXPECT_TRUE(resourcesReleased);\n  EXPECT_TRUE(wasDestructed);\n}",
            "{\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  bool dummy = false;\n  {\n    auto obj = make_weak_only<DestructableMock>(&resourcesReleased, &wasDestructed);\n    {\n      weak_intrusive_ptr<DestructableMock> copy =\n          make_weak_only<DestructableMock>(&dummy, &dummy);\n      copy = obj;\n      EXPECT_TRUE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n    }\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n  }\n  EXPECT_TRUE(resourcesReleased);\n  EXPECT_TRUE(wasDestructed);\n}",
            "{\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  bool dummy = false;\n  {\n    auto obj = make_weak_only<ChildDestructableMock>(&resourcesReleased, &wasDestructed);\n    {\n      weak_intrusive_ptr<DestructableMock> copy =\n          make_weak_only<DestructableMock>(&dummy, &dummy);\n      copy = obj;\n      EXPECT_TRUE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n    }\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n  }\n  EXPECT_TRUE(resourcesReleased);\n  EXPECT_TRUE(wasDestructed);\n}",
            "{\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  bool dummy = false;\n  {\n    auto copy = make_weak_only<DestructableMock>(&dummy, &dummy);\n    {\n      auto obj = make_weak_only<DestructableMock>(&resourcesReleased, &wasDestructed);\n      copy = obj;\n      EXPECT_TRUE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n    }\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n  }\n  EXPECT_TRUE(resourcesReleased);\n  EXPECT_TRUE(wasDestructed);\n}",
            "{\n  bool wasDestructed = false;\n  bool resourcesReleased = false;\n  bool dummy = false;\n  {\n    auto copy = make_weak_only<DestructableMock>(&dummy, &dummy);\n    {\n      auto obj =\n          make_weak_only<ChildDestructableMock>(&resourcesReleased, &wasDestructed);\n      copy = obj;\n      EXPECT_TRUE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n    }\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n  }\n  EXPECT_TRUE(resourcesReleased);\n  EXPECT_TRUE(wasDestructed);\n}",
            "{\n  bool dummy = false;\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  auto obj = make_weak_only<DestructableMock>(&dummy, &dummy);\n  {\n    auto obj2 = make_weak_only<DestructableMock>(&resourcesReleased, &wasDestructed);\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n    obj2 = obj;\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_TRUE(wasDestructed);\n  }\n}",
            "{\n  bool dummy = false;\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  auto obj = make_weak_only<ChildDestructableMock>(&dummy, &dummy);\n  {\n    auto obj2 = make_weak_only<DestructableMock>(&resourcesReleased, &wasDestructed);\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n    obj2 = obj;\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_TRUE(wasDestructed);\n  }\n}",
            "{\n  bool dummy = false;\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  auto obj = make_weak_only<DestructableMock>(&dummy, &dummy);\n  {\n    auto obj2 = make_weak_only<DestructableMock>(&resourcesReleased, &wasDestructed);\n    {\n      auto copy = obj2;\n      EXPECT_TRUE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n      obj2 = obj;\n      EXPECT_TRUE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n    }\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_TRUE(wasDestructed);\n  }\n}",
            "{\n  bool dummy = false;\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  auto obj = make_weak_only<ChildDestructableMock>(&dummy, &dummy);\n  {\n    auto obj2 =\n        make_weak_only<ChildDestructableMock>(&resourcesReleased, &wasDestructed);\n    {\n      weak_intrusive_ptr<DestructableMock> copy = obj2;\n      EXPECT_TRUE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n      obj2 = obj;\n      EXPECT_TRUE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n    }\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_TRUE(wasDestructed);\n  }\n}",
            "{\n  bool dummy = false;\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  auto obj = make_weak_only<ChildDestructableMock>(&dummy, &dummy);\n  {\n    auto obj2 = make_weak_only<DestructableMock>(&resourcesReleased, &wasDestructed);\n    {\n      weak_intrusive_ptr<DestructableMock> copy = obj2;\n      EXPECT_TRUE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n      obj2 = obj;\n      EXPECT_TRUE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n    }\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_TRUE(wasDestructed);\n  }\n}",
            "{\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  auto obj = make_weak_only<DestructableMock>(&resourcesReleased, &wasDestructed);\n  EXPECT_TRUE(resourcesReleased);\n  EXPECT_FALSE(wasDestructed);\n  obj.reset();\n  EXPECT_TRUE(resourcesReleased);\n  EXPECT_TRUE(wasDestructed);\n}",
            "{\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  auto obj = make_weak_only<DestructableMock>(&resourcesReleased, &wasDestructed);\n  {\n    auto copy = obj;\n    obj.reset();\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n    copy.reset();\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_TRUE(wasDestructed);\n  }\n}",
            "{\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  auto obj = make_weak_only<DestructableMock>(&resourcesReleased, &wasDestructed);\n  {\n    auto copy = obj;\n    copy.reset();\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n    obj.reset();\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_TRUE(wasDestructed);\n  }\n}",
            "{\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  auto obj = make_weak_only<DestructableMock>(&resourcesReleased, &wasDestructed);\n  {\n    auto moved = std::move(obj);\n    obj.reset();\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n    moved.reset();\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_TRUE(wasDestructed);\n  }\n}",
            "{\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  auto obj = make_weak_only<DestructableMock>(&resourcesReleased, &wasDestructed);\n  {\n    auto moved = std::move(obj);\n    moved.reset();\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_TRUE(wasDestructed);\n  }\n}",
            "{\n  IntrusiveAndWeak<SomeClass> obj = make_weak_intrusive<SomeClass>();\n  SomeClass* ptr = obj.weak.release();\n  weak_intrusive_ptr<SomeClass> reclaimed =\n      weak_intrusive_ptr<SomeClass>::reclaim(ptr);\n}",
            "{\n  weak_intrusive_ptr<SomeClass> obj = make_weak_only<SomeClass>();\n  SomeClass* ptr = obj.release();\n  weak_intrusive_ptr<SomeClass> reclaimed =\n      weak_intrusive_ptr<SomeClass>::reclaim(ptr);\n}",
            "{\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  bool dummy = false;\n  {\n    IntrusiveAndWeak<DestructableMock> outer =\n        make_weak_intrusive<DestructableMock>(&dummy, &dummy);\n    {\n      IntrusiveAndWeak<DestructableMock> inner =\n          make_weak_intrusive<DestructableMock>(\n              &resourcesReleased, &wasDestructed);\n      EXPECT_FALSE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n      DestructableMock* ptr = inner.weak.release();\n      EXPECT_FALSE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n      outer.ptr = inner.ptr;\n      outer.weak = weak_intrusive_ptr<DestructableMock>::reclaim(ptr);\n    }\n    // inner is destructed\n    EXPECT_FALSE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n    outer.weak.reset();\n    EXPECT_FALSE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n  }\n  // outer is destructed\n  EXPECT_TRUE(resourcesReleased);\n  EXPECT_TRUE(wasDestructed);\n}",
            "{\n  bool resourcesReleased = false;\n  bool wasDestructed = false;\n  {\n    weak_intrusive_ptr<DestructableMock> outer =\n        make_invalid_weak<DestructableMock>();\n    {\n      weak_intrusive_ptr<DestructableMock> inner =\n          make_weak_only<DestructableMock>(&resourcesReleased, &wasDestructed);\n      EXPECT_TRUE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n      DestructableMock* ptr = inner.release();\n      EXPECT_TRUE(resourcesReleased);\n      EXPECT_FALSE(wasDestructed);\n      outer = weak_intrusive_ptr<DestructableMock>::reclaim(ptr);\n    }\n    // inner is destructed\n    EXPECT_TRUE(resourcesReleased);\n    EXPECT_FALSE(wasDestructed);\n  }\n  // outer is destructed\n  EXPECT_TRUE(resourcesReleased);\n  EXPECT_TRUE(wasDestructed);\n}",
            "{\n  // This would cause very weird bugs on destruction.\n  // Better to crash early on creation.\n  SomeClass obj;\n  weak_intrusive_ptr<SomeClass> ptr = make_invalid_weak<SomeClass>();\n#ifdef NDEBUG\n  EXPECT_NO_THROW(ptr = weak_intrusive_ptr<SomeClass>::reclaim(&obj));\n#else\n  EXPECT_ANY_THROW(ptr = weak_intrusive_ptr<SomeClass>::reclaim(&obj));\n#endif\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/test/util/irange_test.cpp",
        "functions": [
            "{\n    std::vector<int> test_vec;\n    for(const auto i : c10::irange(4, 11)){\n        test_vec.push_back(i);\n    }\n    const std::vector<int> correct = {{4,5,6,7,8,9,10}};\n    ASSERT_EQ(test_vec, correct);\n}",
            "{\n    std::vector<int> test_vec;\n    for(const auto i : c10::irange(5)){\n        test_vec.push_back(i);\n    }\n    const std::vector<int> correct = {{0, 1, 2, 3, 4}};\n    ASSERT_EQ(test_vec, correct);\n}",
            "{\n    std::vector<int> test_vec;\n    for(const auto i : c10::irange(-2, 3)){\n        test_vec.push_back(i);\n    }\n    const std::vector<int> correct = {{-2,-1,0,1,2}};\n    ASSERT_EQ(test_vec, correct);\n}",
            "{\n    std::vector<int> test_vec;\n    for(const auto i : c10::irange(3, -3)){\n        test_vec.push_back(i);\n        if(i>20){ //Cap the number of elements we add if something goes wrong\n            break;\n        }\n    }\n    const std::vector<int> correct = {};\n    ASSERT_EQ(test_vec, correct);\n}",
            "{\n    std::vector<int> test_vec;\n    for(const auto i : c10::irange(-3)){\n        test_vec.push_back(i);\n        if(i>20){ //Cap the number of elements we add if something goes wrong\n            break;\n        }\n    }\n    const std::vector<int> correct = {};\n    ASSERT_EQ(test_vec, correct);\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/test/util/LeftRight_test.cpp",
        "functions": [
            "{\n  LeftRight<int> obj;\n\n  obj.write([] (int& obj) {obj = 5;});\n  int read = obj.read([] (const int& obj) {return obj;});\n  EXPECT_EQ(5, read);\n\n  // check changes are also present in background copy\n  obj.write([] (int&) {}); // this switches to the background copy\n  read = obj.read([] (const int& obj) {return obj;});\n  EXPECT_EQ(5, read);\n}",
            "{\n    LeftRight<vector<int>> obj;\n\n    obj.write([] (vector<int>& obj) {obj.push_back(5);});\n    vector<int> read = obj.read([] (const vector<int>& obj) {return obj;});\n    EXPECT_EQ((vector<int>{5}), read);\n\n    obj.write([] (vector<int>& obj) {obj.push_back(6);});\n    read = obj.read([] (const vector<int>& obj) {return obj;});\n    EXPECT_EQ((vector<int>{5, 6}), read);\n}",
            "{\n    LeftRight<vector<int>> obj;\n\n    auto a = obj.write([] (vector<int>&) -> int {return 5;});\n    static_assert(std::is_same<int, decltype(a)>::value, \"\");\n    EXPECT_EQ(5, a);\n}",
            "{\n    LeftRight<int> obj;\n    std::atomic<int> num_running_readers{0};\n\n    std::thread reader1([&] () {\n       obj.read([&] (const int&) {\n           ++num_running_readers;\n           while(num_running_readers.load() < 2) {}\n       });\n    });\n\n    std::thread reader2([&] () {\n        obj.read([&] (const int&) {\n            ++num_running_readers;\n            while(num_running_readers.load() < 2) {}\n        });\n    });\n\n    // the threads only finish after both entered the read function.\n    // if LeftRight didn't allow concurrency, this would cause a deadlock.\n    reader1.join();\n    reader2.join();\n}",
            "{\n    LeftRight<int> obj;\n    std::atomic<bool> reader_running{false};\n    std::atomic<bool> writer_running{false};\n\n    std::thread reader([&] () {\n        obj.read([&] (const int&) {\n            reader_running = true;\n            while(!writer_running.load()) {}\n        });\n    });\n\n    std::thread writer([&] () {\n        // run read first, write second\n        while (!reader_running.load()) {}\n\n        obj.write([&] (int&) {\n            writer_running = true;\n        });\n    });\n\n    // the threads only finish after both entered the read function.\n    // if LeftRight didn't allow concurrency, this would cause a deadlock.\n    reader.join();\n    writer.join();\n}",
            "{\n    LeftRight<int> obj;\n    std::atomic<bool> writer_running{false};\n    std::atomic<bool> reader_running{false};\n\n    std::thread writer([&] () {\n        obj.read([&] (const int&) {\n            writer_running = true;\n            while(!reader_running.load()) {}\n        });\n    });\n\n    std::thread reader([&] () {\n        // run write first, read second\n        while (!writer_running.load()) {}\n\n        obj.read([&] (const int&) {\n            reader_running = true;\n        });\n    });\n\n    // the threads only finish after both entered the read function.\n    // if LeftRight didn't allow concurrency, this would cause a deadlock.\n    writer.join();\n    reader.join();\n}",
            "{\n    LeftRight<int> obj;\n    std::atomic<bool> first_writer_started{false};\n    std::atomic<bool> first_writer_finished{false};\n\n    std::thread writer1([&] () {\n        obj.write([&] (int&) {\n            first_writer_started = true;\n            std::this_thread::sleep_for(std::chrono::milliseconds(50));\n            first_writer_finished = true;\n        });\n    });\n\n    std::thread writer2([&] () {\n        // make sure the other writer runs first\n        while (!first_writer_started.load()) {}\n\n        obj.write([&] (int&) {\n            // expect the other writer finished before this one starts\n            EXPECT_TRUE(first_writer_finished.load());\n        });\n    });\n\n    writer1.join();\n    writer2.join();\n}",
            "{\n    LeftRight<int> obj;\n\n    EXPECT_THROW(\n        obj.read([](const int&) {throw MyException();}),\n        MyException\n    );\n}",
            "{\n    LeftRight<int> obj;\n\n    EXPECT_THROW(\n        obj.write([](int&) {throw MyException();}),\n        MyException\n    );\n}",
            "{\n    LeftRight<int> obj;\n\n    obj.write([](int& obj) {obj = 5;});\n\n    EXPECT_THROW(\n        obj.write([](int& obj) {\n            obj = 6;\n            throw MyException();\n        }),\n        MyException\n    );\n\n    // check reading it returns old value\n    int read = obj.read([] (const int& obj) {return obj;});\n    EXPECT_EQ(5, read);\n\n    // check changes are also present in background copy\n    obj.write([] (int&) {}); // this switches to the background copy\n    read = obj.read([] (const int& obj) {return obj;});\n    EXPECT_EQ(5, read);\n}",
            "{\n    LeftRight<int> obj;\n\n    obj.write([](int& obj) {obj = 5;});\n    bool write_called = false;\n\n    EXPECT_THROW(\n        obj.write([&](int& obj) {\n            obj = 6;\n            if (write_called) {\n                // this is the second time the write callback is executed\n                throw MyException();\n            } else {\n                write_called = true;\n            }\n        }),\n        MyException\n    );\n\n    // check reading it returns new value\n    int read = obj.read([] (const int& obj) {return obj;});\n    EXPECT_EQ(6, read);\n\n    // check changes are also present in background copy\n    obj.write([] (int&) {}); // this switches to the background copy\n    read = obj.read([] (const int& obj) {return obj;});\n    EXPECT_EQ(6, read);\n}",
            "{\n    LeftRight<vector<int>> obj;\n\n    obj.write([](vector<int>& obj) {obj.push_back(5);});\n\n    EXPECT_THROW(\n            obj.write([](vector<int>& obj) {\n                obj.push_back(6);\n                throw MyException();\n            }),\n            MyException\n    );\n\n    // check reading it returns old value\n    vector<int> read = obj.read([] (const vector<int>& obj) {return obj;});\n    EXPECT_EQ((vector<int>{5}), read);\n\n    // check changes are also present in background copy\n    obj.write([] (vector<int>&) {}); // this switches to the background copy\n    read = obj.read([] (const vector<int>& obj) {return obj;});\n    EXPECT_EQ((vector<int>{5}), read);\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/test/util/logging_test.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/test/util/Metaprogramming_test.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/test/util/optional_test.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/test/util/ordered_preserving_dict_test.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/test/util/registry_test.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/test/util/string_view_test.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/test/util/tempfile_test.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/test/util/typeid_test.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/test/util/TypeIndex_test.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/test/util/TypeList_test.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/test/util/TypeTraits_test.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/util/Array.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/util/Backtrace.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/util/C++17.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/util/flags_use_gflags.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/util/flags_use_no_gflags.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/util/Half.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/util/intrusive_ptr.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/util/LeftRight.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/util/Logging.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/util/MathConstants.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/util/numa.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/util/Optional.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/util/SmallVector.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/util/StringUtil.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/util/ThreadLocalDebugInfo.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/util/thread_name.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/util/Type.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/util/typeid.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/util/TypeList.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/util/TypeTraits.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/util/Unicode.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/util/UniqueVoidPtr.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/util/Exception.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/c10/util/Metaprogramming.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/docs/caffe2/process.py",
        "functions": [
            "insert"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/docs/cpp/source/conf.py",
        "functions": [
            "setup"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/docs/source/conf.py",
        "functions": [
            "setup",
            "replace",
            "patched_make_field"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/docs/source/scripts/build_activation_images.py",
        "functions": [
            "plot_function"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/ios/TestApp/benchmark/trace_model.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/ios/TestApp/custom_build/custom_build.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/modules/detectron/upsample_nearest_op_test.py",
        "functions": [],
        "classes": [
            "TestUpsampleNearestOp"
        ]
    },
    {
        "file_path": "../pytorch/scripts/diagnose_protobuf.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/scripts/get_python_cmake_flags.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/scripts/model_zoo/update-caffe2-models.py",
        "functions": [
            "download_models",
            "generate_models",
            "upload_models",
            "cleanup"
        ],
        "classes": [
            "SomeClass"
        ]
    },
    {
        "file_path": "../pytorch/scripts/model_zoo/update-models-from-caffe2.py",
        "functions": [
            "upload_onnx_model",
            "download_onnx_model",
            "download_caffe2_model",
            "caffe2_to_onnx",
            "tensortype_to_ndarray",
            "generate_test_input_data",
            "generate_test_output_data",
            "onnx_verify"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/scripts/release_notes/categorize.py",
        "functions": [
            "main"
        ],
        "classes": [
            "Categorizer"
        ]
    },
    {
        "file_path": "../pytorch/scripts/release_notes/commitlist.py",
        "functions": [
            "create_new",
            "update_existing",
            "to_markdown",
            "main"
        ],
        "classes": [
            "Commit",
            "CommitList"
        ]
    },
    {
        "file_path": "../pytorch/scripts/release_notes/common.py",
        "functions": [
            "dict_to_features",
            "features_to_dict",
            "run",
            "commit_body",
            "commit_title",
            "commit_files_changed",
            "parse_pr_number",
            "get_ghstack_token",
            "run_query",
            "gh_labels",
            "get_features"
        ],
        "classes": [
            "CommitDataCache"
        ]
    },
    {
        "file_path": "../pytorch/scripts/release_notes/namespace_check.py",
        "functions": [
            "get_content",
            "namespace_filter",
            "run",
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/scripts/release_notes/test_release_notes.py",
        "functions": [],
        "classes": [
            "TestCommitList"
        ]
    },
    {
        "file_path": "../pytorch/third_party/build_bundled.py",
        "functions": [
            "collect_license",
            "create_bundled",
            "identify_license"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/third_party/miniz-2.0.8/miniz.c",
        "functions": [
            "mz_adler32(mz_ulong adler, const unsigned char *ptr, size_t buf_len)",
            "mz_free(void *p)",
            "*miniz_def_alloc_func(void *opaque, size_t items, size_t size)",
            "miniz_def_free_func(void *opaque, void *address)",
            "*miniz_def_realloc_func(void *opaque, void *address, size_t items, size_t size)",
            "char",
            "tdefl_sym_freq",
            "void",
            "void",
            "void",
            "void",
            "void",
            "mz_bool",
            "int",
            "MZ_FORCEINLINE",
            "MZ_FORCEINLINE",
            "mz_bool",
            "tdefl_status",
            "tdefl_compress(tdefl_compressor *d, const void *pIn_buf, size_t *pIn_buf_size, void *pOut_buf, size_t *pOut_buf_size, tdefl_flush flush)",
            "tdefl_compress_buffer(tdefl_compressor *d, const void *pIn_buf, size_t in_buf_size, tdefl_flush flush)",
            "tdefl_init(tdefl_compressor *d, tdefl_put_buf_func_ptr pPut_buf_func, void *pPut_buf_user, int flags)",
            "tdefl_get_prev_return_status(tdefl_compressor *d)",
            "tdefl_get_adler32(tdefl_compressor *d)",
            "tdefl_compress_mem_to_output(const void *pBuf, size_t buf_len, tdefl_put_buf_func_ptr pPut_buf_func, void *pPut_buf_user, int flags)",
            "mz_bool",
            "*tdefl_compress_mem_to_heap(const void *pSrc_buf, size_t src_buf_len, size_t *pOut_len, int flags)",
            "tdefl_compress_mem_to_mem(void *pOut_buf, size_t out_buf_len, const void *pSrc_buf, size_t src_buf_len, int flags)",
            "tdefl_create_comp_flags_from_zip_params(int level, int window_bits, int strategy)",
            "*tdefl_write_image_to_png_file_in_memory_ex(const void *pImage, int w, int h, int num_chans, size_t *pLen_out, mz_uint level, mz_bool flip)",
            "*tdefl_write_image_to_png_file_in_memory(const void *pImage, int w, int h, int num_chans, size_t *pLen_out)",
            "*tdefl_compressor_alloc()",
            "tdefl_compressor_free(tdefl_compressor *pComp)",
            "tinfl_decompress(tinfl_decompressor *r, const mz_uint8 *pIn_buf_next, size_t *pIn_buf_size, mz_uint8 *pOut_buf_start, mz_uint8 *pOut_buf_next, size_t *pOut_buf_size, const mz_uint32 decomp_flags)",
            "*tinfl_decompress_mem_to_heap(const void *pSrc_buf, size_t src_buf_len, size_t *pOut_len, int flags)",
            "tinfl_decompress_mem_to_mem(void *pOut_buf, size_t out_buf_len, const void *pSrc_buf, size_t src_buf_len, int flags)",
            "tinfl_decompress_mem_to_callback(const void *pIn_buf, size_t *pIn_buf_size, tinfl_put_buf_func_ptr pPut_buf_func, void *pPut_buf_user, int flags)",
            "*tinfl_decompressor_alloc()",
            "tinfl_decompressor_free(tinfl_decompressor *pDecomp)",
            "MZ_FORCEINLINE",
            "MZ_FORCEINLINE",
            "mz_bool",
            "MZ_FORCEINLINE",
            "MZ_FORCEINLINE",
            "MZ_FORCEINLINE",
            "MZ_FORCEINLINE",
            "MZ_FORCEINLINE",
            "mz_bool",
            "MZ_FORCEINLINE",
            "void",
            "mz_bool",
            "mz_bool",
            "mz_zip_zero_struct(mz_zip_archive *pZip)",
            "mz_bool",
            "mz_zip_reader_end(mz_zip_archive *pZip)",
            "mz_zip_reader_init(mz_zip_archive *pZip, mz_uint64 size, mz_uint flags)",
            "size_t",
            "mz_zip_reader_init_mem(mz_zip_archive *pZip, const void *pMem, size_t size, mz_uint flags)",
            "MZ_FORCEINLINE",
            "mz_zip_reader_is_file_encrypted(mz_zip_archive *pZip, mz_uint file_index)",
            "mz_zip_reader_is_file_supported(mz_zip_archive *pZip, mz_uint file_index)",
            "mz_zip_reader_is_file_a_directory(mz_zip_archive *pZip, mz_uint file_index)",
            "mz_bool",
            "MZ_FORCEINLINE",
            "MZ_FORCEINLINE",
            "mz_bool",
            "mz_zip_reader_locate_file(mz_zip_archive *pZip, const char *pName, const char *pComment, mz_uint flags)",
            "mz_zip_reader_locate_file_v2(mz_zip_archive *pZip, const char *pName, const char *pComment, mz_uint flags, mz_uint32 *pIndex)",
            "mz_zip_reader_extract_to_mem_no_alloc(mz_zip_archive *pZip, mz_uint file_index, void *pBuf, size_t buf_size, mz_uint flags, void *pUser_read_buf, size_t user_read_buf_size)",
            "mz_zip_reader_extract_file_to_mem_no_alloc(mz_zip_archive *pZip, const char *pFilename, void *pBuf, size_t buf_size, mz_uint flags, void *pUser_read_buf, size_t user_read_buf_size)",
            "mz_zip_reader_extract_to_mem(mz_zip_archive *pZip, mz_uint file_index, void *pBuf, size_t buf_size, mz_uint flags)",
            "mz_zip_reader_extract_file_to_mem(mz_zip_archive *pZip, const char *pFilename, void *pBuf, size_t buf_size, mz_uint flags)",
            "*mz_zip_reader_extract_to_heap(mz_zip_archive *pZip, mz_uint file_index, size_t *pSize, mz_uint flags)",
            "*mz_zip_reader_extract_file_to_heap(mz_zip_archive *pZip, const char *pFilename, size_t *pSize, mz_uint flags)",
            "mz_zip_reader_extract_to_callback(mz_zip_archive *pZip, mz_uint file_index, mz_file_write_func pCallback, void *pOpaque, mz_uint flags)",
            "mz_zip_reader_extract_file_to_callback(mz_zip_archive *pZip, const char *pFilename, mz_file_write_func pCallback, void *pOpaque, mz_uint flags)",
            "* mz_zip_reader_extract_iter_new(mz_zip_archive *pZip, mz_uint file_index, mz_uint flags)",
            "* mz_zip_reader_extract_file_iter_new(mz_zip_archive *pZip, const char *pFilename, mz_uint flags)",
            "mz_zip_reader_extract_iter_read(mz_zip_reader_extract_iter_state* pState, void* pvBuf, size_t buf_size)",
            "mz_zip_reader_extract_iter_free(mz_zip_reader_extract_iter_state* pState)",
            "size_t",
            "mz_zip_validate_file(mz_zip_archive *pZip, mz_uint file_index, mz_uint flags)",
            "mz_zip_validate_archive(mz_zip_archive *pZip, mz_uint flags)",
            "mz_zip_validate_mem_archive(const void *pMem, size_t size, mz_uint flags, mz_zip_error *pErr)",
            "mz_zip_get_mode(mz_zip_archive *pZip)",
            "mz_zip_get_type(mz_zip_archive *pZip)",
            "mz_zip_set_last_error(mz_zip_archive *pZip, mz_zip_error err_num)",
            "mz_zip_peek_last_error(mz_zip_archive *pZip)",
            "mz_zip_clear_last_error(mz_zip_archive *pZip)",
            "mz_zip_get_last_error(mz_zip_archive *pZip)",
            "char",
            "mz_zip_is_zip64(mz_zip_archive *pZip)",
            "mz_zip_get_central_dir_size(mz_zip_archive *pZip)",
            "mz_zip_reader_get_num_files(mz_zip_archive *pZip)",
            "mz_zip_get_archive_size(mz_zip_archive *pZip)",
            "mz_zip_get_archive_file_start_offset(mz_zip_archive *pZip)",
            "*mz_zip_get_cfile(mz_zip_archive *pZip)",
            "mz_zip_read_archive_data(mz_zip_archive *pZip, mz_uint64 file_ofs, void *pBuf, size_t n)",
            "mz_zip_reader_get_filename(mz_zip_archive *pZip, mz_uint file_index, char *pFilename, mz_uint filename_buf_size)",
            "mz_zip_reader_file_stat(mz_zip_archive *pZip, mz_uint file_index, mz_zip_archive_file_stat *pStat)",
            "mz_zip_end(mz_zip_archive *pZip)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/third_party/miniz-2.0.8/examples/example1.c",
        "functions": [
            "main(int argc, char *argv[])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/third_party/miniz-2.0.8/examples/example2.c",
        "functions": [
            "main(int argc, char *argv[])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/third_party/miniz-2.0.8/examples/example3.c",
        "functions": [
            "main(int argc, char *argv[])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/third_party/miniz-2.0.8/examples/example4.c",
        "functions": [
            "int",
            "main(int argc, char *argv[])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/third_party/miniz-2.0.8/examples/example5.c",
        "functions": [
            "main(int argc, char *argv[])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/third_party/miniz-2.0.8/examples/example6.c",
        "functions": [
            "void",
            "main(int argc, char *argv[])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/build_libtorch.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/build_pytorch_libs.py",
        "functions": [
            "_overlay_windows_vcvars",
            "_create_build_env",
            "build_caffe2"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/clang_format_all.py",
        "functions": [
            "get_allowlisted_files",
            "def",
            "def",
            "def",
            "parse_args",
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/clang_format_utils.py",
        "functions": [
            "compute_file_sha1",
            "report_download_progress",
            "download_clang_format",
            "get_and_check_clang_format"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/clang_tidy.py",
        "functions": [
            "run_shell_command",
            "split_negative_from_positive_patterns",
            "get_file_patterns",
            "filter_files",
            "get_changed_files",
            "get_all_files",
            "get_changed_lines",
            "run_shell_commands_in_parallel",
            "run_clang_tidy",
            "parse_options",
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/download_mnist.py",
        "functions": [
            "report_download_progress",
            "download",
            "unzip",
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/flake8_hook.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/generate_torch_version.py",
        "functions": [
            "get_sha",
            "get_torch_version"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/nightly.py",
        "functions": [
            "logging_record_exception",
            "logging_rotate",
            "check_in_repo",
            "check_branch",
            "timed",
            "_make_channel_args",
            "_site_packages",
            "_ensure_commit",
            "_nightly_version",
            "_get_listing_linux",
            "_get_listing_osx",
            "_get_listing_win",
            "_glob_pyis",
            "_find_missing_pyi",
            "_get_listing",
            "_remove_existing",
            "_move_single",
            "_copy_files",
            "_link_files",
            "_available_envs",
            "install",
            "make_parser",
            "main"
        ],
        "classes": [
            "Formatter"
        ]
    },
    {
        "file_path": "../pytorch/tools/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/amd_build/build_amd.py",
        "functions": [
            "is_hip_clang"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/autograd/gen_annotated_fn_args.py",
        "functions": [
            "gen_annotated",
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/autograd/gen_autograd.py",
        "functions": [
            "gen_autograd",
            "gen_autograd_python",
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/autograd/gen_autograd_functions.py",
        "functions": [
            "gen_autograd_functions_lib",
            "gen_autograd_functions_python",
            "gen_autograd_functions",
            "process_function",
            "uses_ident",
            "uses_retain_variables",
            "uses_single_grad"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/autograd/gen_python_functions.py",
        "functions": [
            "get_pycname",
            "is_noarg",
            "is_py_variable_method",
            "is_py_torch_function",
            "is_py_nn_function",
            "is_py_fft_function",
            "is_py_linalg_function",
            "gen",
            "create_python_bindings",
            "load_signatures",
            "load_deprecated_signatures",
            "emit_namedtuple_typedefs",
            "method_impl",
            "gen_has_torch_function_check",
            "emit_dispatch_case",
            "forward_decls",
            "method_def",
            "group_overloads",
            "sort_overloads",
            "emit_single_dispatch"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/autograd/gen_trace_type.py",
        "functions": [
            "should_trace",
            "format_trace_op_name",
            "format_trace_inputs",
            "format_prerecord_trace",
            "format_postrecord_trace",
            "declare_returned_variables",
            "tie_return_values",
            "get_return_value",
            "emit_trace_body",
            "type_wrapper_name",
            "gen_trace_type_shard",
            "gen_trace_type"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/autograd/gen_variable_factories.py",
        "functions": [
            "fully_qualified_type",
            "gen_variable_factories"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/autograd/gen_variable_type.py",
        "functions": [
            "gen_variable_type",
            "gen_variable_type_shard",
            "emit_body",
            "dispatch_strategy",
            "is_tensor_type",
            "is_tensor_list_type",
            "modifies_arguments",
            "match_differentiability_info"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/autograd/load_derivatives.py",
        "functions": [
            "load_derivatives",
            "create_derivative",
            "create_differentiability_info",
            "used_gradient_indices",
            "saved_variables",
            "create_op_name",
            "create_op_names",
            "dedup_vars"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/autograd/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/autograd/templates/annotated_fn_args.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/autograd/templates/Functions.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/autograd/templates/python_fft_functions.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/autograd/templates/python_functions.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/autograd/templates/python_linalg_functions.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/autograd/templates/python_nn_functions.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/autograd/templates/python_torch_functions.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/autograd/templates/python_variable_methods.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/autograd/templates/TraceType.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/autograd/templates/VariableType.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/codegen/code_template.py",
        "functions": [],
        "classes": [
            "CodeTemplate"
        ]
    },
    {
        "file_path": "../pytorch/tools/codegen/context.py",
        "functions": [
            "with_native_function",
            "method_with_native_function"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/codegen/gen.py",
        "functions": [
            "parse_native_yaml",
            "cpp_string",
            "compute_meta_function_declaration",
            "dict_representer",
            "format_yaml",
            "pythonify_default",
            "dynamic_type",
            "compute_method_of_yaml",
            "compute_returns_yaml",
            "compute_cpp_argument_yaml",
            "compute_argument_yaml",
            "get_custom_build_selector",
            "main"
        ],
        "classes": [
            "LineLoader",
            "FileManager"
        ]
    },
    {
        "file_path": "../pytorch/tools/codegen/local.py",
        "functions": [
            "use_c10_dispatcher"
        ],
        "classes": [
            "Locals"
        ]
    },
    {
        "file_path": "../pytorch/tools/codegen/model.py",
        "functions": [
            "assert_never",
            "is_generic_dispatch_key",
            "is_cuda_dispatch_key",
            "is_structured_dispatch_key",
            "parse_returns"
        ],
        "classes": [
            "DispatchKey",
            "UseC10Dispatcher"
        ]
    },
    {
        "file_path": "../pytorch/tools/codegen/utils.py",
        "functions": [
            "split_name_params",
            "mapMaybe",
            "concatMap"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/codegen/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/codegen/api/autograd.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/codegen/api/cpp.py",
        "functions": [
            "name",
            "valuetype_type",
            "argumenttype_type",
            "argument_type",
            "returntype_type",
            "return_type",
            "returns_type",
            "return_names",
            "default_expr",
            "argument",
            "arguments"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/codegen/api/dispatcher.py",
        "functions": [
            "name",
            "argumenttype_type",
            "argument_type",
            "returns_type",
            "argument",
            "arguments"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/codegen/api/meta.py",
        "functions": [
            "name"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/codegen/api/native.py",
        "functions": [
            "name",
            "argumenttype_type",
            "returns_type",
            "argument_type",
            "argument",
            "arguments"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/codegen/api/python.py",
        "functions": [
            "_cpp_signature",
            "has_tensor_options",
            "argument_type_str",
            "argument_type_size",
            "argument",
            "signature",
            "_dtype_default_type_hack",
            "namedtuple_fieldnames",
            "argument_type_str_pyi",
            "dispatch_lambda_args",
            "dispatch_lambda_return_str",
            "cpp_dispatch_target",
            "cpp_dispatch_exprs",
            "arg_parser_unpack_method",
            "arg_parser_output_expr",
            "arg_parser_output_exprs",
            "dispatch_lambda_exprs"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/codegen/api/structured.py",
        "functions": [
            "argumenttype_type",
            "argument_type",
            "argument",
            "impl_arguments",
            "meta_arguments",
            "out_arguments"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/codegen/api/translate.py",
        "functions": [
            "translate"
        ],
        "classes": [
            "UnsatError"
        ]
    },
    {
        "file_path": "../pytorch/tools/codegen/api/types.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/codegen/api/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/codegen/dest/register_dispatch_key.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/codegen/dest/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/codegen/selective_build/operator.py",
        "functions": [
            "merge_debug_info",
            "combine_operators",
            "merge_operator_dicts",
            "strip_operator_overload_name"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/codegen/selective_build/selector.py",
        "functions": [
            "merge_kernel_metadata",
            "combine_selective_builders",
            "op_name_from_native_function"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/codegen/selective_build/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/code_analyzer/analyzer.cpp",
        "functions": [
            "main(int argc, char **argv)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/code_analyzer/gen_op_registration_allowlist.py",
        "functions": [
            "canonical_name",
            "load_op_dep_graph",
            "load_root_ops",
            "gen_transitive_closure",
            "gen_transitive_closure_str"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/code_analyzer/op_deps_pass.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/code_analyzer/op_deps_processor.py",
        "functions": [
            "load_op_deps",
            "process_base_ops",
            "convert"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/code_coverage/oss_coverage.py",
        "functions": [
            "report_coverage"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/code_coverage/package/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/code_coverage/package/oss/cov_json.py",
        "functions": [
            "get_json_report"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/code_coverage/package/oss/init.py",
        "functions": [
            "initialization",
            "add_arguments_oss",
            "parse_arguments",
            "get_test_list_by_type",
            "get_test_list",
            "empty_list_if_none",
            "gcc_export_init",
            "get_python_run_only",
            "print_init_info"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/code_coverage/package/oss/run.py",
        "functions": [
            "clang_run",
            "gcc_run"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/code_coverage/package/oss/utils.py",
        "functions": [
            "get_oss_binary_folder",
            "get_oss_shared_library",
            "get_oss_binary_file",
            "get_llvm_tool_path",
            "get_pytorch_folder",
            "detect_compiler_type",
            "clean_up_gcda",
            "get_gcda_files",
            "run_oss_python_test"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/code_coverage/package/oss/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/code_coverage/package/tool/clang_coverage.py",
        "functions": [
            "create_corresponding_folder",
            "run_target",
            "merge_target",
            "export_target",
            "merge",
            "export"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/code_coverage/package/tool/gcc_coverage.py",
        "functions": [
            "update_gzip_dict",
            "run_target",
            "export"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/code_coverage/package/tool/print_report.py",
        "functions": [
            "key_by_percentage",
            "key_by_name",
            "is_intrested_file",
            "is_this_type_of_tests",
            "print_test_by_type",
            "print_test_condition",
            "line_oriented_report",
            "print_file_summary",
            "print_file_oriented_report",
            "file_oriented_report",
            "get_html_ignored_pattern",
            "html_oriented_report"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/code_coverage/package/tool/summarize_jsons.py",
        "functions": [
            "transform_file_name",
            "is_intrested_file",
            "get_json_obj",
            "parse_json",
            "parse_jsons",
            "update_coverage",
            "update_set",
            "summarize_jsons"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/code_coverage/package/tool/utils.py",
        "functions": [
            "run_cpp_test",
            "get_tool_path_by_platform"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/code_coverage/package/tool/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/code_coverage/package/tool/parser/coverage_record.py",
        "functions": [],
        "classes": [
            "CoverageRecord"
        ]
    },
    {
        "file_path": "../pytorch/tools/code_coverage/package/tool/parser/gcov_coverage_parser.py",
        "functions": [],
        "classes": [
            "GcovCoverageParser"
        ]
    },
    {
        "file_path": "../pytorch/tools/code_coverage/package/tool/parser/llvm_coverage_parser.py",
        "functions": [],
        "classes": [
            "LlvmCoverageParser"
        ]
    },
    {
        "file_path": "../pytorch/tools/code_coverage/package/tool/parser/llvm_coverage_segment.py",
        "functions": [
            "parse_segments"
        ],
        "classes": [
            "LlvmCoverageSegment"
        ]
    },
    {
        "file_path": "../pytorch/tools/code_coverage/package/tool/parser/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/code_coverage/package/util/setting.py",
        "functions": [],
        "classes": [
            "TestType",
            "Test",
            "Option",
            "TestPlatform",
            "CompilerType"
        ]
    },
    {
        "file_path": "../pytorch/tools/code_coverage/package/util/utils.py",
        "functions": [
            "convert_time",
            "print_time",
            "print_log",
            "print_error",
            "remove_file",
            "remove_folder",
            "create_folder",
            "clean_up",
            "convert_to_relative_path",
            "replace_extension",
            "related_to_test_list",
            "get_raw_profiles_folder",
            "detect_compiler_type",
            "get_test_name_from_whole_path",
            "check_compiler_type",
            "check_platform_type",
            "check_test_type",
            "raise_no_test_found_exception"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/code_coverage/package/util/utils_init.py",
        "functions": [
            "remove_files",
            "create_folders",
            "add_arguments_utils",
            "have_option",
            "get_options"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/code_coverage/package/util/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/fast_nvcc/fast_nvcc.py",
        "functions": [
            "fast_nvcc_warn",
            "warn_if_windows",
            "warn_if_tmpdir_flag",
            "nvcc_dryrun_data",
            "warn_if_tmpdir_set",
            "contains_non_executable",
            "module_id_contents",
            "unique_module_id_files",
            "make_rm_force",
            "print_verbose_output",
            "straight_line_dependencies",
            "files_mentioned",
            "nvcc_data_dependencies",
            "is_weakly_connected",
            "warn_if_not_weakly_connected",
            "print_dot_graph",
            "def",
            "def",
            "print_command_outputs",
            "write_log_csv",
            "exit_code",
            "wrap_nvcc",
            "fast_nvcc",
            "our_arg"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/jit/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/jit/templates/aten_schema_declarations.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/pyi/gen_pyi.py",
        "functions": [
            "get_py_torch_functions",
            "sig_for_ops",
            "generate_type_hints",
            "gen_nn_functional",
            "gen_pyi",
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/pyi/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/setup_helpers/cmake.py",
        "functions": [
            "_mkdir_p",
            "convert_cmake_value_to_python_value",
            "get_cmake_cache_variables_from_file"
        ],
        "classes": [
            "CMake"
        ]
    },
    {
        "file_path": "../pytorch/tools/setup_helpers/env.py",
        "functions": [
            "check_env_flag",
            "check_negative_env_flag",
            "gather_paths",
            "lib_paths_from_base"
        ],
        "classes": [
            "BuildType"
        ]
    },
    {
        "file_path": "../pytorch/tools/setup_helpers/gen.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/setup_helpers/generate_code.py",
        "functions": [
            "all_generator_source",
            "generate_code",
            "get_selector_from_legacy_operator_selection_list",
            "get_selector",
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/setup_helpers/gen_version_header.py",
        "functions": [
            "parse_version",
            "apply_replacements",
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/setup_helpers/numpy_.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/setup_helpers/__init__.py",
        "functions": [
            "which"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/shared/cwrap_common.py",
        "functions": [
            "parse_arguments",
            "set_declaration_defaults",
            "filter_unique_options",
            "sort_by_number_of_args",
            "parse_header"
        ],
        "classes": [
            "Function",
            "Argument"
        ]
    },
    {
        "file_path": "../pytorch/tools/shared/module_loader.py",
        "functions": [
            "import_module"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/tools/shared/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/abi-check.cpp",
        "functions": [
            "main()"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/functional.py",
        "functions": [
            "broadcast_tensors",
            "broadcast_shapes",
            "split",
            "_indices_product",
            "_index_tensor_with_indices_list",
            "lu_unpack",
            "einsum",
            "_meshgrid",
            "stft",
            "istft",
            "_unique_impl",
            "_unique_consecutive_impl",
            "_return_counts",
            "_return_output",
            "_return_inverse",
            "_consecutive_return_counts",
            "_consecutive_return_output",
            "_consecutive_return_inverse",
            "tensordot",
            "cartesian_prod",
            "block_diag",
            "cdist",
            "atleast_1d",
            "atleast_2d",
            "atleast_3d",
            "norm",
            "chain_matmul",
            "_lu_impl",
            "_check_list_size",
            "_lu_with_infos",
            "_lu_no_infos",
            "align_tensors"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/_vmap_internals.py",
        "functions": [
            "_validate_and_get_batch_size",
            "_num_outputs",
            "_as_tuple",
            "_create_batched_inputs",
            "_unwrap_batched",
            "_validate_outputs",
            "_check_out_dims_is_int_or_int_tuple",
            "_get_name",
            "vmap",
            "_vmap"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/__config__.py",
        "functions": [
            "show",
            "_cxx_flags",
            "parallel_info"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/__future__.py",
        "functions": [
            "set_overwrite_module_params_on_conversion",
            "get_overwrite_module_params_on_conversion"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/__init__.py",
        "functions": [
            "_load_global_deps",
            "typename",
            "is_tensor",
            "is_storage",
            "set_default_tensor_type",
            "set_default_dtype",
            "use_deterministic_algorithms",
            "set_deterministic",
            "are_deterministic_algorithms_enabled",
            "is_deterministic",
            "manager_path",
            "_assert",
            "compiled_with_cxx11_abi"
        ],
        "classes": [
            "DoubleStorage",
            "FloatStorage",
            "HalfStorage",
            "LongStorage",
            "IntStorage",
            "ShortStorage",
            "CharStorage",
            "ByteStorage",
            "BoolStorage",
            "BFloat16Storage",
            "ComplexDoubleStorage",
            "ComplexFloatStorage",
            "QUInt8Storage",
            "QInt8Storage",
            "QInt32Storage",
            "QUInt4x2Storage"
        ]
    },
    {
        "file_path": "../pytorch/torch/hub.py",
        "functions": [
            "import_module",
            "_remove_if_exists",
            "_git_archive_link",
            "_load_attr_from_module",
            "_get_torch_home",
            "_parse_repo_info",
            "_get_cache_or_reload",
            "_check_module_exists",
            "_check_dependencies",
            "_load_entry_from_hubconf",
            "get_dir",
            "set_dir",
            "list",
            "help",
            "load",
            "_load_local",
            "download_url_to_file",
            "_download_url_to_file",
            "_is_legacy_zip_format",
            "_legacy_zip_load",
            "load_state_dict_from_url"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/overrides.py",
        "functions": [
            "wrap_torch_function",
            "_get_overloaded_args",
            "handle_torch_function",
            "is_tensor_method_or_property",
            "is_tensor_like"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/quasirandom.py",
        "functions": [],
        "classes": [
            "SobolEngine"
        ]
    },
    {
        "file_path": "../pytorch/torch/random.py",
        "functions": [
            "set_rng_state",
            "get_rng_state",
            "manual_seed",
            "seed",
            "initial_seed"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/serialization.py",
        "functions": [
            "_is_zipfile",
            "register_package",
            "check_module_version_greater_or_equal",
            "_cpu_tag",
            "_cuda_tag",
            "_cpu_deserialize",
            "validate_cuda_device",
            "_cuda_deserialize",
            "location_tag",
            "default_restore_location",
            "normalize_storage_type",
            "storage_to_tensor_type",
            "_is_path",
            "_open_file_like",
            "_open_zipfile_writer",
            "_is_compressed_file",
            "_should_read_directly",
            "_check_seekable",
            "_check_dill_version",
            "save",
            "_legacy_save",
            "_save",
            "load",
            "_get_layout",
            "_legacy_load",
            "_maybe_decode_ascii",
            "_get_restore_location",
            "_load",
            "_is_torchscript_zip"
        ],
        "classes": [
            "SourceChangeWarning",
            "_opener",
            "_open_file",
            "_open_buffer_reader",
            "_open_buffer_writer",
            "_open_zipfile_reader",
            "_open_zipfile_writer_file",
            "_open_zipfile_writer_buffer"
        ]
    },
    {
        "file_path": "../pytorch/torch/storage.py",
        "functions": [
            "_load_from_bytes"
        ],
        "classes": [
            "_StorageBase"
        ]
    },
    {
        "file_path": "../pytorch/torch/tensor.py",
        "functions": [
            "_wrap_type_error_to_not_implemented",
            "_rebuild_from_type",
            "_convert"
        ],
        "classes": [
            "Tensor"
        ]
    },
    {
        "file_path": "../pytorch/torch/types.py",
        "functions": [],
        "classes": [
            "Storage"
        ]
    },
    {
        "file_path": "../pytorch/torch/_appdirs.py",
        "functions": [
            "ser_data_dir(",
            "ite_data_dir(",
            "ser_config_dir(",
            "ite_config_dir(",
            "ser_cache_dir(",
            "ser_state_dir(",
            "ser_log_dir(",
            "get_win_folder_from_registry(",
            "get_win_folder_with_pywin32(",
            "get_win_folder_with_ctypes(",
            "get_win_folder_with_jna("
        ],
        "classes": [
            "ppDirs("
        ]
    },
    {
        "file_path": "../pytorch/torch/_autograd_functions.py",
        "functions": [],
        "classes": [
            "_LU"
        ]
    },
    {
        "file_path": "../pytorch/torch/_classes.py",
        "functions": [],
        "classes": [
            "_ClassNamespace",
            "_Classes"
        ]
    },
    {
        "file_path": "../pytorch/torch/_jit_internal.py",
        "functions": [
            "createResolutionCallbackFromEnv",
            "createResolutionCallbackFromFrame",
            "get_closure",
            "createResolutionCallbackFromClosure",
            "can_compile_class",
            "get_annotation_str",
            "get_type_hint_captures",
            "createResolutionCallbackForClassMethods",
            "boolean_dispatch",
            "export",
            "unused",
            "ignore",
            "_copy_to_script_wrapper",
            "module_has_exports",
            "should_drop",
            "is_ignored_fn",
            "is_static_fn",
            "get_static_fn",
            "get_torchscript_modifier",
            "copy_torchscript_modifier",
            "_overload",
            "_get_fn_overloads",
            "_clear_fn_overloads",
            "get_class_name_lineno",
            "_overload_method",
            "_get_overloaded_methods",
            "is_tuple",
            "is_list",
            "is_dict",
            "is_optional",
            "is_future",
            "is_final",
            "is_scripting",
            "_qualified_name",
            "fake_range",
            "_try_get_dispatched_fn",
            "_get_named_tuple_properties",
            "_create_named_tuple",
            "_disable_emit_hooks_decorator",
            "_is_exception",
            "raise_error_container_parameter_missing",
            "get_origin",
            "get_args",
            "check_args_exist",
            "container_checker",
            "_isinstance"
        ],
        "classes": [
            "FunctionModifiers",
            "BroadcastingListCls",
            "SourceContext"
        ]
    },
    {
        "file_path": "../pytorch/torch/_linalg_utils.py",
        "functions": [
            "is_sparse",
            "get_floating_dtype",
            "matmul",
            "conjugate",
            "transpose",
            "transjugate",
            "bform",
            "qform",
            "basis",
            "symeig"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/_lobpcg.py",
        "functions": [
            "_symeig_backward_complete_eigenspace",
            "_polynomial_coefficients_given_roots",
            "_polynomial_value",
            "_matrix_polynomial_value",
            "_vector_polynomial_value",
            "_symeig_backward_partial_eigenspace",
            "_symeig_backward",
            "lobpcg",
            "_lobpcg",
            "LOBPCG_call_tracker"
        ],
        "classes": [
            "LOBPCGAutogradFunction",
            "LOBPCG"
        ]
    },
    {
        "file_path": "../pytorch/torch/_lowrank.py",
        "functions": [
            "get_approximate_basis",
            "svd_lowrank",
            "_svd_lowrank",
            "pca_lowrank"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/_namedtensor_internals.py",
        "functions": [
            "check_serializing_named_tensor",
            "build_dim_map",
            "unzip_namedshape",
            "namer_api_name",
            "is_ellipsis",
            "single_ellipsis_index",
            "expand_single_ellipsis",
            "replace_ellipsis_by_position",
            "resolve_ellipsis",
            "update_names_with_list",
            "update_names_with_mapping",
            "update_names"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/_ops.py",
        "functions": [],
        "classes": [
            "_OpNamespace",
            "_Ops"
        ]
    },
    {
        "file_path": "../pytorch/torch/_python_dispatcher.py",
        "functions": [],
        "classes": [
            "PythonDispatcher"
        ]
    },
    {
        "file_path": "../pytorch/torch/_six.py",
        "functions": [
            "with_metaclass",
            "get_function_from_type",
            "istuple",
            "bind_method"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/_storage_docs.py",
        "functions": [
            "add_docstr_all"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/_tensor_docs.py",
        "functions": [
            "add_docstr_all"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/_tensor_str.py",
        "functions": [
            "set_printoptions",
            "_scalar_str",
            "_vector_str",
            "_tensor_str_with_formatter",
            "_tensor_str",
            "_add_suffixes",
            "get_summarized_data",
            "_str_intern",
            "_str"
        ],
        "classes": [
            "__PrinterOptions",
            "_Formatter"
        ]
    },
    {
        "file_path": "../pytorch/torch/_torch_docs.py",
        "functions": [
            "parse_kwargs",
            "merge_dicts"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/_utils.py",
        "functions": [
            "_type",
            "_cuda",
            "_get_async_or_non_blocking",
            "_rebuild_tensor",
            "_rebuild_tensor_v2",
            "_validate_loaded_sparse_tensors",
            "_rebuild_sparse_tensor",
            "_rebuild_xla_tensor",
            "_rebuild_qtensor",
            "_rebuild_parameter",
            "_import_dotted_name",
            "_accumulate",
            "_flatten_dense_tensors",
            "_flatten_sparse_tensors",
            "_unflatten_dense_tensors",
            "_unflatten_sparse_tensors",
            "_reorder_tensors_as",
            "_take_tensors",
            "annotate",
            "_get_available_device_type",
            "_get_device_attr",
            "_get_current_device_index",
            "_get_all_device_indices",
            "_get_devices_properties",
            "_get_device_index",
            "_handle_complex"
        ],
        "classes": [
            "KeyErrorMessage",
            "ExceptionWrapper"
        ]
    },
    {
        "file_path": "../pytorch/torch/_utils_internal.py",
        "functions": [
            "get_file_path",
            "get_file_path_2",
            "get_writable_path",
            "prepare_multiprocessing_environment",
            "resolve_library_path",
            "get_source_lines_and_file"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/_VF.py",
        "functions": [],
        "classes": [
            "VFModule"
        ]
    },
    {
        "file_path": "../pytorch/torch/autograd/anomaly_mode.py",
        "functions": [],
        "classes": [
            "detect_anomaly",
            "set_detect_anomaly"
        ]
    },
    {
        "file_path": "../pytorch/torch/autograd/forward_ad.py",
        "functions": [
            "enter_dual_level",
            "exit_dual_level",
            "make_dual",
            "unpack_dual"
        ],
        "classes": [
            "dual_level"
        ]
    },
    {
        "file_path": "../pytorch/torch/autograd/function.py",
        "functions": [
            "once_differentiable",
            "traceable",
            "_nested_map",
            "_jit_unwrap_structured",
            "_iter_filter",
            "_unflatten"
        ],
        "classes": [
            "_ContextMethodMixin",
            "_HookMixin",
            "BackwardCFunction",
            "FunctionMeta",
            "Function",
            "InplaceFunction",
            "NestedIOFunction"
        ]
    },
    {
        "file_path": "../pytorch/torch/autograd/functional.py",
        "functions": [
            "_as_tuple",
            "_tuple_postprocess",
            "_grad_preprocess",
            "_grad_postprocess",
            "_validate_v",
            "_check_requires_grad",
            "_autograd_grad",
            "_fill_in_zeros",
            "vjp",
            "jvp",
            "_construct_standard_basis_for",
            "jacobian",
            "hessian",
            "vhp",
            "hvp"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/autograd/gradcheck.py",
        "functions": [
            "zero_gradients",
            "make_jacobian",
            "iter_tensors",
            "get_numerical_jacobian",
            "get_analytical_jacobian",
            "get_failed_batched_grad_test_msg",
            "test_batched_grad",
            "_as_tuple",
            "_differentiable_outputs",
            "gradcheck",
            "gradgradcheck"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/autograd/grad_mode.py",
        "functions": [],
        "classes": [
            "_DecoratorContextManager",
            "no_grad",
            "enable_grad",
            "set_grad_enabled"
        ]
    },
    {
        "file_path": "../pytorch/torch/autograd/profiler.py",
        "functions": [
            "load_nvprof",
            "format_time",
            "format_time_share",
            "format_memory",
            "attr_formatter",
            "filter_stack_entry",
            "filter_name",
            "rewrite_name",
            "parse_kineto_results",
            "parse_legacy_records",
            "parse_nvprof_trace",
            "build_table"
        ],
        "classes": [
            "EventList",
            "profile",
            "record_function",
            "emit_nvtx",
            "FormattedTimesMixin",
            "Interval",
            "FunctionEvent",
            "FunctionEventAvg",
            "StringTable",
            "EnforceUnique"
        ]
    },
    {
        "file_path": "../pytorch/torch/autograd/variable.py",
        "functions": [],
        "classes": [
            "VariableMeta",
            "Variable"
        ]
    },
    {
        "file_path": "../pytorch/torch/autograd/__init__.py",
        "functions": [
            "_make_grads",
            "_tensor_or_tensors_to_tuple",
            "backward",
            "grad",
            "_is_checkpoint_valid",
            "variable"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/autograd/_functions/tensor.py",
        "functions": [],
        "classes": [
            "Type",
            "Resize"
        ]
    },
    {
        "file_path": "../pytorch/torch/autograd/_functions/utils.py",
        "functions": [
            "maybe_view",
            "maybe_unexpand",
            "check_onnx_broadcast"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/autograd/_functions/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/backends/__init__.py",
        "functions": [
            "disable_global_flags",
            "flags_frozen"
        ],
        "classes": [
            "ContextProp",
            "PropModule"
        ]
    },
    {
        "file_path": "../pytorch/torch/backends/cuda/__init__.py",
        "functions": [
            "is_built"
        ],
        "classes": [
            "cuFFTPlanCacheAttrContextProp",
            "cuFFTPlanCache",
            "cuFFTPlanCacheManager",
            "cuBLASModule"
        ]
    },
    {
        "file_path": "../pytorch/torch/backends/cudnn/rnn.py",
        "functions": [
            "get_cudnn_mode",
            "init_dropout_state"
        ],
        "classes": [
            "Unserializable"
        ]
    },
    {
        "file_path": "../pytorch/torch/backends/cudnn/__init__.py",
        "functions": [
            "version",
            "is_available",
            "is_acceptable",
            "set_flags"
        ],
        "classes": [
            "CudnnModule"
        ]
    },
    {
        "file_path": "../pytorch/torch/backends/mkl/__init__.py",
        "functions": [
            "is_available"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/backends/mkldnn/__init__.py",
        "functions": [
            "is_available",
            "set_flags"
        ],
        "classes": [
            "MkldnnModule"
        ]
    },
    {
        "file_path": "../pytorch/torch/backends/openmp/__init__.py",
        "functions": [
            "is_available"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/backends/quantized/__init__.py",
        "functions": [
            "_get_qengine_id",
            "_get_qengine_str"
        ],
        "classes": [
            "_QEngineProp",
            "_SupportedQEnginesProp",
            "QuantizedEngine"
        ]
    },
    {
        "file_path": "../pytorch/torch/backends/xnnpack/__init__.py",
        "functions": [],
        "classes": [
            "_XNNPACKEnabled",
            "XNNPACKEngine"
        ]
    },
    {
        "file_path": "../pytorch/torch/backends/_nnapi/prepare.py",
        "functions": [
            "_condensed_zeros_like",
            "convert_model_to_nnapi"
        ],
        "classes": [
            "NnapiModule",
            "NnapiInitWrapper",
            "ListWrapper",
            "DelistWrapper",
            "ListDelistWrapper"
        ]
    },
    {
        "file_path": "../pytorch/torch/backends/_nnapi/serializer.py",
        "functions": [
            "approx_equal",
            "tensor_size",
            "broadcast_shapes",
            "get_conv_pool_shape",
            "fix_shape",
            "serialize_model"
        ],
        "classes": [
            "NNAPI_OperandCode",
            "NNAPI_OperationCode",
            "NNAPI_FuseCode",
            "OperandValueSourceType",
            "TorchScalarTypes",
            "ConvPoolArgs2d",
            "DimOrder",
            "Operand",
            "_NnapiSerializer"
        ]
    },
    {
        "file_path": "../pytorch/torch/backends/_nnapi/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/contrib/_tensorboard_vis.py",
        "functions": [
            "dump_tensorboard_summary",
            "visualize",
            "visualize_graph_executor",
            "visualize_rec"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/contrib/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/CudaIPCTypes.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/DataLoader.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/Device.cpp",
        "functions": [
            "*THPDevice_New(const at::Device& device)",
            "*THPDevice_repr(THPDevice *self)",
            "*THPDevice_str(THPDevice *self)",
            "*THPDevice_pynew(PyTypeObject *type, PyObject *args, PyObject *kwargs)",
            "*THPDevice_type(THPDevice *self, PyObject *noargs)",
            "*THPDevice_index(THPDevice *self, PyObject *noargs)",
            "}",
            "*THPDevice_rc(PyObject *a, PyObject *b, int op)",
            "*THPDevice_reduce(PyObject *_self, PyObject *noargs)",
            "THPDevice_init(PyObject *module)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/dl.c",
        "functions": [
            "PyInit__dl(void)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/Dtype.cpp",
        "functions": [
            "* THPDtype_New(at::ScalarType scalar_type, const std::string& name)",
            "*THPDtype_is_floating_point(THPDtype *self, PyObject *noargs)",
            "*THPDtype_is_complex(THPDtype *self, PyObject *noargs)",
            "*THPDtype_is_signed(THPDtype *self, PyObject *noargs)",
            "}\n\nPyObject",
            "*THPDtype_repr(THPDtype *self)",
            "THPDtype_init(PyObject *module)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/DynamicTypes.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/empty.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/Exceptions.cpp",
        "functions": [
            "THPException_init(PyObject *module)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/Generator.cpp",
        "functions": [
            "* THPGenerator_initDefaultGenerator(at::Generator cdata)",
            "void",
            "PyObject",
            "PyObject",
            "PyObject",
            "PyObject",
            "PyObject",
            "PyObject",
            "PyObject",
            "THPGenerator_init(PyObject *module)",
            "set_pyobj(const Generator& self, PyObject* pyobj)",
            "* pyobj(const Generator& self)",
            "* THPGenerator_Wrap(Generator gen)",
            "* THPGenerator_NewWithVar(PyTypeObject* type, Generator gen)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/Layout.cpp",
        "functions": [
            "*THPLayout_New(at::Layout layout, const std::string& name)",
            "*THPLayout_repr(THPLayout *self)",
            "THPLayout_init(PyObject *module)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/MemoryFormat.cpp",
        "functions": [
            "*THPMemoryFormat_New(at::MemoryFormat memory_format, const std::string& name)",
            "*THPMemoryFormat_repr(THPMemoryFormat *self)",
            "THPMemoryFormat_init(PyObject *module)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/Module.cpp",
        "functions": [
            "PyObject",
            "PyObject",
            "PyObject",
            "PyObject",
            "PyObject",
            "PyObject",
            "PyObject",
            "PyObject",
            "PyObject",
            "* THPModule_setDefaultTensorType(PyObject *_unused, PyObject *type)",
            "* THPModule_setDefaultDtype(PyObject *_unused, PyObject *dtype)",
            "*THPModule_addDocStr(PyObject *_unused, PyObject *args)",
            "*THPModule_inferSize(PyObject *_unused, PyObject *args)",
            "PyObject",
            "PyObject",
            "PyObject",
            "PyObject",
            "*THPModule_hasDistributed(PyObject *_unused, PyObject *noargs)",
            "PyObject",
            "PyObject",
            "PyObject",
            "DLPack_Capsule_Destructor(PyObject* data)",
            "*THPModule_toDLPack(PyObject *_unused, PyObject *data)",
            "*THPModule_fromDLPack(PyObject *_unused, PyObject *data)",
            "*THPModule_setAllowTF32CuDNN(PyObject *_unused, PyObject *arg)",
            "*THPModule_allowTF32CuDNN(PyObject *_unused, PyObject *noargs)",
            "*THPModule_setUserEnabledCuDNN(PyObject *_unused, PyObject *arg)",
            "*THPModule_userEnabledCuDNN(PyObject *_unused, PyObject *noargs)",
            "*THPModule_setUserEnabledMkldnn(PyObject *_unused, PyObject *arg)",
            "*THPModule_userEnabledMkldnn(PyObject *_unused, PyObject *noargs)",
            "*THPModule_setDeterministicCuDNN(PyObject *_unused, PyObject *arg)",
            "*THPModule_deterministicCuDNN(PyObject *_unused, PyObject *noargs)",
            "*THPModule_setDeterministicAlgorithms(PyObject *_unused, PyObject *arg)",
            "*THPModule_deterministicAlgorithms(PyObject *_unused, PyObject *noargs)",
            "*THPModule_setBenchmarkCuDNN(PyObject *_unused, PyObject *arg)",
            "*THPModule_benchmarkCuDNN(PyObject *_unused, PyObject *noargs)",
            "*THPModule_setAllowTF32CuBLAS(PyObject *_unused, PyObject *arg)",
            "*THPModule_allowTF32CuBLAS(PyObject *_unused, PyObject *noargs)",
            "*THPModule_setFlushDenormal(PyObject *_unused, PyObject *arg)",
            "*THPModule_getDefaultDtype(PyObject *_unused, PyObject *arg)",
            "*THPModule_getDefaultDevice(PyObject *_unused, PyObject *arg)",
            "*THPModule_setQEngine(PyObject */* unused */, PyObject *arg)",
            "*THPModule_qEngine(PyObject *_unused, PyObject *noargs)",
            "*THPModule_supportedQEngines(PyObject *_unused, PyObject *noargs)",
            "*THPModule_isEnabledXNNPACK(PyObject *_unused, PyObject *noargs)",
            "PyObject",
            "PyObject",
            "PyObject",
            "PyObject",
            "void",
            "* initModule()",
            "void"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/python_dimname.cpp",
        "functions": [
            "THPUtils_checkDimname(PyObject* obj)",
            "THPUtils_checkDimnameList(PyObject* obj)",
            "THPDimname_parse(PyObject* obj)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/QScheme.cpp",
        "functions": [
            "*THPQScheme_New(at::QScheme qscheme, const std::string& name)",
            "*THPQScheme_reduce(PyObject *_self, PyObject *noargs)",
            "*THPQScheme_repr(THPQScheme *self)",
            "THPQScheme_init(PyObject *module)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/serialization.cpp",
        "functions": [
            "inline",
            "inline",
            "inline",
            "ssize_t",
            "ssize_t"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/Size.cpp",
        "functions": [
            "* THPSize_New(const torch::autograd::Variable& var)",
            "* THPSize_NewFromSizes(int dim, const int64_t *sizes)",
            "bool",
            "PyObject",
            "PyObject",
            "PyObject",
            "PyObject",
            "THPSize_init(PyObject *module)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/Storage.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/Stream.cpp",
        "functions": [
            "PyObject",
            "void",
            "PyObject",
            "PyObject",
            "THPStream_init(PyObject *module)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/stub.c",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/TypeInfo.cpp",
        "functions": [
            "* THPFInfo_New(const at::ScalarType& type)",
            "* THPIInfo_New(const at::ScalarType& type)",
            "* THPFInfo_pynew(PyTypeObject* type, PyObject* args, PyObject* kwargs)",
            "* THPIInfo_pynew(PyTypeObject* type, PyObject* args, PyObject* kwargs)",
            "* THPDTypeInfo_compare(THPDTypeInfo* a, THPDTypeInfo* b, int op)",
            "PyObject",
            "PyObject",
            "PyObject",
            "PyObject",
            "PyObject",
            "PyObject",
            "PyObject",
            "PyObject",
            "PyObject",
            "PyObject",
            "* THPFInfo_str(THPFInfo* self)",
            "* THPIInfo_str(THPIInfo* self)",
            "THPDTypeInfo_init(PyObject* module)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/utils.cpp",
        "functions": [
            "THPUtils_getCallable(PyObject *arg, PyObject **result)",
            "THPUtils_unpackSize(PyObject *arg)",
            "THPUtils_tryUnpackLongs(PyObject *arg, THLongStoragePtr& result)",
            "THPUtils_unpackLongs(PyObject *arg)",
            "THPUtils_tryUnpackLongVarArgs(PyObject *args, int ignore_first, THLongStoragePtr& result)",
            "THPUtils_checkIntTuple(PyObject *arg)",
            "THPUtils_unpackIntTuple(PyObject *arg)",
            "THPUtils_setError(const char *format, ...)",
            "THPUtils_addPyMethodDefs(std::vector<PyMethodDef>& vector, PyMethodDef* methods)",
            "const",
            "* THPUtils_dispatchStateless(\n    PyObject *tensor, const char *name, PyObject *args, PyObject *kwargs)",
            "THPUtils_invalidArguments(PyObject *given_args, PyObject *given_kwargs,\n        const char *function_name, size_t num_options, ...)",
            "setBackCompatBroadcastWarn(bool warn)",
            "getBackCompatBroadcastWarn()",
            "setBackCompatKeepdimWarn(bool warn)",
            "getBackCompatKeepdimWarn()",
            "maybeThrowBackCompatKeepdimWarn(char *func)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/tensor/python_tensor.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/cuda.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/enum.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/jit.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/serialize.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/data/datasets/mnist.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/data/samplers/distributed.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/data/samplers/random.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/data/samplers/sequential.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/data/samplers/stream.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/nn/init.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/nn/module.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/nn/modules/activation.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/nn/modules/adaptive.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/nn/modules/batchnorm.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/nn/modules/conv.cpp",
        "functions": [
            "_get_pad_mode_from_conv_padding_mode(torch::nn::detail::conv_padding_mode_t conv_padding_mode)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/nn/modules/distance.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/nn/modules/dropout.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/nn/modules/embedding.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/nn/modules/fold.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/nn/modules/instancenorm.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/nn/modules/linear.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/nn/modules/loss.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/nn/modules/normalization.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/nn/modules/padding.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/nn/modules/pixelshuffle.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/nn/modules/pooling.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/nn/modules/rnn.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/nn/modules/transformer.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/nn/modules/upsampling.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/nn/modules/_functions.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/nn/modules/container/functional.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/nn/options/activation.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/nn/options/adaptive.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/nn/options/batchnorm.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/nn/options/conv.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/nn/options/dropout.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/nn/options/embedding.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/nn/options/instancenorm.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/nn/options/linear.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/nn/options/normalization.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/nn/options/padding.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/nn/options/pooling.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/nn/options/rnn.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/nn/options/transformer.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/nn/options/vision.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/optim/adagrad.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/optim/adam.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/optim/adamw.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/optim/lbfgs.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/optim/optimizer.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/optim/rmsprop.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/optim/serialize.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/optim/sgd.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/python/init.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/serialize/input-archive.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/api/src/serialize/output-archive.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/autograd/anomaly_mode.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/autograd/autograd.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/autograd/autograd_meta.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/autograd/cpp_hook.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/autograd/custom_function.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/autograd/engine.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/autograd/forward_grad.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/autograd/function.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/autograd/FunctionsManual.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/autograd/function_hook.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/autograd/init.cpp",
        "functions": [
            "* THPAutograd_initExtension(PyObject* _unused, PyObject *unused)",
            "PyObject",
            "PyObject",
            "}",
            "PyObject",
            "}",
            "PyObject",
            "* python_functions()"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/autograd/input_buffer.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/autograd/profiler_cuda.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/autograd/profiler_kineto.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/autograd/profiler_legacy.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/autograd/profiler_utils.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/autograd/python_anomaly_mode.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/autograd/python_cpp_function.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/autograd/python_engine.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/autograd/python_function.cpp",
        "functions": [
            "int",
            "int",
            "void",
            "*THPFunction_new(PyTypeObject *type, PyObject *args, PyObject *kwargs)",
            "std::unordered_set<at::TensorImpl*>",
            "void",
            "void",
            "std::unordered_set<at::TensorImpl*>",
            "void",
            "torch::jit::Node",
            "void",
            "* process_outputs(PyObject *op_obj, const std::shared_ptr<PyNode>& cdata,\n                          THPFunction* grad_fn, const UnpackedInput& unpacked,\n                          PyObject *inputs, THPObjectPtr&& raw_output, bool is_executable,\n                          torch::jit::Node* node)",
            "* THPFunction_name(PyObject *self, PyObject* noargs)",
            "*THPFunction_apply(PyObject *cls, PyObject *inputs)",
            "void",
            "void",
            "* THPFunction_do_backward(PyObject *_self, PyObject *args)",
            "* THPFunction__register_hook_dict(PyObject *_self, PyObject *_var)",
            "* THPFunction_register_hook(PyObject *_self, PyObject *hook)",
            "THPFunction_set_materialize_grads(THPFunction *self, PyObject *value, void *unused)",
            "PyObject",
            "*THPFunction_saved_tensors(THPFunction *self, void *_unused)",
            "*THPFunction_saved_variables(THPFunction *self, void *_unused)",
            "*THPFunction_next_functions(THPFunction *self, void *_unused)",
            "*THPFunction_metadata(THPFunction *self, void *_unused)",
            "THPFunction_initModule(PyObject *module)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/autograd/python_hook.cpp",
        "functions": [
            "PyObject",
            "variable_list",
            "void",
            "void",
            "std::string"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/autograd/python_legacy_variable.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/autograd/python_variable.cpp",
        "functions": [
            "PyObject",
            "* THPVariable_Wrap(Variable var)",
            "int",
            "int",
            "void",
            "PyObject",
            "PyObject",
            "PyObject",
            "*THPVariable_get_T(THPVariable *self, void *unused)",
            "*THPVariable_get_cdata(THPVariable *self, void *unused)",
            "*THPVariable_get_version(THPVariable *self, void *unused)",
            "*THPVariable_get_grad_fn(THPVariable *self, void *unused)",
            "int",
            "PyObject",
            "PyObject",
            "THPVariable_set_data(THPVariable *self, PyObject *data, void *unused)",
            "*THPVariable_get_grad(THPVariable *self, void *unused)",
            "THPVariable_set_grad(THPVariable *self, PyObject *py_grad, void *unused)",
            "*THPVariable_get_volatile(THPVariable *self, void *unused)",
            "THPVariable_set_volatile(THPVariable *self, PyObject *obj, void *unused)",
            "*THPVariable_get_output_nr(THPVariable *self, void *unused)",
            "*THPVariable_get_requires_grad(THPVariable *self, void *unused)",
            "*THPVariable_get_ndim(THPVariable *self, void *unused)",
            "*THPVariable_get_names(PyObject *self, void *unused)",
            "THPVariable_set_names(PyObject *self, PyObject *names, void *unused)",
            "THPVariable_set_requires_grad(THPVariable *self, PyObject *obj, void *unused)",
            "*THPVariable_get_name(THPVariable* self, void *unused)",
            "*THPVariable_get_backwards_hooks(THPVariable *self, void *unused)",
            "THPVariable_set_backwards_hooks(THPVariable *self, PyObject *obj, void *unused)",
            "*THPVariable_get_base(THPVariable *self, void *unused)",
            "*THPVariable_get_shape(THPVariable *self, void *unused)",
            "*THPVariable_is_cuda(THPVariable *self, void *unused)",
            "* THPVariable_is_xpu(THPVariable* self, void* unused)",
            "*THPVariable_is_sparse(THPVariable *self, void *unused)",
            "*THPVariable_is_mkldnn(THPVariable *self, void *unused)",
            "*THPVariable_is_vulkan(THPVariable *self, void *unused)",
            "*THPVariable_is_quantized(THPVariable *self, void *unused)",
            "*THPVariable_is_meta(THPVariable *self, void *unused)",
            "*THPVariable_is_complex(THPVariable *self, void *unused)",
            "PyObject",
            "PyObject",
            "PyObject",
            "*THPVariable_get_real(THPVariable* self, void *unused)",
            "*THPVariable_get_imag(THPVariable* self, void *unused)",
            "THPVariable_set_real(THPVariable *self, THPVariable *real, void *unused)",
            "THPVariable_set_imag(THPVariable* self, THPVariable *imag, void *unused)",
            "THPVariable_initModule(PyObject *module)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/autograd/python_variable_indexing.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/autograd/record_function_ops.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/autograd/saved_variable.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/autograd/TraceTypeManual.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/autograd/variable.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/autograd/VariableTypeManual.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/autograd/functions/accumulate_grad.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/autograd/functions/basic_ops.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/autograd/functions/comm.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/autograd/functions/init.cpp",
        "functions": [
            "PyObject",
            "THPAutograd_initFunctions()"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/autograd/functions/tensor.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/autograd/functions/utils.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/cuda/comm.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/cuda/Event.cpp",
        "functions": [
            "PyObject",
            "PyObject",
            "void",
            "PyObject",
            "PyObject",
            "PyObject",
            "PyObject",
            "}",
            "PyObject",
            "PyObject",
            "}",
            "THCPEvent_init(PyObject *module)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/cuda/Graph.cpp",
        "functions": [
            "THCPGraph_init(PyObject *module)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/cuda/Module.cpp",
        "functions": [
            "void",
            "THCPModule_setDevice(int device)",
            "* THCPModule_setDevice_wrap(PyObject *self, PyObject *arg)",
            "* THCPModule_getDevice_wrap(PyObject *self, PyObject *noargs)",
            "* THCPModule_canDeviceAccessPeer_wrap(PyObject *self, PyObject *args)",
            "* THCPModule_getDeviceCount_wrap(PyObject *self, PyObject *noargs)",
            "* THCPModule_getArchFlags(PyObject *self, PyObject *noargs)",
            "PyObject",
            "* THCPModule_getCurrentStream_wrap(\n    PyObject * /* unused */, PyObject *device_index)",
            "* THCPModule_getDefaultStream_wrap(\n    PyObject * /* unused */, PyObject *device_index)",
            "* THCPModule_setStream_wrap(PyObject *self, PyObject *obj)",
            "* THCPModule_getCompiledVersion(PyObject *self, PyObject *noargs)",
            "* THCPModule_cudaHostAllocator(PyObject *_unused, PyObject *noargs)",
            "* THCPModule_cudaCachingAllocator_raw_alloc(PyObject *_unused, PyObject *args)",
            "* THCPModule_cudaCachingAllocator_raw_delete(PyObject *_unused, PyObject *obj)",
            "* THCPModule_cudaSynchronize(PyObject *_unused, PyObject *noargs)",
            "* THCPModule_cudaIPCCollect(PyObject *_unused, PyObject *noargs)",
            "* THCPModule_cudaSleep(PyObject *_unused, PyObject *cycles)",
            "* THCPModule_cudaLockMutex(PyObject *module, PyObject *noargs)",
            "* THCPModule_cudaUnlockMutex(PyObject *module, PyObject *noargs)",
            "* THCPModule_hasPrimaryContext(PyObject *_unused, PyObject *arg)",
            "* THCPModule_setMemoryFraction(PyObject *_unused, PyObject *args)",
            "* THCPModule_emptyCache(PyObject *_unused, PyObject *noargs)",
            "* THCPModule_memoryStats(PyObject *_unused, PyObject *arg)",
            "* THCPModule_resetAccumulatedMemoryStats(PyObject *_unused, PyObject *arg)",
            "* THCPModule_resetPeakMemoryStats(PyObject *_unused, PyObject *arg)",
            "* THCPModule_memorySnapshot(PyObject *_unused, PyObject *noargs)",
            "void",
            "void",
            "PyObject",
            "* THCPModule_getCurrentBlasHandle_wrap(PyObject *self, PyObject *noargs)",
            "* THCPModule_methods()"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/cuda/nccl.cpp",
        "functions": [
            "* to_nccl_comm(torch::cuda::nccl::ncclComm_t* var)",
            "to_nccl_comm(torch::cuda::nccl::ncclComm_t var)",
            "* to_nccl_unique_id(torch::cuda::nccl::ncclUniqueId* var)",
            "to_nccl_result(torch::cuda::nccl::ncclResult var)",
            "from_nccl_result(ncclResult_t var)",
            "to_nccl_data_type(c10::ScalarType type)",
            "to_nccl_data_type(const at::Tensor& t)",
            "to_nccl_red_op(int var)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/cuda/python_comm.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/cuda/python_nccl.cpp",
        "functions": [
            "* THCPModule_nccl_version(PyObject* self, PyObject* args)",
            "* THCPModule_nccl_unique_id(PyObject* self, PyObject* args)",
            "ncclComm_t",
            "void",
            "std::vector<c10::optional<at::cuda::CUDAStream>>",
            "std::vector<ncclComm_t>",
            "* THCPModule_nccl_init_rank(PyObject* self, PyObject* args)",
            "* THCPModule_nccl_reduce(PyObject* self, PyObject* args)",
            "* THCPModule_nccl_all_reduce(PyObject* self, PyObject* args)",
            "* THCPModule_nccl_broadcast(PyObject* self, PyObject* args)",
            "* THCPModule_nccl_all_gather(PyObject* self, PyObject* args)",
            "* THCPModule_nccl_reduce_scatter(PyObject* self, PyObject* args)",
            "inline",
            "inline"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/cuda/serialization.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/cuda/Storage.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/cuda/Stream.cpp",
        "functions": [
            "PyObject",
            "void",
            "PyObject",
            "PyObject",
            "PyObject",
            "PyObject",
            "PyObject",
            "PyObject",
            "}",
            "THCPStream_init(PyObject *module)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/cuda/Tensor.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/cuda/utils.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/cuda/shared/cudart.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/cuda/shared/cudnn.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/cuda/shared/nvtx.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/deploy/example/trace_simple.py",
        "functions": [],
        "classes": [
            "MyModule"
        ]
    },
    {
        "file_path": "../pytorch/torch/csrc/deploy/interpreter/freeze.py",
        "functions": [
            "indent_msg"
        ],
        "classes": [
            "Freezer"
        ]
    },
    {
        "file_path": "../pytorch/torch/csrc/deploy/interpreter/interpreter.cpp",
        "functions": [
            "extendFrozenModules(struct _frozen *frozenpython, struct _frozen *frozentorch)",
            "void",
            "startup()",
            "teardown()",
            "void",
            "run_some_python(const char* code)",
            "run_python_file(const char* code)",
            "load_model(const char* filename, bool hermetic)",
            "forward_model(size_t model_id, at::Tensor const & input)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/deploy/interpreter/test_main.cpp",
        "functions": [
            "main(int argc, char* argv[])",
            "{\n  ASSERT_TRUE(true);\n}",
            "{\n  Interpreter interp;\n  interp.run_some_python(\"print('hello from first interpeter!')\");\n\n  Interpreter interp2;\n  interp2.run_some_python(\"print('hello from second interpeter!')\");\n}",
            "compare_torchpy_jit(const char* model_filename, at::Tensor const & input)",
            "{\n  char* model_path = std::getenv(\"SIMPLE_MODEL_PATH\");\n  ASSERT_NE(model_path, nullptr);\n  const int A = 10, B = 20;\n  compare_torchpy_jit(\n      model_path, torch::ones(at::IntArrayRef({A, B})));\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/autograd/autograd.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/autograd/init.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/autograd/utils.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/autograd/context/container.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/autograd/context/context.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/autograd/engine/dist_engine.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/autograd/functions/recvrpc_backward.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/autograd/functions/sendrpc_backward.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/autograd/rpc_messages/autograd_metadata.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/autograd/rpc_messages/cleanup_autograd_context_req.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/autograd/rpc_messages/cleanup_autograd_context_resp.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/autograd/rpc_messages/propagate_gradients_req.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/autograd/rpc_messages/propagate_gradients_resp.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/autograd/rpc_messages/rpc_with_autograd.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/autograd/rpc_messages/rpc_with_profiling_req.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/autograd/rpc_messages/rpc_with_profiling_resp.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/autograd/rpc_messages/rref_backward_req.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/autograd/rpc_messages/rref_backward_resp.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/c10d/init.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/c10d/python_comm_hook.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/rpc/init.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/rpc/message.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/rpc/process_group_agent.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/rpc/python_call.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/rpc/python_functions.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/rpc/python_remote_call.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/rpc/python_resp.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/rpc/python_rpc_handler.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/rpc/py_rref.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/rpc/request_callback.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/rpc/request_callback_impl.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/rpc/request_callback_no_python.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/rpc/rpc_agent.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/rpc/rref_context.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/rpc/rref_impl.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/rpc/rref_proto.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/rpc/script_call.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/rpc/script_remote_call.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/rpc/script_resp.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/rpc/tensorpipe_agent.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/rpc/tensorpipe_utils.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/rpc/torchscript_functions.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/rpc/types.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/rpc/unpickled_python_call.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/rpc/unpickled_python_remote_call.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/rpc/utils.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/rpc/testing/faulty_process_group_agent.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/rpc/testing/init.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/rpc/metrics/registry.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/rpc/profiler/remote_profiler_manager.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/distributed/rpc/profiler/server_process_global_profiler.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/generic/serialization.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/generic/Storage.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/generic/StorageMethods.cpp",
        "functions": [
            "PyObject",
            "PyObject",
            "PyObject",
            "PyObject",
            "PyObject",
            "PyObject",
            "PyObject",
            "PyObject",
            "PyObject",
            "* THPStorage_(writeFile)(PyObject *_self, PyObject *args)",
            "* THPStorage_(newWithFile)(PyObject *_unused, PyObject *file)",
            "PyObject",
            "* THPStorage_(_setCdata)(PyObject *_self, PyObject *new_cdata)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/generic/StorageSharing.cpp",
        "functions": [
            "PyObject",
            "PyObject",
            "PyObject",
            "* THPStorage_(newWithWeakPtr)(PyObject *_unused, PyObject *arg)",
            "* THPStorage_(freeWeakRef)(PyObject *_unused, PyObject *arg)",
            "* THPStorage_(expired)(PyObject *_unused, PyObject *arg)",
            "* THPStorage_(sharedFd)(PyObject *_self, PyObject *noargs)",
            "* THPStorage_(isShared)(PyObject *_self, PyObject *noargs)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/generic/utils.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/jit_log.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/jit_opt_limit.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/api/function_impl.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/api/module.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/api/module_save.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/api/object.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/backends/backend_detail.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/backends/backend_init.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/backends/backend_interface.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/backends/backend_resolver.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/arith.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/codegen.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/compute_at.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/dispatch.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/executor.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/executor_kernel_arg.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/executor_launch_params.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/executor_utils.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/fusion.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/graph_fuser.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/index_compute.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/instrumentation.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/interface.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/ir_base_nodes.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/ir_cloner.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/ir_graphviz.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/ir_iostream.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/ir_nodes.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/iter_visitor.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/kernel.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/kernel_cache.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/kernel_ir.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/kernel_ir_builder.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/kernel_ir_printer.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/lower2device.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/lower_alias_memory.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/lower_index.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/lower_insert_syncs.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/lower_loops.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/lower_thread_predicate.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/lower_unroll.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/lower_utils.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/lower_validation.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/expr_evaluator.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/manager.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/mutator.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/parser.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/partition.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/predicate_compute.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/register_interface.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/scheduler.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/shape_inference.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/tensor_view.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/transform_iter.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/transform_replay.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/transform_rfactor.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/type.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/cuda/tools/stringify_file.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/fuser/codegen.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/fuser/compiler.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/fuser/executor.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/fuser/fallback.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/fuser/interface.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/fuser/kernel_cache.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/fuser/cpu/fused_kernel.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/codegen/fuser/cuda/fused_kernel.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/frontend/builtin_functions.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/frontend/canonicalize_modified_loop.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/frontend/concrete_module_type.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/frontend/convert_to_ssa.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/frontend/edit_distance.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/frontend/error_report.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/frontend/exit_transforms.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/frontend/function_schema_parser.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/frontend/inline_loop_condition.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/frontend/ir_emitter.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/frontend/lexer.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/frontend/name_mangler.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/frontend/parser.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/frontend/schema_matching.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/frontend/schema_type_parser.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/frontend/script_type_parser.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/frontend/source_range.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/frontend/string_to_type.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/frontend/strtod.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/frontend/sugared_value.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/frontend/tracer.cpp",
        "functions": [
            "{\n  // TODO: register fallback kernel with tracing function from\n  // `torch/csrc/jit/runtime/register_c10_ops.cpp`.\n  m.fallback(torch::CppFunction::makeFallthrough());\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/frontend/versioned_symbols.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/ir/alias_analysis.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/ir/attributes.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/ir/constants.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/ir/ir.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/ir/irparser.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/ir/node_hashing.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/ir/scope.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/ir/subgraph_matcher.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/ir/type_hashing.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/mobile/observer.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/mobile/export_data.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/mobile/function.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/mobile/import.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/mobile/import_data.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/mobile/interpreter.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/mobile/module.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/mobile/sequential.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/mobile/type_parser.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/mobile/optim/sgd.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/annotate_warns.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/bailout_graph.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/batch_mm.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/canonicalize.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/canonicalize_graph_fuser_ops.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/clear_profiling.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/clear_undefinedness.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/common_subexpression_elimination.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/constant_pooling.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/constant_propagation.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/create_autodiff_subgraphs.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/create_functional_graphs.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/dead_code_elimination.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/decompose_ops.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/erase_number_types.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/fixup_trace_scope_blocks.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/fold_conv_bn.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/freeze_module.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/frozen_conv_folding.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/frozen_graph_optimizations.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/fuse_linear.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/fuse_relu.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/graph_fuser.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/graph_rewrite_helper.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/guard_elimination.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/hoist_conv_packed_params.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/inliner.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/inline_autodiff_subgraphs.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/inline_forked_closures.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/inline_fork_wait.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/inplace_check.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/insert_guards.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/lift_closures.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/liveness.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/loop_unrolling.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/lower_grad_of.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/lower_graph.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/lower_tuples.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/metal_rewrite.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/normalize_ops.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/onnx.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/pass_manager.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/peephole.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/peephole_alias_sensitive.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/peephole_list_idioms.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/prepack_folding.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/remove_dropout.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/remove_expands.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/remove_inplace_ops.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/remove_mutation.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/remove_redundant_profiles.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/requires_grad_analysis.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/shape_analysis.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/specialize_autogradzero.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/subgraph_rewrite.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/tensorexpr_fuser.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/update_differentiable_graph_requires_grad.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/vulkan_rewrite.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/xnnpack_rewrite.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/onnx/cast_all_constant_to_floating.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/onnx/constant_fold.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/onnx/eliminate_unused_items.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/onnx/eval_peephole.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/onnx/fixup_onnx_controlflow.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/onnx/fold_if_node.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/onnx/function_substitution.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/onnx/helper.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/onnx/list_model_parameters.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/onnx/peephole.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/onnx/prepare_division_for_onnx.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/onnx/preprocess_for_onnx.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/onnx/remove_inplace_ops_for_onnx.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/onnx/scalar_type_analysis.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/onnx/shape_type_inference.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/onnx/unpack_quantized_weights.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/quantization/dedup_module_uses.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/quantization/finalize.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/quantization/fusion_passes.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/quantization/helper.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/quantization/insert_observers.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/quantization/insert_quant_dequant.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/quantization/quantization_type.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/utils/check_alias_annotation.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/utils/memory_dag.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/passes/utils/subgraph_utils.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/python/init.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/python/pybind_utils.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/python/python_arg_flatten.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/python/python_custom_class.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/python/python_interpreter.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/python/python_ir.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/python/python_sugared_value.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/python/python_tracer.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/python/python_tree_views.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/python/script_init.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/python/update_graph_executor_opt.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/runtime/slice_indices_adjust.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/runtime/argument_spec.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/runtime/autodiff.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/runtime/graph_executor.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/runtime/instruction.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/runtime/interpreter.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/runtime/jit_exception.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/runtime/logging.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/runtime/operator.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/runtime/print_handler.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/runtime/profiling_graph_executor_impl.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/runtime/profiling_record.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/runtime/register_c10_ops.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/runtime/register_cuda_ops.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/runtime/register_distributed_ops.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/runtime/register_ops_utils.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/runtime/register_prim_ops.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/runtime/register_prim_ops_fulljit.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/runtime/register_special_ops.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/runtime/symbolic_script.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/runtime/vararg_functions.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/runtime/static/fusion.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/runtime/static/impl.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/runtime/static/init.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/runtime/static/ops.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/runtime/static/passes.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/serialization/export.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/serialization/export_module.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/serialization/import.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/serialization/import_export_helpers.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/serialization/import_legacy.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/serialization/import_source.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/serialization/onnx.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/serialization/pickle.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/serialization/pickler.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/serialization/python_print.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/serialization/source_range_serialization.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/serialization/type_name_uniquer.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/serialization/unpickler.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/tensorexpr/block_codegen.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/tensorexpr/bounds_inference.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/tensorexpr/bounds_overlap.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/tensorexpr/codegen.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/tensorexpr/cpp_codegen.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/tensorexpr/cuda_codegen.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/tensorexpr/eval.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/tensorexpr/expr.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/tensorexpr/external_functions.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/tensorexpr/external_functions_registry.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/tensorexpr/function.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/tensorexpr/hash_provider.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/tensorexpr/intrinsic_symbols.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/tensorexpr/ir.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/tensorexpr/ir_mutator.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/tensorexpr/ir_printer.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/tensorexpr/ir_simplifier.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/tensorexpr/ir_visitor.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/tensorexpr/kernel.cpp",
        "functions": [
            "normalizeAndCheckIndex(int64_t idx, int64_t list_size)",
            "at::ScalarType",
            "std::vector<ExprHandle>",
            "TensorExprKernel::broadcast(\n    Tensor* t,\n    const std::vector<ExprHandle>& axes)",
            "TensorExprKernel::chunk(\n    Tensor* t,\n    size_t chunkIdx,\n    int64_t dim,\n    int64_t chunks,\n    const std::vector<ExprHandle>& axes)",
            "promoteToDtype(ExprHandle e, ScalarType dt)",
            "TensorExprKernel::tensorOrConstant(\n    const torch::jit::Value* v,\n    const std::vector<ExprHandle>& axes)",
            "TensorExprKernel::sizesFromVaryingShape(\n    const c10::VaryingShape<int64_t>& shape)",
            "TensorExprKernel::dimsFromSizes(\n    const std::vector<ExprHandle>& sizes)",
            "TensorExprKernel::sizesForValue(\n    const torch::jit::Value* v)",
            "TensorExprKernel::inferSizesForValue(\n    const torch::jit::Value* v)",
            "TensorExprKernel::constant(const torch::jit::Value* v)",
            "promoteIntegerToDefaultType(const ExprHandle& e)",
            "promoteHalfToFloat(const ExprHandle& e)",
            "TensorExprKernel::checkTypes(\n    const ScalarType highType,\n    const int typeConstraints)",
            "TensorExprKernel::promoteInputs(\n    std::vector<ExprHandle>& inputs,\n    const int typeConstraints)",
            "TensorExprKernel::demoteOutput(\n    const ExprHandle& e,\n    const torch::jit::Value* v)",
            "bool",
            "TensorExprKernel::broadcastShapes(\n    std::vector<std::vector<ExprHandle>> shapes)",
            "TensorExprKernel::broadcastShapes(\n    const std::vector<ExprHandle>& a,\n    const std::vector<ExprHandle>& b)",
            "TensorExprKernel::valueShape(\n    const torch::jit::Value* v)",
            "* TensorExprKernel::computeOneOperand(\n    const std::string& name,\n    const torch::jit::Value* v,\n    const std::function<ExprHandle(const ExprHandle&)>& innerExpr,\n    const int checkParamTypes)",
            "* TensorExprKernel::computeTwoOperand(\n    const std::string& name,\n    const torch::jit::Value* v,\n    const std::function<ExprHandle(const ExprHandle&, const ExprHandle&)>&\n        innerExpr)",
            "* TensorExprKernel::computeTwoOperandWithAlpha(\n    const std::string& name,\n    const torch::jit::Value* v,\n    const std::function<ExprHandle(const ExprHandle&, const ExprHandle&)>&\n        innerExpr)",
            "* TensorExprKernel::computeConditionWithTwoOperand(\n    const std::string& name,\n    const torch::jit::Value* v,\n    const std::function<\n        ExprHandle(const ExprHandle&, const ExprHandle&, const ExprHandle&)>&\n        innerExpr)",
            "* TensorExprKernel::computeThreeOperand(\n    const std::string& name,\n    const torch::jit::Value* v,\n    const std::function<\n        ExprHandle(const ExprHandle&, const ExprHandle&, const ExprHandle&)>&\n        innerExpr,\n    bool promote_inputs)",
            "* TensorExprKernel::computeFourOperand(\n    const std::string& name,\n    const torch::jit::Value* v,\n    const std::function<ExprHandle(\n        const ExprHandle&,\n        const ExprHandle&,\n        const ExprHandle&,\n        const ExprHandle&)>& innerExpr)",
            "findDtypeForValue(const torch::jit::Value* v)",
            "* TensorExprKernel::computeValue(const torch::jit::Value* v)",
            "* TensorExprKernel::generateStmt(BackendType backendType)",
            "TensorExprKernel::getCodeGenName(BackendType backendType)",
            "TensorExprKernel::prepareBufferArgs()",
            "TensorExprKernel::inferBackendTypeFromDevice(\n    at::Device device)",
            "TensorExprKernel::bindInput(const torch::jit::Value* input)",
            "* TensorExprKernel::computeSum(const torch::jit::Value* v)",
            "* TensorExprKernel::computeSoftmax(\n    const torch::jit::Value* v,\n    bool log_softmax)",
            "TensorExprKernel::getReductionInfo(\n    const torch::jit::Node* node)",
            "TensorExprKernel::getReductionAxes(\n    const torch::jit::Node* node)",
            "denseAndNonOverlapping(\n    at::ArrayRef<int64_t> sizes,\n    at::ArrayRef<int64_t> strides)",
            "* TensorExprKernel::convertOutputToCorrectStrides(torch::jit::Value* v)",
            "TensorExprKernel::compile()",
            ": graph_(subgraph), code_(subgraph, \"\")",
            "TensorExprKernel::run(Stack& stack)",
            "TensorExprKernel::prepareRunArgs(\n    const at::ArrayRef<IValue>& inputs,\n    std::vector<at::Tensor>& outputs)",
            "* TensorExprKernel::getCodeGenStmt()",
            "TensorExprKernel::runKernel(Stack& stack)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/tensorexpr/llvm_codegen.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/tensorexpr/llvm_jit.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/tensorexpr/loopnest.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/tensorexpr/mem_arena.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/tensorexpr/mem_dependency_checker.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/tensorexpr/reduction.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/tensorexpr/registerizer.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/tensorexpr/tensor.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/tensorexpr/tensorexpr_init.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/tensorexpr/types.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/tensorexpr/unique_name_manager.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/testing/file_check.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/jit/testing/hooks_for_testing.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/multiprocessing/init.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/onnx/init.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/utils/byte_order.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/utils/cuda_lazy_init.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/utils/disable_torch_function.cpp",
        "functions": [
            "* DisableTorchFunction__enter(PyObject* self, PyObject *unused)",
            "* DisableTorchFunction__exit(PyObject* self, PyObject *unused)",
            "* THPModule_isEnabledTorchFunction(PyObject* self, PyObject *unused)",
            "* THPModule_DisableTorchFunctionType()",
            "* THPModule_disable_torch_function(PyObject *self, PyObject *a)",
            "bool",
            "bool",
            "bool",
            "bool",
            "* THPModule_has_torch_function(PyObject*, PyObject *arg)",
            "* THPModule_has_torch_function_unary(PyObject*, PyObject *obj)",
            "* THPModule_has_torch_function_variadic(PyObject*, PyObject *const *args, Py_ssize_t nargs)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/utils/init.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/utils/invalid_arguments.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/utils/object_ptr.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/utils/out_types.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/utils/python_arg_parser.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/utils/python_dispatch.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/utils/structseq.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/utils/tensor_apply.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/utils/tensor_dtypes.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/utils/tensor_flatten.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/utils/tensor_layouts.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/utils/tensor_list.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/utils/tensor_memoryformats.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/utils/tensor_new.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/utils/tensor_numpy.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/utils/tensor_qschemes.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/utils/tensor_types.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/utils/throughput_benchmark.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/csrc/utils/variadic.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/cuda/comm.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/cuda/error.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/cuda/memory.py",
        "functions": [
            "_host_allocator",
            "caching_allocator_alloc",
            "caching_allocator_delete",
            "set_per_process_memory_fraction",
            "empty_cache",
            "memory_stats",
            "memory_stats_as_nested_dict",
            "reset_accumulated_memory_stats",
            "reset_peak_memory_stats",
            "reset_max_memory_allocated",
            "reset_max_memory_cached",
            "memory_allocated",
            "max_memory_allocated",
            "memory_reserved",
            "max_memory_reserved",
            "memory_cached",
            "max_memory_cached",
            "memory_snapshot",
            "memory_summary",
            "list_gpu_processes"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/cuda/nccl.py",
        "functions": [
            "is_available",
            "version",
            "unique_id",
            "init_rank",
            "_check_sequence_type",
            "all_reduce",
            "reduce",
            "broadcast",
            "all_gather",
            "reduce_scatter"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/cuda/nvtx.py",
        "functions": [
            "range_push",
            "range_pop",
            "mark"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/cuda/profiler.py",
        "functions": [
            "init",
            "start",
            "stop"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/cuda/random.py",
        "functions": [
            "get_rng_state",
            "get_rng_state_all",
            "set_rng_state",
            "set_rng_state_all",
            "manual_seed",
            "manual_seed_all",
            "seed",
            "seed_all",
            "initial_seed"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/cuda/sparse.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/cuda/streams.py",
        "functions": [],
        "classes": [
            "Stream",
            "Event"
        ]
    },
    {
        "file_path": "../pytorch/torch/cuda/_utils.py",
        "functions": [
            "_get_device_index",
            "_dummy_type"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/cuda/__init__.py",
        "functions": [
            "is_available",
            "_sleep",
            "_check_capability",
            "_check_cubins",
            "is_initialized",
            "_lazy_call",
            "init",
            "_lazy_init",
            "cudart",
            "check_error",
            "set_device",
            "get_device_name",
            "get_device_capability",
            "get_device_properties",
            "can_device_access_peer",
            "device_count",
            "get_arch_list",
            "get_gencode_flags",
            "current_device",
            "synchronize",
            "ipc_collect",
            "current_stream",
            "default_stream",
            "current_blas_handle"
        ],
        "classes": [
            "DeferredCudaCallError",
            "cudaStatus",
            "CudaError",
            "device",
            "device_of",
            "_CudaBase",
            "DoubleStorage",
            "FloatStorage",
            "LongStorage",
            "IntStorage",
            "ShortStorage",
            "CharStorage",
            "ByteStorage",
            "HalfStorage",
            "BoolStorage",
            "BFloat16Storage",
            "ComplexDoubleStorage",
            "ComplexFloatStorage"
        ]
    },
    {
        "file_path": "../pytorch/torch/cuda/amp/autocast_mode.py",
        "functions": [
            "_cast",
            "custom_fwd",
            "custom_bwd"
        ],
        "classes": [
            "autocast"
        ]
    },
    {
        "file_path": "../pytorch/torch/cuda/amp/common.py",
        "functions": [
            "amp_definitely_not_available"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/cuda/amp/grad_scaler.py",
        "functions": [
            "_refresh_per_optimizer_state"
        ],
        "classes": [
            "_MultiDeviceReplicator",
            "OptState",
            "GradScaler"
        ]
    },
    {
        "file_path": "../pytorch/torch/cuda/amp/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/distributed/constants.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/distributed/distributed_c10d.py",
        "functions": [
            "supports_complex",
            "_store_based_barrier",
            "_rank_not_in_group",
            "_get_group_rank",
            "_get_global_rank",
            "_get_group_size",
            "_check_single_tensor",
            "_check_tensor_list",
            "_check_op",
            "_check_p2p_op_list",
            "is_mpi_available",
            "is_nccl_available",
            "is_gloo_available",
            "is_initialized",
            "_get_default_group",
            "_get_default_store",
            "_update_default_pg",
            "get_backend",
            "init_process_group",
            "_new_process_group_helper",
            "destroy_process_group",
            "get_rank",
            "get_world_size",
            "isend",
            "irecv",
            "send",
            "recv",
            "batch_isend_irecv",
            "broadcast_multigpu",
            "broadcast",
            "all_reduce_multigpu",
            "all_reduce",
            "all_reduce_coalesced",
            "reduce_multigpu",
            "reduce",
            "all_gather_multigpu",
            "_object_to_tensor",
            "_tensor_to_object",
            "all_gather_object",
            "gather_object",
            "broadcast_object_list",
            "scatter_object_list",
            "all_gather",
            "all_gather_coalesced",
            "_validate_output_list_for_rank",
            "gather",
            "scatter",
            "reduce_scatter_multigpu",
            "reduce_scatter",
            "all_to_all_single",
            "all_to_all",
            "barrier",
            "new_group"
        ],
        "classes": [
            "Backend",
            "_reduce_op",
            "group",
            "GroupMember",
            "P2POp"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributed/launch.py",
        "functions": [
            "parse_args",
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/distributed/rendezvous.py",
        "functions": [
            "register_rendezvous_handler",
            "rendezvous",
            "_rendezvous_error",
            "_file_rendezvous_handler",
            "_tcp_rendezvous_handler",
            "_env_rendezvous_handler"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/distributed/__init__.py",
        "functions": [
            "is_available"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/distributed/algorithms/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/distributed/algorithms/ddp_comm_hooks/default_hooks.py",
        "functions": [
            "_allreduce_fut",
            "allreduce_hook",
            "fp16_compress_hook",
            "_get_allgather_out_list",
            "_allgather_then_aggregate_hook"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/distributed/algorithms/ddp_comm_hooks/powerSGD_hook.py",
        "functions": [
            "_orthogonalize",
            "powerSGD_hook",
            "batched_powerSGD_hook"
        ],
        "classes": [
            "PowerSGDState"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributed/algorithms/ddp_comm_hooks/quantization_hooks.py",
        "functions": [
            "_quantize_per_tensor_cuda",
            "_dequantize_per_tensor_cuda",
            "_quantize_per_channel_cuda",
            "_dequantize_per_channel_cuda",
            "_get_allgather_out_list",
            "quantization_pertensor_hook",
            "quantization_perchannel_hook"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/distributed/algorithms/ddp_comm_hooks/__init__.py",
        "functions": [
            "_ddp_comm_hook_wrapper",
            "_powerSGD_comm_hook_wrapper",
            "register_ddp_comm_hook"
        ],
        "classes": [
            "DDPCommHookType"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributed/autograd/__init__.py",
        "functions": [
            "is_available"
        ],
        "classes": [
            "context"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributed/benchmarks/benchmark_ddp_rpc.py",
        "functions": [
            "_retrieve_embedding_parameters",
            "_print_header",
            "_print_benchmark",
            "_print_cont",
            "_run_printable",
            "_run_trainer",
            "run_worker"
        ],
        "classes": [
            "HybridModel"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributed/nn/functional.py",
        "functions": [
            "broadcast",
            "gather",
            "scatter",
            "reduce",
            "all_gather",
            "all_to_all",
            "all_reduce"
        ],
        "classes": [
            "_Broadcast",
            "_Gather",
            "_Scatter",
            "_Reduce",
            "_AllGather",
            "_AlltoAll",
            "_AllReduce"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributed/nn/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/distributed/nn/api/remote_module.py",
        "functions": [
            "_instantiate_template",
            "_create_module",
            "_param_rrefs",
            "_raise_not_supported"
        ],
        "classes": [
            "_RemoteModule",
            "moteModule(_"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributed/nn/api/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/distributed/nn/jit/instantiator.py",
        "functions": [
            "get_arg_return_types_from_interface",
            "_write",
            "_do_instantiate_remote_module_template",
            "instantiate_scriptable_remote_module_template",
            "instantiate_non_scriptable_remote_module_template"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/distributed/nn/jit/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/distributed/nn/jit/templates/remote_module_template.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/distributed/nn/jit/templates/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/distributed/optim/functional_adadelta.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/distributed/optim/functional_adagrad.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/distributed/optim/functional_adam.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/distributed/optim/functional_adamw.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/distributed/optim/functional_rmsprop.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/distributed/optim/functional_sgd.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/distributed/optim/optimizer.py",
        "functions": [
            "_new_local_optimizer",
            "_local_optimizer_step",
            "_new_script_local_optimizer",
            "_wait_for_all"
        ],
        "classes": [
            "_ScriptLocalOptimizer",
            "_LocalOptimizer",
            "DistributedOptimizer"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributed/optim/zero_redundancy_optimizer.py",
        "functions": [
            "_recursive_copy_to_device",
            "_broadcast_object",
            "_get_global_rank"
        ],
        "classes": [
            "ZeroRedundancyOptimizer"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributed/optim/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/distributed/pipeline/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/distributed/pipeline/sync/batchnorm.py",
        "functions": [],
        "classes": [
            "DeferredBatchNorm"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributed/pipeline/sync/checkpoint.py",
        "functions": [
            "checkpoint",
            "is_checkpointing",
            "is_recomputing",
            "save_rng_states"
        ],
        "classes": [
            "Function",
            "Checkpointing",
            "ThreadLocal",
            "Context",
            "Checkpoint",
            "Recompute"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributed/pipeline/sync/copy.py",
        "functions": [],
        "classes": [
            "Context",
            "Copy",
            "Wait"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributed/pipeline/sync/dependency.py",
        "functions": [
            "fork",
            "join"
        ],
        "classes": [
            "Fork",
            "Join"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributed/pipeline/sync/microbatch.py",
        "functions": [
            "check",
            "scatter",
            "gather"
        ],
        "classes": [
            "Batch"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributed/pipeline/sync/phony.py",
        "functions": [
            "get_phony"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/distributed/pipeline/sync/pipe.py",
        "functions": [
            "_recommend_auto_balance",
            "_verify_module",
            "_verify_splitting",
            "_retrieve_device",
            "_split_module"
        ],
        "classes": [
            "BalanceError",
            "Pipe"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributed/pipeline/sync/pipeline.py",
        "functions": [
            "_depend",
            "_copy",
            "_wait",
            "_clock_cycles"
        ],
        "classes": [
            "Pipeline"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributed/pipeline/sync/stream.py",
        "functions": [
            "new_stream",
            "current_stream",
            "default_stream",
            "get_device",
            "wait_stream",
            "record_stream",
            "is_cuda",
            "as_cuda"
        ],
        "classes": [
            "CPUStreamType"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributed/pipeline/sync/utils.py",
        "functions": [
            "partition_model"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/distributed/pipeline/sync/worker.py",
        "functions": [
            "worker",
            "create_workers",
            "join_workers"
        ],
        "classes": [
            "Task"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributed/pipeline/sync/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/distributed/pipeline/sync/skip/layout.py",
        "functions": [
            "inspect_skip_layout"
        ],
        "classes": [
            "SkipLayout"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributed/pipeline/sync/skip/namespace.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/distributed/pipeline/sync/skip/portal.py",
        "functions": [],
        "classes": [
            "rtal:\n",
            "ntext(C",
            "rtalBlue(t",
            "rtalOrange(t",
            "rtalCopy(t"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributed/pipeline/sync/skip/skippable.py",
        "functions": [
            "skippable",
            "verify_skippables"
        ],
        "classes": [
            "Skippable",
            "stash",
            "pop"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributed/pipeline/sync/skip/tracker.py",
        "functions": [
            "current_skip_tracker"
        ],
        "classes": [
            "SkipTracker",
            "SkipTrackerThroughPotals",
            "ThreadLocal"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributed/pipeline/sync/skip/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/distributed/pipeline/sync/_balance/blockpartition.py",
        "functions": [
            "lve(s"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/distributed/pipeline/sync/_balance/profile.py",
        "functions": [
            "layerwise_sandbox",
            "detach",
            "profile_times",
            "profile_sizes"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/distributed/pipeline/sync/_balance/__init__.py",
        "functions": [
            "balance_cost",
            "balance_by_time",
            "balance_by_size"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/distributed/rpc/api.py",
        "functions": [
            "_require_initialized",
            "_init_rpc_states",
            "_gather_to_leader",
            "_broadcast_to_followers",
            "_to_worker_info",
            "_rref_typeof_on_owner",
            "_rref_typeof_on_user",
            "method_factory",
            "_invoke_rpc"
        ],
        "classes": [
            "AllGatherStates"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributed/rpc/backend_registry.py",
        "functions": [
            "_backend_type_repr",
            "backend_registered",
            "register_backend",
            "construct_rpc_backend_options",
            "init_backend",
            "_process_group_construct_rpc_backend_options_handler",
            "_init_process_group",
            "_process_group_init_backend_handler",
            "_tensorpipe_construct_rpc_backend_options_handler",
            "_tensorpipe_check_device_maps",
            "_tensorpipe_init_backend_handler"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/distributed/rpc/constants.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/distributed/rpc/functions.py",
        "functions": [
            "async_execution"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/distributed/rpc/internal.py",
        "functions": [
            "serialize",
            "deserialize",
            "_run_function",
            "_handle_exception",
            "_build_rpc_profiling_key",
            "_start_record_function"
        ],
        "classes": [
            "RPCExecMode",
            "_InternalRPCPickler"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributed/rpc/options.py",
        "functions": [],
        "classes": [
            "TensorPipeRpcBackendOptions"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributed/rpc/rref_proxy.py",
        "functions": [
            "_local_invoke",
            "_invoke_rpc"
        ],
        "classes": [
            "RRefProxy"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributed/rpc/server_process_global_profiler.py",
        "functions": [],
        "classes": [
            "_server_process_global_profile"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributed/rpc/utils.py",
        "functions": [
            "_parse_remote_device"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/distributed/rpc/__init__.py",
        "functions": [
            "is_available"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/distributed/rpc/_testing/faulty_agent_backend_registry.py",
        "functions": [
            "_faulty_process_group_construct_rpc_backend_options_handler",
            "_faulty_process_group_init_backend_handler"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/distributed/rpc/_testing/__init__.py",
        "functions": [
            "is_available"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/distributions/log_normal.py",
        "functions": [],
        "classes": [
            "LogNormal"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/bernoulli.py",
        "functions": [],
        "classes": [
            "Bernoulli"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/beta.py",
        "functions": [],
        "classes": [
            "Beta"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/binomial.py",
        "functions": [
            "_clamp_by_zero"
        ],
        "classes": [
            "Binomial"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/categorical.py",
        "functions": [],
        "classes": [
            "Categorical"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/cauchy.py",
        "functions": [],
        "classes": [
            "Cauchy"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/chi2.py",
        "functions": [],
        "classes": [
            "Chi2"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/constraints.py",
        "functions": [
            "is_dependent"
        ],
        "classes": [
            "Constraint",
            "_Dependent",
            "_DependentProperty",
            "_IndependentConstraint",
            "_Boolean",
            "_OneHot",
            "_IntegerInterval",
            "_IntegerLessThan",
            "_IntegerGreaterThan",
            "_Real",
            "_GreaterThan",
            "_GreaterThanEq",
            "_LessThan",
            "_Interval",
            "_HalfOpenInterval",
            "_Simplex",
            "_Multinomial",
            "_LowerTriangular",
            "_LowerCholesky",
            "_CorrCholesky",
            "_PositiveDefinite",
            "_Cat",
            "_Stack"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/constraint_registry.py",
        "functions": [],
        "classes": [
            "ConstraintRegistry"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/continuous_bernoulli.py",
        "functions": [],
        "classes": [
            "ContinuousBernoulli"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/dirichlet.py",
        "functions": [
            "_Dirichlet_backward"
        ],
        "classes": [
            "_Dirichlet",
            "Dirichlet"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/distribution.py",
        "functions": [],
        "classes": [
            "Distribution"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/exponential.py",
        "functions": [],
        "classes": [
            "Exponential"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/exp_family.py",
        "functions": [],
        "classes": [
            "ExponentialFamily"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/fishersnedecor.py",
        "functions": [],
        "classes": [
            "FisherSnedecor"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/gamma.py",
        "functions": [
            "_standard_gamma"
        ],
        "classes": [
            "Gamma"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/geometric.py",
        "functions": [],
        "classes": [
            "Geometric"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/gumbel.py",
        "functions": [],
        "classes": [
            "Gumbel"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/half_cauchy.py",
        "functions": [],
        "classes": [
            "HalfCauchy"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/half_normal.py",
        "functions": [],
        "classes": [
            "HalfNormal"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/independent.py",
        "functions": [],
        "classes": [
            "Independent"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/kl.py",
        "functions": [
            "register_kl",
            "_dispatch_kl",
            "_infinite_like",
            "_x_log_x",
            "_batch_trace_XXT",
            "kl_divergence"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/distributions/kumaraswamy.py",
        "functions": [
            "_moments"
        ],
        "classes": [
            "Kumaraswamy"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/laplace.py",
        "functions": [],
        "classes": [
            "Laplace"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/lkj_cholesky.py",
        "functions": [],
        "classes": [
            "LKJCholesky"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/logistic_normal.py",
        "functions": [],
        "classes": [
            "LogisticNormal"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/lowrank_multivariate_normal.py",
        "functions": [
            "_batch_capacitance_tril",
            "_batch_lowrank_logdet",
            "_batch_lowrank_mahalanobis"
        ],
        "classes": [
            "LowRankMultivariateNormal"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/mixture_same_family.py",
        "functions": [],
        "classes": [
            "MixtureSameFamily"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/multinomial.py",
        "functions": [],
        "classes": [
            "Multinomial"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/multivariate_normal.py",
        "functions": [
            "_batch_mv",
            "_batch_mahalanobis",
            "_precision_to_scale_tril"
        ],
        "classes": [
            "MultivariateNormal"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/negative_binomial.py",
        "functions": [],
        "classes": [
            "NegativeBinomial"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/normal.py",
        "functions": [],
        "classes": [
            "Normal"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/one_hot_categorical.py",
        "functions": [],
        "classes": [
            "OneHotCategorical",
            "OneHotCategoricalStraightThrough"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/pareto.py",
        "functions": [],
        "classes": [
            "Pareto"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/poisson.py",
        "functions": [],
        "classes": [
            "Poisson"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/relaxed_bernoulli.py",
        "functions": [],
        "classes": [
            "LogitRelaxedBernoulli",
            "RelaxedBernoulli"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/relaxed_categorical.py",
        "functions": [],
        "classes": [
            "ExpRelaxedCategorical",
            "RelaxedOneHotCategorical"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/studentT.py",
        "functions": [],
        "classes": [
            "StudentT"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/transformed_distribution.py",
        "functions": [],
        "classes": [
            "TransformedDistribution"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/transforms.py",
        "functions": [
            "_clipped_sigmoid"
        ],
        "classes": [
            "Transform",
            "_InverseTransform",
            "ComposeTransform",
            "IndependentTransform",
            "ReshapeTransform",
            "ExpTransform",
            "PowerTransform",
            "SigmoidTransform",
            "TanhTransform",
            "AbsTransform",
            "AffineTransform",
            "CorrCholeskyTransform",
            "SoftmaxTransform",
            "StickBreakingTransform",
            "LowerCholeskyTransform",
            "CatTransform",
            "StackTransform"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/uniform.py",
        "functions": [],
        "classes": [
            "Uniform"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/utils.py",
        "functions": [
            "broadcast_all",
            "_standard_normal",
            "_sum_rightmost",
            "logits_to_probs",
            "clamp_probs",
            "probs_to_logits",
            "tril_matrix_to_vec",
            "vec_to_tril_matrix"
        ],
        "classes": [
            "lazy_property"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/von_mises.py",
        "functions": [
            "_eval_poly",
            "_log_modified_bessel_fn"
        ],
        "classes": [
            "VonMises"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/weibull.py",
        "functions": [],
        "classes": [
            "Weibull"
        ]
    },
    {
        "file_path": "../pytorch/torch/distributions/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/fft/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/for_onnx/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/fx/graph.py",
        "functions": [
            "_shadows_builtin_name",
            "_is_magic",
            "_snake_case",
            "get_qualified_name",
            "_find_module_of_method",
            "_format_args",
            "_format_target",
            "_type_repr"
        ],
        "classes": [
            "_InsertPoint",
            "_node_list",
            "Graph"
        ]
    },
    {
        "file_path": "../pytorch/torch/fx/graph_module.py",
        "functions": [
            "exec_with_source",
            "patched_getline",
            "_forward_from_src",
            "deserialize_graphmodule",
            "_copy_attr",
            "_assign_attr"
        ],
        "classes": [
            "GraphModule"
        ]
    },
    {
        "file_path": "../pytorch/torch/fx/immutable_collections.py",
        "functions": [
            "_no_mutation",
            "_create_immutable_container"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/fx/interpreter.py",
        "functions": [],
        "classes": [
            "Interpreter",
            "Transformer"
        ]
    },
    {
        "file_path": "../pytorch/torch/fx/node.py",
        "functions": [
            "map_arg",
            "map_aggregate"
        ],
        "classes": [
            "Node"
        ]
    },
    {
        "file_path": "../pytorch/torch/fx/proxy.py",
        "functions": [
            "_define_reflectable"
        ],
        "classes": [
            "TracerBase",
            "GraphAppendingTracer",
            "TraceError",
            "Proxy",
            "Attribute"
        ]
    },
    {
        "file_path": "../pytorch/torch/fx/subgraph_rewriter.py",
        "functions": [
            "replace_pattern"
        ],
        "classes": [
            "Match",
            "SubgraphMatcher"
        ]
    },
    {
        "file_path": "../pytorch/torch/fx/symbolic_trace.py",
        "functions": [
            "_patch_function",
            "_find_proxy",
            "_create_wrapped_func",
            "_create_wrapped_method",
            "_patch_wrapped_functions",
            "_autowrap_check",
            "wrap",
            "symbolic_trace"
        ],
        "classes": [
            "Tracer",
            "_PatchedFn",
            "_PatchedFnSetItem",
            "_PatchedFnDel",
            "_PatchedFnSetAttr",
            "_Patcher"
        ]
    },
    {
        "file_path": "../pytorch/torch/fx/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/fx/passes/shape_prop.py",
        "functions": [],
        "classes": [
            "ShapeProp"
        ]
    },
    {
        "file_path": "../pytorch/torch/fx/passes/split_module.py",
        "functions": [
            "split_module"
        ],
        "classes": [
            "Partition"
        ]
    },
    {
        "file_path": "../pytorch/torch/fx/passes/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/fx/_experimental/accelerator_partitioner.py",
        "functions": [
            "reset_partition_device",
            "combine_two_partitions",
            "set_parents_and_children",
            "reorganize_partitions",
            "get_bfs_level_partition",
            "get_node_to_partition_mapping",
            "get_device_to_partitions_mapping",
            "check_dependency"
        ],
        "classes": [
            "DAGNode",
            "DAG",
            "PartitionResult",
            "Partitioner"
        ]
    },
    {
        "file_path": "../pytorch/torch/fx/_experimental/const_fold.py",
        "functions": [
            "_make_tuple",
            "split_const_subgraphs"
        ],
        "classes": [
            "FoldedGraphModule"
        ]
    },
    {
        "file_path": "../pytorch/torch/fx/_experimental/fuser.py",
        "functions": [
            "_parent_name",
            "matches_module_pattern",
            "replace_node_module",
            "fuse"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/fx/_experimental/graph_manipulation.py",
        "functions": [
            "replace_target_nodes_with",
            "get_size_of_all_nodes",
            "get_size_of_node",
            "serialize_shape",
            "serialize_tensor_quantization",
            "serialize_weight",
            "serialize_leaf_module",
            "serialize_module"
        ],
        "classes": [
            "size_bytes"
        ]
    },
    {
        "file_path": "../pytorch/torch/fx/_experimental/merge_matmul.py",
        "functions": [
            "get_first_dim",
            "legalize_graph",
            "may_depend_on",
            "are_nodes_independent",
            "merge_matmul"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/fx/_experimental/param_fetch.py",
        "functions": [
            "default_matching",
            "extract_attrs_for_lowering",
            "lift_lowering_attrs_to_nodes"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/fx/_experimental/partitioner_utils.py",
        "functions": [
            "get_extra_size_of",
            "get_latency_of_one_partition",
            "get_partition_to_latency_mapping",
            "get_comm_latency_between",
            "get_latency_of_partitioned_graph"
        ],
        "classes": [
            "Partition",
            "Device",
            "NodeLatency",
            "PartitionLatency",
            "PartitionMode",
            "PartitionerConfig"
        ]
    },
    {
        "file_path": "../pytorch/torch/fx/_experimental/rewriter.py",
        "functions": [
            "_rewrite"
        ],
        "classes": [
            "AST_Rewriter",
            "RewritingTracer"
        ]
    },
    {
        "file_path": "../pytorch/torch/fx/_experimental/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/jit/annotations.py",
        "functions": [
            "get_signature",
            "is_function_or_method",
            "is_vararg",
            "get_param_names",
            "check_fn",
            "parse_type_line",
            "get_type_line",
            "split_type_line",
            "try_real_annotations",
            "get_enum_value_type",
            "try_ann_to_type",
            "ann_to_type"
        ],
        "classes": [
            "Module",
            "EvalEnv"
        ]
    },
    {
        "file_path": "../pytorch/torch/jit/cuda.py",
        "functions": [
            "get_current_device_index",
            "get_device_index",
            "stream",
            "Stream",
            "Event"
        ],
        "classes": [
            "device",
            "StreamContext"
        ]
    },
    {
        "file_path": "../pytorch/torch/jit/frontend.py",
        "functions": [
            "is_reserved_name",
            "build_withitems",
            "build_stmts",
            "get_class_properties",
            "get_jit_class_def",
            "normalize_source_lines",
            "get_jit_def",
            "build_class_def",
            "build_def",
            "build_param_list",
            "build_param",
            "get_default_args",
            "get_default_args_for_class",
            "find_before"
        ],
        "classes": [
            "FrontendError",
            "NotSupportedError",
            "UnsupportedNodeError",
            "FrontendTypeError",
            "Builder",
            "WithItemBuilder",
            "StmtBuilder",
            "ExprBuilder"
        ]
    },
    {
        "file_path": "../pytorch/torch/jit/quantized.py",
        "functions": [
            "apply_permutation",
            "quantize_rnn_cell_modules",
            "quantize_linear_modules",
            "quantize_rnn_modules"
        ],
        "classes": [
            "QuantizedLinear",
            "QuantizedLinearFP16",
            "QuantizedRNNCellBase",
            "QuantizedRNNCell",
            "QuantizedLSTMCell",
            "QuantizedGRUCell",
            "QuantizedRNNBase",
            "QuantizedLSTM",
            "QuantizedGRU"
        ]
    },
    {
        "file_path": "../pytorch/torch/jit/supported_ops.py",
        "functions": [
            "_hidden",
            "_emit_type",
            "_emit_arg",
            "_emit_args",
            "_emit_ret",
            "_emit_rets",
            "_emit_schema",
            "_get_tensor_ops",
            "_get_nn_functional_ops",
            "_get_builtins_helper",
            "_is_math_fn",
            "_get_torchscript_builtins",
            "_get_math_builtins",
            "_get_global_builtins",
            "_list_supported_ops"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/jit/unsupported_tensor_ops.py",
        "functions": [
            "execWrapper",
            "_gen_unsupported_methods_properties",
            "_list_unsupported_tensor_ops"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/jit/_async.py",
        "functions": [
            "fork",
            "wait"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/jit/_builtins.py",
        "functions": [
            "_gen_torch_functional_registered_ops",
            "_is_special_functional_bound_op",
            "_get_builtin_table",
            "_register_builtin",
            "_find_builtin"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/jit/_freeze.py",
        "functions": [
            "freeze",
            "optimize_frozen_module"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/jit/_fuser.py",
        "functions": [
            "_graph_for"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/jit/_logging.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/jit/_pickle.py",
        "functions": [
            "build_intlist",
            "build_tensorlist",
            "build_doublelist",
            "build_boollist",
            "build_tensor_from_id",
            "restore_type_tag"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/jit/_recursive.py",
        "functions": [
            "make_stub",
            "make_stub_from_method",
            "make_stubs_from_exported_methods",
            "_get_valid_constant",
            "infer_concrete_type_builder",
            "create_methods_and_properties_from_stubs",
            "create_hooks_from_stubs",
            "get_module_concrete_type",
            "create_script_module",
            "create_script_module_impl",
            "script_model_defines_attr",
            "add_python_attr_to_scripted_model",
            "get_overload_annotations",
            "get_overload_name_mapping",
            "_check_no_signature",
            "make_stubs_for_overloads",
            "check_module_initialized",
            "infer_methods_to_compile",
            "get_hook_stubs",
            "get_property_stubs",
            "interface_script",
            "try_compile_fn",
            "wrap_cpp_module",
            "compile_unbound_method",
            "lazy_bind"
        ],
        "classes": [
            "SourceContext",
            "ConcreteTypeStore"
        ]
    },
    {
        "file_path": "../pytorch/torch/jit/_script.py",
        "functions": [
            "_is_new_style_class",
            "_compile_and_register_class",
            "script_method",
            "call_prepare_scriptable_func_impl",
            "call_prepare_scriptable_func",
            "script",
            "_check_overload_defaults",
            "_compile_function_with_overload",
            "_get_overloads",
            "_check_directly_compile_overloaded",
            "interface",
            "_recursive_compile_class",
            "_unwrap_optional"
        ],
        "classes": [
            "OrderedDictWrapper",
            "OrderedModuleDict",
            "ScriptMeta",
            "_CachedForward",
            "ScriptWarning",
            "ConstMap"
        ]
    },
    {
        "file_path": "../pytorch/torch/jit/_serialization.py",
        "functions": [
            "save",
            "load",
            "validate_map_location"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/jit/_state.py",
        "functions": [
            "disable",
            "enable",
            "_add_script_class",
            "_get_script_class",
            "_try_get_jit_cached_overloads",
            "_set_jit_overload_cache",
            "_try_get_jit_cached_function",
            "_set_jit_function_cache"
        ],
        "classes": [
            "EnabledProxy"
        ]
    },
    {
        "file_path": "../pytorch/torch/jit/_trace.py",
        "functions": [
            "_create_interpreter_name_lookup_fn",
            "_unique_state_dict",
            "_clone_inputs",
            "verify",
            "_verify_equal",
            "indent",
            "make_tuple",
            "make_module",
            "wrap_check_inputs",
            "trace",
            "trace_module",
            "is_tracing",
            "_script_if_tracing",
            "_get_trace_graph"
        ],
        "classes": [
            "ONNXTracedModule",
            "TracingCheckError",
            "TracerWarning",
            "TracedModule",
            "TopLevelTracedModule"
        ]
    },
    {
        "file_path": "../pytorch/torch/jit/__init__.py",
        "functions": [
            "export_opnames",
            "annotate",
            "script_if_tracing",
            "isinstance"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/jit/mobile/__init__.py",
        "functions": [
            "_load_for_lite_interpreter",
            "_export_operator_list"
        ],
        "classes": [
            "LiteScriptModule"
        ]
    },
    {
        "file_path": "../pytorch/torch/lib/c10d/ProcessGroupGloo.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/lib/c10d/comm.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/lib/c10d/default_comm_hooks.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/lib/c10d/FileStore.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/lib/c10d/frontend.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/lib/c10d/GlooDeviceFactory.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/lib/c10d/HashStore.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/lib/c10d/NCCLUtils.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/lib/c10d/PrefixStore.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/lib/c10d/ProcessGroup.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/lib/c10d/ProcessGroupMPI.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/lib/c10d/ProcessGroupNCCL.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/lib/c10d/ProcessGroupRoundRobin.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/lib/c10d/reducer.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/lib/c10d/Store.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/lib/c10d/TCPStore.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/lib/c10d/Utils.cpp",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/lib/c10d/example/allreduce.cpp",
        "functions": [
            "main(int argc, char** argv)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/lib/c10d/test/FileStoreTest.cpp",
        "functions": [
            "testGetSet(std::string path, std::string prefix = \"\")",
            "stressTestStore(std::string path, std::string prefix = \"\")",
            "{\n  testGetSet(path_);\n}",
            "{\n  testGetSet(path_, \"testPrefix\");\n}",
            "{\n  stressTestStore(path_);\n}",
            "{\n  stressTestStore(path_, \"testPrefix\");\n}"
        ],
        "classes": [
            "FileStoreTest"
        ]
    },
    {
        "file_path": "../pytorch/torch/lib/c10d/test/HashStoreTest.cpp",
        "functions": [
            "testGetSet(std::string prefix = \"\")",
            "stressTestStore(std::string prefix = \"\")",
            "{\n  testGetSet();\n}",
            "{\n  testGetSet(\"testPrefix\");\n}",
            "{\n  stressTestStore();\n}",
            "{\n  stressTestStore(\"testPrefix\");\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/lib/c10d/test/ProcessGroupGlooAsyncTest.cpp",
        "functions": [
            "runAsyncAllreduceTest(\n    const std::string& path,\n    size_t numProcesses = 4,\n    size_t numTensors = 2)",
            "runAsyncBroadcastTest(\n    const std::string& path,\n    size_t numProcesses = 4,\n    size_t numTensors = 1)"
        ],
        "classes": [
            "AsyncTest",
            "AsyncInputIsOutputTest",
            "AsyncAllreduceTest",
            "AsyncBroadcastTest"
        ]
    },
    {
        "file_path": "../pytorch/torch/lib/c10d/test/ProcessGroupGlooTest.cpp",
        "functions": [
            "copyTensors(\n    const std::vector<std::vector<at::Tensor>>& inputs)",
            "testAllreduce(const std::string& path, const at::DeviceType b)",
            "testBroadcast(const std::string& path, const at::DeviceType b)",
            "testAlltoall(const std::string& path, const at::DeviceType b)",
            "testBarrier(const std::string& path)",
            "testWaitDelay(const std::string& path)",
            "testSend(const std::string& path)",
            "testRecv(const std::string& path)",
            "{\n  {\n    TemporaryFile file;\n    testAllreduce(file.path, at::DeviceType::CPU);\n  }\n}",
            "{\n  {\n    TemporaryFile file;\n    testBroadcast(file.path, at::DeviceType::CPU);\n  }\n}",
            "{\n  {\n    TemporaryFile file;\n    testAlltoall(file.path, at::DeviceType::CPU);\n  }\n}",
            "{\n  {\n    TemporaryFile file;\n    testBarrier(file.path);\n  }\n}",
            "{\n  {\n    TemporaryFile file;\n    testSend(file.path);\n  }\n}",
            "{\n  {\n    TemporaryFile file;\n    testRecv(file.path);\n  }\n}",
            "{\n  {\n    TemporaryFile file;\n    testWaitDelay(file.path);\n  }\n}"
        ],
        "classes": [
            "ProcessGroupGlooDelayed",
            "CollectiveTest"
        ]
    },
    {
        "file_path": "../pytorch/torch/lib/c10d/test/ProcessGroupMPITest.cpp",
        "functions": [
            "waitWork(\n    c10::intrusive_ptr<::c10d::ProcessGroupMPI> pg,\n    std::vector<c10::intrusive_ptr<c10d::ProcessGroup::Work>> works)",
            "testAllreduce(int iter = 1000)",
            "testBroadcast(int iter = 10000)",
            "testReduce(int iter = 10000)",
            "testAllgather(int iter = 10000)",
            "testGather(int iter = 10000)",
            "testScatter(int iter = 1)",
            "testSendRecv(bool recvAnysource, int iter = 10000)",
            "testBackendName()",
            "main(int argc, char** argv)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/lib/c10d/test/ProcessGroupNCCLErrorsTest.cpp",
        "functions": [
            "{\n  if (skipTest()) {\n    return;\n  }\n\n  ASSERT_TRUE(setenv(c10d::NCCL_BLOCKING_WAIT, \"1\", 1) == 0);\n  auto options = c10d::ProcessGroupNCCL::Options::create();\n  options->opTimeout = std::chrono::milliseconds(1000);\n  ProcessGroupNCCLSimulateErrors pg(\n      store_, 0, 1, options);\n\n  auto work = pg.allreduce(tensors_);\n  work->wait();\n  EXPECT_TRUE(work->isSuccess());\n  EXPECT_EQ(1, pg.getNCCLCommCacheSize());\n\n  // Now run all reduce with errors.\n  pg.simulate_error();\n  work = pg.allreduce(tensors_);\n  EXPECT_THROW(work->wait(), std::runtime_error);\n\n  // Verify the work item failed.\n  EXPECT_TRUE(work->isCompleted());\n  EXPECT_FALSE(work->isSuccess());\n  EXPECT_THROW(work->wait(), std::runtime_error);\n\n  // Communicators might be aborted here, further operations would fail.\n}",
            "{\n  if (skipTest()) {\n    return;\n  }\n\n  ASSERT_TRUE(setenv(c10d::NCCL_BLOCKING_WAIT, \"1\", 1) == 0);\n  auto options = c10d::ProcessGroupNCCL::Options::create();\n  options->opTimeout = std::chrono::milliseconds(3000);\n  ProcessGroupNCCLTimedOutErrors pg(\n      store_, 0, 1, options);\n\n  auto work = pg.allreduce(tensors_);\n  work->wait();\n  EXPECT_TRUE(work->isSuccess());\n  EXPECT_EQ(1, pg.getNCCLCommCacheSize());\n\n  // Now run all reduce with errors.\n  pg.set_timedout_error();\n  work = pg.allreduce(tensors_);\n  EXPECT_THROW(work->wait(), std::runtime_error);\n\n  // Communicators might be aborted here, further operations would fail.\n}",
            "{\n  if (skipTest()) {\n    return;\n  }\n\n  auto options = c10d::ProcessGroupNCCL::Options::create();\n  options->opTimeout = std::chrono::milliseconds(3000);\n  ProcessGroupNCCLSimulateErrors pg(\n      store_, 0, 1, options);\n\n  auto work = pg.allreduce(tensors_);\n  pg.barrier()->wait();\n  EXPECT_TRUE(work->isSuccess());\n  EXPECT_EQ(1, pg.getNCCLCommCacheSize());\n\n  // Now run all reduce with errors.\n  pg.simulate_error();\n  work = pg.allreduce(tensors_);\n\n  // Should not throw exceptions.\n  work->wait();\n  pg.barrier()->wait();\n\n  // Verify the work item failed.\n  EXPECT_TRUE(work->isCompleted());\n  EXPECT_FALSE(work->isSuccess());\n\n  // Communicators might be aborted here, further operations would fail.\n}"
        ],
        "classes": [
            "WorkNCCLSimulateErrors",
            "ProcessGroupNCCLSimulateErrors",
            "WorkNCCLTimedoutErrors",
            "ProcessGroupNCCLTimedOutErrors",
            "ProcessGroupNCCLErrorsTest"
        ]
    },
    {
        "file_path": "../pytorch/torch/lib/c10d/test/ProcessGroupNCCLTest.cpp",
        "functions": [
            "testAllreduce(const std::string& path, int rank, int size)",
            "testBroadcast(const std::string& path, int rank, int size)",
            "testReduce(const std::string& path, int rank, int size)",
            "testAllgather(const std::string& path, int rank, int size)",
            "testReduceScatter(const std::string& path, int rank, int size)",
            "{\n  if (skipTest()) {\n    return;\n  }\n  {\n    TemporaryFile file;\n    testAllreduce(file.path, rank_, size_);\n  }\n}",
            "{\n  if (skipTest()) {\n    return;\n  }\n  {\n    TemporaryFile file;\n    testBroadcast(file.path, rank_, size_);\n  }\n}",
            "{\n  if (skipTest()) {\n    return;\n  }\n  {\n    TemporaryFile file;\n    testReduce(file.path, rank_, size_);\n  }\n}",
            "{\n  if (skipTest()) {\n    return;\n  }\n  {\n    TemporaryFile file;\n    testAllgather(file.path, rank_, size_);\n  }\n}",
            "{\n  if (skipTest()) {\n    return;\n  }\n  {\n    TemporaryFile file;\n    testReduceScatter(file.path, rank_, size_);\n  }\n}",
            "{\n  if (skipTest()) {\n    return;\n  }\n  {\n    TemporaryFile file;\n    auto test = NCCLTestBase(file.path);\n    test.initialize(rank_, size_);\n    EXPECT_EQ(\n      test.getProcessGroup().getBackendName(), std::string(c10d::NCCL_BACKEND_NAME));\n  }\n}"
        ],
        "classes": [
            "NCCLTestBase",
            "NCCLTest",
            "AllreduceNCCLTest",
            "BroadcastNCCLTest",
            "ReduceNCCLTest",
            "AllgatherNCCLTest",
            "ProcessGroupNCCLTest"
        ]
    },
    {
        "file_path": "../pytorch/torch/lib/c10d/test/TCPStoreTest.cpp",
        "functions": [
            "testHelper(const std::string& prefix = \"\")",
            "{\n  testHelper();\n}",
            "{\n  testHelper(\"testPrefix\");\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/lib/libshm/core.cpp",
        "functions": [
            "get_alloc_info(const char* filename)",
            "start_manager()",
            "& get_manager_socket(const std::string& manager_handle)",
            "libshm_init(const char *manager_exec_path)",
            ": manager_handle_(manager_handle ? manager_handle : \"\")",
            ": THManagedMapAllocatorInit(manager_handle, filename), THRefcountedMapAllocator(filename, flags, size)",
            "THManagedMapAllocator::close()",
            "void",
            "THManagedMapAllocator::makeDataPtr(const char* manager_handle, const char* filename, int flags, ptrdiff_t size)",
            "* THManagedMapAllocator::fromDataPtr(const at::DataPtr& dptr)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/lib/libshm/manager.cpp",
        "functions": [
            "register_fd(int fd)",
            "unregister_fd(int fd)",
            "print_init_message(const char *message)",
            "object_exists(const char *name)",
            "free_used_object(const std::string &name)",
            "main(int argc, char *argv[])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/lib/libshm_windows/core.cpp",
        "functions": [
            "libshm_init(const char *manager_exec_path)",
            "void",
            "THManagedMapAllocator::makeDataPtr(const char* manager_handle, const char* filename, int flags, ptrdiff_t size)",
            "* THManagedMapAllocator::fromDataPtr(const at::DataPtr& dptr)"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/linalg/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/multiprocessing/pool.py",
        "functions": [
            "clean_worker"
        ],
        "classes": [
            "Pool"
        ]
    },
    {
        "file_path": "../pytorch/torch/multiprocessing/queue.py",
        "functions": [],
        "classes": [
            "ConnectionWrapper",
            "Queue",
            "SimpleQueue"
        ]
    },
    {
        "file_path": "../pytorch/torch/multiprocessing/reductions.py",
        "functions": [
            "rebuild_event",
            "reduce_event",
            "rebuild_tensor",
            "rebuild_cuda_tensor",
            "reduce_tensor",
            "fd_id",
            "storage_from_cache",
            "rebuild_storage_fd",
            "rebuild_storage_filename",
            "rebuild_storage_empty",
            "reduce_storage",
            "init_reductions"
        ],
        "classes": [
            "StorageWeakRef",
            "SharedCache"
        ]
    },
    {
        "file_path": "../pytorch/torch/multiprocessing/spawn.py",
        "functions": [
            "_wrap",
            "start_processes",
            "spawn"
        ],
        "classes": [
            "ProcessException",
            "ProcessRaisedException",
            "ProcessExitedException",
            "ProcessContext",
            "SpawnContext"
        ]
    },
    {
        "file_path": "../pytorch/torch/multiprocessing/_atfork.py",
        "functions": [
            "register_after_fork"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/multiprocessing/__init__.py",
        "functions": [
            "set_sharing_strategy",
            "get_sharing_strategy",
            "get_all_sharing_strategies"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/nn/common_types.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/nn/cpp.py",
        "functions": [],
        "classes": [
            "OrderedDictWrapper",
            "ModuleWrapper"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/functional.py",
        "functions": [
            "fractional_max_pool2d_with_indices",
            "_fractional_max_pool2d",
            "fractional_max_pool3d_with_indices",
            "_fractional_max_pool3d",
            "max_pool1d_with_indices",
            "_max_pool1d",
            "max_pool2d_with_indices",
            "_max_pool2d",
            "max_pool3d_with_indices",
            "_max_pool3d",
            "_unpool_output_size",
            "max_unpool1d",
            "max_unpool2d",
            "max_unpool3d",
            "lp_pool2d",
            "lp_pool1d",
            "adaptive_max_pool1d_with_indices",
            "_adaptive_max_pool1d",
            "adaptive_max_pool2d_with_indices",
            "_adaptive_max_pool2d",
            "adaptive_max_pool3d_with_indices",
            "_adaptive_max_pool3d",
            "adaptive_avg_pool2d",
            "adaptive_avg_pool3d",
            "dropout",
            "alpha_dropout",
            "dropout2d",
            "dropout3d",
            "feature_alpha_dropout",
            "_threshold",
            "relu",
            "glu",
            "hardtanh",
            "relu6",
            "elu",
            "selu",
            "celu",
            "leaky_relu",
            "prelu",
            "rrelu",
            "gelu",
            "hardshrink",
            "tanhshrink",
            "softsign",
            "_get_softmax_dim",
            "softmin",
            "softmax",
            "gumbel_softmax",
            "log_softmax",
            "tanh",
            "sigmoid",
            "hardsigmoid",
            "linear",
            "bilinear",
            "silu",
            "hardswish",
            "_no_grad_embedding_renorm_",
            "embedding",
            "embedding_bag",
            "_verify_batch_size",
            "batch_norm",
            "instance_norm",
            "layer_norm",
            "group_norm",
            "local_response_norm",
            "ctc_loss",
            "nll_loss",
            "poisson_nll_loss",
            "gaussian_nll_loss",
            "kl_div",
            "cross_entropy",
            "binary_cross_entropy",
            "binary_cross_entropy_with_logits",
            "smooth_l1_loss",
            "l1_loss",
            "mse_loss",
            "margin_ranking_loss",
            "hinge_embedding_loss",
            "multilabel_margin_loss",
            "soft_margin_loss",
            "multilabel_soft_margin_loss",
            "cosine_embedding_loss",
            "multi_margin_loss",
            "upsample",
            "interpolate",
            "upsample_nearest",
            "upsample_bilinear",
            "grid_sample",
            "affine_grid",
            "_pad",
            "pairwise_distance",
            "triplet_margin_loss",
            "triplet_margin_with_distance_loss",
            "normalize",
            "assert_int_or_pair",
            "unfold",
            "fold",
            "_pad_circular",
            "multi_head_attention_forward"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/nn/grad.py",
        "functions": [
            "_grad_input_padding",
            "conv1d_input",
            "conv1d_weight",
            "conv2d_input",
            "conv2d_weight",
            "conv3d_input",
            "conv3d_weight"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/nn/init.py",
        "functions": [
            "_no_grad_uniform_",
            "_no_grad_normal_",
            "_no_grad_trunc_normal_",
            "_no_grad_fill_",
            "_no_grad_zero_",
            "calculate_gain",
            "uniform_",
            "normal_",
            "trunc_normal_",
            "constant_",
            "ones_",
            "zeros_",
            "eye_",
            "dirac_",
            "_calculate_fan_in_and_fan_out",
            "xavier_uniform_",
            "xavier_normal_",
            "_calculate_correct_fan",
            "kaiming_uniform_",
            "kaiming_normal_",
            "orthogonal_",
            "sparse_",
            "_make_deprecate"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/nn/parameter.py",
        "functions": [],
        "classes": [
            "Parameter",
            "UninitializedParameter"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/_reduction.py",
        "functions": [
            "get_enum",
            "legacy_get_string",
            "legacy_get_enum"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/nn/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/nn/backends/thnn.py",
        "functions": [
            "_get_thnn_function_backend"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/nn/backends/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/nn/intrinsic/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/nn/intrinsic/modules/fused.py",
        "functions": [],
        "classes": [
            "_FusedModule",
            "ConvReLU1d",
            "ConvReLU2d",
            "ConvReLU3d",
            "LinearReLU",
            "ConvBn1d",
            "ConvBn2d",
            "ConvBnReLU1d",
            "ConvBnReLU2d",
            "ConvBn3d",
            "ConvBnReLU3d",
            "BNReLU2d",
            "BNReLU3d"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/intrinsic/modules/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/nn/intrinsic/qat/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/nn/intrinsic/qat/modules/conv_fused.py",
        "functions": [
            "update_bn_stats",
            "freeze_bn_stats"
        ],
        "classes": [
            "_ConvBnNd",
            "ConvBn1d",
            "ConvBnReLU1d",
            "ConvBn2d",
            "ConvBnReLU2d",
            "ConvReLU2d"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/intrinsic/qat/modules/linear_relu.py",
        "functions": [],
        "classes": [
            "LinearReLU"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/intrinsic/qat/modules/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/nn/intrinsic/quantized/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/nn/intrinsic/quantized/modules/bn_relu.py",
        "functions": [],
        "classes": [
            "BNReLU2d",
            "BNReLU3d"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/intrinsic/quantized/modules/conv_relu.py",
        "functions": [],
        "classes": [
            "ConvReLU1d",
            "ConvReLU2d",
            "ConvReLU3d"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/intrinsic/quantized/modules/linear_relu.py",
        "functions": [],
        "classes": [
            "LinearReLU"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/intrinsic/quantized/modules/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/nn/intrinsic/quantized/_reference/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/nn/intrinsic/quantized/_reference/modules/linear_relu.py",
        "functions": [],
        "classes": [
            "LinearReLU"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/intrinsic/quantized/_reference/modules/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/nn/modules/activation.py",
        "functions": [],
        "classes": [
            "Threshold",
            "ReLU",
            "RReLU",
            "Hardtanh",
            "ReLU6",
            "Sigmoid",
            "Hardsigmoid",
            "Tanh",
            "SiLU",
            "Hardswish",
            "ELU",
            "CELU",
            "SELU",
            "GLU",
            "GELU",
            "Hardshrink",
            "LeakyReLU",
            "LogSigmoid",
            "Softplus",
            "Softshrink",
            "MultiheadAttention",
            "PReLU",
            "Softsign",
            "Tanhshrink",
            "Softmin",
            "Softmax",
            "Softmax2d",
            "LogSoftmax"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/modules/adaptive.py",
        "functions": [],
        "classes": [
            "AdaptiveLogSoftmaxWithLoss"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/modules/batchnorm.py",
        "functions": [],
        "classes": [
            "_NormBase",
            "_BatchNorm",
            "BatchNorm1d",
            "BatchNorm2d",
            "BatchNorm3d",
            "SyncBatchNorm"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/modules/channelshuffle.py",
        "functions": [],
        "classes": [
            "ChannelShuffle"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/modules/container.py",
        "functions": [],
        "classes": [
            "Container",
            "Sequential",
            "ModuleList",
            "ModuleDict",
            "ParameterList",
            "ParameterDict"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/modules/conv.py",
        "functions": [],
        "classes": [
            "_ConvNd",
            "Conv1d",
            "onv2d(",
            "nv3d(_",
            "nvTransposeNd(_C",
            "vTranspose1d(_C",
            "Transpose2d(_Co",
            "ranspose3d(_Con",
            "ransposeMixin(_Conv",
            "onvXdMixin(LazyM",
            "nv1d(_Lazy",
            "nv2d(_Lazy",
            "nv3d(_Lazy",
            "nvTranspose1d(_Lazy",
            "nvTranspose2d(_Lazy",
            "nvTranspose3d(_Lazy"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/modules/distance.py",
        "functions": [],
        "classes": [
            "PairwiseDistance",
            "CosineSimilarity"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/modules/dropout.py",
        "functions": [],
        "classes": [
            "_DropoutNd",
            "Dropout",
            "Dropout2d",
            "Dropout3d",
            "AlphaDropout",
            "FeatureAlphaDropout"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/modules/flatten.py",
        "functions": [],
        "classes": [
            "Flatten",
            "Unflatten"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/modules/fold.py",
        "functions": [],
        "classes": [
            "Fold",
            "nfold("
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/modules/instancenorm.py",
        "functions": [],
        "classes": [
            "_InstanceNorm",
            "InstanceNorm1d",
            "InstanceNorm2d",
            "InstanceNorm3d"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/modules/lazy.py",
        "functions": [],
        "classes": [
            "_LazyProtocol",
            "LazyModuleMixin"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/modules/linear.py",
        "functions": [],
        "classes": [
            "Identity",
            "Linear",
            "_LinearWithBias",
            "Bilinear",
            "LazyLinear"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/modules/loss.py",
        "functions": [],
        "classes": [
            "_Loss",
            "_WeightedLoss",
            "L1Loss",
            "NLLLoss",
            "NLLLoss2d",
            "PoissonNLLLoss",
            "GaussianNLLLoss",
            "KLDivLoss",
            "MSELoss",
            "BCELoss",
            "BCEWithLogitsLoss",
            "HingeEmbeddingLoss",
            "MultiLabelMarginLoss",
            "SmoothL1Loss",
            "SoftMarginLoss",
            "CrossEntropyLoss",
            "MultiLabelSoftMarginLoss",
            "CosineEmbeddingLoss",
            "MarginRankingLoss",
            "MultiMarginLoss",
            "TripletMarginLoss",
            "TripletMarginWithDistanceLoss",
            "CTCLoss"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/modules/module.py",
        "functions": [
            "_addindent",
            "register_module_forward_pre_hook",
            "register_module_forward_hook",
            "register_module_backward_hook",
            "register_module_full_backward_hook",
            "_forward_unimplemented"
        ],
        "classes": [
            "_IncompatibleKeys",
            "Module"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/modules/normalization.py",
        "functions": [],
        "classes": [
            "LocalResponseNorm",
            "CrossMapLRN2d",
            "LayerNorm",
            "GroupNorm"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/modules/padding.py",
        "functions": [],
        "classes": [
            "_ConstantPadNd",
            "ConstantPad1d",
            "ConstantPad2d",
            "ConstantPad3d",
            "_ReflectionPadNd",
            "ReflectionPad1d",
            "ReflectionPad2d",
            "_ReplicationPadNd",
            "ReplicationPad1d",
            "ReplicationPad2d",
            "ReplicationPad3d",
            "ZeroPad2d"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/modules/pixelshuffle.py",
        "functions": [],
        "classes": [
            "PixelShuffle",
            "PixelUnshuffle"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/modules/pooling.py",
        "functions": [],
        "classes": [
            "_MaxPoolNd",
            "MaxPool1d",
            "MaxPool2d",
            "MaxPool3d",
            "_MaxUnpoolNd",
            "MaxUnpool1d",
            "MaxUnpool2d",
            "MaxUnpool3d",
            "_AvgPoolNd",
            "AvgPool1d",
            "AvgPool2d",
            "AvgPool3d",
            "FractionalMaxPool2d",
            "FractionalMaxPool3d",
            "_LPPoolNd",
            "LPPool1d",
            "LPPool2d",
            "_AdaptiveMaxPoolNd",
            "AdaptiveMaxPool1d",
            "AdaptiveMaxPool2d",
            "AdaptiveMaxPool3d",
            "_AdaptiveAvgPoolNd",
            "AdaptiveAvgPool1d",
            "AdaptiveAvgPool2d",
            "AdaptiveAvgPool3d"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/modules/rnn.py",
        "functions": [
            "apply_permutation"
        ],
        "classes": [
            "RNNBase",
            "RNN",
            "LSTM",
            "GRU",
            "RNNCellBase",
            "RNNCell",
            "LSTMCell",
            "GRUCell"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/modules/sparse.py",
        "functions": [],
        "classes": [
            "Embedding",
            "EmbeddingBag"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/modules/transformer.py",
        "functions": [
            "_get_clones",
            "_get_activation_fn"
        ],
        "classes": [
            "Transformer",
            "TransformerEncoder",
            "TransformerDecoder",
            "TransformerEncoderLayer",
            "TransformerDecoderLayer"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/modules/upsampling.py",
        "functions": [],
        "classes": [
            "Upsample",
            "UpsamplingNearest2d",
            "UpsamplingBilinear2d"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/modules/utils.py",
        "functions": [
            "_ntuple",
            "_reverse_repeat_tuple",
            "_list_with_default"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/nn/modules/_functions.py",
        "functions": [],
        "classes": [
            "SyncBatchNorm",
            "CrossMapLRN2d",
            "BackwardHookFunction"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/modules/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/nn/parallel/comm.py",
        "functions": [
            "broadcast",
            "broadcast_coalesced",
            "reduce_add",
            "reduce_add_coalesced",
            "scatter",
            "gather"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/nn/parallel/data_parallel.py",
        "functions": [
            "_check_balance",
            "data_parallel"
        ],
        "classes": [
            "DataParallel"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/parallel/distributed.py",
        "functions": [
            "_find_tensors",
            "_dump_DDP_relevant_env_vars"
        ],
        "classes": [
            "_DDPUnevenInputsConfig",
            "DistributedDataParallel"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/parallel/parallel_apply.py",
        "functions": [
            "get_a_var",
            "parallel_apply"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/nn/parallel/replicate.py",
        "functions": [
            "_is_script_module",
            "_is_script_method",
            "_init_script_module",
            "_is_jit_enabled",
            "_replicatable_module",
            "_broadcast_coalesced_reshape",
            "replicate"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/nn/parallel/scatter_gather.py",
        "functions": [
            "is_namedtuple",
            "scatter",
            "scatter_kwargs",
            "gather"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/nn/parallel/_functions.py",
        "functions": [
            "_get_stream"
        ],
        "classes": [
            "Broadcast",
            "ReduceAddCoalesced",
            "Gather",
            "Scatter"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/parallel/__init__.py",
        "functions": [
            "DistributedDataParallelCPU"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/nn/qat/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/nn/qat/modules/conv.py",
        "functions": [],
        "classes": [
            "Conv2d"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/qat/modules/linear.py",
        "functions": [],
        "classes": [
            "Linear"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/qat/modules/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/nn/quantizable/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/nn/quantizable/modules/rnn.py",
        "functions": [],
        "classes": [
            "LSTMCell",
            "_LSTMSingleLayer",
            "_LSTMLayer",
            "LSTM"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/quantizable/modules/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/nn/quantized/functional.py",
        "functions": [
            "avg_pool2d",
            "avg_pool3d",
            "adaptive_avg_pool2d",
            "adaptive_avg_pool3d",
            "conv1d",
            "conv2d",
            "conv3d",
            "interpolate",
            "linear",
            "max_pool1d",
            "max_pool2d",
            "celu",
            "leaky_relu",
            "hardtanh",
            "hardswish",
            "threshold",
            "elu",
            "hardsigmoid",
            "clamp",
            "upsample",
            "upsample_bilinear",
            "upsample_nearest"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/nn/quantized/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/nn/quantized/dynamic/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/nn/quantized/dynamic/modules/linear.py",
        "functions": [],
        "classes": [
            "Linear"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/quantized/dynamic/modules/rnn.py",
        "functions": [
            "apply_permutation"
        ],
        "classes": [
            "PackedParameter",
            "RNNBase",
            "LSTM",
            "GRU",
            "RNNCellBase",
            "RNNCell",
            "LSTMCell",
            "GRUCell"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/quantized/dynamic/modules/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/nn/quantized/modules/activation.py",
        "functions": [],
        "classes": [
            "ReLU6",
            "Hardswish",
            "ELU",
            "LeakyReLU",
            "Sigmoid"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/quantized/modules/batchnorm.py",
        "functions": [],
        "classes": [
            "BatchNorm2d",
            "BatchNorm3d"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/quantized/modules/conv.py",
        "functions": [
            "_reverse_repeat_padding"
        ],
        "classes": [
            "_ConvNd",
            "Conv1d",
            "Conv2d",
            "Conv3d",
            "_ConvTransposeNd",
            "ConvTranspose1d",
            "ConvTranspose2d",
            "ConvTranspose3d"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/quantized/modules/embedding_ops.py",
        "functions": [],
        "classes": [
            "EmbeddingPackedParams",
            "Embedding",
            "EmbeddingBag"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/quantized/modules/functional_modules.py",
        "functions": [],
        "classes": [
            "FloatFunctional",
            "FXFloatFunctional",
            "QFunctional"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/quantized/modules/linear.py",
        "functions": [],
        "classes": [
            "LinearPackedParams",
            "Linear"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/quantized/modules/normalization.py",
        "functions": [],
        "classes": [
            "LayerNorm",
            "GroupNorm",
            "InstanceNorm1d",
            "InstanceNorm2d",
            "InstanceNorm3d"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/quantized/modules/utils.py",
        "functions": [
            "_quantize_weight",
            "_ntuple_from_first",
            "hide_packed_params_repr"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/nn/quantized/modules/__init__.py",
        "functions": [],
        "classes": [
            "Quantize",
            "DeQuantize"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/quantized/_reference/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/nn/quantized/_reference/modules/linear.py",
        "functions": [],
        "classes": [
            "Linear"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/quantized/_reference/modules/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/nn/utils/clip_grad.py",
        "functions": [
            "clip_grad_norm_",
            "clip_grad_norm",
            "clip_grad_value_"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/nn/utils/convert_parameters.py",
        "functions": [
            "parameters_to_vector",
            "vector_to_parameters",
            "_check_param_device"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/nn/utils/fusion.py",
        "functions": [
            "fuse_conv_bn_eval",
            "fuse_conv_bn_weights",
            "fuse_linear_bn_eval",
            "fuse_linear_bn_weights"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/nn/utils/memory_format.py",
        "functions": [
            "convert_conv2d_weight_memory_format"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/nn/utils/prune.py",
        "functions": [
            "identity",
            "random_unstructured",
            "l1_unstructured",
            "random_structured",
            "ln_structured",
            "global_unstructured",
            "custom_from_mask",
            "remove",
            "is_pruned",
            "_validate_pruning_amount_init",
            "_validate_pruning_amount",
            "_validate_structured_pruning",
            "_compute_nparams_toprune",
            "_validate_pruning_dim",
            "_compute_norm"
        ],
        "classes": [
            "BasePruningMethod",
            "PruningContainer",
            "Identity",
            "RandomUnstructured",
            "L1Unstructured",
            "RandomStructured",
            "LnStructured",
            "CustomFromMask"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/utils/rnn.py",
        "functions": [
            "bind",
            "_packed_sequence_init_args",
            "_packed_sequence_init",
            "invert_permutation",
            "pack_padded_sequence",
            "pad_packed_sequence",
            "pad_sequence",
            "pack_sequence"
        ],
        "classes": [
            "PackedSequence"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/utils/spectral_norm.py",
        "functions": [
            "spectral_norm",
            "remove_spectral_norm"
        ],
        "classes": [
            "SpectralNorm",
            "SpectralNormLoadStateDictPreHook",
            "SpectralNormStateDictHook"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/utils/weight_norm.py",
        "functions": [
            "weight_norm",
            "remove_weight_norm"
        ],
        "classes": [
            "WeightNorm"
        ]
    },
    {
        "file_path": "../pytorch/torch/nn/utils/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/onnx/operators.py",
        "functions": [
            "shape_as_tensor",
            "reshape_from_tensor_shape"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/onnx/symbolic_caffe2.py",
        "functions": [
            "register_quantized_ops",
            "_permute_helper",
            "nchw2nhwc",
            "nhwc2nchw",
            "linear_prepack",
            "conv_prepack",
            "upsample_nearest2d",
            "reshape",
            "cat"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/onnx/symbolic_helper.py",
        "functions": [
            "_parse_arg",
            "_maybe_get_const",
            "_maybe_get_scalar",
            "_get_const",
            "_unpack_list",
            "_is_packed_list",
            "parse_args",
            "_scalar",
            "_if_scalar_type_as",
            "_is_none",
            "_is_value",
            "_is_tensor",
            "_is_tensor_list",
            "_get_tensor_rank",
            "_get_tensor_sizes",
            "_get_tensor_dim_size",
            "_unimplemented",
            "_onnx_unsupported",
            "_onnx_opset_unsupported",
            "_onnx_opset_unsupported_detailed",
            "_block_list_in_opset",
            "_try_get_scalar_type",
            "_select_helper",
            "_slice_helper",
            "_hardtanh_helper",
            "_is_fp",
            "_generate_wrapped_number",
            "_sort_helper",
            "_topk_helper",
            "_interpolate_warning",
            "_unsqueeze_helper",
            "_squeeze_helper",
            "_reducesum_helper",
            "_interpolate_size_to_scales",
            "_interpolate_get_scales_if_available",
            "_get_interpolate_attributes",
            "_interpolate_get_scales",
            "_interpolate_get_scales_and_mode",
            "_interpolate_helper",
            "__interpolate_helper",
            "_unbind_helper",
            "_scatter_helper",
            "_arange_cast_helper",
            "_size_helper",
            "_index_fill_reshape_helper",
            "_avgpool_helper",
            "assert_training_mode",
            "_flatten_helper",
            "_is_split_static",
            "_optional_input_placeholder_tensor",
            "_set_opset_version",
            "_set_operator_export_type",
            "_set_training_mode",
            "_set_onnx_shape_inference",
            "_cast_func_template"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/onnx/symbolic_opset10.py",
        "functions": [
            "_max_pool",
            "_avg_pool",
            "_interpolate",
            "__interpolate",
            "_slice",
            "slice",
            "fmod",
            "isinf"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/onnx/symbolic_opset11.py",
        "functions": [
            "clamp",
            "clamp_min",
            "clamp_max",
            "index_put",
            "_interpolate",
            "__interpolate",
            "masked_select",
            "masked_scatter",
            "_len",
            "__getitem_",
            "append",
            "add",
            "insert",
            "pop",
            "Delete",
            "cat",
            "stack",
            "_avg_pool",
            "round",
            "_prepare_onnx_paddings",
            "constant_pad_nd",
            "reflection_pad",
            "replication_pad",
            "det",
            "logdet",
            "arange",
            "size",
            "squeeze",
            "mm",
            "index",
            "index_fill",
            "index_copy",
            "__rshift_",
            "__lshift_",
            "_get_im2col_indices_along_dim",
            "_get_im2col_padded_input",
            "_get_im2col_output_shape",
            "narrow",
            "prim_ConstantChunk"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/onnx/symbolic_opset12.py",
        "functions": [
            "nll_loss",
            "nll_loss2d",
            "celu",
            "argmax",
            "argmin",
            "pow",
            "ge",
            "le"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/onnx/symbolic_opset13.py",
        "functions": [
            "split_with_sizes",
            "unsafe_split",
            "unsafe_split_with_sizes",
            "nonzero_numpy",
            "_reduce_op_symbolic",
            "_reduce_with_dtype"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/onnx/symbolic_opset7.py",
        "functions": [
            "max",
            "min"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/onnx/symbolic_opset8.py",
        "functions": [
            "_interpolate",
            "__interpolate",
            "_try_cast_integer_to_float",
            "_cast_to_type",
            "_comparison_operator",
            "gt",
            "lt",
            "bmm",
            "matmul",
            "prelu",
            "mm",
            "flatten",
            "_constant_fill",
            "full",
            "repeat"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/onnx/symbolic_opset9.py",
        "functions": [
            "unused",
            "_shape_as_tensor",
            "_reshape_from_tensor",
            "reshape",
            "reshape_as",
            "add",
            "sub",
            "rsub",
            "mul",
            "div",
            "floor_divide",
            "floordiv",
            "true_divide",
            "reciprocal",
            "_list",
            "mm",
            "bmm",
            "matmul",
            "neg",
            "sqrt",
            "rsqrt",
            "tanh",
            "sin",
            "cos",
            "tan",
            "asin",
            "acos",
            "atan",
            "sigmoid",
            "sign",
            "_slice",
            "_maybe_cast_reduce_op_input",
            "_reduce_op_symbolic",
            "overload_by_arg_count",
            "_reduce_with_dtype",
            "_sample_dirichlet",
            "_standard_gamma",
            "t",
            "expand",
            "expand_as",
            "size",
            "view",
            "view_as",
            "prim_ConstantSplit",
            "prim_ConstantChunk",
            "unsafe_split",
            "unsafe_split_with_sizes",
            "square",
            "squeeze",
            "prelu",
            "silu",
            "relu",
            "ceil",
            "floor",
            "_len",
            "leaky_relu",
            "get_pool_ceil_padding",
            "_max_pool",
            "_avg_pool",
            "_adaptive_pool",
            "_prepare_onnx_paddings",
            "_convert_padding_node",
            "constant_pad_nd",
            "reflection_pad",
            "replication_pad",
            "_interpolate",
            "__interpolate",
            "wrap_logical_op_with_cast_to",
            "wrap_logical_op_with_cast_to_and_from",
            "wrap_logical_op_with_negation",
            "eq",
            "gt",
            "gt_impl",
            "lt",
            "lt_impl",
            "__rshift_",
            "__lshift_",
            "selu",
            "index_put",
            "index_fill",
            "index_copy",
            "type_as",
            "clone",
            "abs",
            "log",
            "log1p",
            "pow",
            "clamp",
            "max",
            "min",
            "exp",
            "_unsupported_dropout",
            "new_empty",
            "scalar_tensor",
            "tensor",
            "new_zeros",
            "full",
            "full_like",
            "new_full",
            "eye",
            "slice",
            "alias",
            "numel",
            "to",
            "repeat",
            "_generic_rnn",
            "lstm",
            "_one_hidden_rnn",
            "detach",
            "randn",
            "rand",
            "randn_like",
            "rand_like",
            "nonzero_numpy",
            "_any",
            "_all",
            "argmax",
            "argmin",
            "log2",
            "prim_shape",
            "prim_max",
            "prim_data",
            "is_floating_point",
            "__isnot_",
            "prim_unchecked_cast",
            "prim_dtype",
            "prim_tolist",
            "std",
            "var",
            "var_mean",
            "std_mean",
            "arange",
            "masked_fill",
            "index",
            "baddbmm",
            "meshgrid",
            "remainder",
            "gelu",
            "dim",
            "__getitem_",
            "take",
            "_kl_div_log_target_impl",
            "_kl_div_non_log_target_impl",
            "__derive_index",
            "__range_length"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/onnx/symbolic_registry.py",
        "functions": [
            "register_version",
            "register_ops_helper",
            "register_ops_in_version",
            "get_ops_in_version",
            "is_registered_version",
            "register_op",
            "is_registered_op",
            "get_op_supported_version",
            "get_registered_op"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/onnx/utils.py",
        "functions": [
            "is_in_onnx_export",
            "export",
            "_is_constant_tensor_list",
            "_split_tensor_list_constants",
            "_optimize_graph",
            "warn_on_static_input_change",
            "_resolve_args_by_export_type",
            "_decide_keep_init_as_input",
            "_decide_add_node_names",
            "_decide_constant_folding",
            "_decide_external_data_format",
            "_decide_input_format",
            "_trace",
            "_trace_and_get_graph_from_model",
            "_create_jit_graph",
            "_get_named_param_dict",
            "_model_to_graph",
            "export_to_pretty_string",
            "_export_to_pretty_string",
            "_find_missing_ops_onnx_export",
            "_export",
            "_set_input_and_output_names",
            "_run_symbolic_method",
            "_is_onnx_list",
            "_add_attribute",
            "_scalar",
            "_newNode",
            "_graph_op",
            "_block_op",
            "_add_block",
            "_add_input_to_block",
            "_add_output_to_block",
            "_find_symbolic_in_registry",
            "_run_symbolic_function",
            "_graph_at",
            "_graph_constant",
            "_node_getitem",
            "register_custom_op_symbolic",
            "_validate_dynamic_axes"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/onnx/__init__.py",
        "functions": [
            "_export",
            "export",
            ":\n    from torch.onnx i",
            "):\n    from torch.onnx i",
            "ype):\n    from ",
            "):\n    r\"\"\"\n    A context ma",
            "\n    from torch.onnx i",
            "   from torch.onnx i",
            "whether it's in t",
            "e, symbolic_fn, opset_versi"
        ],
        "classes": [
            "ExportTypes"
        ]
    },
    {
        "file_path": "../pytorch/torch/optim/adadelta.py",
        "functions": [],
        "classes": [
            "Adadelta"
        ]
    },
    {
        "file_path": "../pytorch/torch/optim/adagrad.py",
        "functions": [],
        "classes": [
            "Adagrad"
        ]
    },
    {
        "file_path": "../pytorch/torch/optim/adam.py",
        "functions": [],
        "classes": [
            "Adam"
        ]
    },
    {
        "file_path": "../pytorch/torch/optim/adamax.py",
        "functions": [],
        "classes": [
            "Adamax"
        ]
    },
    {
        "file_path": "../pytorch/torch/optim/adamw.py",
        "functions": [],
        "classes": [
            "AdamW"
        ]
    },
    {
        "file_path": "../pytorch/torch/optim/asgd.py",
        "functions": [],
        "classes": [
            "ASGD"
        ]
    },
    {
        "file_path": "../pytorch/torch/optim/lbfgs.py",
        "functions": [
            "_cubic_interpolate",
            "_strong_wolfe"
        ],
        "classes": [
            "LBFGS"
        ]
    },
    {
        "file_path": "../pytorch/torch/optim/lr_scheduler.py",
        "functions": [],
        "classes": [
            "_LRScheduler",
            "LambdaLR",
            "MultiplicativeLR",
            "StepLR",
            "MultiStepLR",
            "ExponentialLR",
            "CosineAnnealingLR",
            "ReduceLROnPlateau",
            "CyclicLR",
            "CosineAnnealingWarmRestarts",
            "OneCycleLR"
        ]
    },
    {
        "file_path": "../pytorch/torch/optim/optimizer.py",
        "functions": [],
        "classes": [
            "_RequiredParameter",
            "Optimizer"
        ]
    },
    {
        "file_path": "../pytorch/torch/optim/rmsprop.py",
        "functions": [],
        "classes": [
            "RMSprop"
        ]
    },
    {
        "file_path": "../pytorch/torch/optim/rprop.py",
        "functions": [],
        "classes": [
            "Rprop"
        ]
    },
    {
        "file_path": "../pytorch/torch/optim/sgd.py",
        "functions": [],
        "classes": [
            "SGD"
        ]
    },
    {
        "file_path": "../pytorch/torch/optim/sparse_adam.py",
        "functions": [],
        "classes": [
            "SparseAdam"
        ]
    },
    {
        "file_path": "../pytorch/torch/optim/swa_utils.py",
        "functions": [
            "update_bn"
        ],
        "classes": [
            "AveragedModel",
            "SWALR"
        ]
    },
    {
        "file_path": "../pytorch/torch/optim/_functional.py",
        "functions": [
            "_make_sparse",
            "adagrad",
            "adam",
            "adamw",
            "sgd",
            "adadelta",
            "rmsprop"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/optim/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/optim/_multi_tensor/adadelta.py",
        "functions": [],
        "classes": [
            "Adadelta"
        ]
    },
    {
        "file_path": "../pytorch/torch/optim/_multi_tensor/adam.py",
        "functions": [],
        "classes": [
            "Adam"
        ]
    },
    {
        "file_path": "../pytorch/torch/optim/_multi_tensor/adamax.py",
        "functions": [],
        "classes": [
            "Adamax"
        ]
    },
    {
        "file_path": "../pytorch/torch/optim/_multi_tensor/adamw.py",
        "functions": [],
        "classes": [
            "AdamW"
        ]
    },
    {
        "file_path": "../pytorch/torch/optim/_multi_tensor/asgd.py",
        "functions": [],
        "classes": [
            "ASGD"
        ]
    },
    {
        "file_path": "../pytorch/torch/optim/_multi_tensor/rmsprop.py",
        "functions": [],
        "classes": [
            "RMSprop"
        ]
    },
    {
        "file_path": "../pytorch/torch/optim/_multi_tensor/rprop.py",
        "functions": [],
        "classes": [
            "Rprop"
        ]
    },
    {
        "file_path": "../pytorch/torch/optim/_multi_tensor/sgd.py",
        "functions": [],
        "classes": [
            "SGD"
        ]
    },
    {
        "file_path": "../pytorch/torch/optim/_multi_tensor/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/package/exporter.py",
        "functions": [
            "_is_builtin_or_stdlib_module",
            "_read_file"
        ],
        "classes": [
            "PackageExporter",
            "_GlobGroup"
        ]
    },
    {
        "file_path": "../pytorch/torch/package/find_file_dependencies.py",
        "functions": [],
        "classes": [
            "_ExtractModuleReferences"
        ]
    },
    {
        "file_path": "../pytorch/torch/package/importer.py",
        "functions": [
            "patched_getfile"
        ],
        "classes": [
            "PackageImporter",
            "_UnpicklerWrapper",
            "_PathNode",
            "_PackageNode",
            "_ModuleNode",
            "_ExternNode"
        ]
    },
    {
        "file_path": "../pytorch/torch/package/_custom_import_pickler.py",
        "functions": [
            "import_module_from_importers",
            "create_custom_import_pickler"
        ],
        "classes": [
            "CustomImportPickler"
        ]
    },
    {
        "file_path": "../pytorch/torch/package/_importlib.py",
        "functions": [
            "_normalize_line_endings",
            "_resolve_name",
            "_sanity_check",
            "_calc___package__",
            "_normalize_path"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/package/_mangling.py",
        "functions": [
            "is_mangled",
            "demangle",
            "get_mangle_prefix"
        ],
        "classes": [
            "PackageMangler"
        ]
    },
    {
        "file_path": "../pytorch/torch/package/_mock.py",
        "functions": [
            "install_method"
        ],
        "classes": [
            "MockedObject"
        ]
    },
    {
        "file_path": "../pytorch/torch/package/_mock_zipreader.py",
        "functions": [],
        "classes": [
            "_HasStorage",
            "MockZipReader"
        ]
    },
    {
        "file_path": "../pytorch/torch/package/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/profiler/profiler.py",
        "functions": [
            "schedule",
            "_default_schedule_fn",
            "tensorboard_trace_handler"
        ],
        "classes": [
            "ProfilerAction",
            "profile"
        ]
    },
    {
        "file_path": "../pytorch/torch/profiler/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/sparse/__init__.py",
        "functions": [
            "addmm",
            "mm",
            "sum",
            "softmax",
            "log_softmax"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/testing/check_kernel_launches.py",
        "functions": [
            "check_code_for_cuda_kernel_launches",
            "check_file",
            "check_cuda_kernel_launches"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/testing/__init__.py",
        "functions": [
            "is_integral",
            "is_quantized",
            "_unravel_index",
            "_compare_tensors_internal",
            "_compare_scalars_internal",
            "assert_allclose",
            "make_non_contiguous",
            "_validate_dtypes",
            "floating_types",
            "floating_types_and_half",
            "floating_types_and",
            "floating_and_complex_types",
            "floating_and_complex_types_and",
            "integral_types",
            "integral_types_and",
            "all_types",
            "all_types_and",
            "complex_types",
            "all_types_and_complex",
            "all_types_and_complex_and",
            "all_types_and_half",
            "get_all_dtypes",
            "get_all_math_dtypes",
            "get_all_complex_dtypes",
            "get_all_int_dtypes",
            "get_all_fp_dtypes",
            "get_all_device_types",
            "_get_default_tolerance"
        ],
        "classes": [
            "_dispatch_dtypes"
        ]
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/autocast_test_lists.py",
        "functions": [],
        "classes": [
            "AutocastTestLists"
        ]
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/common_cuda.py",
        "functions": [
            "initialize_cuda_context_rng",
            "tf32_is_not_fp32",
            "tf32_on_and_off",
            "with_tf32_off",
            "_get_torch_cuda_version"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/common_device_type.py",
        "functions": [
            "_construct_test_name",
            "get_device_type_test_bases",
            "instantiate_device_type_tests",
            "_has_sufficient_memory",
            "largeTensorTest",
            "onlyOnCPUAndCUDA",
            "onlyCPU",
            "onlyCUDA",
            "expectedFailureCUDA",
            "skipCPUIfNoLapack",
            "skipCPUIfNoMkl",
            "skipCUDAIfNoMagma",
            "skipCUDAIfNoMagmaAndNoCusolver",
            "skipCUDAIfRocm",
            "skipCUDAIfNotRocm",
            "skipCUDAIfCudnnVersionLessThan",
            "skipCUDAIfNoCudnn"
        ],
        "classes": [
            "DeviceTypeTestBase",
            "CPUTestBase",
            "CUDATestBase",
            "OpDTypes",
            "ops",
            "skipIf",
            "skipCPUIf",
            "skipCUDAIf",
            "expectedFailure",
            "onlyOn",
            "deviceCountAtLeast",
            "precisionOverride",
            "dtypes",
            "dtypesIfCPU",
            "dtypesIfCUDA",
            "expectedAlertNondeterministic"
        ]
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/common_distributed.py",
        "functions": [
            "skip_if_no_gpu",
            "skip_if_small_worldsize",
            "skip_if_not_multigpu",
            "require_n_gpus_for_nccl_backend",
            "skip_if_lt_x_gpu",
            "requires_gloo",
            "requires_nccl_version",
            "requires_nccl",
            "requires_mpi",
            "skip_if_rocm_single_process",
            "skip_if_rocm",
            "skip_if_win32",
            "create_device",
            "get_timeout",
            "simple_sparse_reduce_tests",
            "initialize_temp_directories",
            "cleanup_temp_dir"
        ],
        "classes": [
            "TestSkip",
            "MultiProcessTestCase"
        ]
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/common_jit.py",
        "functions": [
            "check_output_types",
            "check_against_reference"
        ],
        "classes": [
            "JitCommonTestCase"
        ]
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/common_methods_invocations.py",
        "functions": [
            "_getattr_qual",
            "sample_inputs_unary",
            "sample_inputs_tensor_split",
            "sample_inputs_linalg_norm",
            "sample_inputs_slogdet",
            "sample_inputs_addmm",
            "sample_inputs_addr",
            "sample_inputs_xlogy",
            "sample_inputs_trace",
            "sample_inputs_linalg_inv",
            "np_sinc_with_fp16_as_fp32",
            "sample_inputs_broadcast_to",
            "sample_inputs_div",
            "sample_inputs_stack",
            "sample_inputs_hstack_dstack_vstack",
            "sample_inputs_gather",
            "sample_inputs_diff",
            "sample_inputs_index_select",
            "sample_inputs_index_fill",
            "sample_movedim_moveaxis",
            "sample_repeat_tile",
            "np_unary_ufunc_integer_promotion_wrapper",
            "sample_inputs_linalg_pinv",
            "sample_inputs_linalg_pinv_hermitian",
            "sample_inputs_linalg_solve",
            "sample_inputs_legacy_solve",
            "sample_inputs_std_var",
            "_sample_inputs_svd",
            "sample_inputs_svd",
            "sample_inputs_linalg_svd",
            "sample_inputs_pinverse",
            "sample_inputs_flip",
            "sample_inputs_fliplr_flipud",
            "sample_inputs_diag",
            "sample_inputs_logit",
            "sample_inputs_masked_scatter",
            "sample_inputs_masked_select",
            "index_variable",
            "index_perm_variable",
            "gather_variable",
            "bernoulli_scalar",
            "mask_not_all_zeros",
            "uniform_scalar",
            "normal_scalar_clamp",
            "prod_zeros",
            "ident",
            "method_tests",
            "create_input",
            "_compare_trilu_indices",
            "_compare_large_trilu_indices",
            "run_additional_tri_tests",
            "unpack_variables",
            "exclude_tensor_method"
        ],
        "classes": [
            "DecorateInfo",
            "SkipInfo",
            "SampleInput",
            "AliasInfo",
            "OpInfo",
            "UnaryUfuncInfo",
            "SpectralFuncInfo",
            "ShapeFuncInfo",
            "HermitianOpInfo",
            "TriangularOpInfo",
            "dont_convert",
            "NoArgsClass"
        ]
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/common_nn.py",
        "functions": [
            "get_reduction",
            "get_weight",
            "_rand_tensor_non_equal",
            "wrap_functional",
            "poissonnllloss_no_reduce_test",
            "bceloss_no_reduce_test",
            "bceloss_no_reduce_scalar_test",
            "bceloss_weights_no_reduce_test",
            "bceloss_weights_no_reduce_scalar_test",
            "bce_with_logistic_legacy_enum_test",
            "bce_with_logistic_no_reduce_test",
            "bce_with_logistic_no_reduce_scalar_test",
            "kldivloss_with_target_no_reduce_test",
            "kldivloss_no_reduce_test",
            "kldivloss_no_reduce_scalar_test",
            "kldivloss_with_log_target_no_reduce_test",
            "kldivloss_no_reduce_log_target_test",
            "kldivloss_no_reduce_scalar_log_target_test",
            "l1loss_no_reduce_test",
            "l1loss_no_reduce_complex_test",
            "l1loss_no_reduce_scalar_test",
            "mseloss_no_reduce_test",
            "mseloss_no_reduce_scalar_test",
            "nllloss_no_reduce_test",
            "nllloss_no_reduce_ignore_index_test",
            "nllloss_no_reduce_weights_test",
            "nllloss_no_reduce_weights_ignore_index_test",
            "nllloss_no_reduce_weights_ignore_index_neg_test",
            "nllloss2d_no_reduce_test",
            "nllloss2d_no_reduce_ignore_index_test",
            "nllloss2d_no_reduce_weights_test",
            "nlllossNd_no_reduce_test",
            "nlllossNd_no_reduce_ignore_index_test",
            "nlllossNd_no_reduce_weights_test",
            "smoothl1loss_no_reduce_test",
            "smoothl1loss_no_reduce_scalar_test",
            "smoothl1loss_beta_test",
            "smoothl1loss_zero_beta_test",
            "multilabelmarginloss_0d_no_reduce_test",
            "multilabelmarginloss_1d_no_reduce_test",
            "multilabelmarginloss_index_neg_test",
            "multilabelmarginloss_no_reduce_test",
            "hingeembeddingloss_no_reduce_test",
            "hingeembeddingloss_margin_no_reduce_test",
            "softmarginloss_no_reduce_test",
            "multilabelsoftmarginloss_no_reduce_test",
            "multilabelsoftmarginloss_weights_no_reduce_test",
            "multimarginloss_no_reduce_test",
            "multimarginloss_1d_no_reduce_test",
            "multimarginloss_1d_input_0d_target_no_reduce_test",
            "multimarginloss_p_no_reduce_test",
            "multimarginloss_margin_no_reduce_test",
            "multimarginloss_weights_no_reduce_test",
            "fractional_max_pool2d_test",
            "fractional_max_pool3d_test",
            "kldivloss_reference",
            "kldivloss_log_target_reference",
            "nlllossNd_reference",
            "nllloss_reference",
            "smoothl1loss_reference",
            "_multilabelmarginloss_reference",
            "multilabelmarginloss_reference",
            "hingeembeddingloss_reference",
            "softmarginloss_reference",
            "_multimarginloss_reference",
            "multimarginloss_reference",
            "cosineembeddingloss_reference",
            "tripletmarginloss_reference",
            "marginrankingloss_reference",
            "ctcloss_reference",
            "padding1d_circular",
            "padding2d_circular",
            "padding3d_circular"
        ],
        "classes": [
            "NNTestCase",
            "TestBase",
            "ModuleTest",
            "InputVariableMixin",
            "NewModuleTest",
            "CriterionTest"
        ]
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/common_quantization.py",
        "functions": [
            "test_only_eval_fn",
            "test_only_train_fn",
            "accuracy",
            "train_one_epoch",
            "ddp_setup",
            "ddp_cleanup",
            "run_ddp",
            "convert_dynamic",
            "prepare_dynamic",
            "_make_conv_test_input",
            "skipIfNoFBGEMM",
            "get_script_module",
            "lengths_to_offsets"
        ],
        "classes": [
            "NodeSpec",
            "AverageMeter",
            "QuantizationTestCase",
            "SingleLayerLinearModel",
            "AnnotatedSingleLayerLinearModel",
            "SingleLayerLinearDynamicModel",
            "RNNDynamicModel",
            "RNNCellDynamicModel",
            "LSTMwithHiddenDynamicModel",
            "ConvModel",
            "ConvTransposeModel",
            "AnnotatedConvModel",
            "AnnotatedConvTransposeModel",
            "ConvBnModel",
            "AnnotatedConvBnModel",
            "ConvBnReLUModel",
            "AnnotatedConvBnReLUModel",
            "TwoLayerLinearModel",
            "LinearModelWithSubmodule",
            "AnnotatedTwoLayerLinearModel",
            "ActivationsTestModel",
            "LinearReluModel",
            "NormalizationTestModel",
            "NestedModel",
            "AnnotatedNestedModel",
            "AnnotatedSubNestedModel",
            "AnnotatedCustomConfigNestedModel",
            "QuantSubModel",
            "InnerModule",
            "SkipQuantModel",
            "AnnotatedSkipQuantModel",
            "QuantStubModel",
            "ManualLinearQATModel",
            "ManualConvLinearQATModel",
            "SubModelForFusion",
            "SubModelWithoutFusion",
            "ModelForFusion",
            "ConvBNReLU",
            "ModelWithSequentialFusion",
            "ModelForFusionWithBias",
            "ModelForLinearBNFusion",
            "DummyObserver",
            "ModelWithFunctionals",
            "ResNetBase",
            "ModelMultipleOps",
            "ModelMultipleOpsNoAvgPool",
            "EmbeddingBagModule",
            "EmbeddingModule",
            "EmbeddingWithLinear"
        ]
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/common_quantized.py",
        "functions": [
            "_conv_output_shape",
            "_quantize",
            "_dequantize",
            "_requantize",
            "_calculate_dynamic_qparams",
            "_calculate_dynamic_per_channel_qparams",
            "_snr",
            "override_qengines",
            "qengine_is_fbgemm",
            "qengine_is_qnnpack"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/common_utils.py",
        "functions": [
            "cppProfilingFlagsToProfilingMode",
            "prof_callable",
            "prof_func_call",
            "prof_meth_call",
            "_get_test_report_path",
            "wait_for_process",
            "shell",
            "repeat_test_for_types",
            "discover_test_cases_recursively",
            "get_test_names",
            "chunk_list",
            "run_tests",
            "_check_module_exists",
            "skipIfRocm",
            "wrapDeterministicFlagAPITest",
            "skipIfCompiledWithoutNumpy",
            "_test_function",
            "skipIfNoLapack",
            "skipIfNotRegistered",
            "skipIfNoSciPy",
            "slowTest",
            "slowAwareTest",
            "skipCUDAMemoryLeakCheckIf",
            "skipCUDANonDefaultStreamIf",
            "suppress_warnings",
            "to_gpu",
            "get_function_arglist",
            "set_rng_seed",
            "iter_indices",
            "is_iterable",
            "check_disabled",
            "get_comparison_dtype",
            "download_file",
            "find_free_port",
            "retry_on_connect_failures",
            "retry",
            "make_tensor",
            "prod_single_zero",
            "random_square_matrix_of_rank",
            "random_symmetric_matrix",
            "random_hermitian_matrix",
            "random_symmetric_psd_matrix",
            "random_hermitian_psd_matrix",
            "random_symmetric_pd_matrix",
            "random_hermitian_pd_matrix",
            "make_nonzero_det",
            "random_fullrank_matrix_distinct_singular_value",
            "random_matrix",
            "random_lowrank_matrix",
            "random_sparse_matrix",
            "random_sparse_pd_matrix",
            "do_test_dtypes",
            "do_test_empty_full",
            "clone_input_helper",
            "set_running_script_path",
            "check_test_defined_in_running_script",
            "load_tests",
            "gradcheck",
            "gradgradcheck",
            "_assertGradAndGradgradChecks"
        ],
        "classes": [
            "ProfilingMode",
            "DeterministicGuard",
            "CudaNonDefaultStream",
            "CudaMemoryLeakCheck",
            "TestCase",
            "BytesIOContext"
        ]
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/dist_utils.py",
        "functions": [
            "single_threaded_process_group_agent",
            "dist_init",
            "noop",
            "wait_until_node_failure",
            "wait_until_pending_futures_and_users_flushed",
            "get_num_owners_and_forks",
            "wait_until_owners_and_forks_on_rank",
            "initialize_pg",
            "worker_name",
            "get_function_event"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/expecttest.py",
        "functions": [
            "nth_line",
            "nth_eol",
            "normalize_nl",
            "escape_trailing_quote",
            "ok_for_raw_triple_quoted_string",
            "replace_string_literal"
        ],
        "classes": [
            "EditHistory",
            "TestCase"
        ]
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/hypothesis_utils.py",
        "functions": [
            "_get_valid_min_max",
            "_floats_wrapper",
            "floats",
            "assume_not_overflowing",
            "assert_deadline_disabled"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/jit_metaprogramming_utils.py",
        "functions": [
            "value_to_literal",
            "get_call",
            "get_constant",
            "get_script_args",
            "gen_script_fn_and_args",
            "create_script_fn",
            "partial_apply_nontensors",
            "create_traced_fn",
            "get_nn_functional_compiled_fn_and_inputs",
            "create_script_module",
            "check_alias_annotation",
            "get_nn_module_name_from_kwargs",
            "get_nn_mod_test_name",
            "get_nn_module_class_from_kwargs",
            "try_get_nn_module_compiled_mod_and_inputs",
            "get_all_nn_module_tests"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/jit_utils.py",
        "functions": [
            "execWrapper",
            "do_input_map",
            "clear_class_registry",
            "get_execution_plan",
            "_inline_everything",
            "_tmp_donotuse_dont_inline_everything",
            "_trace",
            "enable_cpu_fuser",
            "enable_cpu_fuser_if",
            "get_forward",
            "get_forward_graph",
            "get_module_method",
            "attrs_with_prefix",
            "warmup_backward",
            "make_global"
        ],
        "classes": [
            "_AssertRaisesRegexWithHighlightContext",
            "JitTestCase"
        ]
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/mypy_wrapper.py",
        "functions": [
            "config_files",
            "glob",
            "in_files",
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/te_utils.py",
        "functions": [],
        "classes": [
            "ExecutionCounter",
            "CudaCodeGenCreated",
            "CudaCodeGenExecuted",
            "LLVMCodeGenCreated",
            "LLVMCodeGenExecuted",
            "SimpleIREvalExecuted"
        ]
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/data/network1.py",
        "functions": [],
        "classes": [
            "Net"
        ]
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/data/network2.py",
        "functions": [],
        "classes": [
            "Net"
        ]
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/data/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/codegen/random_topo_test.py",
        "functions": [
            "get_broadcast_compatible_shape",
            "random_topology_test",
            "prepareInputTensorsToRandomTopoTest",
            "reproString",
            "runDefaultTestWithSeed",
            "runTest",
            "parse_args"
        ],
        "classes": [
            "WrongResultException"
        ]
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/codegen/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/distributed/ddp_under_dist_autograd_test.py",
        "functions": [
            "init_logger",
            "_call_method",
            "_remote_method",
            "_remote_method_async",
            "getLinear",
            "get_training_examples",
            "set_shutdown_signal"
        ],
        "classes": [
            "DdpMode",
            "FeatureSet",
            "RemoteEM",
            "RemoteNet",
            "HybridModel",
            "Trainer",
            "DdpUnderDistAutogradTest",
            "DdpComparisonTest"
        ]
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/distributed/distributed_test.py",
        "functions": [
            "get_timeout",
            "require_backend",
            "require_backends_available",
            "require_world_size",
            "apply_hack_for_nccl",
            "_build_tensor",
            "_build_multidim_tensor"
        ],
        "classes": [
            "Foo",
            "TestNamedTupleInput_1",
            "_FC2",
            "Net",
            "Task",
            "BatchNormNet",
            "Barrier",
            "TestDistBackend",
            "DistributedTest"
        ]
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/distributed/pipe_with_ddp_test.py",
        "functions": [],
        "classes": [
            "PipeWithDDPTest"
        ]
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/distributed/rpc_utils.py",
        "functions": [
            "_check_and_set_tcp_init",
            "_check_and_unset_tcp_init",
            "generate_tests"
        ],
        "classes": [
            "MultiProcess"
        ]
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/distributed/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/distributed/nn/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/distributed/nn/api/remote_module_test.py",
        "functions": [
            "remote_device",
            "create_scripted_module"
        ],
        "classes": [
            "ModuleCreationMode",
            "MyModule",
            "BadModule",
            "RemoteModuleTest"
        ]
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/distributed/nn/api/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/distributed/pipeline/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/distributed/rpc/dist_autograd_test.py",
        "functions": [
            "_set_rpc_done",
            "_check_rpc_done",
            "_torch_ones",
            "_compare_owner_value",
            "create_tensor",
            "my_py_add",
            "my_scalar_add",
            "my_rref_add",
            "my_nested_rref_add",
            "ret_requires_grad",
            "my_py_nested_call",
            "_all_contexts_cleaned_up",
            "_run_trainer",
            "_run_trainer_torchscript"
        ],
        "classes": [
            "SimulateBackwardError",
            "ExecMode",
            "DistAutogradTest",
            "FaultyAgentDistAutogradTest",
            "TensorPipeDistAutogradTest"
        ]
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/distributed/rpc/dist_optimizer_test.py",
        "functions": [
            "_call_method",
            "remote_method",
            "rpc_async_method"
        ],
        "classes": [
            "MyModule",
            "FailingOptimizer",
            "OptimizerFailingOnConstructor",
            "DistOptimizerTest"
        ]
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/distributed/rpc/faulty_rpc_agent_test_fixture.py",
        "functions": [],
        "classes": [
            "FaultyRpcAgentTestFixture"
        ]
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/distributed/rpc/process_group_agent_test_fixture.py",
        "functions": [],
        "classes": [
            "ProcessGroupRpcAgentTestFixture"
        ]
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/distributed/rpc/rpc_agent_test_fixture.py",
        "functions": [],
        "classes": [
            "RpcAgentTestFixture"
        ]
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/distributed/rpc/rpc_test.py",
        "functions": [
            "foo_add",
            "udf_with_torch_ops",
            "_stub_construct_rpc_backend_options_handler",
            "_stub_init_rpc_backend_handler",
            "set_value",
            "wait_for_value_future",
            "set_and_check_done",
            "_call_method_on_rref",
            "get_rref_list",
            "add_rref_to_value",
            "run_nested_pickle",
            "build_complex_tensors",
            "non_cont_test",
            "my_function",
            "my_tensor_function",
            "my_sleep_func",
            "my_complex_tensor_function",
            "my_rref_function",
            "delayed_add",
            "no_result",
            "raise_or_inc",
            "nested_rpc",
            "multi_layer_nested_async_rpc",
            "nested_rref",
            "nested_remote",
            "rref_forward_chain",
            "rpc_return_rref",
            "light_rpc",
            "heavy_rpc",
            "raise_func",
            "raise_func_escape",
            "set_global_rref",
            "clear_global_rref",
            "check_rref_confirmed",
            "get_rref_debug_info",
            "add_use_future_cb",
            "get_events_from_profile",
            "add_use_future_set_result",
            "add_use_future_nested_cb",
            "fail_on_fut",
            "slow_add",
            "return_future"
        ],
        "classes": [
            "StubRpcAgent",
            "MyPickleClass",
            "SlowPickleClass",
            "MyClass",
            "AsyncExecutionClass",
            "FooBackendOptions",
            "RpcTest",
            "ProcessGroupAgentRpcTest",
            "FaultyAgentRpcTest",
            "TensorPipeAgentRpcTest"
        ]
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/distributed/rpc/tensorpipe_rpc_agent_test_fixture.py",
        "functions": [],
        "classes": [
            "TensorPipeRpcAgentTestFixture"
        ]
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/distributed/rpc/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/distributed/rpc/examples/parameter_server_test.py",
        "functions": [
            "timed_log",
            "run_trainer",
            "run_ps"
        ],
        "classes": [
            "BatchUpdateParameterServer",
            "Trainer",
            "ParameterServerTest"
        ]
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/distributed/rpc/examples/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/distributed/rpc/jit/dist_autograd_test.py",
        "functions": [],
        "classes": [
            "JitDistAutogradTest"
        ]
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/distributed/rpc/jit/rpc_test.py",
        "functions": [
            "rref_isinstance",
            "sleep",
            "rpc_return_rref",
            "return_value",
            "owner_create_rref_my_script_class",
            "owner_create_rref_my_script_module",
            "python_function",
            "load_script_module_with_pickled_rref"
        ],
        "classes": [
            "RRefAPITest",
            "MyScriptModuleWithRRefs",
            "RRefTypingTest",
            "FutureTypingTest",
            "MyScriptModule",
            "LocalRRefTest",
            "JitRpcOpTest",
            "JitRpcTest"
        ]
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/distributed/rpc/jit/rpc_test_faulty.py",
        "functions": [],
        "classes": [
            "JitFaultyAgentRpcTest"
        ]
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/distributed/rpc/jit/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/generated/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/test_module/future_div.py",
        "functions": [
            "div_int_future",
            "div_float_future"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/test_module/no_future_div.py",
        "functions": [
            "div_int_nofuture",
            "div_float_nofuture"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/testing/_internal/test_module/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/model_zoo.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/bundled_inputs.py",
        "functions": [
            "augment_model_with_bundled_inputs",
            "augment_many_model_functions_with_bundled_inputs",
            "_inflate_expr",
            "bundle_randn",
            "bundle_large_tensor"
        ],
        "classes": [
            "InflatableArg"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/checkpoint.py",
        "functions": [
            "detach_variable",
            "check_backward_validity",
            "get_device_states",
            "set_device_states",
            "checkpoint",
            "checkpoint_sequential"
        ],
        "classes": [
            "CheckpointFunction"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/collect_env.py",
        "functions": [
            "run",
            "run_and_read_all",
            "run_and_parse_first_match",
            "get_conda_packages",
            "get_gcc_version",
            "get_clang_version",
            "get_cmake_version",
            "get_nvidia_driver_version",
            "get_gpu_info",
            "get_running_cuda_version",
            "get_cudnn_version",
            "get_nvidia_smi",
            "get_platform",
            "get_mac_version",
            "get_windows_version",
            "get_lsb_version",
            "check_release_file",
            "get_os",
            "get_pip_packages",
            "get_env_info",
            "pretty_str",
            "get_pretty_env_info",
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/cpp_extension.py",
        "functions": [
            "_nt_quote_args",
            "_find_cuda_home",
            "_find_rocm_home",
            "_join_rocm_home",
            "_is_binary_build",
            "_accepted_compilers_for_platform",
            "get_default_build_root",
            "check_compiler_ok_for_platform",
            "check_compiler_abi_compatibility",
            "CppExtension",
            "CUDAExtension",
            "include_paths",
            "library_paths",
            "load",
            "load_inline",
            "_jit_compile",
            "_write_ninja_file_and_compile_objects",
            "_write_ninja_file_and_build_library",
            "is_ninja_available",
            "verify_ninja_availability",
            "_prepare_ldflags",
            "_get_cuda_arch_flags",
            "_get_rocm_arch_flags",
            "_get_build_directory",
            "_get_num_workers",
            "_run_ninja_build",
            "_get_exec_path",
            "_import_module_from_library",
            "_write_ninja_file_to_build_library",
            "_write_ninja_file",
            "_join_cuda_home",
            "_is_cuda_file"
        ],
        "classes": [
            "BuildExtension"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/dlpack.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/file_baton.py",
        "functions": [],
        "classes": [
            "FileBaton"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/hooks.py",
        "functions": [
            "unserializable_hook",
            "warn_if_has_hooks"
        ],
        "classes": [
            "RemovableHandle",
            "BackwardHook"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/mkldnn.py",
        "functions": [
            "to_mkldnn"
        ],
        "classes": [
            "MkldnnLinear",
            "_MkldnnConvNd",
            "MkldnnConv1d",
            "MkldnnConv2d",
            "MkldnnConv3d",
            "MkldnnBatchNorm"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/mobile_optimizer.py",
        "functions": [
            "optimize_for_mobile",
            "generate_mobile_module_lints",
            "_get_bundled_inputs_preserved_attributes"
        ],
        "classes": [
            "LintCode"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/show_pickle.py",
        "functions": [
            "main"
        ],
        "classes": [
            "FakeObject",
            "FakeClass",
            "DumpUnpickler"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/throughput_benchmark.py",
        "functions": [
            "format_time"
        ],
        "classes": [
            "ExecutionStats",
            "ThroughputBenchmark"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/_cpp_extension_versioner.py",
        "functions": [
            "update_hash",
            "hash_source_files",
            "hash_build_arguments"
        ],
        "classes": [
            "ExtensionVersioner"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/_pytree.py",
        "functions": [
            "_register_pytree_node",
            "_dict_flatten",
            "_dict_unflatten",
            "_list_flatten",
            "_list_unflatten",
            "_tuple_flatten",
            "_tuple_unflatten",
            "_is_leaf",
            "tree_flatten",
            "tree_unflatten",
            "_broadcast_to_and_flatten"
        ],
        "classes": [
            "NodeDef",
            "TreeSpec",
            "LeafSpec"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/__init__.py",
        "functions": [
            "set_module"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/backcompat/__init__.py",
        "functions": [],
        "classes": [
            "Warning"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/benchmark/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/benchmark/examples/blas_compare.py",
        "functions": [
            "clear_worker_pool",
            "fill_core_pool",
            "_subprocess_main",
            "run_subprocess",
            "_compare_main",
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/benchmark/examples/blas_compare_setup.py",
        "functions": [
            "conda_run",
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/benchmark/examples/compare.py",
        "functions": [
            "main"
        ],
        "classes": [
            "FauxTorch"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/benchmark/examples/end_to_end.py",
        "functions": [
            "parse_args",
            "construct_stmt_and_label",
            "subprocess_main",
            "_main",
            "merge",
            "process_results",
            "construct_table",
            "w_str(r",
            "ad_results(r",
            "n(c",
            "st_source(e",
            "p_fn(a",
            "in(a"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/benchmark/examples/fuzzer.py",
        "functions": [
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/benchmark/examples/op_benchmark.py",
        "functions": [
            "assert_dicts_equal",
            "run",
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/benchmark/examples/simple_timeit.py",
        "functions": [
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/benchmark/examples/spectral_ops_fuzz_test.py",
        "functions": [
            "_dim_options",
            "run_benchmark",
            "_output_csv"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/benchmark/examples/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/benchmark/examples/sparse/compare.py",
        "functions": [
            "generate_coo_data",
            "gen_sparse",
            "main"
        ],
        "classes": [
            "FauxTorch"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/benchmark/examples/sparse/fuzzer.py",
        "functions": [
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/benchmark/examples/sparse/op_benchmark.py",
        "functions": [
            "assert_dicts_equal",
            "run",
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/benchmark/op_fuzzers/binary.py",
        "functions": [],
        "classes": [
            "BinaryOpFuzzer"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/benchmark/op_fuzzers/sparse_binary.py",
        "functions": [],
        "classes": [
            "BinaryOpSparseFuzzer"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/benchmark/op_fuzzers/sparse_unary.py",
        "functions": [],
        "classes": [
            "UnaryOpSparseFuzzer"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/benchmark/op_fuzzers/spectral.py",
        "functions": [
            "power_range"
        ],
        "classes": [
            "SpectralOpFuzzer"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/benchmark/op_fuzzers/unary.py",
        "functions": [],
        "classes": [
            "UnaryOpFuzzer"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/benchmark/op_fuzzers/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/benchmark/utils/common.py",
        "functions": [
            "select_unit",
            "unit_to_english",
            "trim_sigfig",
            "ordered_unique"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/benchmark/utils/compare.py",
        "functions": [
            "optional_min"
        ],
        "classes": [
            "Colorize",
            "_Column",
            "_Row",
            "Table",
            "Compare"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/benchmark/utils/cpp_jit.py",
        "functions": [
            "get_compat_bindings",
            "_compile_template",
            "compile_timeit_template",
            "compile_callgrind_template"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/benchmark/utils/fuzzer.py",
        "functions": [
            "dtype_size",
            "prod"
        ],
        "classes": [
            "FuzzedParameter",
            "ParameterAlias",
            "FuzzedTensor",
            "Fuzzer"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/benchmark/utils/sparse_fuzzer.py",
        "functions": [],
        "classes": [
            "FuzzedSparseTensor"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/benchmark/utils/timeit_template.cpp",
        "functions": [
            "timeit(int n)",
            "{\n    m.def(\"timeit\", &timeit);\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/benchmark/utils/timer.py",
        "functions": [],
        "classes": [
            "Language",
            "CPPTimer",
            "Timer"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/benchmark/utils/_stubs.py",
        "functions": [],
        "classes": [
            "TimerClass",
            "CallgrindModuleType"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/benchmark/utils/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/benchmark/utils/valgrind_wrapper/compat_bindings.cpp",
        "functions": [
            "_valgrind_supported_platform()",
            "_valgrind_toggle()",
            "{\n    m.def(\"_valgrind_supported_platform\", &_valgrind_supported_platform);\n    m.def(\"_valgrind_toggle\", &_valgrind_toggle);\n}"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/benchmark/utils/valgrind_wrapper/timer_callgrind_template.cpp",
        "functions": [
            "main(int argc, char* argv[])"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/benchmark/utils/valgrind_wrapper/timer_interface.py",
        "functions": [
            "wrapper_singleton"
        ],
        "classes": [
            "Serialization",
            "CopyIfCallgrind",
            "GlobalsBridge",
            "_ValgrindWrapper"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/benchmark/utils/valgrind_wrapper/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/bottleneck/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/bottleneck/__main__.py",
        "functions": [
            "redirect_argv",
            "compiled_with_cuda",
            "run_env_analysis",
            "run_cprofile",
            "print_cprofile_summary",
            "run_autograd_prof",
            "print_autograd_prof_summary",
            "parse_args",
            "cpu_time_total",
            "main"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/data/dataloader.py",
        "functions": [],
        "classes": [
            "_DatasetKind",
            "_InfiniteConstantSampler",
            "DataLoader",
            "_BaseDataLoaderIter",
            "_SingleProcessDataLoaderIter",
            "_MultiProcessingDataLoaderIter"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/data/dataset.py",
        "functions": [
            "random_split"
        ],
        "classes": [
            "Dataset",
            "IterableDataset",
            "TensorDataset",
            "ConcatDataset",
            "ChainDataset",
            "BufferedShuffleDataset",
            "Subset"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/data/distributed.py",
        "functions": [],
        "classes": [
            "DistributedSampler"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/data/sampler.py",
        "functions": [],
        "classes": [
            "Sampler",
            "SequentialSampler",
            "RandomSampler",
            "SubsetRandomSampler",
            "WeightedRandomSampler",
            "BatchSampler"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/data/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/data/datapipes/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/data/datapipes/iter/batch.py",
        "functions": [],
        "classes": [
            "BatchIterDataPipe",
            "BucketBatchIterDataPipe"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/data/datapipes/iter/callable.py",
        "functions": [
            "default_fn"
        ],
        "classes": [
            "CallableIterDataPipe",
            "CollateIterDataPipe"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/data/datapipes/iter/listdirfiles.py",
        "functions": [],
        "classes": [
            "ListDirFilesIterDataPipe"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/data/datapipes/iter/loadfilesfromdisk.py",
        "functions": [],
        "classes": [
            "LoadFilesFromDiskIterDataPipe"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/data/datapipes/iter/readfilesfromtar.py",
        "functions": [],
        "classes": [
            "ReadFilesFromTarIterDataPipe"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/data/datapipes/iter/readfilesfromzip.py",
        "functions": [],
        "classes": [
            "ReadFilesFromZipIterDataPipe"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/data/datapipes/iter/sampler.py",
        "functions": [],
        "classes": [
            "SamplerIterDataPipe"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/data/datapipes/iter/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/data/datapipes/utils/common.py",
        "functions": [
            "match_masks",
            "get_file_pathnames_from_root",
            "get_file_binaries_from_pathnames",
            "validate_pathname_binary_tuple"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/data/datapipes/utils/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/data/datasets/common.py",
        "functions": [
            "match_masks",
            "get_file_pathnames_from_root",
            "get_file_binaries_from_pathnames"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/data/datasets/listdirfilesdataset.py",
        "functions": [],
        "classes": [
            "ListDirFilesIterableDataset"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/data/datasets/loadfilesfromdiskdataset.py",
        "functions": [],
        "classes": [
            "LoadFilesFromDiskIterableDataset"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/data/datasets/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/data/_utils/collate.py",
        "functions": [
            "default_convert",
            "default_collate"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/data/_utils/fetch.py",
        "functions": [],
        "classes": [
            "_BaseDatasetFetcher",
            "_IterableDatasetFetcher",
            "_MapDatasetFetcher"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/data/_utils/pin_memory.py",
        "functions": [
            "_pin_memory_loop",
            "pin_memory"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/data/_utils/signal_handling.py",
        "functions": [
            "_set_SIGCHLD_handler"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/data/_utils/worker.py",
        "functions": [
            "get_worker_info",
            "_worker_loop"
        ],
        "classes": [
            "WorkerInfo"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/data/_utils/__init__.py",
        "functions": [
            "_set_python_exit_flag"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/ffi/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/hipify/constants.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/hipify/cuda_to_hip_mappings.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/hipify/hipify_python.py",
        "functions": [
            "openf",
            "match_extensions",
            "matched_files_iter",
            "preprocess_file_and_save_result",
            "preprocess",
            "compute_stats",
            "add_dim3",
            "processKernelLaunches",
            "find_closure_group",
            "find_bracket_group",
            "find_parentheses_group",
            "replace_math_functions",
            "hip_header_magic",
            "replace_extern_shared",
            "get_hip_file_path",
            "is_out_of_place",
            "is_pytorch_file",
            "is_caffe2_gpu_file",
            "preprocessor",
            "file_specific_replacement",
            "file_add_header",
            "fix_static_global_kernels",
            "extract_arguments",
            "str2bool",
            "hipify"
        ],
        "classes": [
            "InputError",
            "bcolors",
            "GeneratedFileCleaner",
            "Trie"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/hipify/version.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/hipify/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/tensorboard/summary.py",
        "functions": [
            "_calc_scale_factor",
            "_draw_single_box",
            "hparams",
            "scalar",
            "histogram_raw",
            "histogram",
            "make_histogram",
            "image",
            "image_boxes",
            "draw_boxes",
            "make_image",
            "video",
            "make_video",
            "audio",
            "custom_scalars",
            "text",
            "pr_curve_raw",
            "pr_curve",
            "compute_curve",
            "_get_tensor_summary",
            "_get_json_config",
            "mesh"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/tensorboard/writer.py",
        "functions": [],
        "classes": [
            "FileWriter",
            "SummaryWriter"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/tensorboard/_caffe2_graph.py",
        "functions": [
            "_make_unique_name",
            "_rename_tensorflow_style",
            "_convert_to_ssa",
            "_get_blob_names",
            "_remap_keys",
            "_rename_all",
            "_add_gradient_scope",
            "_replace_colons",
            "_fill_missing_operator_names",
            "_tf_device",
            "_add_tf_shape",
            "_set_tf_attr",
            "_operator_to_node",
            "_operator_to_node_simp",
            "_blob_to_node",
            "_clear_debug_info",
            "_check_if_forward",
            "_check_if_cpu",
            "_compute_in_out",
            "_filter_ops",
            "_operators_to_graph_def",
            "_propagate_device_option",
            "_try_get_shapes",
            "model_to_graph_def",
            "nets_to_graph_def",
            "protos_to_graph_def"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/tensorboard/_convert_np.py",
        "functions": [
            "make_np",
            "_prepare_pytorch",
            "_prepare_caffe2"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/tensorboard/_embedding.py",
        "functions": [
            "make_tsv",
            "make_sprite",
            "get_embedding_info",
            "write_pbtxt",
            "make_mat"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/tensorboard/_onnx_graph.py",
        "functions": [
            "load_onnx_graph",
            "parse"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/tensorboard/_proto_graph.py",
        "functions": [
            "attr_value_proto",
            "tensor_shape_proto",
            "node_proto"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/tensorboard/_pytorch_graph.py",
        "functions": [
            "parse",
            "graph"
        ],
        "classes": [
            "NodeBase",
            "NodePy",
            "NodePyIO",
            "NodePyOP",
            "GraphPy"
        ]
    },
    {
        "file_path": "../pytorch/torch/utils/tensorboard/_utils.py",
        "functions": [
            "figure_to_image",
            "_prepare_video",
            "make_grid",
            "convert_to_HWC"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/utils/tensorboard/__init__.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/futures/__init__.py",
        "functions": [
            "collect_all",
            "wait_all"
        ],
        "classes": [
            "Future"
        ]
    },
    {
        "file_path": "../pytorch/torch/quantization/fake_quantize.py",
        "functions": [
            "_is_per_channel",
            "_is_per_tensor",
            "_is_fake_quant_script_module",
            "disable_fake_quant",
            "enable_fake_quant",
            "disable_observer",
            "enable_observer"
        ],
        "classes": [
            "FakeQuantizeBase",
            "FakeQuantize",
            "FixedQParamsFakeQuantize"
        ]
    },
    {
        "file_path": "../pytorch/torch/quantization/fuser_method_mappings.py",
        "functions": [
            "fuse_conv_bn",
            "fuse_conv_bn_relu",
            "fuse_linear_bn",
            "get_fuser_method"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/quantization/fuse_modules.py",
        "functions": [
            "_get_module",
            "_set_module",
            "fuse_known_modules",
            "_fuse_modules",
            "fuse_modules"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/quantization/observer.py",
        "functions": [
            "_with_args",
            "_is_observer_script_module",
            "_is_activation_post_process",
            "_is_per_channel_script_obs_instance",
            "get_observer_state_dict",
            "load_observer_state_dict"
        ],
        "classes": [
            "ObserverBase",
            "_ObserverBase",
            "MinMaxObserver",
            "MovingAverageMinMaxObserver",
            "PerChannelMinMaxObserver",
            "MovingAveragePerChannelMinMaxObserver",
            "HistogramObserver",
            "PlaceholderObserver",
            "RecordingObserver",
            "NoopObserver"
        ]
    },
    {
        "file_path": "../pytorch/torch/quantization/qconfig.py",
        "functions": [
            "get_default_qconfig",
            "get_default_qat_qconfig",
            "assert_valid_qconfig"
        ],
        "classes": [
            "QConfig",
            "QConfigDynamic"
        ]
    },
    {
        "file_path": "../pytorch/torch/quantization/quantization_mappings.py",
        "functions": [
            "get_default_static_quant_module_mappings",
            "get_static_quant_module_class",
            "get_dynamic_quant_module_class",
            "get_default_qat_module_mappings",
            "get_default_dynamic_quant_module_mappings",
            "get_default_qconfig_propagation_list",
            "get_default_compare_output_module_list",
            "get_quantized_operator",
            "_get_special_act_post_process",
            "_has_special_act_post_process"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/quantization/quantize.py",
        "functions": [
            "is_activation_post_process",
            "_propagate_qconfig_helper",
            "propagate_qconfig_",
            "_observer_forward_hook",
            "register_activation_post_process_hook",
            "add_observer_",
            "get_unique_devices_",
            "add_quant_dequant",
            "prepare",
            "_remove_activation_post_process",
            "_remove_qconfig",
            "quantize",
            "quantize_dynamic",
            "prepare_qat",
            "quantize_qat",
            "convert",
            "_convert",
            "swap_module",
            "get_observer_dict"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/quantization/quantize_fx.py",
        "functions": [
            "_check_is_graph_module",
            "_swap_ff_with_fxff",
            "_fuse_fx",
            "_prepare_fx",
            "_prepare_standalone_module_fx",
            "fuse_fx",
            "prepare_fx",
            "prepare_qat_fx",
            "_convert_fx",
            "convert_fx",
            "_convert_standalone_module_fx"
        ],
        "classes": [
            "Scope",
            "ScopeContextManager",
            "QuantizationTracer"
        ]
    },
    {
        "file_path": "../pytorch/torch/quantization/quantize_jit.py",
        "functions": [
            "_check_is_script_module",
            "_check_forward_method",
            "script_qconfig",
            "script_qconfig_dict",
            "fuse_conv_bn_jit",
            "_prepare_jit",
            "prepare_jit",
            "prepare_dynamic_jit",
            "_convert_jit",
            "convert_jit",
            "convert_dynamic_jit",
            "_quantize_jit",
            "quantize_jit",
            "antize_dynamic_jit(m"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/quantization/quant_type.py",
        "functions": [
            "quant_type_to_str"
        ],
        "classes": [
            "QuantType"
        ]
    },
    {
        "file_path": "../pytorch/torch/quantization/stubs.py",
        "functions": [],
        "classes": [
            "QuantStub",
            "DeQuantStub",
            "QuantWrapper"
        ]
    },
    {
        "file_path": "../pytorch/torch/quantization/utils.py",
        "functions": [
            "get_combined_dict",
            "is_per_tensor",
            "is_per_channel",
            "get_swapped_custom_module_class",
            "activation_is_statically_quantized",
            "weight_dtype",
            "weight_is_statically_quantized",
            "get_qconfig_dtypes",
            "get_quant_type"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/quantization/_correct_bias.py",
        "functions": [
            "get_module",
            "parent_child_names",
            "get_param",
            "bias_correction"
        ],
        "classes": [
            "MeanShadowLogger"
        ]
    },
    {
        "file_path": "../pytorch/torch/quantization/_equalize.py",
        "functions": [
            "max_over_ndim",
            "min_over_ndim",
            "channel_range",
            "cross_layer_equalization",
            "equalize",
            "converged"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/quantization/_learnable_fake_quantize.py",
        "functions": [],
        "classes": [
            "_LearnableFakeQuantize"
        ]
    },
    {
        "file_path": "../pytorch/torch/quantization/_numeric_suite.py",
        "functions": [
            "_find_match",
            "compare_weights",
            "_get_logger_dict_helper",
            "get_logger_dict",
            "_convert_tuple_to_list",
            "_dequantize_tensor_list",
            "prepare_model_with_stubs",
            "_is_identical_module_type",
            "compare_model_stub",
            "get_matching_activations",
            "prepare_model_outputs",
            "compare_model_outputs"
        ],
        "classes": [
            "Logger",
            "ShadowLogger",
            "OutputLogger",
            "Shadow"
        ]
    },
    {
        "file_path": "../pytorch/torch/quantization/_numeric_suite_fx.py",
        "functions": [
            "remove_qconfig_observer_fx",
            "_get_logger_dict_helper_fx",
            "get_logger_dict_fx",
            "compare_weights_fx",
            "prepare_model_with_stubs_fx",
            "compare_model_stub_fx",
            "get_matching_activations_fx",
            "prepare_model_outputs_fx",
            "compare_model_outputs_fx"
        ],
        "classes": [
            "NumericSuiteQuantizeHandler"
        ]
    },
    {
        "file_path": "../pytorch/torch/quantization/__init__.py",
        "functions": [
            "default_eval_fn"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/quantization/fx/fuse.py",
        "functions": [],
        "classes": [
            "Fuser"
        ]
    },
    {
        "file_path": "../pytorch/torch/quantization/fx/fusion_patterns.py",
        "functions": [],
        "classes": [
            "FuseHandler"
        ]
    },
    {
        "file_path": "../pytorch/torch/quantization/fx/observed_module.py",
        "functions": [
            "mark_observed_module",
            "is_observed_module",
            "mark_observed_standalone_module",
            "is_observed_standalone_module"
        ],
        "classes": [
            "ObservedGraphModule",
            "ObservedStandaloneGraphModule"
        ]
    },
    {
        "file_path": "../pytorch/torch/quantization/fx/pattern_utils.py",
        "functions": [
            "register_fusion_pattern",
            "get_default_fusion_patterns",
            "register_quant_pattern",
            "get_default_quant_patterns",
            "get_default_output_activation_post_process_map",
            "mark_input_output_not_observed",
            "input_output_observed",
            "is_match"
        ],
        "classes": [
            "MatchAllNode"
        ]
    },
    {
        "file_path": "../pytorch/torch/quantization/fx/qconfig_utils.py",
        "functions": [
            "get_flattened_qconfig_dict",
            "convert_dict_to_ordered_dict",
            "get_object_type_qconfig",
            "get_module_name_regex_qconfig",
            "get_module_name_qconfig",
            "get_qconfig"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/quantization/fx/quantization_patterns.py",
        "functions": [],
        "classes": [
            "QuantizeHandler",
            "DefaultQuantizeHandler",
            "CustomModuleQuantizeHandler",
            "StandaloneModuleQuantizeHandler"
        ]
    },
    {
        "file_path": "../pytorch/torch/quantization/fx/quantization_types.py",
        "functions": [],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/quantization/fx/quantize.py",
        "functions": [
            "insert_observer",
            "maybe_insert_observer_for_special_module",
            "insert_observer_for_output_of_the_node",
            "insert_observer_for_input_arg_of_observed_node",
            "node_arg_is_weight",
            "node_arg_is_bias"
        ],
        "classes": [
            "Quantizer"
        ]
    },
    {
        "file_path": "../pytorch/torch/quantization/fx/utils.py",
        "functions": [
            "_parent_name",
            "graph_pretty_str",
            "get_per_tensor_qparams",
            "get_quantize_op_and_qparams",
            "quantize_node",
            "get_custom_module_class_keys",
            "get_linear_prepack_op_for_dtype",
            "get_qconv_prepack_op",
            "get_qconv_op",
            "get_new_attr_name_with_prefix",
            "collect_producer_nodes",
            "graph_module_from_producer_nodes",
            "assert_and_get_unique_device",
            "create_getattr_from_value",
            "create_qparam_nodes"
        ],
        "classes": []
    },
    {
        "file_path": "../pytorch/torch/quantization/fx/__init__.py",
        "functions": [],
        "classes": []
    }
]